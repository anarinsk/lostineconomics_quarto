[
  {
    "objectID": "posts/math-simple/2019-07-18-dot-product.html",
    "href": "posts/math-simple/2019-07-18-dot-product.html",
    "title": "Dot Product with Geometry",
    "section": "",
    "text": "닷 프로덕트 혹은 내적을 기하적으로 이해하면 여러모로 편리하고 기억에도 잘 남는다."
  },
  {
    "objectID": "posts/math-simple/2019-07-18-dot-product.html#tl-dr",
    "href": "posts/math-simple/2019-07-18-dot-product.html#tl-dr",
    "title": "Dot Product with Geometry",
    "section": "",
    "text": "닷 프로덕트 혹은 내적을 기하적으로 이해하면 여러모로 편리하고 기억에도 잘 남는다."
  },
  {
    "objectID": "posts/math-simple/2019-07-18-dot-product.html#definition",
    "href": "posts/math-simple/2019-07-18-dot-product.html#definition",
    "title": "Dot Product with Geometry",
    "section": "Definition",
    "text": "Definition\ndot product는 내적이라고도 번역하지만 여기서는 닷 프로덕트로 쓰기로 하겠다. 먼저 정의부터 살펴보자.\n\\[\n\\mathbf{u}=\\left[u_{1}, {u}_{2}, \\ldots, {u}_{n}\\right] \\in {\\mathbb R}^n\n\\]\n\\[\n\\mathbf{v}=\\left[{v}_{1}, {v}_{2}, \\ldots, {v}_{n}\\right] \\in {\\mathbb R}^n\n\\]\n\\[\n\\mathbf{u} \\cdot \\mathbf{v} = \\sum_{n} u_i v_i\n\\]\n쉽게 말해서 닷 프로덕트는 차원이 같은 두 개의 인풋 벡터를 하나의 스칼라로 바꿔주는 일종의 함수로 이해할 수 있다. 두 개의 벡터를 서로 연관 짓는데 이를 해당 벡터의 길이라는 정보로 압축한다고 보면 얼추 맞을 듯 싶다. 하나의 숫자로 요약된다는 뜻에서 스칼라 프로덕트라고도 불린다. 그림으로 나타내면 아래와 같다.\n\n\n\n\\(\\mathbf v\\)를 \\(\\mathbf u\\)로 프로젝션한다. \\(\\mathbf u\\)는 스크린, \\(\\mathbf v\\)는 투영체라고 생각하면 좋다.\n\n\n\nFrom Definition to Geometry\n닷 프로덕트에 관한 설명은 정의에서 바로 코사인 법칙으로 넘어간다. 하지만 뭔가 분명하지 않다. 이걸 조금 더 풀어보자.\n\n\n\n닷 프로덕트, 내적의 계산법\n\n\n위 그림은 \\(2 \\times 2\\) 벡터의 닷 프로덕트를 각 요소로 분해한 것이다. 이중에서 \\(\\dfrac{\\pi}{2}\\) 각을 이루고 있는 벡터는 서로 곱하면 0이 된다. 따라서 닷 프로덕트 계산에서는 \\(a_x b_x\\)와 \\(a_y b_y\\)가 남게 된다.\n\n\n\n\\(\\cos\\theta\\) 그리고 닷 프로덕트\n\n\n닷 프로덕트란 길이만 문제가 되므로 두 벡터를 한 방향으로 정렬하자.이렇게 되면, 파란색 높이가 \\(0\\)이 된다. 따라서 위 그림과 같은 코사인 법칙이 쉽게 도출된다.\n\n\n그림에서 보듯이 벡터를 회전해도 닷 프로덕트의 크기가 변하지 않을까? 여기서 보듯이 임의의 각도 \\(\\theta\\)로 회전해도 닷 프로덕트의 크기는 변하지 않는다.\n\n\nSymmetry\n\\(\\mathbf{v}\\) 벡터를 \\(\\mathbf u\\) 벡터 위에, 즉 \\(\\mathbf u\\) 벡터를 스크린로 삼아 직각으로 쏜 \\(\\mathbf v\\)의 프로젝션 벡터 \\(\\mathrm{Proj}_{\\mathbf u} {\\mathbf v}\\)의 길이와 \\(\\mathbf u\\) 길이를 곱하면 그것이 \\(\\mathbf u\\)와 \\(\\mathbf v\\)의 닷 프로덕트가 된다. 어느 벡터로 프로젝션 하는지는 관계가 없다. 즉,\n\\[\n{\\mathbf v} \\cdot {\\mathbf u} = \\Vert \\mathbf u \\Vert \\Vert {\\rm Proj}_{\\mathbf u} {\\mathbf v} \\Vert =  \\Vert \\mathbf u \\Vert (\\Vert \\mathbf v \\Vert \\cos\\theta)\n\\]\n\\[\n{\\mathbf u} \\cdot {\\mathbf v} = \\Vert \\mathbf v \\Vert \\Vert {\\rm Proj}_{\\mathbf v} {\\mathbf u} \\Vert = \\Vert \\mathbf v \\Vert (\\Vert \\mathbf u \\Vert \\cos\\theta)\n\\]\n다시 보면, 닷 프로덕트의 정의상 \\({\\mathbf v} \\cdot {\\mathbf u} = {\\mathbf u} \\cdot {\\mathbf v}\\)인 셈이다. 닷 프로덕트는 어떻게 도출하는가? 그 기하학적인 구조는 무엇인가?"
  },
  {
    "objectID": "posts/math-simple/2019-07-18-dot-product.html#with-law-of-cosine",
    "href": "posts/math-simple/2019-07-18-dot-product.html#with-law-of-cosine",
    "title": "Dot Product with Geometry",
    "section": "With ‘Law of Cosine’",
    "text": "With ‘Law of Cosine’\n코사인 법칙을 활용해서 닷 프로덕트를 도출할 수 있다. 맨 처음 그림에서 보듯이 벡터 \\(\\mathbf u - \\mathbf v\\)와 \\(\\mathbf u\\), \\(\\mathbf v\\)는 삼각형을 이룬다. 따라서 코사인 법칙에 따라서 아래와 같이 적을 수 있다.\n\n\n여기를 참고 했다. Law of Cosine도 참고하자.\n\\[\n\\lVert \\mathbf u -  \\mathbf v \\rVert^2 = \\lVert  \\mathbf  u \\rVert^2 + \\lVert   \\mathbf  v \\rVert^2 - 2\\lVert  \\mathbf  u \\rVert \\lVert   \\mathbf  v \\rVert \\cos \\theta\n\\]\n노름(norm, 길이)에 대해서는 대칭과 쌍방선형이 유지되기 때문에 아래와 같이 쓸 수 있다.\n\\[\n\\lVert  \\mathbf u -  \\mathbf v \\rVert^2 = ( \\mathbf u -  \\mathbf v) \\cdot ( \\mathbf u -  \\mathbf v ) = \\lVert \\mathbf u \\rVert^2 +  \\lVert \\mathbf v \\rVert^2 - 2  (\\mathbf u \\cdot \\mathbf v)\n\\]\n따라서\n\\[\n\\mathbf u \\cdot  \\mathbf v = \\lVert \\mathbf u \\rVert \\lVert \\mathbf v \\rVert   \\cos \\theta = \\lVert \\mathbf u \\rVert   ( \\lVert \\mathbf v \\rVert \\cos \\theta) = \\lVert \\mathbf u \\rVert \\rVert \\text{Proj}_{\\mathbf u} \\mathbf v \\lVert\n\\]\n한편 반대로 \\(\\mathbf u\\)에서 \\(\\mathbf v\\)로 프로젝션하는 경우를 생각해 볼 수도 있겠다.\n\\[\n\\mathbf u \\cdot  \\mathbf v = \\lVert \\mathbf u \\rVert \\lVert \\mathbf v \\rVert   \\cos \\theta = \\lVert \\mathbf v \\rVert   ( \\lVert \\mathbf u \\rVert \\cos \\theta) = \\lVert \\mathbf v \\rVert \\rVert \\text{Proj}_{\\mathbf v} \\mathbf u \\lVert\n\\]\n닷 프로덕트로 둘 중 어느 쪽을 써도 좋다."
  },
  {
    "objectID": "posts/math-simple/2019-07-18-dot-product.html#applications",
    "href": "posts/math-simple/2019-07-18-dot-product.html#applications",
    "title": "Dot Product with Geometry",
    "section": "Applications",
    "text": "Applications\n\nCosine similarity\n두 개의 벡터가 얼마나 유사한지를 나타내는 지표로 코사인 유사도라는 게 있다. 위에서 보듯이 두 개의 벡터(\\(\\mathbf v, \\mathbf u\\))가 이루는 각 \\(\\theta\\)의 코사인 값은 다음과 같다.\n\\[\n\\cos \\theta = \\dfrac{\\mathbf u \\cdot \\mathbf v}{\\lVert \\mathbf u \\rVert \\lVert \\mathbf v \\rVert}\n\\]\n두 벡터가 가까울수록 코사인 값이 1에 가깝게 될 것이고, 멀수록 -1에 가깝게 될 것이다. 이른바 코사인 유사도는 이 값의 크기를 따른다. 벡터로 표현된 두 대상 사이의 유클리드 거리와 무관하게 지향하는 방향에 따른 유사도를 측정할 때 이 값을 쓴다.\n\n\nHyperplane\n닷 프로덕트를 이해하고 있으면 기하학 문제를 쉽게 풀 수 있는 게 많다. 가장 좋은 예가 초평면(hyperplane)이다. 예를 들어 3차원 공간에서 점 \\(\\mathbf{x}^0 = (x_1^0, x_2^0, x_3^0)\\)를 지나면서 벡터 \\(\\mathbf{p} = (p_1, p_2, p_3)\\)에 수직인 평면을 찾고 있다고 하자. 복잡해보이지만 닷 프로덕트를 활용하면 쉽게 풀린다. 즉,\n\\[\n\\mathbf{p} \\cdot (\\mathbf{x} - \\mathbf{x}^0) = 0\n\\]\n평면 \\(\\mathbf x\\)가 \\(\\mathbf{x}^0\\)를 지나는 것은 분명하다. 이 평면이 \\(\\mathbf{p}\\)에 수직이라는 것은 두 벡터의 닷 프로덕트가 0이 되면 된다.\n\n\n\n벡터 \\(\\mathbf p\\)와 직교하는 하이퍼플레인 찾기"
  },
  {
    "objectID": "posts/math-simple/2019-07-18-dot-product.html#appendix-geometrically",
    "href": "posts/math-simple/2019-07-18-dot-product.html#appendix-geometrically",
    "title": "Dot Product with Geometry",
    "section": "Appendix: Geometrically",
    "text": "Appendix: Geometrically\n기하적으로 도출하는 보다 복잡한 방법도 있다. 이해를 돕기 위해서 2차원 벡터공간으로 한정해서 논의하겠다. \\(n\\) 차원으로 확대하는 것이 수학적으로 어렵지는 않다.\n\n\n보다 상세한 내용은 여기를 참고하라.\n일단 \\(\\mathbf u\\)가 길이 1로 표준화된 벡터라고 정의를 살짝 바꾸겠다. 즉, 새로운 \\(\\mathbf u\\)는 \\(\\rVert \\mathbf u \\lVert\\)로 \\(\\mathbf u\\)를 나눈 벡터다. 아래 그림처럼 이 벡터를 향해서 2차원 평면의 기저를 구성하는 \\((1,0)(\\equiv i)\\)과 \\((0,1)(\\equiv j)\\)에서 벡터로 프로젝션을 해보자.\n이렇게 프로젝션을 하면 프로젝션된 지점의 \\(x\\) 좌표는 공교롭게도 원점에서부터 해당 프로젝션된 지점까지의 벡터의 길이가 된다. \\(y\\)에 대해서도 마찬가지다.\n\n\n이제 (1,1)에서 벡터 \\(\\mathbf u\\)로 프로젝션을 해보자. (1,1)은 각각 두 개의 기저를 1의 가중치로 선형결합한 벡터다. 이 벡터의 프로젝션의 길이는 어떻게 구성될까? 그림에서 보듯이 \\(u_x + u_y\\)가 된다. 이를 일반적인 논리로 확장해보자. 어떤 임의의 벡터 \\(\\mathbf v(=(x,y))\\)가 존재할 때 해당 벡터는 각각 두 개의 기저의 선형 결합으로 이해할 수 있다.\n\n따라서 \\(\\mathbf v\\) 벡터를 \\(\\mathbf u\\)로 프로젝션한 길이는 다음과 같다.\n\\[\n\\underset{\\mathbf u 프로젝션}{\\left[\\begin{array}{ll}{u_{x}} & { u_{y}}\\end{array}\\right]}\\left[\\begin{array}{l}{x} \\\\ {y}\\end{array}\\right]= u_{x} \\cdot x + u_{y} \\cdot y = \\mathbf u \\cdot \\mathbf v\n\\]\n벡터를 기저의 선형결합을 통해 나타낼 수 있듯이, 벡터의 프로젝션의 길이 역시 비슷한 방식의 선형결합을 동원해서 나타낼 수 있다. 앞서 \\(\\mathbf u\\)가 표준화된 벡터라고 했다. 따라서 원래대로 돌려 놓으면 닷 프로덕트는 프로젝션된 지점까지의 벡터의 거리와 해당 벡터의 길이의 곱이 된다. 즉,\n\\[\n\\mathbf u \\cdot \\mathbf v = \\rVert \\mathbf u \\lVert \\rVert \\text{Proj}_{\\mathbf u} \\mathbf v \\lVert\n\\]"
  },
  {
    "objectID": "posts/math-simple/2022-10-03-RSA.html",
    "href": "posts/math-simple/2022-10-03-RSA.html",
    "title": "RSA, Simply Explained",
    "section": "",
    "text": "RSA 알고리즘을 쉽게 풀어보자."
  },
  {
    "objectID": "posts/math-simple/2022-10-03-RSA.html#tl-dr",
    "href": "posts/math-simple/2022-10-03-RSA.html#tl-dr",
    "title": "RSA, Simply Explained",
    "section": "",
    "text": "RSA 알고리즘을 쉽게 풀어보자."
  },
  {
    "objectID": "posts/math-simple/2022-10-03-RSA.html#왜",
    "href": "posts/math-simple/2022-10-03-RSA.html#왜",
    "title": "RSA, Simply Explained",
    "section": "왜?",
    "text": "왜?\n한글로 된 책이나 블로그 등을 찾아보면 RSA가 제법 많이 소개되어 있다. 아쉽게도 대체로 개념 혹은 전체적인 그림 정도의 설명이 많았고, 알고리즘을 구체적으로 해설하는 경우는 드물더라. 보안 지식이 일천한 나는 그렇게 느꼈다. 알고리즘 자체를 보다 친절하게 소개하는 내용을 두루 찾다가 아래 두 개의 위키를 찾았다. 나중에 까먹을 나 놈을 위해서 내용을 간단히 정리해두도록 하곘다.\n\n\n\n\n\n\nReferences\n\n\n\n\nEuler’s Totient Function | Brilliant Math & Science Wiki\nRSA Encryption | Brilliant Math & Science Wiki\n\n\n\n\n\n\n\n\n\n\n\n\n수신자는 발송자에게 상자와 열쇠를 보낸다. 해당 열쇠는 수신자의 개인 키로만 열 수 있다.\n\n\n\n\n \n\n\n\n\n\n메시지 전달에서 비대칭 암호 체계\n\n\n\n\n\n비대칭 암호의 핵심은 공개 키로 어떤 메시지 혹은 내용을 암호화를 하고 이를 개인 키를 통해서 풀 수 있게 (복호화) 하는 것이다. 공개 키는 널리 퍼트리고, 개인 키는 해당 개인이 보유하고 관리한다. 이런 구조 때문에 암호화와 복호화에 필요한 키를 공유하는 대칭 암호 체계에 비해 비대칭 암호가 보안에 우수하다.\n만일 암호화를 수행해서 공개 키를 불특정 다수에게 전달하고 개인 키를 갖는 쪽이 sender(센더)면 이는 ’전자 서명’이다. 반대로 receiver(리시버)가 공개 키를 배포하고 자신이 개인 키를 보유한다면, 이는 암호화 기반 메시지 전달이다. 동전의 양면 처럼 동일한 개념이므로 여기서는 후자, 즉 암호화 메시지 교환을 다루도록 하겠다."
  },
  {
    "objectID": "posts/math-simple/2022-10-03-RSA.html#개념",
    "href": "posts/math-simple/2022-10-03-RSA.html#개념",
    "title": "RSA, Simply Explained",
    "section": "개념",
    "text": "개념\nRSA 알고리즘의 핵심은 소수의 활용 그리고 오일러 정리다. 필요한 개념 몇 가지 미리 정리하고 가자.\n\nEuler \\(\\phi\\) function\n오일러 피 함수(Euler totient function), \\(\\phi(n)\\), 은 \\(n\\)까지의 정수 중에서 \\(n\\)와 서로소(coprime)인 정수 집합의 크기를 나타낸다. 오일러 피 함수에 관해서 아래와 같은 내용이 성립함을 확인하자.\n\n만일 \\(p\\)가 소수일 때, \\(\\phi(p) = p-1\\)가 성립한다. \\(p\\)가 소수라면 정의상 \\(1, \\dotsc, p-1\\)의 모든 수와 \\(p\\)는 서로소가 된다.\n만일 \\(p,q\\)가 서로소이면, \\(\\phi (pq) = \\phi(p) \\phi(q)\\). 증명이 간단하지 않으니 일단 받아들이자.\n\n\n\n증명은 여기를 참고하자.\n\n\nEuler theorem\n\n\n\n\n\n\n오일러 정리\n\n\n\n\\(n\\)이 양의 정수라고 하고, \\(a\\)와 \\(n\\)은 서로소라고 하자. 이때 아래의 관계가 성립한다.\n\\[\na^{\\phi(n)} \\equiv 1~(\\text{mod } n)\n\\]\n\n\n즉, 오일러 정리는 \\(n\\)에 관한 오일러 피 함수와 \\(n\\)의 나머지 연산 간에 매우 편리한 관계를 보여준다. 오일러 정리애 관한 증명 역시 생략한다.\n\n\n증명은 여기를 참고하자. 증명이 몹시 난해한 것은 아니다.\n잠깐 “나머지 연산”(modulo operation)이 왜 동원되는지 살펴보고 넘어가자. 나머지 연산을 통해 일방향 함수를 쉽게 구성할 수 있다. \\(f(x) = ax\\)가 있다고 하자. \\(x\\)를 알면 \\(f(x)\\)를 쉽게 계산할 수 있고 반대로 \\(f(x)\\)를 알면 \\(x\\)도 쉽게 구할 수 있다. 이런 함수를 양방향 함수라고 한다. 반면, \\(f(x) = a^x\\text{ mod ($b$)}\\)라고 하자. 이때, \\(a, b\\)가 주어진 값이라고 하자. \\(x\\)를 알면 쉽게 \\(y\\)가 계산된다. 반면, \\(f(x)\\)가 주어졌다고 해도 \\(x\\)를 알아내기는 쉽지 않다. 하나씩 다른 값을 넣어보면서 맞는지 확인하는 방법 밖에 없다. 일방향 함수에서는 \\(a^x\\)와 \\(b\\)가 충분히 큰 값일 때, \\(f(x)\\)를 알아도 \\(x\\)를 찾기 쉽지 않다.\n\n\n이런 형태의 문제를 이산 대수의 문제라고 한다."
  },
  {
    "objectID": "posts/math-simple/2022-10-03-RSA.html#step-by-step",
    "href": "posts/math-simple/2022-10-03-RSA.html#step-by-step",
    "title": "RSA, Simply Explained",
    "section": "Step by Step",
    "text": "Step by Step\n여기서는 암호화를 수행하는 쪽이 리시버인 상황을 상정해서 설명하겠다. 리시버는 나에게 온 메시지가 나에게 온 것이 맞는지 그리고 메시지를 나만 볼 수 있는지가 염려된다. 이를 보장하기 위해서 리시버는 아래와 같은 과정을 통해서 공개 키 정보를 대중에게 제공한다.\n\n리시버는 \\(p\\), \\(q\\) 두 개의 (상대적으로 큰) 소수를 생성한다. 값은 필요한 만큼 커야 한다. \\(p \\cdot q=n\\)이 된다. \\(p\\), \\(q\\)는 당연히 비공개 정보여야 한다. 하지만 \\(n\\)은 공개 키가 된다. \\(n\\)으로부터 \\(p\\), \\(q\\)를 찾는 것은 단순 무식한 작업(brute force)을 요하고, 그래서 암호로서 기능할 수 있다.\n\\(\\phi(n) = \\phi (pq) = (p-1) (q-1)\\) 이 성립한다. 만일 \\(\\phi(n)\\)을 알고 있으면 \\(p+q\\)을 알게 된다. \\(pq=n\\)을 알고 있으므로 이차 방정식을 풀면 \\(p\\), \\(q\\)를 알게 된다. 따라서 \\(\\phi(n)\\)은 비공개 정보다. 오일러 피 함수에 해당하는 공개 키를 만들기 위해서 \\(\\phi(n)\\)과 서로소인 \\(e\\)를 하나 생성하도록 하자. 대신 이 녀석이 공개 키가 된다.\n\\(\\phi(n)\\)의 나머지 연산에 대해서 \\(d e = 1\\)을 만족하는 \\(d\\)를 구하자. 이 녀석이 비밀 키가 된다.\n\n\n\n\\(\\phi(pq) = \\phi(p)\\phi(q)\\)가 성립한다. \\(p\\), \\(q\\)는 각각 소수이므로 \\(\\phi(p)=p-1\\), \\(\\phi(q)=q-1\\)이다. 한편, \\(e\\)는 대체로 공개 키의 크기 역할을 한다. 따라서 \\(2^{16}+1\\)이 자주 사용된다.\n이제 공개 키와 비밀키를 한번 나누어 써보도록 하자.\n\n\n\nsecret\npublic\n\n\n\n\n\\(p, q\\)\n\\(n\\)\n\n\n\\(\\phi(n), d\\)\n\\(e\\)\n\n\n\n리시버는 공개 키 \\(n\\), \\(e\\)를 일반에게 공개한 상태다.\n\n이 리시버에게 메시지를 보내고자 하는 센더는 자신의 메시지 \\(m\\)을 공개 키 \\(e\\)를 통해 암호화한다. 이 과정은 별게 아니다. 메시지 혹은 메시지의 해시값에 \\(e\\) 승을 한 값에 \\(n\\)의 나머지 연산을 적용한다. 즉,\n\n\\[\nc \\equiv m^e ~ (\\text{mod } n)\n\\]\n\n\n\n아래에서 보듯이 \\(n\\)이 너무 크면 나머지 연산이 제대로 적용되지 않는다. 또한 \\(e\\)의 값이 너무 크면 계산 과정이 길고 복잡해진다.\n메시지를 메시지 자체라고 생각할 필요는 없다. 메시지의 해시값이라고 생각하면 암호화의 대상이 되는 메시지는 원 메시지보다 훨씬 짧을 수 있다. 리시버와 센더가 맞춰봐야 하는 것은 해당 해시값이다.\n\n\n리시버는 암호화된 메시지를 받은 후에 여기에 \\(d\\) 승을 하고 나머지 연산 \\(n\\)을 적용한다. 즉,\n\n\\[\nc^d \\equiv m~(\\text{mod } n)\n\\]\n위에 보는 것처럼 두 번의 나머지 연산에서 센더는 \\(n\\), \\(e\\)의 공개된 정보(공개 키)만을 활용했고, 리시버는 복호화 과정에서 자신이 갖고 있는 정보, 개인 키 \\(d\\)를 활용했다.\n\n증명\n오일러 정리를 활용하면 위 연산을 쉽게 증명할 수 있다.\n\n오일러 정리에 따르면, \\(m^{\\phi(n)} \\equiv 1~(\\text{mod } n)\\)이 성립한다.\n우리는 \\(d\\)와 \\(e\\)를 고를 때 \\(d e \\equiv 1~(\\text{mod }\\phi(n))\\)이 되도록 골랐다. 따라서 \\(de = k \\phi(n) + 1\\)이 되는 적절한 \\(k\\)가 존재한다는 뜻이다.\n\n이를 정리하면,\n\\[\n\\begin{aligned}\nm^{de} & \\equiv m^{k \\phi(n)+1} \\\\\n& \\equiv m^{k \\phi(n)} m \\\\\n& \\equiv (m^\\phi(n))^k m \\\\\n& \\equiv 1^k m  ~(\\text{mod } n)\n\\end{aligned}\n\\]\n공개 키인 \\(n\\)과 \\(e\\)를 생성하는 과정을 보자. 생성 과정에서 일방향 연산, (충분히 큰) 소수 및 서로소를 활용했다. 따라서 공개 키만으로 암호화에 동원된 \\(p, q, \\phi (pq), d\\)를 빠른 시간 내에 쉽게 알아낼 수 없다. 이것이 암호화가 의도하는 것이다.\n\n\n\n수신자는 발송자에게 상자와 열쇠를 보낸다. 해당 열쇠는 수신자의 개인 키로만 열 수 있다.\n메시지 전달에서 비대칭 암호 체계"
  },
  {
    "objectID": "posts/math-simple/2022-10-05-paradox-of-friendship.html",
    "href": "posts/math-simple/2022-10-05-paradox-of-friendship.html",
    "title": "Paradox of Friendship",
    "section": "",
    "text": "친구의 역설을 수학적으로 풀어보자.\n\n\n\n왜 나의 친구는 나보다 친구가 많은 것처럼 느껴질까? 그냥 그렇게 느끼는 것 뿐일까? 직관적으로 생각하면 이것은 역설이 아닐 수 있다. 나와 친구가 된 사람 중에서 친구를 많이 사귀는 경향이 있는 사람이 포함되어 있다면, 그 사람의 친구는 나보다 많다. 이런 사람의 숫자가 인구에 적당한 숫자로 분포되어 있다면 이것이 친구의 역설을 만들 수 있다. 진짜 그런지 모형을 통해 따져보자.\n\n\n\n네트워크 이론에서 쓰는 용어 몇 가지 정리하자.\n\n\n\n용어\n정의\n기호\n\n\n\n\n노드(node), 버텍스(vertex)\n네트워크에 속한 개체\n\\(V, v\\)\n\n\n엣지(edge)\n노드와 노드를 연결하는 선\n\\(E, e\\)\n\n\n차수(degree)\n엣지의 수\n\\(d(v)\\)\n\n\n\n\\(V\\)는 노드의 집합, \\(E\\)는 엣지의 집합이다. 해당 집합에 속하는 대표 원소는 각각 소문자 \\(v, e\\)로 표기한다. 특정한 노드 개체 \\(v\\)의 차수는 \\(d(v)\\)로 나타낼 수 있다.\n‘방향성이 없는’ 그래프는 \\(G = (V, E)\\)로 정의한다. 방향성이 없다는 것은 친구 관계가 대칭적임을 뜻한다. 즉, A가 B의 친구라면, B도 A의 친구가 된다. 만일 애정 관계라면 ’짝사랑’과 같은 것이 존재할 수 있지만, 일단 친구 관계에서는 그런 관계가 없다고 하자.\n\n\n\n네트워크 전체의 평균 친구 숫자 \\(\\mathbb{E} \\left( d(v) \\right) (\\equiv \\mu)\\)를 구해보자.\n\\[\n\\mu = \\dfrac{\\sum_{v \\in V} d(v)}{|V|} = \\dfrac{2|E|}{|V|}\n\\]\n식의 분모는 자명하다. 네트워크 \\(G\\)에 존재하는 개체의 크기를 나타난다. \\(\\sum_{v \\in V} d(v) = 2|E|\\)가 되는 것 중요하다. \\(E\\)는 노드와 노드 사이의 관계를 모두 표시한 집합이다. \\(e  = (v_i, v_j)\\)라면 이는 노드 \\(i\\)와 \\(j\\)가 서로 친구임을 나타낸다. 전체 친구의 숫자는 \\(e\\) 하나당 2개가 된다. 따라서 \\(E\\)의 크기 \\(|E|\\)의 두 배가 전체 친구의 숫자가 된다.\n\n\n\n우리가 관심이 있는 것은 ’친구의 친구’의 평균적인 크기다. 친구의 수를 재기 위해 친구를 어떻게 골라야 할까? 즉, 친구의 평균 수를 재기 위한 친구를 고를 확률을 먼저 정의해야 한다. 먼저 \\(E\\)에서 \\(e\\) 하나를 고른다. \\(e=(v_i, v_j)\\)라고 하자. \\(v_i\\)가 여러 친구를 갖고 있다면 집합 \\(E\\)의 여러 원소에서 \\(v_i\\)가 등장할 것이다. 이 등장 횟수는 \\(d(v_i)\\)와 같다. 마지막으로 하나의 엣지는 두 개의 노드를 지니고 있으므로 엣지에서 \\(v_i\\)를 택할 확률이 \\(\\frac{1}{2}\\)이다. 정리하면 친구의 친구를 측정할 대상인 \\(v^{f}\\)가 네트워크에서 선택될 확률 \\(P(v^f)\\)는 다음과 같다.\n\\[\nP(v^f)= \\dfrac{d(v^f)}{|E|} \\dfrac{1}{2}\n\\]\n이 확률에 ’친구의 역설’의 비밀이 숨어 있다. 대상 친구가 선택될 확률은 해당 친구의 차수, 즉 그가 지닌 친구의 숫자, \\(d(v^f)\\)에 비례한다. 즉, 친구가 많은 친구가 대상으로 선택될 확률이 높은 것이다.\n\n\n\n친구의 친구의 숫자, 정확하게는 그 기대값은 다음과 같이 쉽게 계산된다. \\[\n\\mathbb E(d(v^f)) = \\sum_{v^f \\in V} P(v^f) d(v^f) = \\sum_{v^f \\in V} \\dfrac{d(v^f)}{2|E|} d(v^f) = \\dfrac{1}{2|E|} \\sum_{v^f \\in V} d(v^f)^2\n\\tag{1}\\]\n\\(v^f\\) 역시 네트워크 내의 한 개체이므로 당분간 상첨자를 떼고 보자. \\(d(v)\\)의 분산을 생각해보자.\n\\[\n{\\rm Var}(d(v)) \\equiv \\sigma^2 = \\mathbb{E}((d(v) - \\mu)^2) = \\mathbb{E}(d(v)^2) - \\mu^2\n\\]\n\\(v\\)를 무작위로 선택했다면, 다음과 같이 정리할 수 있다.\n\\[\n\\mathbb{E}(d(v)^2) = \\dfrac{\\sum_v d(v)^2}{|V|} = \\sigma^2 + \\mu^2\n\\tag{2}\\]\n식 (2)를 식 (1)에 대입하면 다음과 같다.\n\\[\n\\mathbb E(d(v^f))  = \\dfrac{1}{2|E|} \\sum_{v^f \\in V} d(v^f)^2 = \\dfrac{|V|}{2|E|} \\left( \\sigma^2 + \\mu^2 \\right) = \\dfrac{\\mu^2 + \\sigma^2}{\\mu} = \\mu + \\dfrac{\\sigma^2}{\\mu}.\n\\]\n\n\n\n만일 네트워크에서 모든 사람의 친구의 숫자가 동일하다면, 위의 식에서 보듯이 내 친구의 숫자와 내 친구의 친구의 숫자는 동일할 것이다. 모든 사람의 친구의 숫자가 동일하다는 것은 분산이 \\(0\\), 즉 \\(\\sigma^2 = 0\\), 이라는 뜻이다.\n그런데 친구 네트워크가 분산이 0이 되는 형태로 균질하지 않다면, 즉 친구 숫자의 분포가 존재하는 이상 \\(\\sigma^2 &gt; 0\\)이 성립할 수 밖에 없다. 친구 숫자가 균등하지 않는 이상 평균적으로 친구의 친구의 숫자는 내 친구의 숫자보다 크게 된다.\n\n\n재미 삼아서 극단적인 경우를 만들어 보자. \\(n\\)명의 네트워크에서 1명과 \\(n-1\\) 명이 바퀴살 구조로 연결되어 있다고 하자. 이때, \\(n-1\\) 명의 유일한 친구 1명의 평균 친구 숫자는 \\(n-1\\) 명이다. 이 집단에서 \\(n-1\\) 명은 자신의 친구 숫자 \\(1\\) 명보다 친구의 친구의 숫자가 \\(n-1\\) 명으로 압도적으로 크다. 이 집단에서 무작위로 1명을 뽑을 경우 거의 모든 경우 내 친구의 숫자보다 친구의 친구의 숫자가 크다고 느낄 것이다. 평균 친구 숫자는 아래와 같다.\n\\[\n\\mu = \\dfrac{(n-1)\\cdot1 + (n-1)\\cdot1}{n} = \\dfrac{2(n-1)}{n}\n\\]\n한편, 친구의 친구 숫자의 평균은 다음과 같다.\n\\[\n\\mathbb E(d(v^f)) = \\dfrac{(n-1)(n-1) + 1\\cdot1}{n} = \\dfrac{n^2 - 2n +2}{n}\n\\]\n\\(n \\geq 2\\)인 경우 \\(E(d(v^f)) \\geq \\mu\\)가 성립한다.\n\n\n\n보다 직관적으로 말해보겠다. 인구 혹은 그래프 전체에 대해서 보자. 개인(개별 노드)의 친구 숫자(차수) 혹은 그 분포가 인구 전체의 평균적인 친구의 숫자를 결정한다. 이때 각 개인의 친구 숫자는 평균을 계산할 때 한 번 반영된다. 그런데 ’친구의 친구’의 숫자는 어떨까? 한 개인이 많은 친구를 지니고 있다고 하자. 그는 누군가의 친구로 여러 번 등장할 것이다. 따라서 ’친구의 친구’의 숫자 계산할 때 친구가 많은 사람은 여러 번 등장한다. 친구가 많은 사람, 즉 큰 숫자가 여러 번 더해지게 되므로 친구의 친구의 숫자는 대체로 개인의 평균적인 친구 숫자보다 클 것이다! 이 동영상을 참고하자."
  },
  {
    "objectID": "posts/math-simple/2022-10-05-paradox-of-friendship.html#tl-dr",
    "href": "posts/math-simple/2022-10-05-paradox-of-friendship.html#tl-dr",
    "title": "Paradox of Friendship",
    "section": "",
    "text": "친구의 역설을 수학적으로 풀어보자.\n\n\n\n왜 나의 친구는 나보다 친구가 많은 것처럼 느껴질까? 그냥 그렇게 느끼는 것 뿐일까? 직관적으로 생각하면 이것은 역설이 아닐 수 있다. 나와 친구가 된 사람 중에서 친구를 많이 사귀는 경향이 있는 사람이 포함되어 있다면, 그 사람의 친구는 나보다 많다. 이런 사람의 숫자가 인구에 적당한 숫자로 분포되어 있다면 이것이 친구의 역설을 만들 수 있다. 진짜 그런지 모형을 통해 따져보자.\n\n\n\n네트워크 이론에서 쓰는 용어 몇 가지 정리하자.\n\n\n\n용어\n정의\n기호\n\n\n\n\n노드(node), 버텍스(vertex)\n네트워크에 속한 개체\n\\(V, v\\)\n\n\n엣지(edge)\n노드와 노드를 연결하는 선\n\\(E, e\\)\n\n\n차수(degree)\n엣지의 수\n\\(d(v)\\)\n\n\n\n\\(V\\)는 노드의 집합, \\(E\\)는 엣지의 집합이다. 해당 집합에 속하는 대표 원소는 각각 소문자 \\(v, e\\)로 표기한다. 특정한 노드 개체 \\(v\\)의 차수는 \\(d(v)\\)로 나타낼 수 있다.\n‘방향성이 없는’ 그래프는 \\(G = (V, E)\\)로 정의한다. 방향성이 없다는 것은 친구 관계가 대칭적임을 뜻한다. 즉, A가 B의 친구라면, B도 A의 친구가 된다. 만일 애정 관계라면 ’짝사랑’과 같은 것이 존재할 수 있지만, 일단 친구 관계에서는 그런 관계가 없다고 하자.\n\n\n\n네트워크 전체의 평균 친구 숫자 \\(\\mathbb{E} \\left( d(v) \\right) (\\equiv \\mu)\\)를 구해보자.\n\\[\n\\mu = \\dfrac{\\sum_{v \\in V} d(v)}{|V|} = \\dfrac{2|E|}{|V|}\n\\]\n식의 분모는 자명하다. 네트워크 \\(G\\)에 존재하는 개체의 크기를 나타난다. \\(\\sum_{v \\in V} d(v) = 2|E|\\)가 되는 것 중요하다. \\(E\\)는 노드와 노드 사이의 관계를 모두 표시한 집합이다. \\(e  = (v_i, v_j)\\)라면 이는 노드 \\(i\\)와 \\(j\\)가 서로 친구임을 나타낸다. 전체 친구의 숫자는 \\(e\\) 하나당 2개가 된다. 따라서 \\(E\\)의 크기 \\(|E|\\)의 두 배가 전체 친구의 숫자가 된다.\n\n\n\n우리가 관심이 있는 것은 ’친구의 친구’의 평균적인 크기다. 친구의 수를 재기 위해 친구를 어떻게 골라야 할까? 즉, 친구의 평균 수를 재기 위한 친구를 고를 확률을 먼저 정의해야 한다. 먼저 \\(E\\)에서 \\(e\\) 하나를 고른다. \\(e=(v_i, v_j)\\)라고 하자. \\(v_i\\)가 여러 친구를 갖고 있다면 집합 \\(E\\)의 여러 원소에서 \\(v_i\\)가 등장할 것이다. 이 등장 횟수는 \\(d(v_i)\\)와 같다. 마지막으로 하나의 엣지는 두 개의 노드를 지니고 있으므로 엣지에서 \\(v_i\\)를 택할 확률이 \\(\\frac{1}{2}\\)이다. 정리하면 친구의 친구를 측정할 대상인 \\(v^{f}\\)가 네트워크에서 선택될 확률 \\(P(v^f)\\)는 다음과 같다.\n\\[\nP(v^f)= \\dfrac{d(v^f)}{|E|} \\dfrac{1}{2}\n\\]\n이 확률에 ’친구의 역설’의 비밀이 숨어 있다. 대상 친구가 선택될 확률은 해당 친구의 차수, 즉 그가 지닌 친구의 숫자, \\(d(v^f)\\)에 비례한다. 즉, 친구가 많은 친구가 대상으로 선택될 확률이 높은 것이다.\n\n\n\n친구의 친구의 숫자, 정확하게는 그 기대값은 다음과 같이 쉽게 계산된다. \\[\n\\mathbb E(d(v^f)) = \\sum_{v^f \\in V} P(v^f) d(v^f) = \\sum_{v^f \\in V} \\dfrac{d(v^f)}{2|E|} d(v^f) = \\dfrac{1}{2|E|} \\sum_{v^f \\in V} d(v^f)^2\n\\tag{1}\\]\n\\(v^f\\) 역시 네트워크 내의 한 개체이므로 당분간 상첨자를 떼고 보자. \\(d(v)\\)의 분산을 생각해보자.\n\\[\n{\\rm Var}(d(v)) \\equiv \\sigma^2 = \\mathbb{E}((d(v) - \\mu)^2) = \\mathbb{E}(d(v)^2) - \\mu^2\n\\]\n\\(v\\)를 무작위로 선택했다면, 다음과 같이 정리할 수 있다.\n\\[\n\\mathbb{E}(d(v)^2) = \\dfrac{\\sum_v d(v)^2}{|V|} = \\sigma^2 + \\mu^2\n\\tag{2}\\]\n식 (2)를 식 (1)에 대입하면 다음과 같다.\n\\[\n\\mathbb E(d(v^f))  = \\dfrac{1}{2|E|} \\sum_{v^f \\in V} d(v^f)^2 = \\dfrac{|V|}{2|E|} \\left( \\sigma^2 + \\mu^2 \\right) = \\dfrac{\\mu^2 + \\sigma^2}{\\mu} = \\mu + \\dfrac{\\sigma^2}{\\mu}.\n\\]\n\n\n\n만일 네트워크에서 모든 사람의 친구의 숫자가 동일하다면, 위의 식에서 보듯이 내 친구의 숫자와 내 친구의 친구의 숫자는 동일할 것이다. 모든 사람의 친구의 숫자가 동일하다는 것은 분산이 \\(0\\), 즉 \\(\\sigma^2 = 0\\), 이라는 뜻이다.\n그런데 친구 네트워크가 분산이 0이 되는 형태로 균질하지 않다면, 즉 친구 숫자의 분포가 존재하는 이상 \\(\\sigma^2 &gt; 0\\)이 성립할 수 밖에 없다. 친구 숫자가 균등하지 않는 이상 평균적으로 친구의 친구의 숫자는 내 친구의 숫자보다 크게 된다.\n\n\n재미 삼아서 극단적인 경우를 만들어 보자. \\(n\\)명의 네트워크에서 1명과 \\(n-1\\) 명이 바퀴살 구조로 연결되어 있다고 하자. 이때, \\(n-1\\) 명의 유일한 친구 1명의 평균 친구 숫자는 \\(n-1\\) 명이다. 이 집단에서 \\(n-1\\) 명은 자신의 친구 숫자 \\(1\\) 명보다 친구의 친구의 숫자가 \\(n-1\\) 명으로 압도적으로 크다. 이 집단에서 무작위로 1명을 뽑을 경우 거의 모든 경우 내 친구의 숫자보다 친구의 친구의 숫자가 크다고 느낄 것이다. 평균 친구 숫자는 아래와 같다.\n\\[\n\\mu = \\dfrac{(n-1)\\cdot1 + (n-1)\\cdot1}{n} = \\dfrac{2(n-1)}{n}\n\\]\n한편, 친구의 친구 숫자의 평균은 다음과 같다.\n\\[\n\\mathbb E(d(v^f)) = \\dfrac{(n-1)(n-1) + 1\\cdot1}{n} = \\dfrac{n^2 - 2n +2}{n}\n\\]\n\\(n \\geq 2\\)인 경우 \\(E(d(v^f)) \\geq \\mu\\)가 성립한다.\n\n\n\n보다 직관적으로 말해보겠다. 인구 혹은 그래프 전체에 대해서 보자. 개인(개별 노드)의 친구 숫자(차수) 혹은 그 분포가 인구 전체의 평균적인 친구의 숫자를 결정한다. 이때 각 개인의 친구 숫자는 평균을 계산할 때 한 번 반영된다. 그런데 ’친구의 친구’의 숫자는 어떨까? 한 개인이 많은 친구를 지니고 있다고 하자. 그는 누군가의 친구로 여러 번 등장할 것이다. 따라서 ’친구의 친구’의 숫자 계산할 때 친구가 많은 사람은 여러 번 등장한다. 친구가 많은 사람, 즉 큰 숫자가 여러 번 더해지게 되므로 친구의 친구의 숫자는 대체로 개인의 평균적인 친구 숫자보다 클 것이다! 이 동영상을 참고하자."
  },
  {
    "objectID": "posts/regression/2020-11-11-log-linear-regression.html",
    "href": "posts/regression/2020-11-11-log-linear-regression.html",
    "title": "Understanding Log-Linear Regression Model",
    "section": "",
    "text": "당연히 알고 있다고 생각하지만 모르는 게 생각보다 많다. 회귀 분석에서 로그-리니어 모델, 즉 종속 변수에 로그를 취하고 독립 변수가 선형인 모델에서 계수를 어떻게 이해해야 할까?"
  },
  {
    "objectID": "posts/regression/2020-11-11-log-linear-regression.html#왜-로그로-변환할까",
    "href": "posts/regression/2020-11-11-log-linear-regression.html#왜-로그로-변환할까",
    "title": "Understanding Log-Linear Regression Model",
    "section": "왜 로그로 변환할까?",
    "text": "왜 로그로 변환할까?\n우선 이것부터 따져보자. 교과서나 자료를 찾아보면 \\(y_i\\)를 로그 변환하는 이유가 \\(y_i\\)의 분포를 정규분포에 가깝게 만들어주기 때문이라는 내용이 있다. 소표본을 다루는 경우라면 오차 항의 정규 분포를 가정하기 때문에 타당한 이야기일 수도 있다. 대표본이라면 중심 극한 정리(Central Limit Theorem)에 의지하는 것으로 충분하다.\n우선 아래 그림에서 보듯이 로그로 변환했을 때 회귀 분석이 보다 타당해지는 경우가 있다. 로그는 곱셈을 덧셈으로 폴어주는 역할을 한다. \\(y_i = e^{\\alpha \\beta x_i}\\)의 경우 함수 형태가 \\(e^\\alpha\\)와 \\(e^{\\beta x_i}\\)의 곱으로 구성되어 있고, 이 녀석을 회귀 분석으로 추정하는 것은 적합하지 않다. 이때 \\(\\log y_i\\)를 취하면 회귀 분석으로 다루기 좋은 녀석으로 바뀐다.\n\n\n\n\n\n\n \n\n\n\n\n\n비선형의 함수 형태를 선형으로 바꿔 회귀분석을 활용할 수 있다.\n\n\n\n\n \n\n\n\n곱으로 표현되는 식이 어떤 경우가 해당할까? 어떤 기준점의 몇 배로 늘고 주는 것이 자연스러운 맥락을 떠올려보자. 여기서 몇 배가 된다는 것은 다시 말하면 퍼센트 변화를 뜻한다. 즉, 로그 변환은 수치의 절대적인 변화량보다는 퍼센트 변화가 의미를 지닐 때 유용하게 사용할 수 있다.\n비슷한 맥락이지만 데이터의 분산이 클 때도 로그 변환이 유효하다. 부(wealth)의 분포는 극단적인 경우가 많다. 매우 적은 부를 소유한 사람부터 매우 많은 부를 소유한 사람까지 분산이 매우 크다. 이런 경우 로그 변환을 하면 분산이 크게 줄어든다."
  },
  {
    "objectID": "posts/regression/2020-11-11-log-linear-regression.html#근삿값으로-본-계수의-의미",
    "href": "posts/regression/2020-11-11-log-linear-regression.html#근삿값으로-본-계수의-의미",
    "title": "Understanding Log-Linear Regression Model",
    "section": "근삿값으로 본 계수의 의미",
    "text": "근삿값으로 본 계수의 의미\n편의상 독립 변수와 종속 변수 모두 스칼라 값인 아래와 같은 로그-선형 모형을 살펴보자.\n\\[\n\\ln y_i = \\alpha + \\beta x_i + \\varepsilon_i\n\\]\n\\(\\Delta \\ln y_i\\)의 의미를 풀면 다음과 같다.\n\\[\n\\begin{aligned}\n\\Delta \\ln y_i & = \\ln y_1 - \\ln y_0 \\\\\n& = \\ln(\\frac{y_1}{y_0}) \\\\\n& = \\ln(\\frac{y_0 + \\Delta y}{y_0}) \\\\\n& = \\ln(1+\\frac{\\Delta y}{y_0})\n\\end{aligned}\n\\]\n\\(\\ln(1+\\frac{\\Delta y}{y_0})\\)를 보자. \\(z=0\\) 근처에서 \\(\\ln (1+z) \\approx z\\)가 성립한다. 즉, 만일 \\(\\frac{\\Delta y}{y_0} \\approx 0\\)라면,\n\\[\n\\Delta \\ln y_i =  \\ln(1+\\frac{\\Delta y}{y_0}) \\approx \\dfrac{\\Delta y}{y_0} = \\% \\Delta y = \\beta \\Delta x\n\\]\n이 경우 \\(\\beta\\)가 \\(x_i\\) 변화에 따른 \\(y_i\\)의 변화율이라는 수학적인 해석을 그대로 가져올 수 있다. \\(\\frac{\\Delta y}{y_0} \\approx 0\\)를 만족하려면 \\(y_i\\)의 변화율이 크지 않아야 한다. 로그-선형 모형의 회귀식을 추정해 \\(\\beta\\)를 보고할 때 “\\(x_i\\)가 1단위 변화할 때”라는 표현을 쓴다. 이는 \\(\\Delta x = 1\\)로 둔다는 뜻이다.\n\\[\n\\Delta \\ln y_i \\approx \\dfrac{\\Delta y}{y_0} = \\% \\Delta y = \\beta\n\\]\n결국 \\(\\beta\\)의 값이 0과 크게 다르지 않다면 이 값은 \\(x_i\\)가 1단위 변화할 때 \\(y_i\\)의 변화율에 미치는 영향”으로 해석할 수 있다."
  },
  {
    "objectID": "posts/regression/2020-11-11-log-linear-regression.html#변화율을-정확하게-계산해-보자",
    "href": "posts/regression/2020-11-11-log-linear-regression.html#변화율을-정확하게-계산해-보자",
    "title": "Understanding Log-Linear Regression Model",
    "section": "변화율을 정확하게 계산해 보자",
    "text": "변화율을 정확하게 계산해 보자\n근삿값을 쓰지 말고 % 변화율을 정확하게 계산해 보자. 물론 이 값이 필요한 경우에 해당한다.\n\\[\n\\begin{aligned}\n\\% \\Delta y_i & \\equiv \\dfrac{y_1 - y_0}{y_0} \\\\\n& = \\dfrac{y_1}{y_0} - 1 \\\\\n& = \\exp(\\ln (\\dfrac{y_1}{y_0})) - 1 \\\\\n& = \\exp(x_1 \\beta - x_0 \\beta + \\varepsilon_1 - \\varepsilon_0) - 1 \\\\\n& = \\exp(\\Delta x \\beta + \\Delta \\varepsilon) - 1\n\\end{aligned}\n\\]\n\n\n\\(z=0\\) 근방에서 테일러급수를 1차까지 근사하면 저 값을 얻을 수 있다. \\(z=0\\) 인근에서 근사하는 이유는 \\(z=0\\) 근처에서 \\(\\frac{(z-0)^k}{k!}\\) for \\(k=2,3, \\dotsc\\)과 같은 고차 항의 크기가 점점 줄어들기 때문이다.\n\\(\\Delta \\varepsilon =0\\)를 가정하고 \\(\\Delta x =1\\)로 두면, 위 식으로 \\(y_i\\)의 % 변화율을 계산할 수 있다."
  },
  {
    "objectID": "posts/regression/2020-11-11-log-linear-regression.html#계수의-해석",
    "href": "posts/regression/2020-11-11-log-linear-regression.html#계수의-해석",
    "title": "Understanding Log-Linear Regression Model",
    "section": "계수의 해석",
    "text": "계수의 해석\n지수 함수 \\(e^x\\)의 그래프를 생각해 보자. \\(x\\)가 커짐에 따라서 도함수의 기울기가 커진다는 점을 알 수 있다. 위의 전개에서 보듯이 \\(\\frac{\\Delta y}{y_0} \\approx 0\\)일 때 \\(\\beta\\)는 실제의 도함수 기울기에 값에 근접한다. \\(\\frac{\\Delta y}{y_0} \\approx 0\\)의 가정이란 \\(y\\)의 증가율이 크지 않다는 의미이다. 예를 들어보자. 만일 \\(\\beta = 0.3\\)이라고 하자. 실제 \\(\\%\\Delta y\\)를 구해보면,\n\\[\n\\%\\Delta y = \\exp(\\beta) - 1 = 0.35\n\\]\n약 5% 정도 과소평가되었음을 알 수 있다. 이 크기의 의미나 중요성은 분석자가 선택할 문제다. 다만 \\(\\beta\\)가 너무 크게 나왔다면, 실재 값과의 오차가 생길 수 있다. 로그-선형 모델의 경우 원래 크기보다 퍼센트 변화를 과소 측정한다. 원래 지수적으로 늘어나는 것을 로그를 취해 선형으로 끌어내린 결과이다.\n\n\n\n비선형의 함수 형태를 선형으로 바꿔 회귀분석을 활용할 수 있다."
  },
  {
    "objectID": "posts/regression/2022-06-04-simpson-paradox-regression.html",
    "href": "posts/regression/2022-06-04-simpson-paradox-regression.html",
    "title": "Simpson’s Paradox with Regression",
    "section": "",
    "text": "심슨의 역설을 보통은 회귀 분석으로 설명하지 않는다. 그런데 회귀 분석으로 보면 보다 명확하다. 심슨 역설의 전형적인 사례를 펭귄 부리의 길이와 높이를 통해 살펴보도록 하자.\n\n\n데이터는 여기를 참고하자.\n\n\n\n펭귄 부리의 길이와 높이\n\n\nculmen은 새의 부리를 뜻한다. 옆 그림에서 보듯이 length는 부리의 앞으로 튀어나온 길이를, depth는 부리의 높이를 의미한다. 아래 보듯이 이 데이터는 펭귄의 세 가지 종족, 성별 등을 별도로 담고 있다.\n\n\nCode\n # Basic packages\nimport pandas as pd \nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n# Stats models pip \nimport statsmodels.formula.api as sm\nimport statsmodels as statsmodels\n%matplotlib inline\n\ncsv_addr = \"data/penguins_size.csv\"\nplt.style.use(\"fivethirtyeight\")# for pretty graphs\ndf  = pd.read_csv('data/penguins_size.csv')\ndf.head();\n#df.info();\ndf = df.dropna()\ndf.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 334 entries, 0 to 343\nData columns (total 7 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            334 non-null    object \n 1   island             334 non-null    object \n 2   culmen_length_mm   334 non-null    float64\n 3   culmen_depth_mm    334 non-null    float64\n 4   flipper_length_mm  334 non-null    float64\n 5   body_mass_g        334 non-null    float64\n 6   sex                334 non-null    object \ndtypes: float64(4), object(3)\nmemory usage: 20.9+ KB\n\n\n\n\nCode\nplt.rcParams['figure.figsize'] = [8, 4]\nsns.set(font_scale=0.7)\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\nsns.regplot(x = 'culmen_length_mm',y = 'culmen_depth_mm', data = df, scatter_kws={'alpha': 0.4}, ax=ax1)\nr = stats.pearsonr(df['culmen_length_mm'], df['culmen_depth_mm'])[0]\nax1.text(.03, 1, 'r={:.3f}'.format(r), transform=ax1.transAxes)\ncolors = ['darkorange', 'royalblue', '#555555']\nmarkers = ['.', '+', 'x']\n#\nfor i, value in enumerate(df['species'].unique()):\n    ax2 = sns.regplot(x=\"culmen_length_mm\", y=\"culmen_depth_mm\", ax=ax2,\n                      scatter_kws={'alpha': 0.4},\n                     color=colors[i],\n                     #marker=markers[i],                      \n                     data=df[df['species'] == value],\n                     label=value)\nax2.legend(loc='best');\n\n\n\n\n\n\n\n\n\n패널의 왼쪽 그림에서 보듯이 종 구분 없이 펭귄 부리의 길이와 높이를 보면 서로 음의 상관성을 지니고 있는 듯 보인다. 그런데 이를 종별로 구별해서 살펴보면 오히려 길이와 높이는 양의 상관성을 지니고 있다.\n\n\n\n\n\n펭귄 종류\n\n\n\n\nCode\nols1 = sm.ols(formula=\"culmen_depth_mm ~ culmen_length_mm\", data=df).fit(use_t=True)\nols2 = sm.ols(formula=\"culmen_depth_mm ~ species + culmen_length_mm\", data=df).fit(use_t=True)\nols3 = sm.ols(formula=\"culmen_depth_mm ~ species * culmen_length_mm\", data=df).fit(use_t=True)\n#ols1.summary()\n#ols2.summary()\n\nfrom stargazer.stargazer import Stargazer\nstargazer = Stargazer([ols1, ols2, ols3])\nstargazer\n\n#regs = [ols1, ols2, ols3]\n#from statsmodels.iolib.summary2 import summary_col\n#print(summary_col(\n#                  regs,\n#                  stars=True, \n#                  float_format='%0.2f',\n#                  model_names=['(1)','(2)','(3)'],\n#                  info_dict={\n#                    'N':lambda x: \"{0:d}\".format(int(x.nobs)), \n#                    'F': lambda x: \"{0:.2f}\".format(x.fvalue),\n#                    }, \n#                  regressor_order=['Intercept','culmen_length_mm','secies'])\n#    )\n\n\n\nDependent variable: culmen_depth_mm(1)(2)(3)\n\n\nIntercept20.786***10.619***11.488***\n(0.854)(0.691)(1.162)\nculmen_length_mm-0.082***0.199***0.177***\n(0.019)(0.018)(0.030)\nspecies[T.Chinstrap]-1.919***-3.919*\n(0.226)(2.070)\nspecies[T.Chinstrap]:culmen_length_mm0.046\n(0.046)\nspecies[T.Gentoo]-5.080***-6.187***\n(0.194)(1.778)\nspecies[T.Gentoo]:culmen_length_mm0.027\n(0.041)\n\n\nObservations334334334R20.0520.7660.767Adjusted R20.0490.7640.764Residual Std. Error1.919 (df=332)0.956 (df=330)0.957 (df=328)F Statistic18.313*** (df=1; 332)360.759*** (df=3; 330)216.026*** (df=5; 328)\nNote:*p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n회귀 분석에서 종을 통제한 경우와 그렇지 않은 경우의 culmen_length_mm(부리의 길이)의 계수를 비교해보자. (1)은 종족을 통제하지 않은 회귀식으로 culmen_length_mm의 계수는 음수이다. 반면 종족을 통제한 (2)의 회귀식은 종족의 구분해 각 절편과 해당 종족 내의 부리의 길이와 높이의 관계를 계산해 이를 적절하게 가중 평균한 값이 culmen_length_mm의 계수가 된다. 회귀 테이블에서 보듯이 culmen_length_mm의 계수는 음수에서 양수로 바뀌어 있다.\n\n\n\n\n나머지 계수의 의미는 기본이 되는 Adelie 종족을 기준으로 다른 두 개의 종족의 절편이 얼마나 떨어져 있는지를 보여준다. 회귀식을 적어보면 다음과 같다.\n식 (1) \\(y_i = \\alpha_i + \\beta x_i\\)\n식 (2) \\(y_i = \\alpha_i + \\beta x_i + D_{1i} + D_{2i}\\)\n\n\\(y_i\\): culmen_depth_mm 부리의 높이\n\\(x_i\\): culmen_length_mm 부리의 길이\n\\(D_{1i}\\): 종족이 Chinstrap일 경우 1 이외는 0\n\\(D_{2i}\\): 종족이 Gentoo일 경우 1이외는 0\n\n식 (3)은 \\(\\beta_i\\)가 그룹별로 달라지는지 여부를 교호작용 항목을 통해 확인했다. (3)이 보여주듯이 그룹별로 \\(\\beta_i\\)는 통계적으로 유의미한 차이가 없다.\n\n펭귄 부리의 길이와 높이\n펭귄 종류"
  },
  {
    "objectID": "posts/regression/2022-06-04-simpson-paradox-regression.html#회귀-분석으로-보는-심슨의-역설",
    "href": "posts/regression/2022-06-04-simpson-paradox-regression.html#회귀-분석으로-보는-심슨의-역설",
    "title": "Simpson’s Paradox with Regression",
    "section": "",
    "text": "심슨의 역설을 보통은 회귀 분석으로 설명하지 않는다. 그런데 회귀 분석으로 보면 보다 명확하다. 심슨 역설의 전형적인 사례를 펭귄 부리의 길이와 높이를 통해 살펴보도록 하자.\n\n\n데이터는 여기를 참고하자.\n\n\n\n펭귄 부리의 길이와 높이\n\n\nculmen은 새의 부리를 뜻한다. 옆 그림에서 보듯이 length는 부리의 앞으로 튀어나온 길이를, depth는 부리의 높이를 의미한다. 아래 보듯이 이 데이터는 펭귄의 세 가지 종족, 성별 등을 별도로 담고 있다.\n\n\nCode\n # Basic packages\nimport pandas as pd \nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n# Stats models pip \nimport statsmodels.formula.api as sm\nimport statsmodels as statsmodels\n%matplotlib inline\n\ncsv_addr = \"data/penguins_size.csv\"\nplt.style.use(\"fivethirtyeight\")# for pretty graphs\ndf  = pd.read_csv('data/penguins_size.csv')\ndf.head();\n#df.info();\ndf = df.dropna()\ndf.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 334 entries, 0 to 343\nData columns (total 7 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            334 non-null    object \n 1   island             334 non-null    object \n 2   culmen_length_mm   334 non-null    float64\n 3   culmen_depth_mm    334 non-null    float64\n 4   flipper_length_mm  334 non-null    float64\n 5   body_mass_g        334 non-null    float64\n 6   sex                334 non-null    object \ndtypes: float64(4), object(3)\nmemory usage: 20.9+ KB\n\n\n\n\nCode\nplt.rcParams['figure.figsize'] = [8, 4]\nsns.set(font_scale=0.7)\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\nsns.regplot(x = 'culmen_length_mm',y = 'culmen_depth_mm', data = df, scatter_kws={'alpha': 0.4}, ax=ax1)\nr = stats.pearsonr(df['culmen_length_mm'], df['culmen_depth_mm'])[0]\nax1.text(.03, 1, 'r={:.3f}'.format(r), transform=ax1.transAxes)\ncolors = ['darkorange', 'royalblue', '#555555']\nmarkers = ['.', '+', 'x']\n#\nfor i, value in enumerate(df['species'].unique()):\n    ax2 = sns.regplot(x=\"culmen_length_mm\", y=\"culmen_depth_mm\", ax=ax2,\n                      scatter_kws={'alpha': 0.4},\n                     color=colors[i],\n                     #marker=markers[i],                      \n                     data=df[df['species'] == value],\n                     label=value)\nax2.legend(loc='best');\n\n\n\n\n\n\n\n\n\n패널의 왼쪽 그림에서 보듯이 종 구분 없이 펭귄 부리의 길이와 높이를 보면 서로 음의 상관성을 지니고 있는 듯 보인다. 그런데 이를 종별로 구별해서 살펴보면 오히려 길이와 높이는 양의 상관성을 지니고 있다.\n\n\n\n\n\n펭귄 종류\n\n\n\n\nCode\nols1 = sm.ols(formula=\"culmen_depth_mm ~ culmen_length_mm\", data=df).fit(use_t=True)\nols2 = sm.ols(formula=\"culmen_depth_mm ~ species + culmen_length_mm\", data=df).fit(use_t=True)\nols3 = sm.ols(formula=\"culmen_depth_mm ~ species * culmen_length_mm\", data=df).fit(use_t=True)\n#ols1.summary()\n#ols2.summary()\n\nfrom stargazer.stargazer import Stargazer\nstargazer = Stargazer([ols1, ols2, ols3])\nstargazer\n\n#regs = [ols1, ols2, ols3]\n#from statsmodels.iolib.summary2 import summary_col\n#print(summary_col(\n#                  regs,\n#                  stars=True, \n#                  float_format='%0.2f',\n#                  model_names=['(1)','(2)','(3)'],\n#                  info_dict={\n#                    'N':lambda x: \"{0:d}\".format(int(x.nobs)), \n#                    'F': lambda x: \"{0:.2f}\".format(x.fvalue),\n#                    }, \n#                  regressor_order=['Intercept','culmen_length_mm','secies'])\n#    )\n\n\n\nDependent variable: culmen_depth_mm(1)(2)(3)\n\n\nIntercept20.786***10.619***11.488***\n(0.854)(0.691)(1.162)\nculmen_length_mm-0.082***0.199***0.177***\n(0.019)(0.018)(0.030)\nspecies[T.Chinstrap]-1.919***-3.919*\n(0.226)(2.070)\nspecies[T.Chinstrap]:culmen_length_mm0.046\n(0.046)\nspecies[T.Gentoo]-5.080***-6.187***\n(0.194)(1.778)\nspecies[T.Gentoo]:culmen_length_mm0.027\n(0.041)\n\n\nObservations334334334R20.0520.7660.767Adjusted R20.0490.7640.764Residual Std. Error1.919 (df=332)0.956 (df=330)0.957 (df=328)F Statistic18.313*** (df=1; 332)360.759*** (df=3; 330)216.026*** (df=5; 328)\nNote:*p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n회귀 분석에서 종을 통제한 경우와 그렇지 않은 경우의 culmen_length_mm(부리의 길이)의 계수를 비교해보자. (1)은 종족을 통제하지 않은 회귀식으로 culmen_length_mm의 계수는 음수이다. 반면 종족을 통제한 (2)의 회귀식은 종족의 구분해 각 절편과 해당 종족 내의 부리의 길이와 높이의 관계를 계산해 이를 적절하게 가중 평균한 값이 culmen_length_mm의 계수가 된다. 회귀 테이블에서 보듯이 culmen_length_mm의 계수는 음수에서 양수로 바뀌어 있다.\n\n\n\n\n나머지 계수의 의미는 기본이 되는 Adelie 종족을 기준으로 다른 두 개의 종족의 절편이 얼마나 떨어져 있는지를 보여준다. 회귀식을 적어보면 다음과 같다.\n식 (1) \\(y_i = \\alpha_i + \\beta x_i\\)\n식 (2) \\(y_i = \\alpha_i + \\beta x_i + D_{1i} + D_{2i}\\)\n\n\\(y_i\\): culmen_depth_mm 부리의 높이\n\\(x_i\\): culmen_length_mm 부리의 길이\n\\(D_{1i}\\): 종족이 Chinstrap일 경우 1 이외는 0\n\\(D_{2i}\\): 종족이 Gentoo일 경우 1이외는 0\n\n식 (3)은 \\(\\beta_i\\)가 그룹별로 달라지는지 여부를 교호작용 항목을 통해 확인했다. (3)이 보여주듯이 그룹별로 \\(\\beta_i\\)는 통계적으로 유의미한 차이가 없다.\n\n펭귄 부리의 길이와 높이\n펭귄 종류"
  },
  {
    "objectID": "posts/regression/2019-10-25-understanding-regression.html",
    "href": "posts/regression/2019-10-25-understanding-regression.html",
    "title": "Understanding Regression",
    "section": "",
    "text": "회귀 분석에 관한 미주알 고주알\n\n\n\n\n\n선형 대수를 통해 회귀 분석을 이해하면 새로운 깨달음을 얻을 수 있다."
  },
  {
    "objectID": "posts/regression/2019-10-25-understanding-regression.html#tl-dr",
    "href": "posts/regression/2019-10-25-understanding-regression.html#tl-dr",
    "title": "Understanding Regression",
    "section": "",
    "text": "회귀 분석에 관한 미주알 고주알\n\n\n\n\n\n선형 대수를 통해 회귀 분석을 이해하면 새로운 깨달음을 얻을 수 있다."
  },
  {
    "objectID": "posts/regression/2019-10-25-understanding-regression.html#regression-in-vector-space",
    "href": "posts/regression/2019-10-25-understanding-regression.html#regression-in-vector-space",
    "title": "Understanding Regression",
    "section": "Regression in vector space",
    "text": "Regression in vector space\n여기서 회귀 분석을 해설할 생각은 없다. 이미 너무나 많은 그리고 매우 훌륭한 내용들이 책, 웹, 강의로 넘쳐날테니까. 이 글의 용도는 그림 하나로 지나치기 쉬운 회귀 분석의 ’핵심’을 살피는 것이다. crossvalidated에서 아래 그림을 보는 순간 일종의 ’돈오돈수’가 강림했다. (이렇게 이해하면 쉬웠을 것을…)\n\n\n\n\n\n\n \n\n\n\n\n\n벡터 스페이스에 바라본 회귀 분석\n\n\n\n\n \n\n\n\n먼저 우리에게 익숙한 회귀 분석 모델을 매트릭스로 적어보자.\n\\[\n\\underset{n \\times 1}{\\phantom{\\mathbf \\gamma}\\mathbf{Y}\\phantom{\\mathbf \\gamma}} = \\underset{n \\times k}{\\phantom{\\mathbf \\gamma} \\mathbf{X} \\phantom{\\mathbf \\gamma} }\\underset{k \\times 1}{\\boldsymbol \\beta} + \\underset{n \\times 1}{\\phantom{\\boldsymbol \\beta} \\mathbf \\varepsilon \\phantom{\\mathbf \\gamma} }\n\\]\n식에 관한 자세한 설명 역시 생략한다. \\(n\\) 개의 관찰 수과 \\(k\\) 개의 독립변수를 지닌 중회귀 분석 모형이라고 생각하면 되겠다. 앞서 본 그림은 보통 회귀 분석의 예시로 많이 활용되는 아래 그림과는 다르다.\n\n\n흔히 \\(\\mathbf Y\\)를 종속변수, \\(\\mathbf X\\)를 독립변수로 부른다. 그대로 쓰도록 하자.\n\n\n\n\n\n\n \n\n\n\n\n\n독립변수 1개인 회귀 분석\n\n\n\n\n \n\n\n\n위 그림은 1개의 독립변수가 존재할 때 이것과 종속변수를 그대로 2차원 평면에 관찰 수만큼 찍은 것이다. 첫번째 그림에서 “Observed Y”는 점 하나가 종속변수 \\(n\\)개의 관측치를 포괄한다. \\(\\mathbf{Y} \\in {\\mathbb R}^{n}\\) 벡터, 즉 \\(n\\) 차원 벡터이고, 이것이 회귀식 좌변의 관찰값 \\(n\\) 개를 표현한다.\n이제 선형대수의 세계로 들어가보자. \\(\\mathbf X\\)의 하나의 열(column)이 \\(n\\) 개의 관찰 값을 지닌 독립변수이다. 이 각각의 컬럼 \\(x_i\\)는 \\(x_i \\in {\\mathbb R}^{n}\\) 벡터이다. \\(x_i\\) 벡터 \\(k\\) 개가 생성할 수 있는 공간이 \\(\\mathbf X\\)의 열 공간(column space)이다. 앞으로 이를 col \\(\\mathbf X\\)로 표기하자.\n\\(x_i \\in {\\mathbb R}^{n}\\) 벡터가 \\(k(&lt;n)\\) 개 있다고 하자. 이는 \\(n\\) 보다 차원이 낮기 때문에 기하학적으로는 \\(n\\) 차원 공간에서 초 평면(hyperplane)으로 나타날 것이다. 위 그림에서 컬럼 스페이스가 평면으로 표현되는 것은 이러한 취지다. 3차원 벡터의 열 공간이 생성하는 초 평면을 예시하면 아래와 같다. 즉 3차원 공간 안에 놓인 2차원 평면이다.\n\n\n\n\n\n\n \n\n\n\n\n\n2차원 컬럼 스페이스\n\n\n\n\n \n\n\n\ncol \\(\\mathbf X\\)의 최대 차원, 즉 \\(\\mathbf X\\)의 랭크(위수)는 무엇일까? 회귀 분석에서는 대체로 \\(n &gt; k\\)가 일반적이고 이런 상황에서 \\(\\mathbf X\\)의 랭크는 \\(k\\)를 넘을 수 없다. 다시 말하면, \\(\\mathbf X\\)가 생성하는(span)하는 컬럼 스페이스의 차원의 크기가 \\(k\\)를 넘을 수 없다. 그리고 잘 된 회귀 분석이라면 \\({\\rm rank}(\\mathbf X) = k\\)를 만족한다.\n맨 앞에 제시했던 그림을 다시 보자. 아래 색칠된 평면이 \\(\\mathbf X\\)가 생성하는 컬럼 스페이스, 즉 col \\(\\mathbf X\\)를 표현하고 있다. 몹시 특별한 경우가 아니라면 \\(\\mathbf Y \\in {\\mathbb R}^{n}\\) 벡터가 col \\(\\mathbf X\\)에 속할 가능성은 없다. 그렇다면 회귀 분석의 필요도 애초에 없었을 것이다. col \\(\\mathbf X\\)를 통해서 \\(\\mathbf Y\\)를 완벽하게 예측할 수 있는데 뭘 더 할까? 우리가 다루는 분석 문제는 \\(n\\) 차원 벡터를 \\(k\\) 차원 초 평면에 두기 힘든 상황이다.\n\n\n이를 선형 대수에서 배운 연립방정식을 푸는 문제로 이해해도 좋겠다. \\(A x = b(b \\neq \\mathbf{0})\\)라고 하자. \\(n\\) 개의 미지수가 유일한 해를 지니고 위해서는 \\({\\rm rank}(A) = n\\)이어야 한다. 즉 서로 독립인 식이 \\(n\\) 개 주어져야 고유의 해 \\(x\\)를 찾을 수 있다. 그런데 회귀 분석은 식이 \\(k(&lt;n)\\) 개만 주어진 상황이다.\n회귀 분석의 목표는 독립변수를 통해서, 더 정확하게는 독립변수의 열 공간이 생성하는 초 평면을 이용해서, 종속변수를 ‘가장’ 잘 설명하는 무엇을 찾는 것이다. 즉 회귀 분석이란 종속변수와 ‘닮은’ 것을 독립변수가 형성하는 초 평면 col \\(\\mathbf X\\)에서 찾는 것이다. 직관적으로 쉽게 떠올릴 수 있는 것은 이 평면과 \\(\\mathbf Y\\)의 (유클리드) 거리를 가장 짧게 만들어주는 벡터일 것이다. 그리고 이 최단거리는 \\(\\mathbf Y\\)에서 \\(\\mathbf X\\) 컬럼 스페이스로 내린 수선의 발이 닿는 col \\(\\mathbf X\\)의 지점이다. col \\(\\mathbf X\\) 내에 있는 이런 지점을 찾는 연산자(operator)가 회귀 분석의 추정 계수 \\(\\hat{\\boldsymbol \\beta}\\)이다. 즉,\n\\[\n\\hat{\\boldsymbol \\beta} = ({\\mathbf X}'{\\mathbf X})^{-1} ({\\mathbf X}' \\mathbf Y)\n\\]\n\n\n정석은 아니지만 이 연산자를 이해하는 흥미로운 방법이 있다.\n\\({\\mathbf X} {\\boldsymbol \\beta} \\equiv {\\mathbf Y}\\)가 연립방정식이라면 해는 \\({\\mathbf X}^{-1}\\)을 구해서 얻을 수 있을 것이다. 하지만 \\({\\mathbf X} \\in \\mathbb R^{n \\times k}\\)이므로 딱 떨어지는 특수해 1개를 구할 수 없다. 되도록 근사값의 해를 구하려면 어떻게 해야 할까?\n\\[\n\\begin{aligned}\n{\\mathbf X}'{\\mathbf X} \\hat{\\boldsymbol \\beta} & = {\\mathbf X}'{\\mathbf Y} \\\\\n\\hat{\\boldsymbol \\beta} & = ({\\mathbf X}'{\\mathbf X})^{-1}{\\mathbf X}'{\\mathbf Y}\n\\end{aligned}\n\\]\n\\(\\hat{\\boldsymbol \\beta}\\)가 왠지 원래 식의 근사값으로 기능할 것 같지 않은가? (실제로 그렇다)\n이 연산자를 독립변수의 모음인 col \\(\\mathbf X\\)에 적용하면 일종의 예측치 \\(\\mathbf{X} \\hat{\\boldsymbol \\beta}  =\\hat{\\mathbf Y}\\)이 산출된다. 그림에서 보듯이 \\(\\hat{\\mathbf Y}\\)은 \\(\\mathbf Y\\)와 col \\(\\mathbf X\\)의 거리를 최소화하는 위치에 존재한다. \\(\\hat{\\mathbf Y}\\)는 어떤 벡터일까? \\(\\hat{\\mathbf Y} \\in {\\mathbb R}^n\\) 벡터지만, col \\(\\mathbf X(\\in {\\mathbb R}^k)\\)내에 위치하고 있다. \\(n\\) 차원이 \\(k\\) 차원으로 축소된 셈이다. 이것이 회귀 분석의 기하적 핵심이다.\n선형 대수의 관점에서 내용을 다시 음미해보자. \\(x_i \\in {\\mathbb R}^n\\) (for \\(i = 1, \\dotsc, k\\)) 벡터의 리그레서 \\(k\\) 개를 선형 결합해서 초 평면의 한점, 즉 원래의 관찰 \\(\\mathbf Y\\)와 최소 거리를 지니는 벡터를 찾아야 한다. 이 거리를 최소화하는 \\(\\beta_i\\)를 알고 있다면 이 벡터는 다음과 같이 표현된다. \\({\\mathbf X} = [x_1, \\dotsc, x_k]\\)일 때,\n\\[\n\\begin{aligned}\n\\underset{(n \\times 1)}{\\hat{\\mathbf Y}} & = {\\mathbf X} {\\boldsymbol \\beta} \\\\\n& = [x_1, \\dotsc, x_k]\n\\begin{bmatrix}\n\\beta_1 \\\\\n\\vdots \\\\\n\\beta_k\n\\end{bmatrix} \\\\\n&=\nx_1 \\beta_1 + \\dotsc + x_k \\beta_k\n\\end{aligned}\n\\]\n위의 벡터 스페이스 그림을 다시 한 번 노려보시라. \\(\\beta_i\\)는 col \\(\\mathbf X\\)를 구성하는 벡터 \\(x_i\\)에 부여되는 선형 결합의 가중치를 의미한다."
  },
  {
    "objectID": "posts/regression/2019-10-25-understanding-regression.html#rm-r2은-피타고라스-정리의-응용일-뿐이다",
    "href": "posts/regression/2019-10-25-understanding-regression.html#rm-r2은-피타고라스-정리의-응용일-뿐이다",
    "title": "Understanding Regression",
    "section": "\\(\\rm R^2\\)은 피타고라스 정리의 응용일 뿐이다",
    "text": "\\(\\rm R^2\\)은 피타고라스 정리의 응용일 뿐이다\n이제 \\(\\mathrm R^2\\)의 의미를 살펴보자. 결론부터 이야기하면 \\(\\mathrm R^2\\)는 그림에서 \\((\\mathbf Y - \\overline{\\mathbf Y})\\) 벡터와 \\((\\hat{\\mathbf Y}-\\overline{\\mathbf Y})\\) 벡터가 이루는 각의 코사인 값, 즉 \\(\\cos \\theta\\)다. 잠깐! 왜 직접 거리를 재지 않고 코사인 값을 재는 것일까? 우리는 얼마나 가까운지를 판단하기 쉽지 않다. 그래서 가까운 정도를 상대적인 비율로 나타내면 좋을 것이다. 즉, 독립변수의 컬럼 스페이스에 위치한 \\(\\overline{\\mathbf Y}\\)를 기준으로 거리를 재는 셈이다. 이렇게 측정된 상대적인 거리가 \\(\\cos \\theta\\)이다. 이는 원점을 중심으로 두 벡터 사이의 코사인 값을 재는 코사인 유사도와 거의 같은 개념이다! 코사인 유사도란 길이가 서로 다른 두 벡터가 얼마나 비슷한지를 측정한다. 이를 응용하면 \\(\\mathrm R^2\\)란 관찰된 값(\\(\\mathbf Y\\))과 피팅된 값(\\(\\mathbf {\\hat Y}\\))이 얼마나 비슷한지를 측정한다.\n\n\n이런 면에서 보면, \\(\\mathrm R^2\\)에 코사인 유사도가 숨어 있는 셈이다. 두 벡터의 코사인 유사도란 개별 벡터가 지니고 있는 (유클리드) 길이와 관계 없이 벡터의 지향성을 중심으로 비슷한 정도를 파악하는 것이다. \\(\\mathrm R^2\\) 역시 마찬가지다.\n\\(\\overline{\\mathbf Y}\\)는 무엇일까? 포스팅의 맨 처음 보았던 그림과 같이 \\(\\overline{Y} \\mathbf{1}_n\\)로 표기할 수 있다. \\(\\mathbf Y\\)의 평균값 \\(\\overline{Y}\\)만으로 구성된 \\((n \\times 1)\\) 벡터다. 이 벡터는 col \\(\\mathbf X\\) 안에 있을까? 당연히 그렇다. \\(\\mathbf X\\)는 (이상적으로는) \\(k(&lt;n)\\) 차원의 벡터이고, \\(\\overline{\\mathbf Y}\\)는 1차원 벡터다. 따라서 col \\(\\mathbf X\\) 안 어딘가에 \\(\\overline{\\mathbf Y}\\)이 있다.\n\n\n왜 그런지 잠시 따져보자. 앞서 보았듯이 독립변수의 평면은 \\(\\alpha_1 x_1 + \\dotsb + \\alpha_k x_k\\) 와 같은 형태의 선형 결합을 통해 달성된다. 즉, \\(\\alpha_i\\)를 어떻게 잡는지에 따라서 \\(k\\) 차원까지 이 식을 통해서 생성할 수 있다. 그런데 \\(\\overline{\\mathbf Y}\\)는 1차원 즉, 모든 원소가 \\(\\overline{y}\\), 즉 \\(y\\)의 평균이다. 따라서 이를 만족하는 \\(\\alpha_i\\)(for \\(i = 1, \\dotsc, k\\))를 \\({\\rm col}~{\\mathbf X}\\)에서 반드시 찾을 수 있다.\n그렇다면 이 코사인 값의 의미는 무엇일까? 첫번째 그림에서 보듯이 세 개의 벡터가 직각삼각형을 이루고 있으므로 아래의 식이 성립한다.\n\\[\n\\underset{\\text{TSS}}{\\Vert \\mathbf Y - \\overline{\\mathbf Y} \\Vert^2} = \\underset{\\text{RSS}}{\\Vert \\mathbf Y - \\hat{\\mathbf Y} \\Vert^2} + \\underset{\\text{ESS}}{\\Vert \\hat{\\mathbf Y} - \\overline{\\mathbf Y} \\Vert^2}\n\\]\n흔한 피타고라스의 정리다. 그런데 이것 어디서 많이 보던 식이다. 회귀 분석 배우면 언제나 나오는 식이다. 종속변수의 평균과 종속변수의 총 제곱의 합(TSS: Total Sum of Squares)은 설명된 제곱의 합(ESS: Explained Sum of Squares)과 잔차 제곱의 합(RSS:Residual Sum of Squares)와 같다. 복잡해 보일 수도 있는 이 식은 기하학적으로 보면 그냥 피타고라스의 공식이다.\n양변을 \\(\\Vert \\mathbf Y - \\overline{\\mathbf Y} \\Vert^2\\)으로 나누면 다음과 같다.\n\\[\n1 =  \\dfrac{\\Vert \\mathbf Y - \\hat{\\mathbf Y} \\Vert^2}{\\Vert \\mathbf Y - \\overline{\\mathbf Y} \\Vert^2} + \\dfrac{\\Vert \\hat{\\mathbf Y} - \\overline{\\mathbf Y} \\Vert^2}{\\Vert \\mathbf Y - \\overline{\\mathbf Y} \\Vert^2}\n\\]\n정의에 따라서 \\(1 = \\dfrac{\\text{RSS}} {\\text{TSS}} +  {\\mathrm R}^2\\)가 된다. 즉,\n\\[\n  {\\mathrm R}^2 = 1 - \\dfrac{\\text{RSS}}{\\text{TSS}}\n\\]\n알스퀘어 \\(\\textrm R^2\\)이 종종 회귀 분석의 성과 지표로 활용되고는 한다. 기하학적으로 보면 col \\(\\mathbf X\\) 내에 표현된 \\(\\hat{\\mathbf Y}\\) 가 \\(\\mathbf Y\\)와 얼마나 가깝게 있는지를 \\(\\overline{\\mathbf Y}\\)를 기준으로 지표화한 것이다. \\({\\mathrm R}^2\\)는 회귀 분석의 성과 지표로 어떤 의미를 지닐까? 분석의 목표가 회귀 분석을 통한 예측이라면 즉 종속변수의 관찰값과 독립변수의 평면에서 예측한 값이 얼마나 떨어져 있는지 여부가 중요하다면 \\(\\textrm R^2\\)는 의미를 지닐 수 있다. 반면 분석의 목표가 특정한 독립변수가 종속변수에 미치는 인과 관계에 관한 것이라면 \\(\\textrm R^2\\)는 의미가 없다.\n아울러 회귀 분석이라는 이름을 달고 있지만 전형적인 회귀 분석의 방법을 따르지 않는 기법에서 \\(\\textrm R^2\\)가 정의되지 않는 경우도 있다. 잘 알려진 로지스틱 회귀가 이에 해당한다. 로지스틱 회귀에서 회귀 계수의 추정은 여기서 봤듯이 관찰과 col \\(\\mathbf X\\) 사이의 거리를 최소화하는 방식이 아니라 우도(likelihood)를 극대화하는 방식을 따른다. 따라서 벡터 공간의 최소 거리라는 개념에 기반한 \\(\\textrm R^2\\)를 로지스틱 회귀에서는 정의할 수 없다.\n\n\n궁여지책으로 이와 유사한 지표를 만들어낼 수는 있겠다. 여기를 참고하라."
  },
  {
    "objectID": "posts/regression/2019-10-25-understanding-regression.html#곁눈질-regression-vs-pca",
    "href": "posts/regression/2019-10-25-understanding-regression.html#곁눈질-regression-vs-pca",
    "title": "Understanding Regression",
    "section": "곁눈질: Regression vs PCA",
    "text": "곁눈질: Regression vs PCA\n회귀 분석과 PCA는 어떻게 다른가? 여러가지 답이 있을 수 있다. 그걸 다 소개하겠다는 게 아니다. 둘이 데이터 모델링의 시야에서 어떻게 다른지를 살펴보는 게 이 글의 목적이다. 이 글은 둘을 어떻게 실행하는지를 다루지 않는다. 앞선 PCA 관련 포스팅을 읽고 오시면 이해에 도움이 될 것이다.\n\n\n더 자세한 내용은 여기를 참고하자.\n\n공통점\n\nFeature\n일단 둘 다 \\(k\\) 개의 feature 비슷한 것을 지닌다. 그리고 \\(n\\) 개의 데이터 포인트가 제시된다.\n\n\n차원 축소\n흔히 PCA를 차원축소의 방법으로 이해하는데, 이 말은 맞다. 반대로 회귀 분석은 이와 다르다고 이해하는 경우가 많은데 이 말은 틀리다. 회귀 분석도 어떻게 보면 ’차원 축소’다. 회귀 분석에서 target 변수는 \\(n\\) 차원 공간 위의 주어진 한 점이다. 우리의 목표는 이 한 점을 잘 설명하는 더 낮은 차원의 어떤 지점을 찾는 것이다. 이런 점에서 본다면 회귀 분석 역시 차원 축소의 한 방법이라고 봐야 할 것이다.\n\n\n극소화\nPCA에서 ’분산 최대화’에 이르기까지 과정을 생략하다보면, PCA를 별도의 어떤 방법으로 인식하곤 한다. 그런데 앞선 포스팅에서 보았듯이 ’분산 최대화’란 사실 피처 벡터와 이를 예측하기 위한 어떤 벡터 사이의 거리를 최소화하는 과정에서 도출된 결과다. 이런 점에서 본다면, 회귀 분석이든 PCA는 MSE(Mean Square Error)를 최소화한다는 점에서는 목적 함수의 유형은 동일하다.\n\n\n\n차이점\n\nSupervised or Unsupervised?\n회귀 분석과 PCA를 지도 학습(supervised learning), 비지도 학습(unsupervised learning)으로 구분할 수는 없다. 다만 이 구분과 어느 정도 비슷한 부분이 있다. 회귀 분석은 target이 있다. 이 타겟과의 거리를 최소화하는 feature 공간의 어떤 위치를 찾는 것이 목적이다. 반면, PCA에는 target이 없다. \\(k\\) 개의 feature를 최소 거리로 투영할 수 있는 스크린 벡터를 찾는게 목적이다. 간단히 말해서 PCA는 target 없이 벡터의 거리가 1인 임의의 프로젝션 벡터를 찾는 것이 목적이다.\n\n\n\n벡터 스페이스에 바라본 회귀 분석\n독립변수 1개인 회귀 분석\n2차원 컬럼 스페이스"
  },
  {
    "objectID": "posts/regression/2022-06-06-berkson-paradox-regression.html",
    "href": "posts/regression/2022-06-06-berkson-paradox-regression.html",
    "title": "Berkson’s Paradox with Regression",
    "section": "",
    "text": "심슨의 역설과 마찬가지로 벅슨의 역설을 보통 회귀 분석으로 설명하지 않는다. 그런데 이 문제 역시 회귀 분석으로 보면 보다 명확해진다. 벅슨의 역설은 인과 추론에서 말하는 충돌 요인(collider)의 맥락에서 주로 발생한다. 정확히 말하면 벅슨의 역설은 변인의 통제 여부보다는 (인지하지 못하는) 표본의 제한성에서 비롯한다. 아쉽게도 벅슨의 역설을 예시하는 현실 데이터는 별로 없다. 여기서는 충돌 요인을 일으키는 플롯을 상정하고 이에 맞춰 가상의 데이터를 생성한다. 회귀 분석을 통해 이 데이터를 다시 음미하면서 벅슨의 역설을 살펴보도록 하자."
  },
  {
    "objectID": "posts/regression/2022-06-06-berkson-paradox-regression.html#회귀-분석으로-보는-벅슨의-역설",
    "href": "posts/regression/2022-06-06-berkson-paradox-regression.html#회귀-분석으로-보는-벅슨의-역설",
    "title": "Berkson’s Paradox with Regression",
    "section": "",
    "text": "심슨의 역설과 마찬가지로 벅슨의 역설을 보통 회귀 분석으로 설명하지 않는다. 그런데 이 문제 역시 회귀 분석으로 보면 보다 명확해진다. 벅슨의 역설은 인과 추론에서 말하는 충돌 요인(collider)의 맥락에서 주로 발생한다. 정확히 말하면 벅슨의 역설은 변인의 통제 여부보다는 (인지하지 못하는) 표본의 제한성에서 비롯한다. 아쉽게도 벅슨의 역설을 예시하는 현실 데이터는 별로 없다. 여기서는 충돌 요인을 일으키는 플롯을 상정하고 이에 맞춰 가상의 데이터를 생성한다. 회귀 분석을 통해 이 데이터를 다시 음미하면서 벅슨의 역설을 살펴보도록 하자."
  },
  {
    "objectID": "posts/regression/2022-06-06-berkson-paradox-regression.html#플롯",
    "href": "posts/regression/2022-06-06-berkson-paradox-regression.html#플롯",
    "title": "Berkson’s Paradox with Regression",
    "section": "플롯",
    "text": "플롯\n여기 적는 내용은 스토리텔링이지만 또 단순한 스토리텔링은 아니다. 코로나19와 흡연의 관계를 조사하기로 한 연구자가 있다고 하자. 그는 입원 환자의 자료를 살펴보고 놀라운 결론을 얻었다. 흡연하는 사람일수록 코로나 증세가 덜 심하다는 관계를 파악했다. 일반적인 통념과 반대되는 결론을 얻었던 것이다. 이것이 맞는 분석일까? 먼저 아래의 인과 다이어그램을 보자.\n\n\n이 연구는 코로나19 인식에 있어서 충돌 요인의 문제를 다양하게 지적하고 있다.\n\n\n\n\n\n\n \n\n\n\n\n\n입원 여부는 충돌 요인(collider)이 된다.\n\n\n\n\n \n\n\n\n담배를 많이 피울수록 혹은 그래왔을수록 코로나19 이외의 요인으로도 병원에 입원할 가능성이 높아진다. 또한 코로나 증세가 심할수록 병원에 입원할 가능성이 높아진다. 이 경우 병원에 입원한다는 변인이 두 요인(흡연의 정도, 코로나19 중증도) 모두에 영향을 받는 충돌 요인이 된다. 따라서 충돌 요인을 통제할 경우 흡연의 정도와 코로나19의 중증도 사이의 관계가 왜곡된다. 이러한 취지로 데이터를 생성해보도록 하자.\n\n\nCode\n# Basic packages\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\n# Stats models \nimport statsmodels.formula.api as sm\nimport statsmodels.stats.sandwich_covariance as sw\nimport statsmodels as statsmodels\n\ndef generate_unit_df(pack_of_cigar, n, sd=1, covid_threshold=2, cigar_threshold=6):\n\n    mean_of_severity_covid = pack_of_cigar * 0.3\n    mean_of_severity_cigar = pack_of_cigar * 1.4\n\n    df = pd.DataFrame(\n        {   \n            'pack_of_cigar': pack_of_cigar,\n            'covid_severity': np.random.normal(mean_of_severity_covid, 1, n),\n            'cigar_severity': np.random.normal(mean_of_severity_cigar, 0.5, n)\n        }\n    )\n    df = df.assign(\n        **{\n            'covid_severity': np.where(df['covid_severity'] &gt; 0, df['covid_severity'], 0), \n            'cigar_severity': np.where(df['cigar_severity'] &gt; 0, df['cigar_severity'], 0), \n            'is_hospitalized': np.where((df['covid_severity'] &gt; covid_threshold) | (df['cigar_severity'] &gt; cigar_threshold), \"Yes\", \"No\"),\n            'is_observed': np.random.uniform(0, 1, n)\n        }\n    )\n\n    df = df.query(\n            \"(`covid_severity` &lt;= 3.5)\"\n        )\n    df = df.query(\n            \"(`is_hospitalized` == 'Yes') | (`is_hospitalized` == 'No' & `is_observed` &lt;= 0.2)\"  \n    )\n\n    df = df.query(\n            \"(`is_hospitalized` == 'No' & `is_observed` &lt;= 0.2) | (is_observed &lt;= 0.5)\"\n    )\n\n    return df \n    \nres = pd.DataFrame()\n\nfor pack in np.linspace(0, 6, 60):\n    n = int(np.random.uniform(20, 40, 1)[0])\n    res = pd.concat([res, generate_unit_df(pack,n)])\n\n\n위의 플롯에 따라서 가상의 데이터를 생성했다. 코로나19 중증도는 흡연의 정도에 양의 영향을 받는다. 그리고 흡연의 정도는 별도로 건강에 악영향을 준다. 따라서 코로나19 중증도, 흡연의 정도 모두 해당 환자가 입원할 가능성을 결정하게 된다.\n\n\nCode\npalette = sns.color_palette(\"dark\")\n#sns.palplot(palette)\nplt.rcParams['figure.figsize'] = [8, 4]\nplt.style.use(\"fivethirtyeight\")# for pretty graphs\nsns.set(font_scale=0.7)\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\nsns.regplot(x = 'pack_of_cigar',y = 'covid_severity', data = res, ax=ax1, color='grey',scatter_kws={'alpha': 0.4})\n#\nfor i, value in enumerate(res['is_hospitalized'].unique()):\n    ax2 = sns.regplot(x=\"pack_of_cigar\", y=\"covid_severity\",\n                     #color=colors[value],\n                     #marker=markers[i],      \n                     scatter_kws={'alpha': 0.3 if value == \"Yes\" else 0.15},        \n                     data=res[res['is_hospitalized'] == value],\n                     label=value,\n                     ax = ax2)\n\nax2.legend(loc='best')\n\nax1.set_aspect(1.5); ax2.set_aspect(1.5)\n\n\n\n\n\n충돌 요인은 어떻게 작용하는가? pack_of_cigar는 흡연의 정도를 covid_severity는 코로나19 중증도를 의미한다.\n\n\n\n\n위의 왼쪽 그래프에서 보듯이 추출된 표본 전체에 대해서는 흡연의 정도와 코로나19의 중증도 사이에 양의 관계가 존재한다. 그런데 만일 충돌 요인인 입원 여부를 회귀 분석에서 통제하면 어떻게 될까? 오른쪽 그림에서 보듯이 병원에 입원한 환자에 대해서는 음의 상관성이 관찰된다. 왜 이럴까? 병원의 입원하는 변인은 코로나19의 중증도 이외에 흡연 정도에도 영향을 받는다. 흡연을 많이 할수록 코로나와 관계없이 그 자체로 입원할 가능성이 커진다. 흡연 정도가 낮을 경우 입원을 했다면 코로나19의 중증도에 따른 것일 가능성이 크다. 반면 흡연 정도가 높을 경우 코로나19 중증도는 상대적으로 다양한 상태를 지니게 되고, 따라서 평균적으로는 흡연 정도가 낮은 입원 환자에 비해서 낮은 코로나19 중증도를 지닐 수 있다.\n\nCode\nols1 = sm.ols(formula=\"covid_severity ~ pack_of_cigar\", data=res).fit(use_t=True)\nols2 = sm.ols(formula=\"covid_severity ~ pack_of_cigar + is_hospitalized\", data=res).fit(use_t=True)\nols3 = sm.ols(formula=\"covid_severity ~ pack_of_cigar + is_hospitalized\", data=res[res.is_hospitalized==\"Yes\"]).fit(use_t=True)\n#ols1.summary()\n#ols2.summary()\n\n#stargazer sucks \nfrom stargazer.stargazer import Stargazer\nstargazer = Stargazer([ols1, ols2, ols3])\nstargazer\n#regs = [ols1, ols2, ols3]\n#from statsmodels.iolib.summary2 import summary_col\n#print(summary_col(\n#                  regs,\n#                  stars=True, \n#                  float_format='%0.2f',\n#                  model_names=['(1)','(2)','(3)'],\n#                  info_dict={\n#                    'N':lambda x: \"{0:d}\".format(int(x.nobs)), \n#                    'F': lambda x: \"{0:.2f}\".format(x.fvalue),\n#                    }, \n#                  regressor_order=['Intercept','pack_of_cigar','is_hospitalized[T.Yes]#'])\n#    )\n\n\n\n\n \n\n\n\nDependent variable: covid_severity(1)(2)(3)\n\n\nIntercept0.474***0.646***2.540***\n(0.081)(0.076)(0.215)\nis_hospitalized[T.Yes]1.133***\n(0.105)\npack_of_cigar0.213***-0.022-0.182***\n(0.020)(0.028)(0.044)\n\n\nObservations572572341R20.1640.3070.047Adjusted R20.1630.3050.045Residual Std. Error0.870 (df=570)0.793 (df=569)0.873 (df=339)F Statistic112.101*** (df=1; 570)126.278*** (df=2; 569)16.876*** (df=1; 339)\nNote:*p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n \n\n\n\n회귀 분석에서 이러한 결과를 잘 확인할 수 있다. 회귀 분석에서 현실에 가장 근접한 분석은 회귀식 (1)이다. 입원 여부를 통제하게 될 경우(회귀식 (2))는 흡연의 정도가 코로나19의 중증도에 미치는 영향을 왜곡하게 된다. 벅슨의 역설의 극단적인 버전은 입원한 환자만 표본으로 삼아 분석을 실시하는 경우이다. 회귀식 (3)에서 보듯이 흡연의 정도와 코로나19 중증도의 정도가 가장 많이 왜곡된다.\n\n\n\\(\\mathrm R^2\\) 값을 무조건 분석의 성과 지표로 삼으면 안 되는 이유도 확인하고 지나가자. 충돌 요인 변수가 통제되면 \\(\\mathrm R^2\\)은 증가한다. 설명 변수가 늘어날수록 설명 변수의 차원이 높아지게 되므로 벡터 공간에서 잔차의 길이가 줄어들게 된다. 이는 동어 반복에 가깝다. 위에서 보듯이 \\(\\mathrm R^2\\)가 줄었으니 분석력이 더 높아진 것일까?\n벅슨의 역설은 생존자 편향(survivorship bias)과도 일맥상통한다. 유명한 아래의 그림을 다시 확인해보자. 살아 돌아온 비행기들이 맞은 부위는 오히려 보강이 필요하지 않은 부위다. 돌아오지 못한 비행기들은 현재 생존한 비행기들이 맞지 않은 부위 때문에 추락했을지 모른다.\n\n\n\n\n\n\n \n\n\n\n\n\nAbraham Wald가 했다는 전설적인 통찰의 사실 여부는 검증된 바 없다고 한다.\n\n\n\n\n \n\n\n\n\n\n\n입원 여부는 충돌 요인(collider)이 된다.\n충돌 요인은 어떻게 작용하는가? pack_of_cigar는 흡연의 정도를 covid_severity는 코로나19 중증도를 의미한다.\nAbraham Wald가 했다는 전설적인 통찰의 사실 여부는 검증된 바 없다고 한다."
  },
  {
    "objectID": "posts/machine-learning/2022-11-29-shannon-entropy.html",
    "href": "posts/machine-learning/2022-11-29-shannon-entropy.html",
    "title": "Shannon’s Entropy",
    "section": "",
    "text": "섀넌의 (정보) 엔트로피에 대해서 궁금했던 것들"
  },
  {
    "objectID": "posts/machine-learning/2022-11-29-shannon-entropy.html#tl-dr",
    "href": "posts/machine-learning/2022-11-29-shannon-entropy.html#tl-dr",
    "title": "Shannon’s Entropy",
    "section": "",
    "text": "섀넌의 (정보) 엔트로피에 대해서 궁금했던 것들"
  },
  {
    "objectID": "posts/machine-learning/2022-11-29-shannon-entropy.html#이-글은-왜-쓰나",
    "href": "posts/machine-learning/2022-11-29-shannon-entropy.html#이-글은-왜-쓰나",
    "title": "Shannon’s Entropy",
    "section": "이 글은 왜 쓰나?",
    "text": "이 글은 왜 쓰나?\n섀넌의 엔트로피는 일상적으로 쓰고 중요한 개념이지만 정작 그 개념의 핵심이 뭔지 잊을 때가 있다. 내가 지금 그 꼴이고 그래서 정리 삼아서 포스트를 하나 남겨 보겠다. 미리 밝혀두겠다. 섀넌의 엔트로피와 그 역사적 의미 등 대해서는 좋은 책도 많고 구글링을 하면 이 글보다 좋은 자료가 많이 나온다. 이런 부분을 여기서 반복하지는 않겠다.\n\n\n섀넌이 어떻게 이 개념을 “엔트로피”라고 이름 붙이게 되었을까? 일설에 따르면 섀넌은 ‘정보’ 혹은 ’불확실성’이라는 명칭이 여러 가지 이유로 적절하지 않다고 생각했다. 당시 섀넌이 조언을 구했던 폰 노이만이 이 개념을 “엔트로피”라고 불러야 한다고 말했다고 한다. 이유는 두 가지다. 우선 ’섀넌의 엔트로피’가 통계물리학에 이미 있는 개념이고 그 명칭이 “엔트로피”이다. 둘째, 이 개념을 제대로 아는 사람이 없을 것이므로 논쟁에서 네가 우위를 점할 수 있다. 츌처"
  },
  {
    "objectID": "posts/machine-learning/2022-11-29-shannon-entropy.html#정의",
    "href": "posts/machine-learning/2022-11-29-shannon-entropy.html#정의",
    "title": "Shannon’s Entropy",
    "section": "정의",
    "text": "정의\n섀넌의 정보 엔트로피 \\(H(X)\\)의 정의는 다음과 같다. \\(X\\)는 확률 변수라고 하자. \\(\\chi\\)는 적절한 임의의 가측 집합을 뜻하는데, 일단 넘어가도록 하자.\n\n\n약간을 사설을 늘어놓자면, 확률 변수는 사건으로 존재하는 실험 집합(sample space)을 실수 공간으로 옮겨 두는 함수다. 이렇게 옮겨진 실숫값은 확률 분포를 지니게 되고 이를 통해 여러 가지 계산을 도모할 수 있다.\n\\[\\begin{align*}\nH(X) &=  \\sum_{x \\in \\chi} p(x) \\log \\dfrac{1}{p(x)} = -\\sum_{x \\in \\chi} p(x) \\log p(x) \\\\\n     & = \\mathbb E [\\dfrac{1}{\\log p(x)}] = - \\mathbb E [\\log p(x)]\\\\\n\\end{align*}\\]\n\\(\\mathbb E(\\cdot)\\)의 표현이 보여주듯이 \\(H(X)\\)는 \\(\\log \\frac{1}{p(x)}\\)의 기댓값이다. 이 녀석을 먼저 들여다보자. \\(\\log \\frac{1}{p(x)}\\)는 확률 변수 \\(X\\)에서 \\(x\\)에 대응하는 사건이 일어날 확률이 주는 ’놀라움’의 크기로 해석할 수 있다. \\(p(x)=1\\)인 사건은 놀랍지 않다. 확실히 일어나는 사건이기 때문이다. 반면 일어날 확률이 높지 않은 사건은 놀라운 사건이다. 따라서 이러한 놀라움의 정도는 \\(\\frac{1}{p(x)}\\)로 측정할 수 있다. 여기에 계산의 편의성을 위해서 \\(\\log\\)를 취한다. 이렇게 계산된 기댓값이 섀넌의 엔트로피다.\n\n\n경제학에서 불확실성 하의 선택에서 사용하는 효용함수를 떠올려보자. 위험 기피적인 선호를 지닌 사람의 선호로 흔히 활용하는 것이 \\(\\log(\\cdot)\\)다. 불확실성 하의 선호를 처음 연구했던 사람이 폰 노이만와 모르겐스테른인데, 이들은 섀넌과 비슷한 시기에 활동했던 사람들이다. 모종의 평행이론일까?\n엔트로피, 즉 무질서의 정도라는 말이 함축하듯이 주어진 확률 변수의 구조가 무작위일수록 엔트로피가 클 것이다. 반면 확률 변수의 구조가 무작위에서 멀어질수록 엔트로피가 줄어든다. (공정한) 동전 던지기와 (공정한) 주사위 던지기를 생각해 보자. 어느 쪽이 엔트로피가 클까? 주사위 던지기 쪽이 크다. 확률이 각각 1/2, 1/6로 같다면 \\(H\\)를 결정하는 것은 \\(\\log_{2} {2}\\)과 \\(\\log_{2} {6}\\)이 된다. 보다 직관적으로 말해보자. 공정한 동전 던지기는 앞면 아니면 뒷면이다. 공정한 주사위는 6가지 경우의 수가 나온다. 후자의 불확실성, 즉 무질서한 정도가 더 크다."
  },
  {
    "objectID": "posts/machine-learning/2022-11-29-shannon-entropy.html#정보-엔트로피는-왜-유용할까",
    "href": "posts/machine-learning/2022-11-29-shannon-entropy.html#정보-엔트로피는-왜-유용할까",
    "title": "Shannon’s Entropy",
    "section": "정보 엔트로피는 왜 유용할까?",
    "text": "정보 엔트로피는 왜 유용할까?\n정보가 확률적으로 제공된다고 하자. 이 말은 정보를 일종의 확률 분포를 통해 이해하겠다는 뜻이다. 영어로 된 책이 한 권이 있다고 하자. 이 책에 들어 있는 알파벳의 분포를 떠올려 보자. 확률 분포로 본 정보가 어느 정도의 다양성을 지니고 있는지를 요약하는 지표가 섀넌의 엔트로피다. 이 정보가 왜 중요할까? 앞서 말한 책을 디지털로 인코딩하는 작업을 떠올려보자. 어떻게 하면 보다 효율적으로 책의 정보를 가공할 수 있을까? 구체적으로 예를 들어보자.\nABCD가 동일한 비율로 존재하는 정보가 있다고 하자. 이 정보를 디지털로 인코딩하려면 2비트를 사용하면 된다. 2비트로 인코딩할 수 있는 경우의 수가 4가지이기 때문이다. A는 00, B는 01, C는 10, D는 11로 인코딩할 수 있다.\n이제 (실제의 알파벳 정보가 그렇듯이) ABCD로 구성된 정보가 다른 분포를 지닌다고 해보자. A는 0.5, B는 0.25, C와 D는 0.125의 확률로 분포한다. 이 정보를 디지털로 인코딩하려면 얼마나 많은 비트를 사용해야 할까? 2비트로 할 수도 있지만 이는 일종의 낭비다. 70%가 A라면 이 녀석을 더욱 간단하게 인코딩하고 비트 크기를 아낄 수 있다. 예를 들어, A는 1, B는 01, C와 D는 각각 001, 000으로 인코딩한다고 해보자. 이 인코딩은 비트를 절약해줄까? 그렇다.\n\n\n비트를 왜 위와 같은 방법으로 쪼갰을까? 만일 두 자리로 고정된 비트를 인코딩에 활용한다면 마디에 대한 고민을 할 필요가 없다. 그러나, 위 사례처럼 정보를 아끼기 위해서 자리 수가 변하는 비트를 활용한다면 마디와 마디를 구별해야 한다. 이때 위와 같이 정보를 인코딩하면 마디 구분이 별도로 필요 없다. 앞 정보를 처리한 후 1 나오면 A다. 01이 들어오면 B이고 00이 나오면 다음 자리가 1인지 0인지에 따라서 C, D를 처리하면 된다.\n\\[\n1 * (0.5) + 2 * (0.25) + 3 * (0.125) + 3 * (0.125) = 1.75\n\\]\n2비트가 아니라 1.75 비트면 된다. 이렇게 절약된 비트는 자원의 절약을 뜻하기도 한다. 저장 공간을 떠올려도 좋고 통신이라면 오고 가는 전기 신호의 양으로 생각해도 좋겠다. 아래 두 개의 테이블을 비교해 보자. 계산의 편의를 위해서 로그의 밑수는 4로 잡았다.\n\n\n\n\n\n\n\n\n\n\n\n정보\n\\(p\\)\n\\(\\log_4 \\frac{1}{p}\\)\n\\(p \\log_4 \\frac{1}{p}\\)\n비트 표현\n비트수\n\n\n\n\nA\n0.25\n1\n0.25\n00\n2\n\n\nB\n0.25\n1\n0.25\n01\n2\n\n\nC\n0.25\n1\n0.25\n10\n2\n\n\nD\n0.25\n1\n0.25\n11\n2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n정보\n\\(p\\)\n\\(\\log_4 \\frac{1}{p}\\)\n\\(p \\log_4 \\frac{1}{p}\\)\n비트 표현\n비트수\n\n\n\n\nA\n0.5\n0.5\n0.25\n1\n1\n\n\nB\n0.25\n1\n0.25\n01\n2\n\n\nC\n0.125\n1.5\n0.1875\n001\n3\n\n\nD\n0.125\n1.5\n0.1875\n000\n3\n\n\n\n위 두 표에서 보듯이, 첫 번째 정보 묶음의 섀넌 엔트로피는 1이다. 두 번째 묶음의 섀넌 엔트로피는 0.875다. 후자가 전자보다 작다. 이는 정보의 분포에 따라서 엔트로피가 가장 무질서한, 즉 가장 클 때보다 효율적인 인코딩 방법이 존재함을 보여준다."
  },
  {
    "objectID": "posts/machine-learning/2022-11-29-shannon-entropy.html#cross-entropy",
    "href": "posts/machine-learning/2022-11-29-shannon-entropy.html#cross-entropy",
    "title": "Shannon’s Entropy",
    "section": "Cross Entropy",
    "text": "Cross Entropy\n크로스 엔트로피 역시 섀넌 엔트로피에서 파생된 개념이다. 크로스 엔트로피는 두 확률 분포의 차이를 측정하는 지표이다. 크로스 엔트로피는 다음과 같이 정의된다.\n\\[\nH(p,q)=-\\sum_{x \\in \\chi} p(x) \\log q(x)\n\\]\n섀넌 엔트로피의 개념에서 확률의 효용을 측정하는 값으로 예측 확률을 사용한다고 보면 되겠다. 즉, 실제로 존재하는 확률이 \\(p(x)\\)라고 할 때 이를 예측한 값이 \\(q(x)\\)라고 하면, 위의 값은 실제 확률과 비교한 예측 확률의 성과를 나타난다. \\(q(x) = p(x)\\)일 때 \\(H(p,q)\\)는 최솟값을 지니게 된다.\n크로스 엔트로피는 분류 문제를 풀 때 손실 함수로 많이 활용된다. 왜 그럴까? 이것이 이른바 그래이언트 소실(vanishing gradient) 문제이다. 흔히 손실 함수로 활용되는 오차제곱항에 비해서 크로스 엔트로피 손실 함수는 올바른 확률에서 멀리 떨어져 있을 때 기울기의 값이 훨씬 크다. 이는 값이 \\([0,1]\\)에 다 위치하고 있기 때문이다. 경사 하강법을 쓸 때 크로스 엔트로피 오차 함수일 때 훨씬 빠르게 원하는 위치로 접근한다.\n\n\n\n\n\n\n\n\n\n참값이 1일 떄\n\n\n\n\n \n\n\n\n\n\n참값이 0일 때\n\n\n\n\n\n\n \n\n\n오차 함수로 크로스 엔트로피를 사용할 때의 그래디언트와 오차 함수로 평균 제곱 오차를 사용할 때의 그래디언트를 비교해보자. 왼쪽은 참 값이 1이고, 오른쪽은 참 값이 0이라고 가정했을 때의 그래디언트를 나타낸다.\n\n\n \n\n\n\n이산 분포를 가정했을 때 \\(\\chi\\)를 전체 분류의 크기를 담은 첨수 집합이라고 하자. 이제 1이라는 종류만을 담은 참 값은 그림의 오른쪽과 같고, 반면 모델이 예측한 각 분류의 확률은 왼쪽이라고 하자. 이때 크로스 엔트로피는 아래 그림과 같이 계산될 수 있다. S는 \\(q(x)\\), T는 \\(p(x)\\)를 나타낸다.\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n기계학습에서 크로스 엔트로피와 관련된 내용은 statquest-cross entrophy를 참고하자.\n\n로지스틱 함수의 경우\n로지스틱 함수란 베르누이 분포(발생하거나 그렇지 않거나)를 지니는 사건의 확률을 표현하는 함수의 하나이다. 로지스틱 함수는 다음과 같이 정의된다.\n\\[\n\\sigma(x) = \\frac{1}{1+e^{-x}} = \\frac{e^x}{1+e^x}\n\\]\n로지스틱 함수가 편리한 이유는 \\(x\\)에 대해서 연속이고, \\((0,1)\\) 사이의 값이 매핑되기 때문에 확률값으로 근사해서 사용할 수 있다. 로지스틱 함수의 크로스 엔트로피를 구해보자.\n\\[\n\\begin{aligned}\nh(x) & = -p\\log(\\frac{e^x}{1+e^x}) - (1-p)\\log(1-\\frac{e^x}{1+e^x}) \\\\\n    & = \\log(1+e^x) - px\n\\end{aligned}\n\\]\n\\(h'(x)\\)의 값을 구하면 다음과 같다.\n\\[\nh'(x) = \\dfrac{e^x}{1+e^x} - p = \\sigma(x) - p\n\\]\n앞서 언급한 대로 \\(\\sigma(x)-p = 0\\)일 때 극대화 1계 조건이 완성된다. \\(h''(x) &gt; 0\\)이므로 1계 조건이 만족할 때 최솟값을 \\(H(x)\\)는 최솟값을 지니게 된다. 즉, 로지스틱 함수가 측정하는 발생 확률이 실제의 \\(p\\)와 일치할 때 크로스 에트로피가 최솟값이 된다.\n\n\n\n참값이 1일 떄\n참값이 0일 때"
  },
  {
    "objectID": "posts/stats-simple/2022-05-27-SE.html",
    "href": "posts/stats-simple/2022-05-27-SE.html",
    "title": "Sample Statistics and Standard Error",
    "section": "",
    "text": "\\[\n\\def\\E{{\\mathbb E}}\n\\def\\V{{\\mathbb V}}\n\\def\\ES#1{\\overline{#1}}\n\\]"
  },
  {
    "objectID": "posts/stats-simple/2022-05-27-SE.html#tl-dr",
    "href": "posts/stats-simple/2022-05-27-SE.html#tl-dr",
    "title": "Sample Statistics and Standard Error",
    "section": "TL; DR",
    "text": "TL; DR\n\n기본 통계학 용어와 개념 몇 개를 두서없이 내 맘대로 정리한다.\n자주 잊는 나를 위한 개인적인 용도"
  },
  {
    "objectID": "posts/stats-simple/2022-05-27-SE.html#why",
    "href": "posts/stats-simple/2022-05-27-SE.html#why",
    "title": "Sample Statistics and Standard Error",
    "section": "Why",
    "text": "Why\n통계학을 배운 사람들이라면 표준 오차는 대체로 잘 아는 내용이다. 그런데 나는 가끔 까먹는다. 개인적인 용도를 위해서 관련된 앞뒤 내용 몇 가지를 순서 없이 정리해둔다."
  },
  {
    "objectID": "posts/stats-simple/2022-05-27-SE.html#big-ifs",
    "href": "posts/stats-simple/2022-05-27-SE.html#big-ifs",
    "title": "Sample Statistics and Standard Error",
    "section": "Big Ifs",
    "text": "Big Ifs\n\n알려진 파라미터는 없다.\n알려진 분포도 없다.\n표본은 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2 &lt; \\infty\\)인 분포에서 IID(independent and identically distributed)로 추출된다."
  },
  {
    "objectID": "posts/stats-simple/2022-05-27-SE.html#finite-sample-vs-asymptotic-properties",
    "href": "posts/stats-simple/2022-05-27-SE.html#finite-sample-vs-asymptotic-properties",
    "title": "Sample Statistics and Standard Error",
    "section": "Finite Sample vs Asymptotic Properties",
    "text": "Finite Sample vs Asymptotic Properties\n“유한 표본 finite sample”이란 어떤 크기든 표본의 크기가 정해져 있다는 의미이다. 가끔 “소 표본 small sample”이라는 표현도 활용된다. “점근적 특성 asymptotic properties”이란 표본 크기가 계속 커질 때 추정량이 지니는 특성을 의미한다. 통계학을 배울 때는 유한 표본의 추정량(estimator)에 관해 먼저 엄밀하게 배운다. 통계학을 활용한다는 실용적인 관점에서 중요한 것은 추정량의 점근적 특징이다.\n점근성에 관해서 두 가지를 짚고 가자. 일치성은 샘플의 크기가 커질수록 추정량이 모수에 접근하는 특징이다. 다른 하나는 중심 극한 정리(central limit theorem)이다. 샘플의 크기가 커질수록 추정량의 분포가 정규 분포에 접근하게 된다. 일치성이 확보되면 추정량이 불편성을 지니고 있지 않아도 표본의 크기가 커질수록 참값에 충분히 가깝게 접근한다. 한편 중심 극한 정리는 추정량의 통계적인 검정을 위한 매우 중요한 방법을 제공한다. 아래에서 다시 살펴보기로 하자."
  },
  {
    "objectID": "posts/stats-simple/2022-05-27-SE.html#unbiasedness-efficiency-consistency",
    "href": "posts/stats-simple/2022-05-27-SE.html#unbiasedness-efficiency-consistency",
    "title": "Sample Statistics and Standard Error",
    "section": "Unbiasedness, Efficiency, Consistency",
    "text": "Unbiasedness, Efficiency, Consistency\n파라미터 \\(\\theta\\)와 이 모수에 관한 추정량 \\(\\hat \\theta\\)이 있다고 하자.\n\n\n표본 \\(x_i\\)가 있다고 할 때, \\(\\hat \\theta\\)는 표본 \\(x_i\\)라는 정보를 통해 구성된다. 즉, \\(\\hat\\theta \\equiv \\hat\\theta(x_i)\\).\nUnbiased \\[\n\\E(\\hat \\theta) = \\theta\n\\]\n불편성은 추정량의 중요한 특징이지만, 불편성만으로 충분하지 않다. 극단적인 예로 \\(X\\)에서 추출된 샘플 하나를 \\(x_1\\)라고 하자. 이 샘플 하나를 추정량으로 쓰면 이 역시 불편성을 지니고 있다 (\\(\\E(x_1) = \\theta\\)). 하지만 이 추정량은 좋은 추정량이 아니다.\nEfficiency\n\\(\\theta\\)에 대해서 \\(\\hat \\theta_1\\)과 \\(\\hat \\theta_2\\) 두 개의 추정량이 있다고 하자. \\[\n\\rm{Var} (\\hat\\theta_1) \\leq \\rm{Var} (\\hat\\theta_2)\n\\]\n모든 \\(\\theta\\)에 대해서 위의 부등식이 성립하고, 적어도 하나의 \\(\\theta\\)에 대해서 강 부등호가 성립하면 \\(\\hat\\theta_1\\)이 \\(\\hat\\theta_2\\)보다 효율적이다.\nConsistent\n표본의 크기에 따른 추정량의 시퀀스 \\(\\lbrace \\hat\\theta_n \\rbrace\\)이 있다고 할 때, \\[\n\\underset{n \\to \\infty}{\\rm plim}~\\hat\\theta_n = \\theta  \n\\]\n\n\n\n\n\n\n \n\n\n\n\n\n파라미터 값 4를 추정하기 위한 샘플 추정량; 샘플 크기가 증가하면서 4로 접근한다. 예시의 샘플 추정량은 biased된 추정량이다.\n\n\n\n\n \n\n\n\n\n\nplim의 정의는 다음과 같다. 표본 크기 \\(n\\)과 임의의 양의 상수 \\(c\\)에 대하여 표본 추정량 \\(\\hat\\theta_n\\)은 \\(\\theta\\)의 일치 추정량(consistent estimator)이라고 한다.\n\\[\n\\lim_{n\\to\\infty}P[|\\hat\\theta_n - \\theta|\\geq c]=0\n\\]"
  },
  {
    "objectID": "posts/stats-simple/2022-05-27-SE.html#concepts",
    "href": "posts/stats-simple/2022-05-27-SE.html#concepts",
    "title": "Sample Statistics and Standard Error",
    "section": "Concepts",
    "text": "Concepts\n\n\n\n\n\n\n\n\n\n용어\n영어 표현\n정의\n사례 혹은 코멘트\n\n\n\n\n모수\nparameter\n한 모집단의 고정된 특성 혹은 이를 나타내는 값\n\\(\\E[Y_i]\\), 분포의 \\(\\mu\\), \\(\\sigma^2\\)\n\n\n표본 통계량\nsample statistics\n표본에 따라서 변화하는 값\n\\(\\ES{Y}_n\\), \\(S(Y_i)^2\\), \\(SE\\), \\(\\widehat{SE}\\)\n\n\n표본 평균\nsample mean\n표본의 평균\n\\(\\ES{Y}_n = \\frac{1}{n}\\sum_{i=1}^n Y_i\\)\n\n\n표본 분산\nsample variance\n표본의 분산\n\\(S(Y_i)^2 = \\frac{1}{n-1}\\sum_{i=1}^n (Y_i - \\ES{Y}_n)^2\\)\n\n\n표준 오차\nstandard error\n표본 통계량의 표준 편차\n\\(SE(\\ES{Y}_n) = \\frac{\\sigma_Y}{\\sqrt{n}}\\)\n\n\n표준 오차의 추정치\nestimated standard error\n표준 오차 계산 시 \\(\\sigma_Y \\to S(Y_i)\\)\n\\(\\widehat{SE}(\\ES{Y}_n) = \\frac{S(Y_i)}{\\sqrt{n}}\\)\n\n\n\\(t-\\)통계량\n\\(t-\\)statistic\n\\(t(\\mu) = \\frac{\\ES{Y}_n - \\mu}{\\widehat{SE}(\\ES{Y}_n)}\\)\n\\(n\\)이 커질 때 정규분포에 근접"
  },
  {
    "objectID": "posts/stats-simple/2022-05-27-SE.html#sample-mean",
    "href": "posts/stats-simple/2022-05-27-SE.html#sample-mean",
    "title": "Sample Statistics and Standard Error",
    "section": "Sample Mean",
    "text": "Sample Mean\nIID 추출로 크기 \\(n\\)의 표본 \\(Y_1, \\dotsc, Y_n\\)을 얻었다고 하자. \\(Y_i\\)가 모평균 \\(\\mu\\)와 모 표준편차 \\(\\sigma\\)를 따른다. 표본 평균의 정의는 다음과 같다.\n\\[\n\\ES{Y}_n = \\sum_{i=1}^n Y_i.\n\\]\n표본 평균과 달리 \\(Y_i\\)의 기댓값, 즉 모평균은 \\(\\E (Y_i) \\equiv \\mu\\)라고 쓴다. 여기는 \\(n\\)이 붙지 않는다. 이는 모평균의 특성으로 일종의 고정된 (미지의) 값이다. 기댓값 \\(\\E(Y_i)\\)를 추정하는 값으로서 표본 평균 \\(\\ES{Y}_n\\)의 세 가지 특징을 알아보자.\n\n\\(\\E(\\ES Y_n) = \\mu\\)\n\\(\\V(\\ES Y_n) = {\\sigma^2}/{n}\\)\n\n\nUnbiasedness\n1에서 보듯이 \\(\\ES{Y}_n\\)은 불편 추정량이다.\n\n\nConsistency\n\\(n\\)이 증가하면 LLN에 따라서 \\(\\ES{Y}_n \\overset{P}{\\longrightarrow} \\mu\\)가 성립한다.\n\n\n\\(\\overset{P}{\\longrightarrow}\\)는 확률적인 수렴, 즉 앞서 정의를 살펴본 probability limit을 뜻한다. LLN은 약한 버전과 강한 버전이 있다. Kolmogorov의 강한 버전은 증명이 복잡하다. 약한 버전의 증명은 여기를 참고하자. Chebyshev 부등식과 \\(\\lim_{n \\to \\infty} \\V(\\ES{Y}_n) = 0\\)을 활용한다.\n\n\nCentral Limit Theorem\n\\[\nZ_n = \\lim_{n \\to \\infty} \\dfrac{\\ES{Y}_n - \\mu}{\\frac{\\sigma}{\\sqrt{n}}} \\sim \\rm N(0,1)\n\\]"
  },
  {
    "objectID": "posts/stats-simple/2022-05-27-SE.html#sample-variance",
    "href": "posts/stats-simple/2022-05-27-SE.html#sample-variance",
    "title": "Sample Statistics and Standard Error",
    "section": "Sample Variance",
    "text": "Sample Variance\n\\(\\sigma\\)의 추정량인 표본 분산 \\(S_n\\)는 다음과 같다.\n\\[\nS^2_n = \\dfrac{1}{n-1} \\sum_{i=1}^{n} (Y_i - \\ES{Y}_n)^2\n\\]\n\\(S^2_n\\)은 불편 추정량이고 일치 추정량이다. \\(n\\)이 충분히 크다면 불편 추정량 여부는 중요하지 않다. \\(\\dfrac{1}{10000}\\)과 \\(\\dfrac{1}{9999}\\)의 차이가 큰 의미가 있을까? 분모의 \\((n-1)\\) 대신 \\(n\\)이 들어간 표본 추정량 역시 일치성을 지니고 있다."
  },
  {
    "objectID": "posts/stats-simple/2022-05-27-SE.html#standard-errorse",
    "href": "posts/stats-simple/2022-05-27-SE.html#standard-errorse",
    "title": "Sample Statistics and Standard Error",
    "section": "Standard Error(SE)",
    "text": "Standard Error(SE)\n어떤 통계량의 표준 오차(Standard Error)는 표본 통계량의 표준 편차를 뜻한다. 표본 통계량 \\(\\ES{Y}_n\\)의 표준 편차 \\(\\sqrt{\\V(\\ES{Y}_n)}\\)을 의미한다. \\(\\sigma^2 &lt; \\infty\\)를 가정할 때,\n\\[\n\\E(\\ES{Y}_n - \\mu)^2 = \\E (\\dfrac{\\sum(Y_i -\\mu)}{n})^2 = \\dfrac{1}{n^2} n \\sigma^2 = \\dfrac{\\sigma^2}{n}\n\\]\n표준오차 SE는 다음과 같다.\n\\[\nSE = \\dfrac{\\sigma}{\\sqrt{n}}\n\\]\n\\(SE\\)의 추정량 \\(\\widehat{SE}\\)는 \\(\\sigma\\) 대신 \\(S_n\\)을 사용한다.\n\\[\n\\widehat{SE} = \\dfrac{S_n}{\\sqrt{n}}\n\\]"
  },
  {
    "objectID": "posts/stats-simple/2022-05-27-SE.html#asymptotically-normal",
    "href": "posts/stats-simple/2022-05-27-SE.html#asymptotically-normal",
    "title": "Sample Statistics and Standard Error",
    "section": "Asymptotically Normal!",
    "text": "Asymptotically Normal!\n가설 검정에 활용하는 \\(t-\\)통계량이 정규 분포에 근사하는 이유는 무엇일까?\n\\[\nt(\\mu) = \\frac{\\overline{Y}-\\mu}{\\widehat{SE}(\\overline{Y})}\n\\]\n\\(t-\\)통계량의 분자와 분모를 살펴보면 각각 \\(n\\)이 커질 때 분자와 분모는 모두 0으로 수렴한다. 이 비율이 정규분포에 수렴한다는 사실은 중심극한 정리를 이용해 증명할 수 있다. 일단 결론만 기억하도록 하자. 요컨대 \\(t\\)-통계량은 표본 크기 \\(n\\)이 증가하면서 표준 정규 분포에 근사하게 된다. 다시 말하면 추정량 \\(\\ES{Y}_n\\)은 평균이 \\(\\mu\\)이고 표준편차가 \\(\\frac{\\sigma}{\\sqrt{n}}\\)인 정규 분포에 근사하게 된다.\n\n\n\n\n\n\n \n\n\n\n\n\n\\(n\\)이 커질수록 \\(\\ES{X}_n\\)의 분포는 표준 정규 분포에 근접한다. \\(x_i\\)가 추출된 모집단의 분포를 찾는 것이 아니다. 우리에게 중요한 것은 추정량 \\(\\ES{X}_n\\)이고 이 녀석의 분포를 묘사하는 것이 CLT이다.\n\n\n\n\n \n\n\n\n\\(t-\\)통계량은 대 표본(large sample)의 통계적 검정에 기둥이다. 원래 자료가 어느 분포에서 나왔는지와 관계없이 표본 통계량을 활용하는 \\(t-\\)통계량은 정규 분포를 따르게 되고 이를 통해 가설 검정을 실시할 수 있다.\n\n\n회귀 분석의 검정 또한 \\(t-\\)통계량에 근거한다. 여기를 참고하도록 하자."
  },
  {
    "objectID": "posts/stats-simple/2022-05-27-SE.html#t-값은-해당-통계량의-통계적인-증거일-뿐이다",
    "href": "posts/stats-simple/2022-05-27-SE.html#t-값은-해당-통계량의-통계적인-증거일-뿐이다",
    "title": "Sample Statistics and Standard Error",
    "section": "\\(t\\)-값은 해당 통계량의 ‘통계적인’ 증거일 뿐이다",
    "text": "\\(t\\)-값은 해당 통계량의 ‘통계적인’ 증거일 뿐이다\n\\(t-\\)통계량의 크기는 검정을 위한 통계학적 증거일 뿐이다. 이 점을 잊지 말자. \\(t-\\)통계량의 형태에서 보듯이 분자가 충분히 크거나 혹은 분모가 충분히 작을 때 이 값이 커진다. 이는 신뢰 구간에 대해서도 마찬가지다. 신뢰 구간은 표준 오차에 반영되어 있는 통계적 정밀성에 의해 결정되지 우리가 발견하고자 하는 관계의 내용상 강도에 의해서 결정되지 않는다. 즉 \\(t-\\)통계량 및 신뢰 구간의 모습을 보고 해당 독립 변수가 종속 변수에 미치는 효과의 강도로 오해하면 곤란하다.\n울드리지 교수는 이를 통계적 유의성과 실용적 유의성의 차이로 설명한다. 통계적으로 유의미한 변수를 찾으면 우리는 대체로 기분이 좋아진다. 하지만 통계적으로 유의한 그 관계가 실용적으로도 그럴까? 만일 통계적 유의성을 지닌 계수가 사실상 의미가 없는 경우라면 어떨까? 책을 읽을 때 다리를 떨면 책을 읽는 속도가 통계적으로 유의미하게 0.1% 증가한다고 하자. 이는 사실상 의미 있는 결과일까? (책을 읽을 때는 열심히 다리를 떨어라?)"
  },
  {
    "objectID": "posts/stats-simple/2022-05-27-SE.html#more",
    "href": "posts/stats-simple/2022-05-27-SE.html#more",
    "title": "Sample Statistics and Standard Error",
    "section": "More",
    "text": "More\n이하의 내용은 딱히 필요하지는 않다. 관심이 있는 경우는 살펴보면 좋겠다.\n\n\\(S^2\\)을 \\((n-1)\\)로 나누는 이유\n\\(S^2\\)의 분모에 왜 \\((n-1)\\)이 들어갈까? 불편 추정량을 얻기 위해서다. 불편 추정량이란 해당 통계치의 기댓값이 모수가 되는 추정량을 의미한다. 직접 \\(S^2\\)의 기댓값을 구해보자. 먼저,\n\\[\n\\begin{aligned}\n\\sigma^2 = {\\rm Var}(x_i) & = \\mathbb E[(x_i - \\mu)^2] \\\\\n& = \\mathbb E [x_i^2 - 2 x_i \\mu + \\mu^2] \\\\\n& = \\mathbb E(x_i^2) - 2\\mu E(x_i) + \\mu^2 \\\\\n& =  \\mathbb E(x_i^2) - \\mu^2\n\\end{aligned}\n\\]\n\\(\\mathbb E(x_i^2) = \\sigma^2 + \\mu^2\\) 임을 기억해두자.\n이제 \\(S^2\\)의 기댓값을 구해보자. 분자 먼저 계산하자.\n\\[\n\\begin{aligned}\n\\mathbb E[\\sum(x_i - \\overline{x})^2] & = \\mathbb E[\\sum (x_i^2 - 2 x_i \\overline{x} + \\overline{x}^2)] \\\\\n& = \\mathbb E[\\sum x_i^2 - n 2 \\overline{x} \\cdot \\overline{x} + n \\overline{x}^2] \\\\\n& = \\mathbb E[\\sum x_i^2 - n \\overline{x}^2)] \\\\\n& = \\sum \\mathbb E(x_i^2) - n \\mathbb E(\\overline{x}^2)\n\\end{aligned}\n\\]\n합해지는 부분의 각각을 따져보자.\n\\[\n\\begin{aligned}\n\\sum \\mathbb E(x_i^2) = n (\\sigma^2 + \\mu^2)\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\mathbb E(\\overline{x}^2) & = \\mathbb E[(\\dfrac{x_1 + x_2 + \\dotsb + x_n}{n})^2] \\\\\n\\end{aligned}\n\\]\n\n\\(\\mathbb E[(\\dfrac{x_1 + x_2 + \\dotsb + x_n}{n})^2]\\)의 분자를 계산하면 된다. 먼저 각 \\(x_i\\)의 제곱이 \\(n\\)개 나온다. 다음으로 각각 \\(x_i\\)가 독립적으로 추출되었으므로 \\(i \\neq j\\)일 때 \\(\\mathbb E(x_i x_j) = \\mathbb E(x_i) \\mathbb E(x_j) = \\mu^2\\)이 된다. \\(n\\) 개 중에서 2개를 순서에 관계없이 뽑게 된다. 즉,\n\n\\[\n\\begin{aligned}\n\\mathbb E[(x_1 + x_2 + \\dotsb + x_n)^2]  & = n (\\sigma^2 + \\mu^2) + 2 \\dfrac{n(n-1)}{2!} \\mu^2 \\\\\n& = n \\sigma^2 + n^2 \\mu^2\n\\end{aligned}\n\\]\n따라서,\n\\[\n\\mathbb E(\\overline{x}^2)  = \\dfrac{\\sigma^2}{n} + \\mu^2\n\\]\n이제 각각을 넣어 계산을 완료하자.\n\\[\n\\begin{aligned}\n\\mathbb E[\\sum(x_i - \\overline{x})^2] & = \\sum \\mathbb E(x_i^2) - n \\mathbb E(\\overline{x}^2) \\\\\n& = n \\sigma^2 + n \\mu^2 - \\sigma^2 - n \\mu^2 \\\\\n& = (n-1) \\sigma^2\n\\end{aligned}\n\\]\n따라서 불편 추정량이 되기 위해서는 \\(S^2\\)의 분모에 \\((n-1)\\)이 필요하다.\n\n\n\\(S^2_n\\)의 일치성\n\\(S^2\\)의 일치성을 증명하는 데 필요한 내용을 알아보자. 엄밀한 증명은 생략하고 간략하게 아이디어만 적도록 하겠다. \\(\\sigma &lt; \\infty\\)를 가정하자. 이때\n\\[\n\\begin{aligned}\nS_n^2 & = \\dfrac{1}{n-1}\\sum_{i=1}^n (X_i - \\overline{X}_n) \\\\\n& = \\dfrac{n}{n-1}(\\dfrac{\\sum X_i^2}{n} - \\overline X_n) \\\\\n& \\stackrel{P}{\\longrightarrow} 1\\cdot(\\E(X^2)-\\mu^2) = \\sigma^2\n\\end{aligned}\n\\]\n위에서 보듯이 \\(S^2_n\\)이든 \\(\\dfrac{1}{n}\\sum_{i=1}^n (X_i - \\overline{X}_n)\\)이든 둘 다 일치 추정량이라는 것을 쉽게 알 수 있다.\n\n\n자세한 내용은 여기 책의 해당 부분을 참고하라.\n\n\n회귀 분석의 \\(t-\\)통계량\n회귀 분석의 계수의 표본 추정량 \\(\\hat \\beta\\)는 다음과 같다. \\[\n\\hat \\beta = (X^T X)^{-1}(X y)\n\\]\n\\[\nt_i = \\dfrac{\\hat \\beta_i - \\beta}{S \\sqrt{(X^T X)_{ii}^{-1}}}\n\\]\nwith\n\\[\nS(y_i)^2 = \\dfrac{1}{n-k} \\sum_{i=1}^n (y_i -  x^r_i \\hat\\beta)\n\\]\n\n\n여기서 \\(\\beta_k\\)는 중회귀 분석의 \\(k\\)–번째 계수를 뜻한다.\n\n\\(x^r_i\\): \\(X\\)의 \\(i\\)’th 행(row) 벡터\n\\(\\underset{(1 \\times k)}{x^r_i}\\underset{(k \\times 1)}{\\vphantom{x^r_i}\\hat\\beta} = \\hat y_i\\)\n\n회귀 분석의 \\(i\\)–번째 계수인 \\(\\beta_i\\)는 \\(t_i\\)를 통해 검정할 수 있다. \\(n\\)이 충분히 클 경우 \\(t_i \\sim \\rm N(0,1)\\)이 된다.\n\n\nCLT and LLN illustrated\nLLN과 CLT은 동전의 양면처럼 보이기도 한다. 아래 첫번째 그림에서 보듯이 \\([0,1]\\) 사이를 고정해서 보면 표본의 크기가 증가할수록 분산이 줄어들게 되고 추정량이 파라미터 주변으로 모이게 된다. 반면, 두번째 그림에서 보듯이, 표본의 크기에 따라서 \\(x\\) 축의 비율을 조절하면 분포가 점점 정규 분포를 닮아간다.\n\n\n\n\n\n\n \n\n\n\n\n\nLLN; \\(n\\)이 커짐에 따라서 평균값으로 모이는 현상이 발생한다. 위 그래프와 달리 \\(x\\) 축의 범위를 0, 1 사이로 고정했다.\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nCLT; 0, 1을 각각 0.8, 0.2의 확률로 갖는 베르누이 분포가 있을 때, 확률 변수의 샘플 크기가 커짐에 따라 표본 평균은 정규 분포를 닮아간다.\n\n\n\n\n \n\n\n\n\n\n\n파라미터 값 4를 추정하기 위한 샘플 추정량; 샘플 크기가 증가하면서 4로 접근한다. 예시의 샘플 추정량은 biased된 추정량이다.\n\\(n\\)이 커질수록 \\(\\ES{X}_n\\)의 분포는 표준 정규 분포에 근접한다. \\(x_i\\)가 추출된 모집단의 분포를 찾는 것이 아니다. 우리에게 중요한 것은 추정량 \\(\\ES{X}_n\\)이고 이 녀석의 분포를 묘사하는 것이 CLT이다.\nLLN; \\(n\\)이 커짐에 따라서 평균값으로 모이는 현상이 발생한다. 위 그래프와 달리 \\(x\\) 축의 범위를 0, 1 사이로 고정했다.\nCLT; 0, 1을 각각 0.8, 0.2의 확률로 갖는 베르누이 분포가 있을 때, 확률 변수의 샘플 크기가 커짐에 따라 표본 평균은 정규 분포를 닮아간다."
  },
  {
    "objectID": "posts/math-of/2019-12-11-Peron-Frobenus-1.html",
    "href": "posts/math-of/2019-12-11-Peron-Frobenus-1.html",
    "title": "Perron-Frobenius Theorem, part 1",
    "section": "",
    "text": "정칙 행렬(regular matrix)의 경우 페론-프로베니우스의 정리는 아이겐밸류와 아이겐벡터에 관해서 강력한 조건을 걸어준다.\n정칙 행렬의 경우 가장 큰 양의 유일한 실수 아이겐밸류가 존재하며, 이 값에 상응하는 아이겐벡터는 양이다.\n이 정리를 쓸모 있게 활용할 수 있는 사례는 마르코프 체인의 극한 분포다. 이때 가장 큰 아이겐밸류는 1이 되며, 좌 아이겐벡터와 우 아이겐벡터를 활용해 마르코프 과정의 극한 분포를 아이겐벡터로 손쉽게 구할 수 있다."
  },
  {
    "objectID": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#tl-dr",
    "href": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#tl-dr",
    "title": "Perron-Frobenius Theorem, part 1",
    "section": "",
    "text": "정칙 행렬(regular matrix)의 경우 페론-프로베니우스의 정리는 아이겐밸류와 아이겐벡터에 관해서 강력한 조건을 걸어준다.\n정칙 행렬의 경우 가장 큰 양의 유일한 실수 아이겐밸류가 존재하며, 이 값에 상응하는 아이겐벡터는 양이다.\n이 정리를 쓸모 있게 활용할 수 있는 사례는 마르코프 체인의 극한 분포다. 이때 가장 큰 아이겐밸류는 1이 되며, 좌 아이겐벡터와 우 아이겐벡터를 활용해 마르코프 과정의 극한 분포를 아이겐벡터로 손쉽게 구할 수 있다."
  },
  {
    "objectID": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#definitions",
    "href": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#definitions",
    "title": "Perron-Frobenius Theorem, part 1",
    "section": "Definitions",
    "text": "Definitions\n\npositive, nonnegative\n\n양(positive): 행렬의 모든 원소가 양의 값을 지닐 때\n비음(nonnegative): 행렬의 모든 원소가 비음일 때, 가 원래 정의다. 하지만 여기서는 “non-negative and non-zero”의 의미로 사용한다. 즉, 모든 원소가 비음이면서 행렬 혹은 벡터는 \\(\\mathbf 0\\)이 아니다. 즉, \\(z \\geq 0\\) with \\(z \\neq 0\\).\n\n벡터 \\(x\\), \\(y\\)가 있을 때 \\(x &gt; y\\)는 \\((x-y)\\)가 양이라는 뜻이다. 앞으로 벡터와 행렬에 대해서 \\(&gt;\\) 그리고 \\(\\geq\\)는 모두 원소-단위(element-wise)를 뜻한다."
  },
  {
    "objectID": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#basic-facts",
    "href": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#basic-facts",
    "title": "Perron-Frobenius Theorem, part 1",
    "section": "Basic facts",
    "text": "Basic facts\nFor \\(z \\geq 0\\),\n\nIf \\(A \\geq 0\\) then \\(A z \\geq 0\\).\nIf \\(A&gt;0\\) then \\(A z &gt; 0\\).\n\n역도 성립한다. 즉, if \\(Az &gt;(\\geq)\\;0\\), then \\(A &gt;(\\geq)\\;0\\)\n\nIf \\(x \\geq 0\\) and \\(x \\neq 0\\), \\(\\pi = (\\frac{1}{\\boldsymbol{1}^T x}) x\\)와 같은 표준화된 형태를 확률 분포로 활용할 수 있다.\n\n\\(\\pi\\) 벡터에 속하는 원소 \\(i\\)는 \\(\\pi_i = \\dfrac{x_i}{\\sum_j x_j}\\)."
  },
  {
    "objectID": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#regular-nonnegative-matrices",
    "href": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#regular-nonnegative-matrices",
    "title": "Perron-Frobenius Theorem, part 1",
    "section": "Regular nonnegative matrices",
    "text": "Regular nonnegative matrices\n\\(A \\in \\mathbb{R}^{n \\times n}\\) 그리고 \\(A \\geq 0\\)를 가정하자. \\(A\\)는 다음의 조건을 만족할 때 정칙 행렬(regular matrix)이라고 한다; 1보다 큰 정수 \\(k\\)에 대해서 \\(A^k &gt; 0\\)를 만족한다.\n\nA matrix for a graph\n노드들 간의 그래프 관계를 가장 쉽게 나타낼 수 있는 것이 행렬이다. 즉, \\(i, j \\in \\{ 1, 2, \\dotsc, n \\}\\) 일 때, \\(A_{ij}&gt;0\\)이면 \\(i \\to j\\)의 엣지를 그릴 수 있음을 나타낸다. 이때 \\((A^k)_{ij} &gt; 0\\)와 동치는 \\(i\\) 노드와 \\(j\\) 노드를 연결하는 길이 \\(k\\)의 경로가 존재함을 의미한다. 이때 \\(A\\)가 정칙 행렬이라는 가정의 의미는 무엇일까? 이는 모든 노드에서 다른 어떤 노드로 이동하는 임의의 \\(k\\) 길이의 경로가 항상 존재한다는 뜻이다.\n\n\nExamples\n\nNot regular 비정칙\n\\[\\begin{bmatrix} 1& 1 \\\\0& 1 \\end{bmatrix}\\]\n\\[\\begin{bmatrix} 0& 1 \\\\1& 0 \\end{bmatrix}\\]\n\n\nRegular 정칙\n\\[\\begin{bmatrix} 1& 1& 0 \\\\0& 0& 1\\\\ 1&0&0 \\end{bmatrix}\\]\n\n정칙 행렬이 아닌 경우에는 \\(A^k(k \\geq 1)\\)을 하더라도 같은 자리에 0이 남게 된다.\n\\(A\\)가 정칙 행렬이라면 \\(A \\geq 0\\)이더라도 \\(A^k &gt; 0\\)가 된다."
  },
  {
    "objectID": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#perron-frobenius-theorem",
    "href": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#perron-frobenius-theorem",
    "title": "Perron-Frobenius Theorem, part 1",
    "section": "Perron-Frobenius theorem",
    "text": "Perron-Frobenius theorem\n증명은 일단 생략하자. 그리 어렵지 않지만 페론-프로베니우스 정리 자체가 중요하기 때문에 이에 집중하겠다."
  },
  {
    "objectID": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#for-regular-matrices",
    "href": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#for-regular-matrices",
    "title": "Perron-Frobenius Theorem, part 1",
    "section": "For regular matrices",
    "text": "For regular matrices\n\\(A \\geq 0\\)이고 \\(A\\)가 정칙 행렬이면 아래를 모두 만족한다.\n\n아이겐밸류 \\(\\lambda_{\\rm pf}\\)는 실수이며 양이다.\n좌 아이겐벡터와 우 아이겐벡터 모두 양이다.\n다른 모든 아이겐밸류 \\(\\lambda\\)에 대해서, \\(\\lvert \\lambda \\rvert &lt; \\lambda_{\\rm pf}\\)\n아이겐밸류 \\(\\lambda_{\\rm pf}\\)의 근은 1개다.\n\\(\\lambda_{\\rm pf}\\)의 좌 아이겐벡터, 우 아이겐벡터는 유일하다(unique).\n\n물론 아이겐벡터는 아이겐스페이스에 속하므로 벡터 전체에 대한 스케일링이 가능하다. \\(\\lambda_{\\rm pf}\\)는 행렬 \\(A\\)의 페론-프로베니우스의 근(혹은 PF 아이겐밸류)라고 부른다.\n\nFor nonnegative matrices\n\\(A \\geq 0\\).\n\n아이겐밸류 \\(\\lambda_{\\rm pf}\\)는 실수이며 비음이다.\n\\(\\lambda_{\\rm pf}\\)의 좌 아이겐벡터, 우 아이겐벡터 모두 비음이다.\n다른 이외의 아이겐밸류가 존재한다면, 해당 아이겐밸류 \\(\\lambda\\)에 대해서, \\(\\lvert \\lambda \\rvert \\leq \\lambda_{\\rm pf}\\)\n아이겐밸류, 아이겐벡터는 유일하지 않다."
  },
  {
    "objectID": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#markov-chain",
    "href": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#markov-chain",
    "title": "Perron-Frobenius Theorem, part 1",
    "section": "Markov chain",
    "text": "Markov chain\n페론-프로베니우스 정리가 가장 아름답게 활용되는 사례는 마르코프 체인 모델이다. 확률 과정(stochastic process) \\(X_0, X_1, \\dotsc, X_n\\)이 아래와 같은 과정을 따른다고 하자.\n\\[\n{\\rm Prob}(X_{t+1} = j \\vert X_t =i) = p_{ij}\n\\]\n즉, 이는 \\(i \\to j\\)의 확률, 즉 \\(i\\) 상태에서 \\(j\\) 상태로 옮겨갈 확률을 의미한다. 마르코프 체인의 특징은 \\((t+1)\\) 기의 상태를 결정하는 것은 오직 \\(t\\) 기의 상태다. 즉, \\(t-k\\) for \\(k=1, \\dots, t\\) 는 \\((t+1)\\)의 상태를 결정하는 데 영향을 주지 않는다. \\(P\\)는 이행 행렬(transition matrix) 혹은 확률 행렬(stochastic matrix)라고 부른다.\n\\[\nP =\n\\begin{bmatrix}\np_{11}& p_{12}& \\dotsc& p_{1n} \\\\\np_{21}& p_{22}& \\dotsc& p_{2n}  \\\\\n\\vdots &\\vdots&\\ddots&\\vdots \\\\\np_{n1}& p_{n2}& \\dotsc& p_{nn}\n\\end{bmatrix}\n\\]\n\\(P\\)의 각 행의 합은 1이 된다는 점을 새겨두자. \\(t\\) 기에 \\(i\\) 상태에 있었다면, \\((t+1)\\) 기에는 \\(1, 2, \\dotsc, n\\) 중 어느 하나로는 상태를 변경해야 한다.\n행 벡터 \\(p_t \\in \\mathbb{R}^n\\) 를 \\(X_t\\)의 분포라고 하자.\n\\[\n{(p_t^T)}_i = {\\rm Prob}(X_t = i)\n\\]\n를 의미한다. 즉, \\(t\\) 기에 \\(i\\) 상태가 실현될 혹은 존재할 확률이다. \\((t+1)\\) 기의 확률 분포를 벡터로 표현하면 다음과 같다. \\(p_{t+1} = p_t P\\).\n확률 행렬를 활용해서 마르코프 체인의 문제를 어떻게 풀까? 일단 적당한 형태의 확률 행렬 \\(P\\)가 있다고 하자. 즉 \\(P\\)는 비음이고 \\(P^k &gt; 0\\)이 성립한다(즉, \\(P\\)는 정칙 행렬). \\(P\\)에 페론-프로베니우스의 정리를 적용할 수 있다! 즉,\n\n아이겐밸류 \\(\\lambda_{\\rm pf}\\)는 실수이고 양수이며 유일하다.\n좌 아이겐벡터, 우 아이겐벡터 모두 양수이고 유일하다(unique).\n\\(\\lambda_{\\rm pf}\\)를 제외한 다른 모든 아이겐밸류 \\(\\lambda\\)에 대해서, \\(\\lambda_i &lt; \\lambda_{\\rm pf}\\) for \\(i \\neq {\\rm pf}\\).\n\n\\(P\\)라는 확률 과정에 대해서 아래의 두 사실을 증명하도록 하자.\n\n아이겐밸류 1이 존재한다.\n1이 가장 큰 유일한 아이겐밸류, 즉 \\(\\lambda_{\\rm pf} = 1\\).\n\n이것이 증명되면 마르코프 체인의 극한 분포를 찾는데, 페론-프로베니우스의 정리를 활용할 수 있다.\n\nEigenvalue 1 exists!\n1의 아이겐밸류가 존재한다. 어떻게 알 수 있을까?\n\\[\nP {\\boldsymbol 1}_n = (1){\\boldsymbol 1}_n\n\\]\n확률 행렬 \\(P\\)에 대해서 모든 원소가 1인 \\(n\\) 차원의 열 벡터 \\({\\boldsymbol 1}_n\\)에 관해서 위의 식이 당연히 성립한다. 즉, 확률 행렬 \\(P\\)의 우 아이겐벡터는 \\({\\boldsymbol 1}_n\\)이고 그때의 아이겐밸류는 \\(1\\)이다. 그러면 아이겐밸류 1에 해당하는 좌 아이겐벡터 \\(\\pi\\) 가 존재한다고 하자. 이를 적으면 다음과 같다.\n\\[\n\\pi P = \\pi (1)\n\\]\n만일 \\(1\\)이 아이겐밸류 중에서 가장 큰 값이라면, 페론-프로베니우스의 정리에 따라서 아이겐밸류 1에 해당하는 유일한 좌 아이겐벡터 \\(\\pi\\)가 존재한다. 이 좌 아이겐벡터는 아이겐벡터의 특성을 지니고 있다. 즉, 어떤 상태 \\(\\pi\\)에서 한번의 확률 과정을 거치더라도 여전히 그 상태에 머물러 있게 된다. \\(\\pi\\)는 일종의 균형 상태로 해석할 수 있다.\n\n\n1 is the largest eigenvalue!\n페론-프로베니우스의 정리에 따라서 아이겐밸류 1이 가장 큰 아이겐밸류라면, 이에 상응하는 아이겐벡터 \\(\\pi\\)는 양이며 유일하다. \\(\\pi\\)는 스케일링이 가능하기 때문에 스케일링을 거치면 \\(P\\)에 의해 표현되는 마르코프 체인 확률 과정의 무한 반복, 즉 \\(P^\\infty\\)가 수렴하는 유일한 분포가 된다. 어떻게 증명할까? 생각보다 쉽다.\n\n\nProof\n만일 1 이외의 아이겐밸류 \\(\\hat \\lambda &gt; 1\\)가 존재한다고 하자. 이제 어떤 열 벡터 \\(x\\)에 속하는 최대값을 \\(x_{\\max}\\)라고 하자. 이때 \\(P x\\)의 결과 생산되는 열 벡터의 각 원소는 \\(x_i\\) for \\(i = 1, 2, \\dotsc, n\\)의 컨벡스 결합이다. 따라서 \\(Px = x^c\\)에 속한 어떤 원소 \\(x_i^c\\)도 \\(x_{\\max}\\) 보다 클 수 없다. 즉,\n\\[\nx^c_i \\leq x_{\\max}\n\\]\n\n\n\\(p_{i1} x^c_1 + p_{i2} x^c_2 + \\dotsb + p_{in} x^c_n\\) with \\(p_{i1} + p_{i2} + \\dotsc + p_{in} =1\\) for \\(i = 1, 2, \\dotsc, n\\)\n그런데 \\(P x = \\hat \\lambda x\\)가 성립하고 \\(\\hat \\lambda &gt;1\\)이기 때문에, \\(x_{\\max} \\hat \\lambda &gt; x_{\\max}\\)가 성립해야 한다. 즉 모순이다. 귀류법에 따라서 \\(\\lambda \\leq 1\\)이고, 이때 아이겐밸류의 최대값은 1이다. 즉, 페론-프로베니우스의 근 \\(\\lambda_{\\rm pf} = 1\\)이다.\n확률 행렬 \\(P\\), 아이겐밸류 1에 상응하는 좌 아이겐벡터 \\(\\pi^*\\)라고 하자. 페론-프로베니우스의 정리 활용하면 아래와 같다.\n\n좌 아이겐벡터 \\(\\pi^*\\)는 유일하고, 모든 원소는 실수이며 양이다.\n이를 적절하게 스케일링하면 분포가 된다.\n마르코프 체인의 초기 상태와 무관하게 확률 과정을 반복할수록 이 분포에 수렴한다.\n\n보통 마르코프 체인을 설명할 때 좌 아이겐밸류와 우 아이겐밸류를 구별하지 않는 경우가 있다. 이는 여러모로 손해다. 위에서 보듯이, 수렴 분포를 증명하는 과정에서 유용하게 활용된다.\n\n\n행의 합을 1로 할지, 열의 합을 1로 할지는 이행 확률을 어떻게 정의할지 나름이다. \\(P\\)의 정의를 확인하고, 위와 같이 정의한 경우라면 1에 대응하는 좌 아이겐벡터가 극한 수렴 분포가 된다. 반대로, 확률 행렬을 \\(P^T\\)로 정의했다면 우 아이겐벡터가 극한 분포이다.\n\n\nDefinition of limiting distribution\n확률 분포 \\(\\pi = [\\pi_0, \\pi_1, \\pi_2, \\dotsc, \\pi_k]\\)는 아래 조건을 만족할 때 마르코프 체인 \\(P_n\\)의 극한 분포라고 부른다. 만일\n\\[\n\\pi_j = \\lim_{n \\to \\infty} P(X_n = j | X_0 = i) ,~\\forall i, j \\in S\n\\]\n이고\n\\[\n\\sum_{j \\in S} \\pi_j = 1.\n\\]\n몇 가지 점만 확인해보자.\n\n극한 분포는 초기 상태에 의존하지 않는다.\n만일 극한 분포가 존재한다면, 아래 같은 식이 성립한다.\n\n\\[\n\\lim_{n \\to \\infty} P^n =\n\\begin{bmatrix}\n\\pi \\\\\n\\vdots \\\\\n\\pi\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#limiting-behavior-of-markov-chain",
    "href": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#limiting-behavior-of-markov-chain",
    "title": "Perron-Frobenius Theorem, part 1",
    "section": "Limiting Behavior of Markov Chain",
    "text": "Limiting Behavior of Markov Chain\n마르코프 체인은 어떻게 \\(\\pi^*\\)로 수렴하게 될까? 확률 행렬 \\(P\\)의 아이겐밸류 \\(1 = \\lambda_1 &gt; \\lambda_2 \\geq \\dotsc \\geq \\lambda_n &gt; 0\\), 각각에 대응하는 아이겐벡터를 \\(v_1, v_2, \\dotsc, v_n\\)이라고 하자. 아이겐벡터가 각각 선형독립이라고 가정하자. 이때 아이겐벡터로 구성된 \\(Q\\)는 가역(invertible) 행렬이다.\n\\(\\pi^T_t  = Q y_t\\) 로 나타낼 수 있다. 즉 \\(Q\\)의 선형결합을 통해 \\(n\\) 차원의 임의의 벡터를 표현할 수 있다. \\(\\pi\\)가 열 벡터이기 때문에 이를 행 벡터로 바꿨다는 점에 유의하자. 한편,\n\n\n사실 기존의 \\(\\pi\\)가 좌 아이겐벡터였다면 여기서는 이를 우 아이겐벡터로 바꾼 것이다. 물론, 확률 행렬 역시 \\(P^T\\)가 되어야 한다.\n\\[\n\\begin{aligned}\n\\pi_{t+1}^T & = P^T \\pi_t^T \\\\\nQ y_{t+1} & = P^T Q_{t} y_t \\\\\nQ^{-1} Q y_{t+1} & = Q^{-1}P^T Q_{t} y_t \\\\\ny_{t+1} & = D y_t\n\\end{aligned}\n\\]\n두 가지를 상기하자.\n\n행렬 \\(A\\)와 전치 행렬 \\(A^T\\)는 동일한 아이겐밸류를 지니게 된다.\nD는 아이겐밸류로 구성된 대각행렬이다. 편의상 크기 순서대로 나열되어 있다고 하자.\n\n\n\n\\(\\det(A^T−\\lambda I) = \\det((A−\\lambda I)^T)=\\det(A−\\lambda I)\\)\n앞서 본 바에 따라서 \\(\\lambda_1 =1\\)이다.\n\\[\ny_t =\n\\begin{bmatrix}\n\\lambda_1& \\dotsc& 0 \\\\\n\\vdots& \\ddots& \\vdots \\\\\n0& \\dotsc& \\lambda_n\n\\end{bmatrix} y_{t-1}.\n\\]\n이 차분방정식의 해는 아래와 같다.\n\\[\ny_t =\n\\begin{bmatrix}\n\\lambda_1& \\dotsc& 0 \\\\\n\\vdots& \\ddots&\\vdots \\\\\n0& \\dotsc& \\lambda_n\n\\end{bmatrix}^t y_{0} =\n\\begin{bmatrix}\n\\lambda_1^t& \\dotsc& 0 \\\\\n\\vdots& \\ddots& \\vdots \\\\\n0& \\dotsc& \\lambda_n^t\n\\end{bmatrix} y_0\n\\]\n\\(y_0 = [c_1, \\dotsc, c_n]^T\\)라고 두면, \\(y_t = [c_1 \\lambda_1^t, \\dotsc, c_1 \\lambda_n^t]^T\\)가 된다. \\(Q = [v_1, \\dotsc, v_n]\\)가 아이겐벡터 \\(v_i\\)로 구성된 매트릭스라고 할 때, \\[\n\\pi_t^T \\equiv Q y_t = c_1 \\lambda_1^t v_1 +  \\dotsb + c_1 \\lambda_n^t v_n.\n\\]\n이제 \\(t \\to \\infty\\)를 적용해보자. \\(\\lambda_i &lt; \\lambda_1 = 1\\) for \\(i = 2, 3, \\dotsc, n\\)이므로, \\(\\pi_{\\infty}^T = c_1 v_1\\)가 된다. \\(v_1\\)이 표준화된 확률 분포 벡터이므로 \\(c_1 =1\\)이어야 한다."
  },
  {
    "objectID": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#appendix-irreducibility-and-aperiodicity",
    "href": "posts/math-of/2019-12-11-Peron-Frobenus-1.html#appendix-irreducibility-and-aperiodicity",
    "title": "Perron-Frobenius Theorem, part 1",
    "section": "Appendix: Irreducibility and Aperiodicity",
    "text": "Appendix: Irreducibility and Aperiodicity\n마르코프 체인이 수렴하는 분포를 갖게 될 조건으로 보통 두 가지 조건, 기약성(irreducibility) 그리고 비주기성(aperiodicity)이 제시된다. 먼저 간단히 둘의 내용을 살펴보자.\n\nIrreducible matrix\n기약성의 정의는 아래와 같다.\n\\(P\\)가 확률 행렬이라고 할 때, 상태 \\(x\\), \\(y\\)에 대해서 양의 실수 \\(j\\), \\(k\\)가 존재하면, 두 상태는 서로 교류할 수 있다고 칭한다.\n\\[\nP^j (x, y) &gt; 0~~\\text{and}~~P^k(y,x) &gt; 0\n\\]\n이 정의의 의미는 무엇일까? 일정한 상태를 거치면 \\(x \\to y\\) 그리고 \\(y \\to x\\)로 옮기는 것이 확률적으로 가능하다는 뜻이다. 기약성이란 모든 상태가 교류할 수 있는 상태를 뜻한다. 다시 말하면 어떤 상태에 들어가서 여기서 빠져나올 수 없는 경우가 발생한 가능성이 없을 때 기약성이 성립한다.\n\nIrreducible\n\\[\\begin{bmatrix} 0.9& 0.1& 0.0 \\\\0.4& 0.4& 0.2\\\\ 0.1& 0.1& 0.8 \\end{bmatrix}\\]\n\n\nReducible\n\\[\\begin{bmatrix} 1.0& 0.0& 0.0 \\\\0.1& 0.8& 0.1\\\\ 0.0& 0.2& 0.8 \\end{bmatrix}\\]\n\n\n\nAperiodic matrix\n대충 말하면 마르코프 체인 위의 이동이 예측 가능한 형태로 이루어질 수 있으면 안된다. 먼저 예를 보도록 하자.\n\\[\\begin{bmatrix} 0& 1& 0 \\\\0& 0& 1\\\\ 1& 0& 0 \\end{bmatrix}\\]\n\n각 상태가 일정한 간격으로 존재하게 된다. 즉,\n\n1번, 2번, 3번 상태는 \\(\\{ k, k+3, k+6, \\dotsc \\}\\) 번째에 존재하게 된다.\n\n주기성(periodicity)의 수학적인 정의는 다음과 같다.\n\\[\nk = {\\rm gcd} \\{ n &gt; 0~|~{\\rm Pr}(X_n = i | X_0 = i) &gt; 0 \\}\n\\]\ngcd란 greatest common divisor, 즉 최대공약수를 의미한다. 만일 해당 상태로 \\(\\{ 6, 8, 12, \\dotsc \\}\\) 번에 돌아갈 확률이 양이라면, gcd는 2가 된다.\n\n\n확률 행렬의 원소가 0, 1로만 되어 있지 않아도 주기 행렬이 될 수 있다는 사실에 유의하자.\n이때 \\(k &gt; 1\\)이면 주기 행렬이고 \\(k=1\\)이면 비주기 행렬이다. \\(k=1\\)의 의미는 무엇일까? \\(t\\) 기에 상태 \\(s\\)에 있을 때, \\(t+1\\) 기에 역시 \\(s\\)에 있을 확률이 양이라는 뜻이다. 그리고 확률 행렬을 구성하는 모든 상태에 주기성이 없을 때, 이러한 확률 행렬을 비주기 행렬이라고 한다.\n\n\nRegular matrix vs irreducible and aperiodic matrix\n페론-프로베니우스 정리에 따르면 정칙 행렬일 때 극한 분포가 존재하게 된다. 정칙 행렬과 기약 행렬, 비주기 행렬 사이의 수학적 관계는 어떨까? 결론부터 말하면, 둘은 동치다. 증명은 간단하다.\n\nA: 정칙 행렬\nB: 기약 행렬이면서 비주기 행렬\n\n\nA → B\nIrreducible\n정칙 행렬이면 \\(P^k &gt; 0\\)이다. \\(P^{k+1}\\)의 \\(i\\) 행 \\(j\\) 열의 원소는 다음과 같다.\n\\[\np_{ij}^{k+1} = \\sum_{t=1}^{n} p_{it} p_{tj}^k &gt; 0\n\\]\n위의 식이 성립하는 이유는 정칙 행렬의 경우 적어도 하나의 \\(t\\)에 관해서 \\(p_{it} &gt; 0\\)이 성립해야 한다. 만일 이것이 성립하지 않으면 정칙 행렬이 될 수 없다. 즉, \\(P^{k+1} &gt;0\\)이고, \\(P^{k+2}, P^{k+3}, \\dotsc\\)모두 양이다.\nAperiodic\n\\(\\{k ,k+1, k+2, \\dotsc\\}\\)의 gcd는 1이다.\n\n\nA ← B\n기약 행렬이면 언제나 정칙 행렬이다.\n\n\n\nComments\nIrreducible and aperiodic\n만일 확률 행렬이 기약이면 이때 비주기성 여부를 어떻게 확인할까? 행렬이 기약 행렬이라면, 해당 행렬을 구성하는 하나의 상태만 비주기성을 지니면 전체 행렬이 비주기성을 지닌다. 증명은 조금만 생각해보시라.\nWhy Aperiodicity?\n극한 분포 존재에 비주기성은 왜 필요할까? 만일 이 조건이 성립하지 않으면 극한 분포로 계산된 것이 사실은 극한 분포라고 할 수 없게 된다. 즉,\n\\[\n\\lim_{n \\to \\infty} P^n  \\neq\n\\begin{bmatrix}\n\\pi \\\\\n\\vdots \\\\\n\\pi\n\\end{bmatrix}.\n\\]\n예를 들어보자. 상태 2개이고 확률 행렬이 아래와 같다고 하자.\n\\[\nP =\n\\begin{bmatrix}\n0 &1 \\\\\n1 & 0\n\\end{bmatrix}\n\\] 극한 분포를 계산하면 \\([\\dfrac{1}{2}, \\dfrac{1}{2}]\\)이 나온다. 상태 1에서 출발했다면, 상태 1이 \\(\\{2, 4, 6\\}\\) 번에 나타나게 되고, 이때 gcd는 2가 된다. 이때 확률 행렬의 곱을 살펴보면 아래와 같다. \\(k = 1, 2,\\cdots\\)에 대해서\n\\[\n\\begin{aligned}\nP^n & =\n\\begin{bmatrix}\n0 & 1 \\\\\n1 & 0\n\\end{bmatrix},~\\text{for}~n = 2k-1 \\\\\nP^n & =\n\\begin{bmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix},~\\text{for}~n = 2k\n\\end{aligned}\n\\]\n따라서 \\(\\lim_{n \\to \\infty} P^n\\)은 수렴하지 않는다. 앞서 계산한 극한 분포는 두 극단의 평균일 뿐이다. 이때 극한 분포 역시 존재하지 않는다."
  },
  {
    "objectID": "posts/math-of/2020-07-03-bayesian-inference.html",
    "href": "posts/math-of/2020-07-03-bayesian-inference.html",
    "title": "Bayesian Inference with MCMC",
    "section": "",
    "text": "베이지언 추론에 관해서 수박 겉핥기로 살펴본다.\nMCMC의 기본 논리를 정리한다."
  },
  {
    "objectID": "posts/math-of/2020-07-03-bayesian-inference.html#tl-dr",
    "href": "posts/math-of/2020-07-03-bayesian-inference.html#tl-dr",
    "title": "Bayesian Inference with MCMC",
    "section": "",
    "text": "베이지언 추론에 관해서 수박 겉핥기로 살펴본다.\nMCMC의 기본 논리를 정리한다."
  },
  {
    "objectID": "posts/math-of/2020-07-03-bayesian-inference.html#bayes-theorem",
    "href": "posts/math-of/2020-07-03-bayesian-inference.html#bayes-theorem",
    "title": "Bayesian Inference with MCMC",
    "section": "Bayes’ theorem",
    "text": "Bayes’ theorem\n\\[\n\\begin{aligned}\nP(A\\lvert B) & = \\dfrac{P(B\\lvert A) P(A)}{P(B)} \\\\\n& = \\underbrace{\\left( \\dfrac{P(B\\lvert A)}{P(B)} \\right)}_{\\rm updating}  \\overbrace{P(A)}^{\\rm base}\n\\end{aligned}\n\\]\n\\(P(A)\\)는 prior, 즉 사전 확률이다. 즉, \\(A\\)의 발생 확률에 관한 사전적인 기대 혹은 지식이다. 때로는 기저 확률이라고도 부른다. 이 지식을 \\(B\\)라는 증거(evidence)를 통해서 업데이트하는 것이 베이즈 정리다. 이때 업데이트하는 \\(( )\\) 부분이다.\n베이즈 정리의 흔한 하지만 언제나 재미있는 사례를 위 식을 통해 다시 들여다보자. 어떤 질병의 정탐(true positive) 확률, 즉 검사의 양성 판정이 곧 발병을 의미할 확률이 매우 높다고 하자. 이때 어떤 사람이 양성 판정을 받았다면, 이 사람은 매우 높은 확률로 해당 질병에 감염된 것일까? 말장난 이것 같지만, 직관적으로는 그럴 것 같다.\n해당 질병에 걸릴 확률 자체가 낮다면, 즉 기저 확률이 낮다면, 질병에서 양성 반응이 나왔다는 사실만으로는 해당 질병에 정탐 확률 만큼 높게 감염되었다고 보기 어렵다. 정탐 확률은 베이즈 정리에서 업데이팅 파트를 의미하고, 해당 질병에 걸릴 확률은 기저 확률에 해당한다. 기저가 매우 낮다면, updating 부분이 높아도 사후 확률은 그렇게까지 높지 않을 수 있다.\n베이즈 “착각”은 흔하게 발생한다. 우리가 흔히 접하는 확률은 정탐 확률이다. 즉 99% 정확도라고 하면 질병이 있을 때 이를 탐지할 확률 (\\(P(B \\lvert A)\\))이다. 위에서 듯이, 이는 양성 결과를 받을 때 병에 걸렸을 확률과는 다르다."
  },
  {
    "objectID": "posts/math-of/2020-07-03-bayesian-inference.html#bayesian-inference",
    "href": "posts/math-of/2020-07-03-bayesian-inference.html#bayesian-inference",
    "title": "Bayesian Inference with MCMC",
    "section": "Bayesian inference",
    "text": "Bayesian inference\n\n추정이란 모집단에서 얻은 샘플을 통해서 모집단 분포의 특성(파라미터)를 추측하는 과정이다. 추정을 위해서 필요한 것은 ’분포’다. 베이즈 정리에 기반해 사후 분포를 구하는 방법은 아래와 같다.\n\n\\[\n\\begin{aligned}\np(\\theta\\lvert data) = \\dfrac{p(data \\lvert \\theta) p(\\theta)}{P(data)} = \\dfrac{ \\overbrace{ {\\mathcal L} (\\theta\\lvert data)}^{\\rm Likelihood}  \\overbrace{p(\\theta)}^{\\rm prior}}{ \\underbrace{P(data)}_{\\rm evidence} }\n\\end{aligned}\n\\]\n각각 나누어 살펴보자.\n\n\\(P(data)\\): evidence, 데이터를 관찰할 확률을 뜻한다.\n\\(p(data\\lvert \\theta) = {\\mathcal L}(\\theta\\lvert data)\\): Likelihood, 관찰된 데이터의 ‘우도’ 혹은 가능도를 나타낸다.\n\\(p(\\theta)\\): prior, 데이터를 포함하지 않은 파라미터의 사전 분포를 뜻한다.\n파라미터 공간은 n 차원 벡터다. \\(\\theta \\in \\mathbb R^n\\), \\(\\theta = (\\theta_1, \\theta_2, \\dotsc, \\theta_n)\\).\n\n식의 분자는 모두 파리미터 \\(\\theta\\)의 함수다. 분모는 상수다. 뒤에 다시 설명하겠지만, \\(p(\\theta \\lvert  data)\\)를 \\(\\theta\\)에 대해서 최적화한다면, 분자만 고려하면 된다.\n대소문자를 구별해서 쓴 것에 유의하자. 소문자 \\(p\\)는 확률 분포, 즉 확률 밀도 함수(pmf) 혹은 확률 질량 함수(pdf)를 뜻한다. 대문자 \\(P\\)는 확률이다.\n\n위 그림을 보자. 사전 분포는 우도에 따라서 재평가 되면서 사후 분포를 만들어 낸다. 우도(때로는 가능도라고 표현하기도 한다)에 관해서 조금 더 살펴보자."
  },
  {
    "objectID": "posts/math-of/2020-07-03-bayesian-inference.html#something-about-likelihood",
    "href": "posts/math-of/2020-07-03-bayesian-inference.html#something-about-likelihood",
    "title": "Bayesian Inference with MCMC",
    "section": "Something about likelihood",
    "text": "Something about likelihood\n관찰된 \\(data\\) 아래에서 이 결과가 가능한 ’정도’를 파리미터의 함수로 나타낸 것, 정도로 이해하면 좋다. 우도를 의미할 때 ’확률’이라는 표현을 쓰지 않은 것이 좋다. 왜 그럴까?\n\nProbability vs Likelihood\n\n이산 분포에서 확률 = 우도?\n이산 분포에서는 특정한 파라미터에서 1개의 데이터를 관찰할 때 확률과 우도가 같다. 이는 probability mass function(pmf)이 그 값을 관찰할 확률과 같기 때문이다. 하지만 우도를 구할 때 \\(data\\)가 꼭 하나 여야 할까? 이는 어떤 데이터를 보고 업데이트하는지에 달려 있다.\n예를 들어보자. 동전을 던져서 HH를 관찰했다고 하자. 동전의 앞면이 나올 확률이 \\(p\\)라고 하고 독립 시행이라면, 이는 \\(p^2\\)가 이 관찰 결과의 ’우도’이다. 물론 이는 HH라는 결과를 얻을 확률이기도 하다.\n\\[\nP(HH\\lvert p=0.5) = 0.5^2\n\\]\n이렇게 표현해보자. 이는 HH가 관찰되었을 때 \\(p=0.5\\)라는 파라미터의 가능도가 \\(0.5^2\\)라는 뜻이다. 즉,\n\\[\n\\mathcal{L} (p=0.5 \\lvert  HH) = 0.5^2\n\\]\n사족이지만, HH가 관찰되었을 때 \\(p=0.5\\)일 확률이 \\(0.25\\)이라는 말은 아니다. 즉,\n\\[\n\\mathcal{L} (p=0.5 \\lvert  HH) \\neq P (p=0.5 \\lvert  HH)\n\\]\n\n\n연속 분포에서 확률 \\(\\neq\\) 우도?\n연속 분포에서 우도는 probability density function(pdf)과 같다고 설명되어 있는 경우가 있다. 이 말은 맞기도 하고 아니기도 하다. \\(data\\)의 관찰 수가 1개라면 이 말은 맞다. 하지만, 이산 분포의 경우와 같이 2개 이상일 때는 pdf와 우도가 같다고 말할 수 없다. 최우추정법에서 pmf 혹은 pdf가 곱해진 형태를 떠올리면 이해가 조금 쉬울 수 있겠다.\n\n\n우도는 pmf 혹은 pdf일까?\n관찰이 1개라면 앞서 보았듯이 우도는 pmf 그리고 pdf가 된다. pdf가 된다는 것은 무슨 의미일까? 파라미터 공간 전체에 대해서 합하면 혹은 적분하면 1이 되어야 한다. 그래서 pdf다. 그런데 일반적으로 우도를 적분을 한다고 해서 1이 되지 않는다. 앞서 보았던 예로 가보자.\n\\[\n\\int_0^1 p^{1/2} dp \\neq 1\n\\]\n그렇다면 사후 분포 \\(P(\\theta\\lvert data)\\)는 혹은 pmf인가 pdf인가? 그렇다. \\(\\int_\\theta P(\\theta\\lvert data) d \\theta\\)를 구하면 1이다.\n\n\n\nHow to infer\n\n베이즈 추론에서 아래의 표현을 많이 접하게 된다.\n\n\\[\n\\begin{aligned}\np(\\theta\\lvert data) = \\dfrac{\\mathcal L(data \\lvert  \\theta) p(\\theta)}{P(data)} \\propto {\\mathcal L}(\\theta\\lvert data) p(\\theta)\n\\end{aligned}\n\\]\n왜 온전한 \\(p(\\theta\\lvert data)\\)를 구하지 않고 분모를 제외하려고 할까?\n이유는 두 가지다. 첫째, 베이즈 추론에서 우리의 목적함수는 \\(p(\\theta\\lvert data)\\)다. 즉, 이 값을 극대화해주는 \\(\\theta\\)를 찾는 것이 목적이다. 이렇게 보면, MLE와 사실상 같은 방법이라고 할 수 있다. 분모의 \\(P(data)\\)에는 \\(\\theta\\)가 없다. 즉, 목적함수를 극대화하는 파리미터를 찾는 데 분모는 영향을 주지 않는다.\n둘째 \\(P(data)\\)는 계산하기가 만만치 않다. 많은 경우는 아예 불가능하다. 예를 들어 \\(\\theta\\)가 다차원이라면 적분이 아예 불가능할 수 있다. MCMC에서 이 문제를 다시 볼 것이다.\n어쨌든 해당 목적 함수의 최적화를 통해 찾은 파라미터를 MAP(Maximum A Posteriori)라고 부른다. MAP은 posterior의 mode(최빈값)이기도 하다. MAP은 \\(p(\\theta\\lvert data)\\)는 분포에서 가장 높은 봉우리를 지니는 파라미터를 찾는 것인데, 이는 해당 값이 가장 많이 나오는 값이라는 뜻이기도 하다.\n\n\nMAP vs MLE\n만일 prior에 해당하는 모든 파라미터 공간에서 적절한 \\(k\\)에 대해서 \\(p(\\theta) = k\\)로 둔다면, 즉 prior에 관해 특별한 가정을 하지 않는다면, 이는 MLE와 동일한 값이 될 것이다. 모든 파라미터 공간에 대해서 동일한 사전 분포를 부여한 형태가 MLE라고 이해하면 되겠다. MLE \\(\\subset\\) MAP"
  },
  {
    "objectID": "posts/math-of/2020-07-03-bayesian-inference.html#mcmc",
    "href": "posts/math-of/2020-07-03-bayesian-inference.html#mcmc",
    "title": "Bayesian Inference with MCMC",
    "section": "MCMC!",
    "text": "MCMC!\n\nWhy?\nMCMC는 Markov Chain Monte Carlo Simulation의 약어다. 둘을 각자 하나씩 뜯어보기 전에, 왜 MCMC라는 걸 고민하게 되었을까? 이유는 간단하다. 앞서 베이즈 추론에서 보았지만, \\(\\mathcal L (\\theta\\lvert data) p(\\theta)\\)는 쉽게 구할 수 있다.\n\n사전 분포 \\(p(\\theta)\\)는 내 마음대로 정하면 되는 것이다.\n여기에 \\(data\\), 즉 관찰을 부어 넣으면 우도가 된다.\n\nMAP 혹은 MLE 형태의 ’추정치’만을 얻고 싶었다면 여기서 더 고민할 게 없다. 하지만 추정치를 얻었다면 검정을 해야 한다. 베이즈 추론의 강점은 파라미터를 직접 추정하고 이 추정치가 참일 확률을 직접 계산할 수 있다는 데 있다. 빈도주의 추론처럼 빙빙 돌리지 않는 것이 베이즈 추론의 강점이다. 그런데 이것을 하려면 \\(\\theta\\)의 분포가 필요하다…\n\\[\nP(data) = \\int_{\\theta}  {\\mathcal L}(\\theta\\lvert data) p(\\theta) d \\theta\n\\]\n문제는 위 식의 적분, 특히 \\(p(\\theta)\\) 분포를 포함한 적분이 쉽지 않다는 데 있다. Prior가 계산 가능한 수준이라고 해도 \\(\\theta\\)가 \\(n\\) 차원의 벡터일 수 있다. 이를 정확하게 계산해서 해석 해(analytic solutions)를 얻는 것은 대체로 가능하지 않다.\n\n\nFirst MC: Monte Carlo\n사실 이럴 때 동원할 수 있는 방법이 몬테카를로 시뮬레이션이다. 해석 해를 구할 수 없지만 어떤 파라미터 포인트 \\(\\theta_i\\) 를 넣으면 \\(\\mathcal L(\\theta_i\\lvert data)(=p(data\\lvert \\theta_i))\\)는 알 수 있다. \\(\\theta_i \\in \\theta\\)를 충분히 많이 뽑아서 평균을 내면 \\(P(data)\\)가 되지 않을까?\n이해를 돕기 위해서 일변수 함수로 다시 표현해보자. 어떤 함수 \\(f(x)\\)를 계산할 수 있고 \\(p(x)\\)를 샘플링할 수 있다고 하자. 우리가 구하고 싶은 것은 아래의 적분 값이다.\n\\[\n\\int f(x) p(x) dx\n\\]\n해석 해가 불가능해도 샘플링이 가능하면 해석 해의 근사치를 얻을 수 있다. 즉, 적당히 많은 수, 즉 \\(N\\) 개의 \\(X_i\\)를 샘플링해서 \\(f(X_i)\\)를 얻어 평균값을 구하면 된다. 즉,\n\\[\n\\int f(x) p(x) dx \\approx \\sum_{i=1}^{N} \\dfrac{f(X_i)}{N}\n\\]\n여기서 잠깐! 식의 오른 쪽에 \\(p(x)\\)가 사라졌다는 점을 주목해서 보자. 왜 일까? \\(X_i\\)를 샘플링했다는 것, 즉 \\(p(x)\\)가 샘플링 가능했다는 것은 왼쪽 적분 식에서 \\(p(x)\\)의 분포를 고려해서 \\(X_i\\)를 뽑았다는 이야기다. 즉, 분포에 맞게 \\(X_i\\)가 뽑혔다는 것은 \\(X_i\\)가 많이 분포한 영역에서 많이 뽑히고 적게 분포한 영역에서 적게 뽑힌 것이다. 따라서 \\(f(X_i)\\)의 단순 평균으로 적분 값은 근사할 수 있게 된다.\n\n\nSecond MC: Markov Chain\n몬테카를로에서 끝났다면 그래도 편했을 것이다. 샘플링을 할 수 있다면, 하자! 샘플링이 ‘충분히’ 쉬울까? 파라미터의 차원이 3개만되도, 샘플링을 위해이 탐사해야 하는 파리미터의 공간이 많이 커진다. 이런 상황에서 샘플링을 하는 것 자체가 어렵게 된다.\n샘플링을 잘 하기 위해서는 이를 위한 전략이 필요하다. 관찰이 많이 될 것 같은 파라미터 공간 주변에서는 많이 뽑고, 별로 없을 것 같은 공간 주변에서는 적당히 뽑은 후 빨리 빠져나올 수 있어야 한다. 이런 좋은 샘플링 전략의 그럴듯한 근거를 제시하는 것이 또다른 MC, 마르코프 연쇄이다.\n마르코프 연쇄가 왜 이런 전략을 제공할까?\n\n마르코프 연쇄는 간단하다. 바로 전기의 상태가 다음 기의 상태를 결정하는 최소 기억의 구조를 지니고 있다. 그래서 전략을 만들기 쉽다.\n마르코프 연쇄의 가장 좋은 특징: 몇 가지 조건이 충족되면 파라미터 공간 위의 ‘수렴’ 분포가 존재하며 이 분포가 고유(unique)하다. 게다가 이 수렴 분포는 초기 값에도 의존하지 않는다.\n마르코프 연쇄를 통해 충분히 많은 수의 샘플링을 거치면 그때까지 획득된 결과를 파라미터 공간에 관한 분포의 근사치로 간주할 수 있다.\n\n이렇게 얻은 수렴 분포가 \\(p(data)\\)의 분포와 일치하면, 끝이다. 해당 샘플링의 결과가 우리가 알고 싶은 분포의 쓸만한 근사치가 된다."
  },
  {
    "objectID": "posts/math-of/2020-07-03-bayesian-inference.html#magic-of-mcmc",
    "href": "posts/math-of/2020-07-03-bayesian-inference.html#magic-of-mcmc",
    "title": "Bayesian Inference with MCMC",
    "section": "Magic of MCMC",
    "text": "Magic of MCMC\nMCMC에서 몬테카를로 부분은 그리 놀랄 게 없다. 자연스럽다. 깜놀할 부분은 마르코프 연쇄 부분이다. 파라미터의 분포를 수렴 분포로 지니는 이행 확률 혹 마르코프 연쇄의 밀도 함수를 우리는 알지 못한다. 이 상태에서 어떻게 파라미터의 분포의 근사치를 얻을 수 있다는 말인가? MCMC의 핵심은 이 수렴분포로 접근하게 만드는 효과적인 이행확률을 만들어내는 데 있다.\n해법은 임의의 적절한 밀도 함수가 파리미터의 분포를 따를 수 있도록 규칙을 부여해주는 것이다. 이 역할을 수행하는 것이 Metropolis 알고리듬, M-H(Metropolis-Hastings) 알고리듬이다. 다행스럽게도 이 규칙들이 복잡하지 않고 간단하다. 이것이 마법이다! 이렇게 임의로 만들어진 밀도 함수가 원하는 파라미터의 분포를 유일한 수렴 분포로 지니기 위해서는 마르코프 연쇄의 어떤 속성들을 지니고 있어야 한다. 이는 이른바 detailed balance 조건을 통해 보장된다. 즉,\n\\[\n\\pi(x) T(y\\lvert x) = \\pi(y) T(x\\lvert y)\n\\]\n이를 앞서 적은 식의 맥락에서 다시 풀어보자.\n\\[\np(\\theta^i\\lvert data) p(\\theta^j\\lvert \\theta^i) = p(\\theta^j\\lvert data) p(\\theta^i\\lvert \\theta^j).\n\\]\n여기서 \\(\\theta^k\\)는 마르코프 연쇄 위에서 얻은 \\(\\theta\\)의 수열을 뜻한다. 정리하면 파라미터의 사후 분포를 수렴 분포로 지니는 마르코프 연쇄의 어떤 밀도 함수(이행 행렬)를 구성하고, 이 밀도 함수가 detailed balance를 만족시키면 되겠다.\n\nMetropolis algorithm\n\n이행 행렬로 임의의 밀도 함수 \\(Q(\\theta^i \\lvert  \\theta^{i-1})\\)를 정하자. 이를 밀도함수로 받아들일지 여부를 아래와 같은 확률로 결정한다. 이를 수용확률이라고 부른다.\n\n\\[\nr = \\min \\left( \\dfrac{\\pi(\\theta^i)}{\\pi(\\theta^{i-1})}, 1 \\right)\n\\]\n\n즉, 이전값(\\(\\theta^{i-1}\\))보다 새로운 값(\\(\\theta^i\\))이 더 큰 확률을 주면, 이 밀도함수를 1의 확률로 받아 들인다. 반면 그렇지 않으면 확률의 크기에 따라서 이를 수용한다. 이제 \\(\\theta^{i-1} = \\theta^a\\)에서 \\(\\theta^i = \\theta^b\\), 즉 \\(\\theta^a \\to \\theta^b\\) 로 이행할 확률을 구해보자. 만일 \\(\\pi(\\theta^a\\lvert data) \\leq \\pi(\\theta^b\\lvert data)\\)라고 해보자.\n\n\\[\n\\begin{aligned}\nP(\\theta^i = \\theta^b \\lvert  \\theta^{i-1} = \\theta^a)  & = \\underbrace{\\pi(\\theta^a \\lvert  data)}_{(\\ast)} \\overbrace{Q(\\theta^b \\lvert  \\theta^a) \\min \\left( \\dfrac{\\pi(\\theta^b\\lvert data)}{\\pi(\\theta_{a}\\lvert data)}{\\pi(\\theta^{a})}, 1 \\right)}^{(\\ast\\ast)} \\\\\n& = \\pi(\\theta^a\\lvert data) Q(\\theta^b\\lvert \\theta^a) \\cdot 1\n\\end{aligned}\n\\]\n\n\\(\\pi(\\theta^a)\\), 즉 \\((\\ast)\\) 그냥 prior를 통해 쉽게 구할 수 있다. \\((\\ast\\ast)\\) 역시 어렵지 않게 구할 수 있다.\n\n이번에는 detailed balance를 살펴보기 위해서 반대로 \\(\\theta^b \\to \\theta^a\\)를 구해보자.\n\\[\n\\begin{aligned}\nP(\\theta^i = \\theta^a \\lvert  \\theta^{i-1} = \\theta^b)  & = \\pi(\\theta^b\\lvert data) Q(\\theta^a\\lvert \\theta^b) \\min \\left( \\dfrac{\\pi(\\theta^a\\lvert data)}{\\pi(\\theta^b\\lvert data)}, 1 \\right) \\\\\n& = \\pi(\\theta^b\\lvert data) Q(\\theta^b\\lvert \\theta^a) \\cdot \\dfrac{\\pi(\\theta^a\\lvert data)}{\\pi(\\theta^b\\lvert data)} \\\\\n& = Q(\\theta^a\\lvert \\theta^b)  \\pi(\\theta^a\\lvert data)\n\\end{aligned}\n\\]\n\n메트로폴리스 알고리듬의 가정 중 하나는 이행 행렬이 대칭이라는 것이다. 즉, \\(Q(\\theta^b\\lvert \\theta^a)  = Q(\\theta^a\\lvert \\theta^b)\\). 따라서 detailed balance가 성립한다. \\(\\pi(\\theta^a\\lvert data) &gt; \\pi(\\theta^b\\lvert data)\\)인 경우에 대해서도 비슷하게 도출할 수 있다.\n\n\n\nMetropolis-Hastings algorithm\n\nM-H 알고리듬은 임의의 밀도 함수, 즉 \\(Q(\\cdot)\\)가 대칭이라는 제약도 풀어버린 것이다. 수용 확률 \\(r\\) 이 다음과 같이 정의된다.\n\n\\[\nr = \\min \\left( \\dfrac{\\dfrac{\\pi(\\theta^i \\lvert  data)}{Q(\\theta^i\\lvert \\theta^{i-1})} }{\\dfrac{\\pi(\\theta^{i-1} \\lvert  data)}{Q(\\theta^{i-1}\\lvert \\theta^i)} }, 1 \\right)\n\\]\n\nMetropolis 알고리듬의 사례에 제시된 바를 따라가보면 대칭이라는 조건 없이 detailed balance를 만족한다는 사실을 쉽게 계산해볼 수 있다."
  },
  {
    "objectID": "posts/math-of/2020-07-03-bayesian-inference.html#toy-code",
    "href": "posts/math-of/2020-07-03-bayesian-inference.html#toy-code",
    "title": "Bayesian Inference with MCMC",
    "section": "Toy code",
    "text": "Toy code\n# Computation\nimport scipy as sp \nimport scipy.stats as st \nimport numpy as np \n# Vis \nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\n# Definition \nthetas = np.linspace(0, 1, 200)\nprior = st.beta(a, b)\npost = prior.pdf(thetas) * st.binom(n, thetas).pmf(h)\npost /= (post.sum() / len(thetas))\n\n# Func for metropolis algorithm \ndef target(lik, prior, n, h, theta):\n    if theta &lt; 0 or theta &gt; 1:\n        return 0\n    else:\n        return lik(n, theta).pmf(h)*prior.pdf(theta)\n\n# Parameters \nn = 100\nh = 61\na = 10\nb = 10\nlik = st.binom\nprior = st.beta(a, b)\nsigma = 0.3\nnaccept = 0\ntheta = 0.1\nniters = 10000\nsamples = np.zeros(niters+1)\nsamples[0] = theta\n\n# Iteraton \nfor i in range(niters):\n    theta_p = theta + st.norm(0, sigma).rvs()\n    rho = min(1, target(lik, prior, n, h, theta_p)/target(lik, prior, n, h, theta ))\n    u = np.random.uniform()\n    if u &lt; rho:\n        naccept += 1\n        theta = theta_p\n    samples[i+1] = theta\nnmcmc = len(samples)//2\nprint (f\"Efficiency = {naccept/niters}\")\n코드에 관한 설명은 간략하게 하겠다. 코드의 출처는 여기를 참고하라. 진행은 다음과 같다. 이 코드는 다음과 같은 베타 분포, \\(\\beta(a, b)\\)를 사전 확률로 지닌다. 사후 확률은 사전 확률의 pdf와 이항 분포 \\(B(n, p)\\)의 pmf를 곱이 사후 확률의 분자가 된다. 식에서 \\(p = h / n\\)으로 두면 된다. 이때 사후 분포의 근사치를 어떻게 만들어낼 것인가?\n\n사전 분포 \\(\\beta(a, b)\\)를 잡는다.\n우도는 이항분포의 pmf를 활용한다. 이때 \\(n\\), \\(h\\)의 값이 필요하다.\n아래와 같은 실행을 10,000 번의 실행을 반복한다.\n\n최초의 theta는 0.1로 둔다.\n임의의 theta 값을 정규 분포값에서 생성해낸다.\n\nmetropolis 알고리듬에 따라서 이 값과 최초의 theta 혹은 바로 전에 생성된 theta, 두 값을 평가한다. 평가는 극도로 단순한 방식으로 진행된다. 각기 다음 상태로 넘어갈 확률은 전기의 파라미터에만 의존한다.\n\n\n\n위 시각화의 코드는 다음과 같다.\npost = st.beta(h+a, n-h+b)\n\nplt.figure(figsize=(12, 9))\nplt.hist(samples[nmcmc:], 40, histtype='step', density=True, linewidth=1, label='Distribution of posterior samples');\nplt.hist(prior.rvs(nmcmc), 40, histtype='step', density=True, linewidth=1, label='Distribution of prior samples');\nplt.plot(thetas, post.pdf(thetas), c='red', linestyle='--', alpha=0.5, label='True posterior')\nplt.xlim([0,1]);\nplt.legend(loc='best');\n그림에서 보듯이 MCMC가 사후 확률을 잘 따라가고 있다. MCMC는 정말로 잘 수렴할까? 즉, 이론대로 어떤 파라미터에서 출발하더라도 비슷한 분포로 수렴할까? 분포의 수렴은 수치적으로는 따지기 쉽지 않은 개념이다. 느낌만 보도록 하자. 아래에서 보면, 초기값이 관계 없이 모든 값에서 사후 분포에 수렴하는 것을 확인할 수 있다. 즉, \\(x\\) 축에 표시된 반복 횟수가 일정 수준을 넘어서면 모든 마르코프 연쇄가 사후 분포 범위 안에서 움직이고 있다."
  },
  {
    "objectID": "posts/math-of/2019-05-06-math-svm.html",
    "href": "posts/math-of/2019-05-06-math-svm.html",
    "title": "Mathematics of Support Vector Machine",
    "section": "",
    "text": "Support Vector Machine (SVM)의 알고리듬을 수학적으로 어떻게 도출할 수 있을까?\n보다 직관적으로 이해할 수 있는 방법은 없을까?"
  },
  {
    "objectID": "posts/math-of/2019-05-06-math-svm.html#key-questions",
    "href": "posts/math-of/2019-05-06-math-svm.html#key-questions",
    "title": "Mathematics of Support Vector Machine",
    "section": "",
    "text": "Support Vector Machine (SVM)의 알고리듬을 수학적으로 어떻게 도출할 수 있을까?\n보다 직관적으로 이해할 수 있는 방법은 없을까?"
  },
  {
    "objectID": "posts/math-of/2019-05-06-math-svm.html#key-synopsis",
    "href": "posts/math-of/2019-05-06-math-svm.html#key-synopsis",
    "title": "Mathematics of Support Vector Machine",
    "section": "Key Synopsis",
    "text": "Key Synopsis\n\nSVM은 기본적으로 최소화(minimize)를 한 후 이를 다시 극대화(maximize)를 하는 최대최소(maxmin) 형태의 최적화 문제이다.\n\n최소화: 분류(classification)의 기준이 되는 두 영역을 나누는 하이퍼플레인을 찾은 후 이 하이퍼플레인과 가장 가깝게 위치하는 두 영역의 벡터(서포트 벡터)를 찾는다.\n최대화: 분류 기준이 되는 하이퍼플레인과 평행한 두 서포트 벡터를 지나는 하이플레인의 거리를 최대화 한다.\n\n이 maxmin 문제를 풀면 목적함수에는 training set에 속한 벡터들의 닷 프로덕트만 남게 되고, 덕분에 최적화 문제가 단순해진다.\n이 닷 프로덕트들로 구성된 부분을 다른 함수 형태로 바꿔서 SVM 알고리듬의 ’커널’을 유연하게 바꿀 수 있다. 이것이 커널 트릭 (Kernel trick)이다."
  },
  {
    "objectID": "posts/math-of/2019-05-06-math-svm.html#svm-mathematically",
    "href": "posts/math-of/2019-05-06-math-svm.html#svm-mathematically",
    "title": "Mathematics of Support Vector Machine",
    "section": "SVM Mathematically",
    "text": "SVM Mathematically\n\nPreliminary concepts\n\nLength of a vector\n벡터 \\({\\bf x} = (x_1, x_2, \\dotsc, x_n)\\) 의 벡터의 길이, 즉 유클리드 노름(norm), 은 다음과 같이 정의된다.\n\\[\n\\Vert {\\bf x} \\Vert = \\sqrt{x_1^2 + x_2^2 + \\dotsc + x_n^2}\n\\]\n\n\nDirection of a vector\n벡터 \\(\\bf x\\)의 방향성 \\(\\bf w\\)는 다음과 같이 정의할 수 있다.\n\\[\n\\mathbf{w} = \\left( \\dfrac{x_1}{ \\Vert \\bf x \\Vert }, \\dfrac{x_2}{ \\Vert \\bf x \\Vert } \\right)\n\\]\n그림으로 나타내보자.\n\n이는 다음과 같이 삼각함수로 표시할 수 있다. \\[\n\\mathbf{w} = \\left(  \\cos~\\theta, \\cos~\\alpha  \\right)\n\\]\n\n\nDot product (inner product)\n내적은 벡터 연산의 일종으로, 이는 두 벡터를 스칼라 값으로 바꿔주는 일종의 함수다.\n\n\\[\n\\begin{aligned}\n\\cos \\theta & = \\cos (\\beta -\\alpha) \\\\\\\\\n& = \\cos  \\beta \\cos \\alpha + \\sin \\beta  \\ \\sin \\alpha \\\\\\\\\n& = \\dfrac{x_1}{\\Vert \\rm x \\Vert} \\dfrac{y_1}{\\Vert \\rm y \\Vert} + \\dfrac{x_2}{\\Vert \\rm x \\Vert} \\dfrac{y_2}{\\Vert \\rm y \\Vert} \\\\\\\\\n& = \\dfrac{x_1 y_1 + x_2 y_2}{\\Vert \\rm x \\Vert \\Vert \\rm y \\Vert}\n\\end{aligned}\n\\]\n이를 아래와 같이 정리할 수도 있다.\n\\[\n\\rm x \\cdot \\rm y = \\Vert \\rm x \\Vert \\Vert \\rm y \\Vert \\cos \\theta\n\\]\n\n\nHyperplane\n\n\\(n\\) 차원 공간을 가를 수 있는 해당 공간의 차원보다 하나 낮은 수학적 관계라고 풀어서 쓸 수 있다.\n\n즉, \\(x_1\\)이나 \\(x_2\\) 중 하나만 주어지면 나머지 위치가 주어진다.\n\n쉽게 \\(y = x + 1\\)의 직선을 생각하면 된다. 2차원 평면에서 \\(x\\)의 값이 주어지면 y값이 정해진다. 이 직선은 2차원 평면에 위치하지만 사실상 1차원의 속성을 지니게 된다.\n\n\\({\\bf x} = (x_1, x_2)\\)의 벡터가 있다고 할 때, 하이퍼플레인은 벡터 \\(\\bf w\\)와 \\(b\\)에 의해 정의된다. 즉,\n\\[\n\\mathbf{w} \\cdot {\\bf x} + b = 0\n\\]\n\n\nClassifier\n하이퍼플레인을 기준으로 클래시파이어를 다음과 같이 정의한다. 특정한 관찰 벡터 \\(\\bf x\\)가 있다고 하자. 이때 분류 \\(h\\)의 정의는 아래와 같다.\n\\[\nh({\\bf x})  =\n\\begin{cases}\n+1\\hspace{3em} & \\text{if} \\hspace{1em} \\mathbf{w} \\cdot {\\bf x} + b \\geq 0 \\\\\\\\\n-1 \\hspace{3em} & \\text{if} \\hspace{1em} \\mathbf{w} \\cdot {\\bf x} + b &lt; 0\n\\end{cases}\n\\]"
  },
  {
    "objectID": "posts/math-of/2019-05-06-math-svm.html#explained-visually",
    "href": "posts/math-of/2019-05-06-math-svm.html#explained-visually",
    "title": "Mathematics of Support Vector Machine",
    "section": "Explained Visually",
    "text": "Explained Visually\n그림으로 보다 직관적으로 이해해보자.\n\n어떤 원점을 기준으로 training example까지의 벡터를 \\({\\bf x}_i\\)라고 하자. 이때 둘을 가르는 하이퍼플레인이 있을 때 이와 직교하는 벡터 (orthogonal vector) $ $를 생각해보자. 왜 orthogonal해야 하는가? 잠시 후 그 이유를 알 수 있다. 하이퍼플레인은 기본적으로는 두 벡터 사이의 닷 프로덕트다. 닷 프로덕트를 그림으로 나타낼 수 있는 방법은 이를 projection으로 생각해보는 것이다.\n\n\n내적이라고 번역되기도 하지만 여기서는 그냥 ’닷 프로덕트’라고 쓰리고 하겠다.\n즉, \\({\\bf x}_i\\)를 $ $로 프로젝션을 한다면(projection of \\({\\bf x}_i\\) on $ $), 이는\n\\[\n\\text{Proj}_\\mathbf{w} {\\bf x}_i = \\dfrac{\\mathbf{w} \\cdot{\\bf x}_i}{\\Vert \\bf w \\Vert}\n\\]\n닷 프로덕트의 부분이 시각적으로는 projection 결과 곱하기 \\(\\Vert \\bf w \\Vert\\)로 나타난다. 즉, \\({\\bf x}_i\\)에서 \\(\\bf w\\)를 향해 내린 선분이 프로젝션이고 이를 \\(\\Vert \\bf w \\Vert\\)로 스케일링 한 \\(\\bf w\\) 위에서의 길이가 닷 프로덕트를 시각적으로 나타낸 것이다. 이 프로젝션의 길이에 따라서 해당 트레이닝 샘플이 어떤 것으로 분류될지에 관해서 파악할 수 있다. \\(\\bf \\Vert w \\Vert\\)가 고정되어 있다고 하면, 프로젝션의 크기가 일정 숫자보다 크면 분류의 오른쪽에 작으면 분류의 왼쪽에 위치하는 것이다. 이를 아래와 같이 표시해보자.\n\\[\\mathbf{w} \\cdot {\\bf x}_{\\mathrm r} + b \\geq 1\\]\n\\[\\mathbf{w} \\cdot {\\bf x}_{\\mathrm l} + b \\leq 1\\]\n프로젝션의 길이가 일정한 기준보다 길면 오른쪽에 짧으면 왼쪽에 위치한 것으로 분류할 수 있다. 이 조건을 \\(y_i\\)와 함께 나타내보자. 즉,\n\\[\ny_i ( \\mathbf{w} \\cdot {\\bf x}_ i + b) - 1  \\geq 0\n\\]\n앞서 분류기에서 해당 값이 0보다 크면 \\(y_i ( \\mathbf{w} \\cdot {\\bf x}_ i + b) - 1 \\geq 0\\)가 성립한다. 반면, 해당 값이 0보다 작으면 음수를 곱하는 것이 되어 부등호가 바뀌게 되고, 이 경우 역시 위의 식이 성립한다.\n\n이제 \\(\\cos \\theta\\)를 벡터 \\({\\bf x}_{\\rm svr} - {\\bf x} _{\\rm svl}\\)와 \\(\\mathbf{w}\\)가 이루는 각이라고 생각하자. 이때 \\(\\mathbf{w}\\)는 하이퍼플레인과 orthogonal하며 적절한 training sample 즉, 적절한 하나의 서포트 벡터를 지난다. 이때 \\(\\cos \\theta\\)는 다음과 같이 쉽게 정의된다.\n\n\n벡터의 방향에 대해서 약간 갸우뚱하는 분들이 있을지 모르겠다. \\(\\cos \\theta\\)를 제대로 정의하기 위해서는 \\(-({\\bf x}_{\\rm svr} - {\\bf x}_{\\rm svl})\\), \\(- \\mathbf{w}\\)라고 쓰는 것이 맞을 것이다. 하지만, 둘의 닷 프로덕트를 구하면 서로 상쇄되어 아래 적은 것과 동일하다.\n\\[\\cos \\theta = \\dfrac{({\\bf x} _ {\\rm svr} - {\\bf x} _ {\\rm svl}) \\cdot \\bf w}{\\Vert {\\bf x} _ {\\rm svr} - {\\bf x} _ {\\rm svl} \\Vert \\Vert \\mathbf{w} \\Vert}\\]\n한편, 하이퍼플레인과 평행하면서 서포트 벡터를 지나가는 하이퍼플레인의 거리 \\(\\Delta_{\\bf x}\\)는 다음과 같다.\n\\[\\dfrac{ \\Delta _ {\\bf x} }{\\Vert {\\bf x} _ {\\rm svr} -  {\\bf x} _ {\\rm svl} \\Vert } = \\cos \\theta = \\dfrac{({\\bf x} _ {\\rm svr} - {\\bf x} _ {\\rm svl}) \\cdot \\bf w}{\\Vert {\\bf x} _ {\\rm svr} - {\\bf x} _ {\\rm svl} \\Vert \\Vert \\mathbf{w} \\Vert}\\]\n따라서\n\\[\\Delta _ {\\bf x}  = \\dfrac{({\\bf x} _ {\\rm svr} - {\\bf x} _ {\\rm svl}) \\cdot \\bf w}{\\Vert \\mathbf{w} \\Vert}\\]\n\\(y_i ( \\mathbf{w} \\cdot {\\bf x}_ i + b) - 1  = 0\\)의 양변에 \\(y_i\\)를 곱하면, \\(y_i^2 ( \\mathbf{w} \\cdot {\\bf x}_ i + b)  = y_i\\)가 된다. \\(y_i^2 =1\\)이므로,\n\\[\n\\begin{aligned}\n{\\bf x}_ {\\rm svr} \\cdot \\mathbf{w} + b  & = 1  \\\\\n{\\bf x}_ {\\rm svl}  \\cdot \\mathbf{w} + b  & = -1\n\\end{aligned}\n\\]\n여기서 \\(({\\bf x} _ {\\rm svr} - {\\bf x} _ {\\rm svl}) \\cdot \\mathbf{w} = 2\\)를 쉽게 도출할 수 있다. 결론적으로 두 서포트 벡터 사이의 거리를 최대화하는 문제는 \\(\\Vert \\bf w \\Vert\\)를 최소화하는 문제와 같다."
  },
  {
    "objectID": "posts/math-of/2019-05-06-math-svm.html#optimization-for-svm",
    "href": "posts/math-of/2019-05-06-math-svm.html#optimization-for-svm",
    "title": "Mathematics of Support Vector Machine",
    "section": "Optimization for SVM",
    "text": "Optimization for SVM\n\nMetrics to compare hyperplanes\n\nDefining functional margin\n\\(f_i = y_i(\\mathbf{w} \\cdot {\\bf x}_i + b)\\)가 있다고 하자. 이때 분류가 제대로 이루어졌다면, \\(f_i\\)의 부호는 언제나 양수다. 위의 분류의 정의에 따르면 그렇다. 데이터 셋 \\(D\\)의 정의는 다음과 같다.\n\\[\nD = \\left\\lbrace ({\\bf x}_i, y_i) \\mid {\\bf x}_ i \\in \\mathbb R^n,~y_ i \\in \\lbrace -1, 1\\rbrace  \\right\\rbrace_{i=1}^m\n\\]\n펑셔널 마진(functional margin)이라고 불리는 \\(F\\) 는 다음과 같다.\n\\[\nF = \\min_{i = 1, \\dotsc, m} y_i( \\mathbf{w} \\cdot {\\bf x} _i + b )\n\\]\n\\(\\mathbf{w}\\)와 \\(b\\)로 정의되는 하이퍼플레인이 모든 트레이닝 셋을 잘 분류했다면, \\(f_i &gt; 0\\)가 성립한다. 이 \\(f_i\\) 중 가장 작은 값이 functional margin이다. 그리고 두 번째로 서로 다른 하이퍼플레인 중에서 가장 큰 \\(F\\)를 지니는 하이퍼플레인이 최적이 하이퍼플레인이다.\n\n\\(F\\)를 얻기 위한 과정에서 최소화 로직이 들어간다. 즉, 해당 하이퍼플레인과 가장 가깝게 위치한 관측치를 얻어내는 과정\n이렇게 얻어낸 \\(F\\)들을 서로 다른 하이퍼플레인들 사이에 비교하고, 가장 큰 \\(F\\)를 주는 하이퍼플레인을 채택한다.\n\n표준화를 위해서 \\(\\bf w\\)의 norm으로 \\(f_i\\) 값을 나누고 극대화 문제를 정식화하면 아래와 같다.\n\n\n\nDerivation of SVM optimization problem\n표준화를 위해서 \\(\\Vert \\bf w \\Vert\\)로 목적함수와 제약을 나누자.\n\\[\n\\max_{\\mathbf{w} , b} M\\hspace{1em}\\text{s.t.}\\hspace{1em}\\gamma_i \\geq M\\hspace{1em}\\text{for}\\hspace{1em}i = 1,\\dotsc, m\n\\]\nwhere\n\\[\n\\gamma_i = y_i \\left( \\dfrac{\\mathbf{w} }{\\Vert \\mathbf{w} \\Vert} \\cdot {\\bf x}_i + \\dfrac{b}{\\Vert \\mathbf{w} \\Vert} \\right)\n\\]\n\\[\nM = \\min_{i=1, \\dotsc, m} \\gamma_i\n\\]\n표준화된 펑셔널 마진을 최대화하되, 트레이닝 샘플들이 이것보다 커야 한다는 조건(최소화)이 제약으로 들어간다. 즉, 아래의 식은 최소화 제약 하에서 \\(F\\)를 최대화한다는 이중 최적화 과정을 보여 준다.\n\\[\n\\max_{\\mathbf{w} , b} \\dfrac{F}{\\Vert w \\Vert}\\hspace{1em}\\text{s.t.}\\hspace{1em}f_i \\geq F \\hspace{1em}\\text{for}\\hspace{1em}i = 1,2, \\dotsc, m\n\\]\n위 극대화 문제에서 모든 변수는 상대값으로 정의할 수 있으므로 \\(F\\)를 1로 제한해도 해는 바뀌지 않는다. 그리고 아래와 같은 차례로 정식화할 수 있다.\n\\[\n\\max_{\\mathbf{w} , b} \\dfrac{1}{\\Vert w \\Vert}\\hspace{1em}\\text{s.t.}\\hspace{1em}f_i \\geq 1\\hspace{1em}\\text{for}\\hspace{1em}i = 1,2, \\dotsc, m\n\\]\n\\[\n\\min_{\\mathbf{w} , b} {\\Vert w \\Vert}\\hspace{1em}\\text{s.t.}\\hspace{1em}f_i \\geq 1\\hspace{1em}\\text{for}\\hspace{1em}i = 1,2, \\dotsc, m\n\\]\n\\[\n\\min_{\\mathbf{w} , b} \\dfrac{1}{2}{\\Vert w \\Vert}^2\\hspace{1em}\\text{s.t.}\\hspace{1em}f_i \\geq 1\\hspace{1em}\\text{for}\\hspace{1em}i = 1,2, \\dotsc, m\n\\]\n\n\nOptimization by Wolfe duality\n제약 하의 극대화 문제이므로 라그랑주 최적화로 바뀌서 볼 수 있다. 다음과 같이 라그랑주 방정식을 정의하자.\n\\[\n{\\mathcal L}(\\mathbf{w} , b, {\\boldsymbol \\alpha}) = \\frac{1}{2} \\mathbf{w} \\cdot \\mathbf{w} - \\sum_{i=1}^m \\alpha_i \\left [ y_i (\\mathbf{w} \\cdot {\\bf x}  + b) -1 \\right]\n\\]\n여기서 벡터 \\(\\boldsymbol \\alpha\\)는 라그랑주 최적화의 라그랑주 승수로 제약식을 반영하는 부분이다.\n일단, \\(\\alpha_i\\)를 무시하고 두 최적화 변수인 \\(\\bf w\\)와 \\(b\\) 에 대해서면 1계 조건을 풀면 다음과 같다.\n\\[\n\\begin{aligned}\n\\nabla_\\mathbf{w} {\\mathcal L}( {\\mathbf{w}, b, \\boldsymbol \\alpha} ) & = \\mathbf{w} - \\sum_{i}^{m} {\\alpha_i} {y_i} {x_i} = 0 \\\\\n\\nabla_{b} {\\mathcal L}({\\mathbf{w}, b, \\boldsymbol \\alpha}) & = - \\sum_{i}^{m} \\alpha_i y_i = 0\n\\end{aligned}\n\\]\n이 녀석들을 다시 라그랑주 방정식에 대입하면, \\(\\boldsymbol \\alpha\\)로만 된 일종의 maximal function 혹은 라그랑주 방정식의 하한(infimum)을 만들 수 있다. Wolfe duality에 따르면, 최소화 최대화를 한 번에 푸는 것과 한 가지 문제를 먼저 푼 후 해당 결과를 목적 함수에 넣고 두 번째 문제를 순차적으로 푸는 것이 동일하다. 따라서 위의 일계 조건을 목적 함수에 넣은 목적함수는 구해보자.\n\\[\nW(\\boldsymbol \\alpha)  = \\sum_{i=1}^m \\alpha_i - \\dfrac{1}{2}\\sum_{i=1}^{m} \\sum_{j=1}^m \\alpha_i \\alpha_j y_i y_j {\\bf x}_i \\cdot {\\bf y}_j\n\\]\n이제 문제는 \\(\\boldsymbol \\alpha\\)에 관해서 극대화 문제를 푸는 것으로 바뀐다. 즉,\n\\[\n\\max_{\\boldsymbol \\alpha} W( {\\boldsymbol \\alpha} )\\hspace{1em}\\text{s.t.}\\hspace{1em}{\\alpha_i} \\geq 0, \\sum_{i=1}^m \\alpha_i { \\left( y_i ( \\mathbf{w} \\cdot {\\bf x}^* + b) -1 \\right)} = 0\n\\]\n제약 부분이 부등식이므로 KT(Kuhn-Tucker) 조건에 따라서 풀면 된다.\n\\[\n\\alpha_i \\left[ y_i (\\mathbf{w} \\cdot {\\bf x}^* + b) -1 \\right] = 0\n\\]\nKT 조건이란 부등식 제약을 푸는 테크닉이다. 즉, \\(\\alpha_i &gt;0\\)의 제약이 유효하다면 제약을 만족시키기 위해서는 \\(y_i (\\mathbf{w} \\cdot {\\bf x}^* + b) -1 = 0\\)이 만족해야 한다. 이렇게 제약이 걸리는 경우에 위치한 \\(x^*\\)가 바로 ’서포트 벡터’다. 반면, \\(\\alpha_i =0\\)는 제약이 등호로 걸릴 필요가 없는 트레이닝 셋의 관찰들이다. 이들은 분류 하이퍼플레인까지의 길이가 서포트 벡터의 길이보다 크다.\n\n\nCompute w and b\n\\(\\bf w\\) 의 경우 1계 조건에서 쉽게 얻을 수 있다.\n\\[\n\\mathbf{w} - \\sum_{i=1}^m \\alpha_i y_i {\\bf x} _i = 0\n\\]\n한편, \\(b\\)의 경우 서포트 벡터의 경우 위에서 본 것 같이 제약 식의 등호가 성립한다. 즉, 서포트 벡터를 \\(x^*\\)라고 할 때,\n\\[\ny_i (\\mathbf{w} \\cdot {\\bf x}^* + b) -1 = 0\n\\]\n\n양변에 \\(y_i\\)를 곱하면, \\(y_i^2 = 1\\)이므로,\n\n\\[\nb = y_i - \\mathbf{w} \\cdot {\\bf x}^*\n\\]\n\n서포트 벡터가 S개 존재할 경우라면,\n\n\\[\nb = \\dfrac{1}{S} \\sum_{i=1}^S \\left( y_i - \\mathbf{w} \\cdot {\\bf x}^*_i \\right)\n\\]\n\n\nLimitation\n앞서 본 것을 이른바 hard margin SVM이다. 즉, 서포트 벡터 사이의 마진을 획일적으로 적용하는 분류 알고리듬이다. 하드 마진 SVM은 다음의 두가지 경우에 취약하다.\n\n데이터에 노이즈가 있을 경우\n하드 마진의 큰 문제는 아웃라이어에 취약할 수 밖에 없다는 것이다. 풀어서 말하면 제약이 선형이고 그 제약이 강력하다는 데 있다. 트레이닝 데이터에 이런 저런 노이즈가 있을 경우 하드 마진은 아예 계산이 불가능할 수 있다. 이때 사용하는 기법이 soft margin SVM이다.\n\n\n데이터 자체가 선형으로 분리되지 않을 경우\n애초부터 데이터 자체가 선형을 통한 분류를 허용하지 않을 경우에는 비선형 분류를 사용할 수 있다. 이때 동원하는 테크닉이 커널 트릭 (kernel trick)이다."
  },
  {
    "objectID": "posts/math-of/2019-05-06-math-svm.html#soft-margin-svm",
    "href": "posts/math-of/2019-05-06-math-svm.html#soft-margin-svm",
    "title": "Mathematics of Support Vector Machine",
    "section": "Soft Margin SVM",
    "text": "Soft Margin SVM\n제약을 약간 풀어주는 \\(\\zeta\\)를 도입하여 최적화 문제를 정식화하면 아래와 같다.\n\\[\n\\min_{\\mathbf{w}, b, {\\boldsymbol \\zeta}} \\dfrac{1}{2} \\Vert \\mathbf{w} \\Vert^2 + C \\sum_{i=1}^m \\zeta_i~\\text{s.t}~ y_i ( \\mathbf{w} \\cdot {\\bf x}_i + b) \\geq 1 - \\zeta_i~\\text{for}~ i = 1,2,\\dotsc, m\n\\]\n문제를 풀면\n\\[\n\\max_{\\boldsymbol \\alpha} \\sum_{i=1}^m \\alpha_i - \\dfrac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^{m} \\alpha_i \\alpha_j {y_i} {y_j} {\\bf x}_i \\cdot {\\bf x}_j \\hspace{1em} \\text{s.t.}\n\\]\n\\[\n0 \\leq \\alpha_i \\leq C\\hspace{1em}\\text{for}\\hspace{1em}i=1,2,\\dotsc, m\n\\]\n\\[\n\\sum_{i=1}^m \\alpha_i y_i = 0\n\\]\n\nWhat is C\n정규화 파라미터인 \\(C\\)를 어떻게 이해할까? 식 그대로 보면, \\(\\boldsymbol \\zeta\\)를 얼마나 중요하게 최적화 문제에 반영할 것인지가 중요하다. 다시 말하면 이는 에러를 어떻게 볼 것인가와 연결되어 있다. 만일 \\(C\\)가 양의 무한대 값이라면 이는 하드 마진과 동일하다. 만일 \\(C=0\\) 이라면 \\(\\alpha_i=0\\)가 된다. 이는 사실상 선형 제약이 사라지게 되는 결과가 된다. 따라서 하이퍼플레인이 어떤 것도 분류하기 못하게 될 것이다. 즉, C는 하드 마진과 소프트 마진 사이를 적절하게 조절하는 역할을 수행한다.\n\n\nKernel Trick\n마지막에 얻은 극대화 문제를 살펴보면, training set이 관련된 부분이 딱 하나 밖에 없다. \\({\\bf x}_i \\cdot {\\bf x}_j\\) 뿐이다. 따라서 이 부분을 유연하게 조정해줌으로써 비선형적 형태의 분류를 만들 수 있는 것이다. 앞서 봤던 하드 마진 SVM은 선형 커널을 사용한다. 즉,\n\\[\nK({\\bf x}_i, {\\bf x}_j) = {\\bf x}_i \\cdot {\\bf x}_j\n\\]\n이런 커널만 있을 형태는 없다. 여러가지 함수를 커널로 취할 수 있을 것이다. 가장 많이 사용되는 커널은 RBF(Radial Basis Function) 혹은 가우시안이라고 한다.\n\\[\nK({\\bf x}_i, {\\bf x}_j) = \\exp \\left( -\\gamma \\Vert {\\bf x}_i - {\\bf x}_j \\Vert \\right)\n\\]\n\n\\(\\gamma\\) 값이 충분히 작으면 선형 커널과 비슷하게 작동한다.\n\\(\\gamma\\)가 크면 서포트 벡터에게 크게 영향 받는다."
  },
  {
    "objectID": "posts/math-of/2019-05-06-math-svm.html#resource",
    "href": "posts/math-of/2019-05-06-math-svm.html#resource",
    "title": "Mathematics of Support Vector Machine",
    "section": "Resource",
    "text": "Resource\n이 자료는 아래 내용을 바탕으로 만들어졌습니다.\n\nBasic: LINK\nIllustration: LINK"
  },
  {
    "objectID": "posts/git/2020-03-05-using-git-w10.html",
    "href": "posts/git/2020-03-05-using-git-w10.html",
    "title": "Using Git ‘Smoothly’ in Windows 10",
    "section": "",
    "text": "Note\n\n\n\n윈도에서 깃을 쓸 때 이렇게 불편하게 쓰지 않아도 된다."
  },
  {
    "objectID": "posts/git/2020-03-05-using-git-w10.html#why",
    "href": "posts/git/2020-03-05-using-git-w10.html#why",
    "title": "Using Git ‘Smoothly’ in Windows 10",
    "section": "Why",
    "text": "Why\n단언컨대 git은 곧 문과생도 알아야 할 필수 도구가 될 것이다. 버전 관리가 절실해지는 그리고 코딩이 학제를 넘어선 필수처럼 인정되는, 그런 세상에서 컴퓨터를 끼고 있으면서 git의 사용을 피하기는 힘들 듯 싶다. git에 관한 포스트는 아니니 여기까지 하자.\nmacos나 linux 계열을 쓸 때는 git에 관해서 크게 고민하지 않아도 된다. 터미널 켜고, CLI(Command Line Interface)로 쓰면 그만이다. 이렇게 쓰는 것이 윈도에서는 쉽지 않다. 물론 윈도에서 WSL로 리눅스를 지원하기는 한다. 하지만 그냥 메인 os 위에 얹어 쓰는 게 편할 때가 있다."
  },
  {
    "objectID": "posts/git/2020-03-05-using-git-w10.html#what",
    "href": "posts/git/2020-03-05-using-git-w10.html#what",
    "title": "Using Git ‘Smoothly’ in Windows 10",
    "section": "What",
    "text": "What\n우리는 아래 두 개의 소프트웨어를 쓸 것이다.\n\nGit for Windows\nCmder\n\n\nGit for Windows\n웬만하면 64비트로 깔자. 그리고 중간에 여러 가지 선택지에 관해서 질문한다. 커맨드라인은 어떤 것으로 쓸 것인지 등등. 원래 git이 linux에 뿌리를 두고 있는 만큼 윈도의 디폴트 명령창보다는 Bash를 쓰는 편이 좋다. ls 등의 명령어를 자유롭게 쓸 수 있어서 꽤 편하다. 윈도용 git은 특화된 git-bash를 제공하니, 이 녀석을 쓰면 좋을 듯 싶다.\n\n\nCmder\n“커맨더”라고 읽으면 된다. git은 이미 깔았으므로 쓰면 된다. 다만 좀 더 편리한 환경에서 CLI를 쓰기 위해서 Cmder를 깔아보도록 하자. 이 녀석은 별도의 인스톨 없이 쓸 수 있다. git을 포함한 무거운 버전과 git이 빠진 미니 버전이 있다. 어차피 우리는 별도로 깃을 깔았으니, 미니 버전을 다운받으면 되겠다. 다운 받은 후 아무 위치에나 두어도 된다. 어차피 exe 파일만 사용할 것이기 때문이다. 다만, 관리가 편하도록 나는 아래의 위치에 두었다.\nUsers\\[your id]\\cmder_mini\\\n최초 실행하면 윈도우가 경고를 날린다. 이래 그림에서 형광색이 칠해진 부분을 클릭하고 프로그램을 허용해준다. 이후 몇 번의 경고성 질문이 더 날아온다. 전부 “허용”해주면 되겠다.\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n그리고 cmder 실행 파일 위에서 좌 클릭해서, 속성 &gt; 호환성 &gt; 관리자 권한으로 이 프로그램을 실행을 체크해두는 편을 권한다. 혹시 dock에 cmder를 박아둔 상태라면 Shift 키와 함께 좌 클릭을 하면 속성을 선택할 수 있다."
  },
  {
    "objectID": "posts/git/2020-03-05-using-git-w10.html#how",
    "href": "posts/git/2020-03-05-using-git-w10.html#how",
    "title": "Using Git ‘Smoothly’ in Windows 10",
    "section": "How",
    "text": "How\n깃을 편하게 쓰기 위해서 Cmder의 설정을 약간 바꿔주겠다. 우선 아래의 그림처럼 맨 위 메뉴의 삼선을 클릭하면 Cmder의 세팅으로 갈 수 있다.\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n엄청나게 많은 설정들이 있다. 창을 투명으로 만든다든가, 텍스트의 폰트를 바꾼다든가, 하는 것들이 가능하다. 여기서는 git bash를 쓰는 설정만 간단하게 설명하도록 하자.\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n그림에서 보듯이 startup &gt; task를 선택한다. 선택 가능한 CLI 중에서 {Bash:: Git bash}를 선택한다. 이 녀석을 디폴트 CLI로 설정한다. 시작 디렉토리를 지정하고 싶다면 아래 Startup dir...을 선택해 바꿔주면 된다."
  },
  {
    "objectID": "posts/git/2020-03-05-using-git-w10.html#finally",
    "href": "posts/git/2020-03-05-using-git-w10.html#finally",
    "title": "Using Git ‘Smoothly’ in Windows 10",
    "section": "Finally?",
    "text": "Finally?\n아래 그림에서 보듯이 윈도 명령 창에서는 먹지 않는 ls 등의 명령어가 잘 먹고, git도 편안하게 사용할 수 있다."
  },
  {
    "objectID": "posts/git/2020-03-05-using-git-w10.html#seriously",
    "href": "posts/git/2020-03-05-using-git-w10.html#seriously",
    "title": "Using Git ‘Smoothly’ in Windows 10",
    "section": "Seriously!",
    "text": "Seriously!\n여기까지 좋은데, git-bash에서 python을 쓰시는 분들이라면 python을 제대로 띄울 수 없다. 해결책은 간단하다. 아래와 같이 실행하면 된다.1\n매번 이럴게 winpty로 띄울 수는 없으니 .bashrc에 넣도록 하자.\n$ echo \"alias python='winpty python.exe'\" &gt;&gt; ~/.bashrc\n넣은 뒤에 터미널을 재실행하거나 source ~/.bashrc를 실행해주면 된다."
  },
  {
    "objectID": "posts/git/2020-03-05-using-git-w10.html#footnotes",
    "href": "posts/git/2020-03-05-using-git-w10.html#footnotes",
    "title": "Using Git ‘Smoothly’ in Windows 10",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n출처는 여기다.\n$ winpty python.exe\nPython 3.7.6 (default, Oct  2 2018, 09:18:58)\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt;\n↩︎"
  },
  {
    "objectID": "posts/economics/2020-01-22-Wealth-divided.html",
    "href": "posts/economics/2020-01-22-Wealth-divided.html",
    "title": "The College Wealth Divide",
    "section": "",
    "text": "The College Wealth Divide: Education and Inequality in America, 1956-2016 download Alina K. Bartscher, Moritz Kuhn, and Moritz Schularick"
  },
  {
    "objectID": "posts/economics/2020-01-22-Wealth-divided.html#source",
    "href": "posts/economics/2020-01-22-Wealth-divided.html#source",
    "title": "The College Wealth Divide",
    "section": "",
    "text": "The College Wealth Divide: Education and Inequality in America, 1956-2016 download Alina K. Bartscher, Moritz Kuhn, and Moritz Schularick"
  },
  {
    "objectID": "posts/economics/2020-01-22-Wealth-divided.html#addressing-issues",
    "href": "posts/economics/2020-01-22-Wealth-divided.html#addressing-issues",
    "title": "The College Wealth Divide",
    "section": "Addressing Issues",
    "text": "Addressing Issues\n\n새로운 설문 데이터의 발굴을 통해 대졸자와 비대졸자 사이의 소득과 부의 장기 추세를 살펴본다.\n대학 졸업에 따른 소득 프리미엄과 부 프리미엄의 패턴 차이가 확연히 존재하는데, 이러한 결과가 생긴 원인을 추적한다."
  },
  {
    "objectID": "posts/economics/2020-01-22-Wealth-divided.html#data",
    "href": "posts/economics/2020-01-22-Wealth-divided.html#data",
    "title": "The College Wealth Divide",
    "section": "Data",
    "text": "Data\n\n미국 연준에서 다운로드 받을 수 있는 Survey of Consumer Finances(SCF)라는 데이터가 있다. 이 데이터는 3년 간격으로 1983년부터 설문 자료를 수집하고 있는데, 여타 센서스와 같은 설문 항목과 비교해서 금용 관련된 상세한 내용을 담고 있다.\n그런데 SCF에 선배라고 할만한 자료가 1947년에서 1971년 사이 그리고 1977년에 대해서 미시건 대의 서베이 리서치 센터에 존재한다. Kuhn, Schularick, Steins가 이 두 자료를 코드 북에 기반해서 자료를 최대한 비슷하게 맞춰 결합했고, 이렇게 1949년~2016년의 전후 기간을 망라한 소득, 부 그리고 관련된 인구 통계적 정보를 담고 있는 데이터 셋이 만들어졌다. 저자들은 이를 SCF+라고 부른다.[^1] [^1]: 매칭과 데이터 결합에 필요한 절차 및 기법은 논문에 비교적 상세하게 소개되어 있으니 관심 있는 분은 참조하시라."
  },
  {
    "objectID": "posts/economics/2020-01-22-Wealth-divided.html#issues",
    "href": "posts/economics/2020-01-22-Wealth-divided.html#issues",
    "title": "The College Wealth Divide",
    "section": "Issues",
    "text": "Issues\n\nIncome premium vs wealth premium\n\n저자들의 관심사는 대졸자와 비대졸자(앞으로 혼란의 여지가 없을 때 각각 c(college), nc(noncollege)로 표기하겠다) 사이에 소득과 부의 차이가 역사적으로 어떻게 진화했는지를 파악하는 것이다. 우선 그림 1을 보자.\n\n\n\n그림1에서 \\(y\\)축은 1971년도 수준을 1로 두었을 때 각 연도의 소득과 부의 수준을 나타낸다. 시간에 흐름에 따라서 소득의 차이가 상대적으로 적게 벌어졌음에 반해서 부의 차이는 크게 벌어지고 있다. 특히 1980년대 이후 차이가 크게 벌어지고 있다.\n이는 소득과 부의 비율을 c와 nc로 나누어 비교한 그림2에서 보다 분명하게 드러난다.\n\n\n\n\nDecomposing wealth premium\n\\[\n\\dfrac{\\overline{W}_{e,t}}{\\overline{W}_{e,71}} = \\dfrac{\\sum^{3}_{i=1} s_{e,i,t} \\overline{W}_{e,i,t}}{\\overline{W}_{e,71}} = \\sum^{3}_{i=1} s_{e,i,t} \\dfrac{\\overline{W}_{e,i,71}}{\\overline{W}_{e,71}} \\dfrac{\\overline{W}_{e,i,t}}{\\overline{W}_{e,i,71}}\n\\] - 변수 - \\(\\overline {W}_\\cdot\\): 해당 집단이 보유한 평균 부 - \\(s_\\cdot\\): 해당 부 계층의 비율. - \\(s_{c, 1, 81}\\)이라면 1981년도 c에 속한 사람들 중에서 전체 부의 계층 1에 속하는 비율을 나타낸다.\n\n인덱스\n\n\\(e = {\\rm c, nc}\\)\n\\(t =\\) 56, 61, 66, 71, 76, 81, 86, 91, 96, 01, 06,11, 16\n\\(i = 1, 2, 3\\)\n\n\\(e\\)는 c와 nc의 구분을 \\(t\\)는 연도, 그리고 \\(i\\)는 세 가지로 구분한 부 계층을 구분하기 위한 인덱스다. 1은 하위 50%, 2는 중위 50%~90%, 그리고 3은 상위 10%를 각각 나타낸다.\n분해 식을 통해서 크게 세가지 변동을 구분할 수 있다.\n\n\\(s\\)의 변화\n\\[\\dfrac{\\overline{W}_{e,i,71}}{\\overline{W}_{e,71}}\\]: 기준 연도의 부 계층의 차이\n\\[\\dfrac{\\overline{W}_{e,i,t}}{\\overline{W}_{e,i,71}}\\]: 기준 연도 대비 특정 부 계층의 연도별 변화\n\n이 세 가지에 분해 요소 중에서 시간을 따라가지 않은 두 번째를 제외하고 나머지에 대해서 반사실(counterfactual)을 적용해보자.\nCounterfactual 1 \\[\n\\dfrac{\\overline{W}_{x,i,t}}{\\overline{W}_{x,i,71}} =\n\\begin{cases}\n\\dfrac{\\overline{W}_{nc,i,t}}{\\overline{W}_{nc,i,71}} & \\text{if $x = \\rm{c}$} \\\\\n\\dfrac{\\overline{W}_{c,i,t}}{\\overline{W}_{c,i,71}}  & \\text{if $x = \\rm{nc}$}\n\\end{cases}\n\\]\nCounterfactual 2\n\n\\(s_{x,i,t}\\) 대신 \\(s_{x,i,71}\\)을 적용한다. 즉, 시간이 지나면서 학력별 부 계급의 분포가 1971년도 지표에 고정되어 있었을 상황을 대입해본다. 이는 시간이 지나면서 소득 불평등의 패턴이 n, nc 사이에 차별적으로 타나났는지를 추적한다.\n같은 맥락에서 n와 nc의 \\(s\\)를 바꾸는 분석도 해볼 수 있을 듯 한데, 저자들이 시도하지는 않았다.\n\n\n\n\n그림 3의 A는 c의 부에 대해서 반사실 1, 2 그리고 1+2를 적용했을 때의 변화를 나타낸다. 반사실 1의 영향이 크고, 반사실 2는 거의 영향을 주지 않았다. 이를 통해 시간이 지나면서 c의 경우 nc에 비해서 더 많은 부를 축적했음을 보여준다. 반면, 코호트(n, nc) 내에서 부의 계층 변화는 거의 영향을 주지 않았다.\n한편, nc의 경우는 반사실 1과 반사실 2가 모두 부의 축적에 악영향을 주었음을 알 수 있다.\n각 코호트별로 부의 계층별 점유율 변화는 그림 4와 같다.\n\n\n\n그림에서 보듯이 c의 경우 연도 변화에 따른 계층별 변화가 크지 않다. nc의 경우 상위 10%에 속하는 비율이 경향적으로 낮아지고 있다.\n\n\n\n그림 5는 전체 인구에서 c가 차지하는 비중의 연도별 변화와 중간 계층(50~90%)의 변화가 비슷하게 진행되었음을 알 수 있다. 반면 c의 경우 50% 아래로 떨어지기보다는 상위 10%로 진입한 경향이 많았다는 점도 확인할 수 있다."
  },
  {
    "objectID": "posts/economics/2020-01-22-Wealth-divided.html#regression-analysis",
    "href": "posts/economics/2020-01-22-Wealth-divided.html#regression-analysis",
    "title": "The College Wealth Divide",
    "section": "Regression analysis",
    "text": "Regression analysis\n\n대학 졸업 여부가 어느 측면에서 부의 축적에 영향을 주었는지 살펴보기 위해서 계량적 분석을 시도 했다. 즉, c 여부가 부의 증가에 어떻게 영향을 주었는가를 보다 면밀하게 살펴보는 것이 분석의 목표다.\n\n\n\n그림 6은 c와 nc의 격차를 소득과 부 각각에 관해 표시한 것이다. 앞서 보았듯이 1980년대 이전까지는 소득과 부 모두 1 주변에 머물다가 1980년대 이후 부의 증가가 점점 격차를 벌이며 증가하는 추세를 보이고 있다. 혹시 이러하는 추세가 c에 속한 상위 10%의 보다 빠른 부의 축적 때문이었을까? 코호트를 중위 소득 계층(50~90%)으로 제한해서 살펴보면 그림 7과 같다. 그림에서 보듯이 c의 자산 증가는 최상 계층의 현상이 아닌 일반적인 추세였다고 볼 수 있겠다.\n\n\n\n질문은 무엇이 c의 빠른 부의 축적을 낳았는가, 하는 대목이다. 일반 기본적으로 살펴본 회귀 식은 다음과 같다.\n\n\\[\nW_{it} = \\alpha_0 + \\underbrace{\\beta_1 c_{it}}_{A} + \\underbrace{\\sum_{t &gt; 1956} \\beta_{2,t}~\\mathbb{I}_{year = t} \\cdot c_t}_{B} +  \\underbrace{\\sum_{t &gt; 1956} \\beta_{3,t}~\\mathbb{I}_{year = t}}_{C} + \\underbrace{\\Gamma' X_{it}}_{D} + \\xi_{it}\n\\]\n\n회귀분석의 각 부분을 간략하게 살펴보자.\n\nA: 대학 졸업 여부가 전체 기간에 걸쳐 부에 미치는 효과\nB: 연도별로 구분된 대학 졸업 여부가 부에 미치는 효과\nC: 연도별 효과가 부에 미치는 효과\nD: 통제 변수 (소득수준, 결혼 여부, 자녀 유무 등)\n\n부에 c가 미치는 효과는 \\(\\beta_1 + \\beta_{2,t}\\)로 연도별로 측정할 수 있다.\n\n\n\n그림 8에서 보듯이 c의 효과는 분명하다. 다만 소득 계층 기준으로 전체 집단의 효과가 50~90%의 중간 층에 비해 강하게 나타고 있다. 그림 9를 통해 이 내용을 다시 살펴보자.\n\n\n\n그림 9는 소득 계층별로 나누어 결과를 나타내고 있다. 왼쪽은 좌변의 종속 변수가 부이고 오른쪽은 종속 변수가 소득이다.\n\nc에 대해서 부의 효과가 전반적으로 높으며 특히 상위 10%에 두드러진다.\n소득에 대해서는 이러한 효과가 나타나지 않는다. 특히 상위 10%를 제외하면 c의 소득 증가 효과는 거의 없다고 봐도 좋다.\n\n논문에서는 이러한 c의 효과가 어디서 비롯하는지를 조금 더 탐구하고 있다. 자료의 한계 때문에 상세하게 추적하지는 못한다. 다만 c와 nc 사이에 존재하는 중요한 차이로 금융 지식(financial literacy)의 차이를 지목하고 있다. 즉, 소득을 투자로 전환할 수 있는 수단을 알고 있었는지 여부가 중요하다는 것이다. 논문에서 주목한 또 하나의 차이는 사업체의 소유 여부다. 이 역시 부의 차이를 만들어내는 데 일정한 역할을 한다.\n논문에서 제기한 또 하나의 흥미로운 질문은 금융 지식의 여부가 c와 nc 사이에 세분화되어 있는지 여부다. 다시 말하면, 두 코호트가 같이 금융 상품에 투자했다면, 누가 더 잘 하는가에 관한 것이다.\n\n\n\n그림 10의 A에 따르면 사업체 보유자와 미 보유자 사이에는 수익률 차이가 존재한다. 하지만 n와 nc 사이에 차이는 거의 없다. 나머지 그림에서도 n와 nc 사이에 뚜렷한 차이를 발견하기 힘들다. 즉 c와 nc 사이의 금융 지식의 차이란 투자 대상의 인지 및 실행과 같은 차원일 가능성이 높다는 것이다."
  },
  {
    "objectID": "posts/economics/2020-01-22-Wealth-divided.html#extra",
    "href": "posts/economics/2020-01-22-Wealth-divided.html#extra",
    "title": "The College Wealth Divide",
    "section": "Extra",
    "text": "Extra\n\n개인적으로 재미있게 본 내용 하나 추가한다. 유유상종 혼(assortative marriage)이 존재하는지 여부에 관한 것이다.\n\n교육 년수를 12년 미만(중퇴), 고졸, 대졸로 구분하면 3X3 테이블이 나온다.\n이제 각각의 경우에 해당하는 부부의 비율을 구한다.\n각각의 인구 비율이 무작위로 매칭되었을 때의 비율을 구한다.\n실제의 유유상종 혼의 비율과 무작위의 비율을 비교하면 유유상종의 정도가 계산된다.\n\n논문에서 밝힌 바에 따르면 대졸자의 유유상종 혼은 줄어드는 추세다. 즉, 1965년에 위 비율은 5.9였는데, 2016년에는 1.8에 불과하다. 즉 유유상종 혼은 감소하는 추세다.\n다음으로 유유상종 혼이 부의 창출에 있어서 단순 합을 넘어서는 추가적인 이득을 제공하는가 여부에 관한 것이다.\n\n\n\n\n유유상종과 부의 불평등\n\n\n\nA, B에서 보듯이 소득과 부 모두 유유상종 혼 상태의 가구가 평균보다 두 배 가량 높다. 하지만 C, D에서 보듯이 이를 각 해당 연도의 유유상종 혼 인구가 점유한 부의 비율과 유유상종 혼 인구의 비율로 나눈 수치는 거의 일정한 수준을 유지하고 있다."
  },
  {
    "objectID": "posts/the-lectures/2024-02-13-statquest-transformer.html",
    "href": "posts/the-lectures/2024-02-13-statquest-transformer.html",
    "title": "Transformer",
    "section": "",
    "text": "Transformer를 급히 찍먹한다."
  },
  {
    "objectID": "posts/the-lectures/2024-02-13-statquest-transformer.html#tl-dr",
    "href": "posts/the-lectures/2024-02-13-statquest-transformer.html#tl-dr",
    "title": "Transformer",
    "section": "",
    "text": "Transformer를 급히 찍먹한다."
  },
  {
    "objectID": "posts/the-lectures/2024-02-13-statquest-transformer.html#인풋과-아웃풋의-크기가-다를-때",
    "href": "posts/the-lectures/2024-02-13-statquest-transformer.html#인풋과-아웃풋의-크기가-다를-때",
    "title": "Transformer",
    "section": "인풋과 아웃풋의 크기가 다를 때",
    "text": "인풋과 아웃풋의 크기가 다를 때\nRNN은 CNN과 달리\n\n\n\n\n\n\n \n\n\n\n\n\n기본 인코딩 세팅은 그림과 같다."
  },
  {
    "objectID": "posts/the-lectures/2024-02-13-statquest-transformer.html#four-key-components",
    "href": "posts/the-lectures/2024-02-13-statquest-transformer.html#four-key-components",
    "title": "Transformer",
    "section": "Four Key Components",
    "text": "Four Key Components\n트랜스포머는 크게 4가지의 구성요소로 이루어져 있다.\n\nPositional Encoding\nSelf-Attention Mechanism\nEncoder\nDecoder\n\n\nPositional Encoding\n단어의 위치를 인코딩하는 방법이다. 여러가지 방법이 있지만 사인-코사인 커브를 사용하는 것이 제일 일반적이라고 한다. 언뜻 보면 이해가 가지 않지만 사인 코사인의 파동 값을 활용하면 별다른 정보 손실 없이 벡터로 토큰의 위치 정보를 잘 반영할 수 있다.\n\n\n\n\n\n\n\n\n\n포지셔널 인코딩은 그림과 같이 수행한다.\n\n\n\n\n \n\n\n\n\n\n“+” 그림은 포지너설 인코딩을 의미한다.\n\n\n\n\n\n\n\nSelf-Attention Mechanism\n자신을 포함해서 단어 사이의 유사도를 계산한다.\n\n\n\n\n\n\n \n\n\n\n\n\n자신을 포함해서 문장 내 단어 사이의 유사도를 추적하자.\n\n\n\n\n \n\n\n\n세 가지 하부 요소가 있다.\n\nQueries: 각 단어 자체를 표현하는 뉴럴넷의 중간 결과\nKeys: 각 단어와 다른 단어를 비교할 때 활용할 뉴럴넷의 중간 결과\nValues: 각 단어의 셀프 어텐션을 거친 중요도를 표현하는 뉴럴넷의 (중간) 결과\n\n쿼리와 키의 닷프로덕트를 구하면 스칼라 값을 얻게 된다. 이 녀석을 다시 softmax 함수에 넣어 정규화한 후 이 값을 세번째 구성요소인 Value를 거치도록 한다.\n\n\n\n\n\n\n \n\n\n\n\n\n셀프 어텐션 인코딩 과정\n\n\n\n\n \n\n\n\n그림을 보면서 다시 한번 확인하자. 위 그림은 “let’s”가 자신 및 “go”와의 셀프 어텐션을 고려하여 Query, Key, Value를 계산하는 과정을 보여준다.\n같은 방식으로 “go”에 대해서도 계산을 수행한다. 여기서 중요한 대목이 나온다. “go”에 대해서 인코딩을 할 때 Query, Key, Value의 웨이트를 “Let’s” 때 썼던 것을 그대로 활용한다. 한 문장 안에서 단어의 의미가 맺고 있는 연결망이 같다고 보면다면 재활용이 가능하다. 그리고 이 때문에 병렬화가 가능하다! 즉 RNN처럼 앞부터 순차적으로 계산할 필요성이 사라지는 것이다.\n\n\n정리\n\n\n\n\n\n\n\n\n\n트랜스포머 인코딩의 4단계\n\n\n\n\n \n\n\n\n\n\n병렬화가 가능하다!\n\n\n\n\n\n\nWord Embedding: 단어를 벡터로 표현한다.\nPositional Encoding: 단어의 위치를 인코딩한다.\nSelf-Attention Mechanism: 단어 사이의 유사도를 계산한다.\nResidual Connection\n\n\n\nComments\n\n\n\n\n\n\n\n\n\n멀티-헤드 어텐션\n\n\n\n\n \n\n\n\n\n\nResidual Connection\n\n\n\n\n\n\n \n\n\n멀티-헤드 어텐션은 같은 단어가 여러 개의 의미를 지니는 경우를 위해 필요하다. 몇 개를 설정해야 하는지는 흑마술이다. 원활한 학습을 도모하기 위해서 워드 임베딩과 포지셔널 임베딩의 벡터를 더하는 것이 residual connection의 역할이다.\n\n\n \n\n\n\n만일 셀프 어텐션에서 같은 언어끼리라도 문장에서 서로 다른 의미망을 지닐 수 있다면 여러 개의 어텐션 유닛이 필요할 것이다. 이를 multi-head attention이라고 한다."
  },
  {
    "objectID": "posts/the-lectures/2024-02-13-statquest-transformer.html#decoder",
    "href": "posts/the-lectures/2024-02-13-statquest-transformer.html#decoder",
    "title": "Transformer",
    "section": "Decoder",
    "text": "Decoder\n강의는 영어-스페인어의 번역의 맥락을 살펴보고 있다. 따라서 스페인어의 인코딩에서 시작한다.\n스페인어에 대해서 4단계의 트랜스포머 셀프-어텐션 프로세스를 마치고 어텐션 아웃풋을 얻는다. 인코딩의 과정이 기본적으로 동일하다. 다만 서로 다른 구조(언어)의 문장이므로 각 단계에 활용되는 웨이트는 다르다.\n\n\n\n\n\n\n \n\n\n\n\n\n디코더에 들어갈 인풋의 인코딩"
  },
  {
    "objectID": "posts/the-lectures/2024-02-13-statquest-transformer.html#encoder-decoder-attention",
    "href": "posts/the-lectures/2024-02-13-statquest-transformer.html#encoder-decoder-attention",
    "title": "Transformer",
    "section": "Encoder-Decoder Attention",
    "text": "Encoder-Decoder Attention\n이제 이 두 개의 어텐션을 엮을 차례다. 어텐션 밸류가 생성된 디코더를 쿼리 자리에 넣고 인코더의 키를 활용해서 결과를 얻는다.\n\n\n\n\n\n\n\n\n\n인코더-디코더 어텐션\n\n\n\n\n \n\n\n\n\n\n인코더-디코더 어텐션 밸류 아웃풋\n\n\n\n\n\n인코더-디코더 어텐션의 아웃풋이 생성되고 난 후 마지막에 뉴럴넷을 통해서 스페인어 아웃풋을 산출한다. &lt;EOS&gt;(End of Sentence)까지 투입을 마치면 한 문장에 관한 번역이 완료된다.\n\n\n\n기본 인코딩 세팅은 그림과 같다.\n포지셔널 인코딩은 그림과 같이 수행한다.\n“+” 그림은 포지너설 인코딩을 의미한다.\n자신을 포함해서 문장 내 단어 사이의 유사도를 추적하자.\n셀프 어텐션 인코딩 과정\n트랜스포머 인코딩의 4단계\n병렬화가 가능하다!\n멀티-헤드 어텐션\nResidual Connection\n디코더에 들어갈 인풋의 인코딩\n인코더-디코더 어텐션\n인코더-디코더 어텐션 밸류 아웃풋"
  },
  {
    "objectID": "posts/the-lectures/2024-02-22-statquest-matrix.html",
    "href": "posts/the-lectures/2024-02-22-statquest-matrix.html",
    "title": "Matrix Algebra and Neural Networks",
    "section": "",
    "text": "선형대수는 인생을 쉽게 하지~"
  },
  {
    "objectID": "posts/the-lectures/2024-02-22-statquest-matrix.html#tl-dr",
    "href": "posts/the-lectures/2024-02-22-statquest-matrix.html#tl-dr",
    "title": "Matrix Algebra and Neural Networks",
    "section": "",
    "text": "선형대수는 인생을 쉽게 하지~"
  },
  {
    "objectID": "posts/the-lectures/2024-02-22-statquest-matrix.html#넋두리",
    "href": "posts/the-lectures/2024-02-22-statquest-matrix.html#넋두리",
    "title": "Matrix Algebra and Neural Networks",
    "section": "넋두리",
    "text": "넋두리\n선형대수는 딥러닝 알고리즘 과정을 묘사하고 이해는데 편리하고 간결한 표현 형식을 제공한다. 강의의 내용을 살펴보자."
  },
  {
    "objectID": "posts/the-lectures/2024-02-22-statquest-matrix.html#행렬의-본질",
    "href": "posts/the-lectures/2024-02-22-statquest-matrix.html#행렬의-본질",
    "title": "Matrix Algebra and Neural Networks",
    "section": "행렬의 본질",
    "text": "행렬의 본질\n행렬을 함수로 이해하면 좋다. 즉, 어떤 인풋이 있을 때 이를 이렇게 저렇게 변형하는 것이 형렬의 역할이다.\n\n\n\n\n\n\n\n\n\n행렬은 변형\n\n\n\n\n \n\n\n\n\n\n행렬 곱은 합성함수와 유사하다"
  },
  {
    "objectID": "posts/the-lectures/2024-02-22-statquest-matrix.html#뉴럴넷을-행렬-연산으로-표현하기",
    "href": "posts/the-lectures/2024-02-22-statquest-matrix.html#뉴럴넷을-행렬-연산으로-표현하기",
    "title": "Matrix Algebra and Neural Networks",
    "section": "뉴럴넷을 행렬 연산으로 표현하기",
    "text": "뉴럴넷을 행렬 연산으로 표현하기\n\n\n\n\n\n\n\n\n\n아래의 뉴럴넷은 위의 행렬 연산\n\n\n\n\n \n\n\n\n\n\n매트릭스 표현"
  },
  {
    "objectID": "posts/the-lectures/2024-02-22-statquest-matrix.html#pytorch의-사례-보기",
    "href": "posts/the-lectures/2024-02-22-statquest-matrix.html#pytorch의-사례-보기",
    "title": "Matrix Algebra and Neural Networks",
    "section": "pytorch의 사례 보기",
    "text": "pytorch의 사례 보기\n파이토치 설명 중에서 다음과 같은 대목이 눈에 띈다.\n\n\n\n\n\n\n\n\n\n선형 결합으로 구성된 뉴럴넷\n\n\n\n\n \n\n\n\n\n\n뉴럴넷의 선형적 의미"
  },
  {
    "objectID": "posts/the-lectures/2024-02-22-statquest-matrix.html#어텐션의-행렬-표현",
    "href": "posts/the-lectures/2024-02-22-statquest-matrix.html#어텐션의-행렬-표현",
    "title": "Matrix Algebra and Neural Networks",
    "section": "어텐션의 행렬 표현",
    "text": "어텐션의 행렬 표현\n어텐션도 네트워크로 그리면 복잡하지만 행렬로 표현하면 간단하다!\n\n\n\n\n\n\n\n\n\n어텐션의 행렬 표현\n\n\n\n\n \n\n\n\n\n\n풀어보면 이렇다!\n\n\n\n\n\n\n\n\n행렬은 변형\n행렬 곱은 합성함수와 유사하다\n아래의 뉴럴넷은 위의 행렬 연산\n매트릭스 표현\n선형 결합으로 구성된 뉴럴넷\n뉴럴넷의 선형적 의미\n어텐션의 행렬 표현\n풀어보면 이렇다!"
  },
  {
    "objectID": "posts/the-lectures/2024-02-13-statquest-rnn.html",
    "href": "posts/the-lectures/2024-02-13-statquest-rnn.html",
    "title": "Recurrent Neural Network",
    "section": "",
    "text": "RNN 찍먹하자."
  },
  {
    "objectID": "posts/the-lectures/2024-02-13-statquest-rnn.html#tl-dr",
    "href": "posts/the-lectures/2024-02-13-statquest-rnn.html#tl-dr",
    "title": "Recurrent Neural Network",
    "section": "",
    "text": "RNN 찍먹하자."
  },
  {
    "objectID": "posts/the-lectures/2024-02-13-statquest-rnn.html#기본-구조",
    "href": "posts/the-lectures/2024-02-13-statquest-rnn.html#기본-구조",
    "title": "Recurrent Neural Network",
    "section": "기본 구조",
    "text": "기본 구조\nRNN은 Recurrent Neural Network의 약자로, 시퀀스 데이터를 처리하는 데 사용되는 신경망이다. 시퀀스 데이터란, 데이터의 순서가 중요한 데이터를 말한다. 예를 들어, 문장, 음성, 동영상 등이 있다. RNN은 이러한 계열, 순서를 지니는 데이터에 활용된다.\n다른 신경망과 구별되는 RNN의 핵심 발상은 한번 신경망을 거친 결과가 뒤에 따라온 데이터와 함께 학습에 다시 활용된다는 것이다. 그림으로 표현한 아래의 내용을 확인하자.\n\n\n\n\n\n\n\n\n\n피드백 루프로 표현하는 방식\n\n\n\n\n \n\n\n\n\n\n나란히 아래로 표현하는 방식\n\n\n\n\n\n피드백 루프로 표현하는 방식이 혼란의 여지가 있으므로 나란히 표현하는 방식을 활용해 구체적인 계산을 살펴보자.\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n투입이 3개일 때\n\n\n\n\n \n\n\n\n\n\n같은 웨이트와 바이어스를 공유한다!"
  },
  {
    "objectID": "posts/the-lectures/2024-02-13-statquest-rnn.html#약점",
    "href": "posts/the-lectures/2024-02-13-statquest-rnn.html#약점",
    "title": "Recurrent Neural Network",
    "section": "약점",
    "text": "약점\n피드백 루프가 점점 커지거나 피드백 루프가 점점 약해지는 것을 막기 힘들다. 이는 무엇을 의미할까? 체인의 법칙에 따라서 역전파를 하는 상황을 생각해보자. 이에 따라서 특정 도함수의 계수가 지나치게 크거나 작아지게 된다. 이는 학습률에 따른 탐색 범위를 지나치게 왔다갔다 하게되거나 특정 범위를 벗어나지 못하게 만들 수 있다.\n\n\n\n\n\n\n\n\n\n너무 큰 웨이트를 지닐 때 효과가 증폭된다.\n\n\n\n\n \n\n\n\n\n\n역전파시 경사하강의 탐색 경로에 문제가 생길 수 있다.\n\n\n\n\n\n\n\n\n\n탐색 범위가 큰 값과 작은 값을 오간다.\n\n\n\n\n \n\n\n\n\n\n탐색 범위가 과하게 좁아진다."
  },
  {
    "objectID": "posts/the-lectures/2024-02-13-statquest-rnn.html#몇-가지-더",
    "href": "posts/the-lectures/2024-02-13-statquest-rnn.html#몇-가지-더",
    "title": "Recurrent Neural Network",
    "section": "몇 가지 더",
    "text": "몇 가지 더\n만일 문장의 토큰(단어)를 투입해야 하는 경우를 생각해보자. 당연히 단어를 그대로 넣을 수 없으니 W2V과 같은 방법을 써서 토큰을 벡터로 바꿔야 한다. 이때 RNN의 역전파 과정에서 이 W2V 네트워크 역시 조정될 수 있다는 점을 기억하자.\n시퀀셜 데이터를 인풋으로 쓰기 때문에 인풋의 길이를 어느 정도는 통제할 수 있다. 예를 들어 10개의 시리즈를 지닌 데이터와 5개의 데이터를 지닌 시리즈가 있다고 하자. 인풋으로 2개를 쓴다면, 이 두 시리즈 모두를 RNN 학습에 동원할 수 있다.\n\n\n\n피드백 루프로 표현하는 방식\n나란히 아래로 표현하는 방식\n투입이 3개일 때\n같은 웨이트와 바이어스를 공유한다!\n너무 큰 웨이트를 지닐 때 효과가 증폭된다.\n역전파시 경사하강의 탐색 경로에 문제가 생길 수 있다.\n탐색 범위가 큰 값과 작은 값을 오간다.\n탐색 범위가 과하게 좁아진다."
  },
  {
    "objectID": "posts/the-lectures/2024-02-14-lstm.html",
    "href": "posts/the-lectures/2024-02-14-lstm.html",
    "title": "Long Short-Term Memory (LSTM) Network",
    "section": "",
    "text": "LSTM을 찍먹해보자."
  },
  {
    "objectID": "posts/the-lectures/2024-02-14-lstm.html#tl-dr",
    "href": "posts/the-lectures/2024-02-14-lstm.html#tl-dr",
    "title": "Long Short-Term Memory (LSTM) Network",
    "section": "",
    "text": "LSTM을 찍먹해보자."
  },
  {
    "objectID": "posts/the-lectures/2024-02-14-lstm.html#넋두리",
    "href": "posts/the-lectures/2024-02-14-lstm.html#넋두리",
    "title": "Long Short-Term Memory (LSTM) Network",
    "section": "넋두리",
    "text": "넋두리\nRNN의 가장 큰 문제는 웨이트의 크기에 따라서 효과가 지나치게 증폭되거나 지나치게 줄어드는 데 있다. 경사하강법을 사용할 때 최적 파라미터의 범위가 지나치게 크게 변하거나 지나치게 작게 변하면 원활한 최적화가 어렵다. 이러한 문제를 막기 위해 웨이트의 크기가 제한된다면 이는 그 자체로 최적화에 위배된다. 이러한 문제를 완화하기 위해 제안된 네트워크 구조가 LSTM이다.\n이걸 조금 말로 풀어보자. Long Short-term Memory란 말 그대로 과거의 정보가 미래로 전달되는 경로를 장기와 단기로 나누겠다는 것이다. 아래 기본 구조에서 보듯이 시점 혹은 노드의 중요도에 따라서 해당 노드가 뒤에 올 노드에 미치는 영향의 정도가 다를 수 있다. 그런데 RNN은 하나의 단일한 엣지 혹은 경로를 통해서 두 가지 정보, 즉 해당 노드가 바로 다음에 오는 노드에 미치는 영향과 더 멀리 떨어진 노드에 미치는 영향을 하나로 뭉쳐서 전달힌다. 이 과정에서 정보의 손실이 발생할 수 있다. LSTM 모델이란 이 경로를 두 개로 각각 분리한 것이다.\n\n\n\n\n\n\n \n\n\n\n\n\nRNN의 문제점; KABOOM!!!은 explode, poof!!! vanish를 의미한다."
  },
  {
    "objectID": "posts/the-lectures/2024-02-14-lstm.html#기본-구조",
    "href": "posts/the-lectures/2024-02-14-lstm.html#기본-구조",
    "title": "Long Short-Term Memory (LSTM) Network",
    "section": "기본 구조",
    "text": "기본 구조\nLSTM의 기본 구조는 복잡해보이지만, 아이디어는 단순하다.\n\n\n\n\n\n\n\n\n\nLSTM의 아이디어\n\n\n\n\n \n\n\n\n\n\nLSTM의 기본 구조\n\n\n\n\n \n\n\n\n\n\n웨이트와 바이어스가 없는 장기 기억\n\n\n\n\n\n\n \n\n\n장기와 단기의 정보를 별도로 전달하는 발상이 LSTM이다."
  },
  {
    "objectID": "posts/the-lectures/2024-02-14-lstm.html#three-gates",
    "href": "posts/the-lectures/2024-02-14-lstm.html#three-gates",
    "title": "Long Short-Term Memory (LSTM) Network",
    "section": "Three Gates",
    "text": "Three Gates\n원래 용어에 따르면 LSTM은 세 개의 게이트로 구성되어 있다.\n\nForget Gate; 장기 기억을 할인하는 과정을 의미한다.\nInput Gate; 새로운 정보를 장기 기억에 추가하는 과정을 의미한다.\nOutput Gate; 장기 기억을 바탕으로 새로운 단기 정보를 생성하는 과정을 의미한다.\n\n전기에서 넘어온 장기 기억과 단기 기억이 존재한다고 가정하자.\n업데이트에는 Sigmoid 함수와 Tanh 함수를 사용한다. 두 함수의 특성을 보면 활용하는 이유를 알 수 있다. Sigmoid 함수는 0과 1 사이의 값을 가지며, Tanh 함수는 -1과 1 사이의 값을 가진다. 전자는 기억을 할인하는 비율을 결정하고 후자는 기억 자체의 크기를 결정한다.\n\n\n\n\n\n\n\n\n\nSigmoid 함수\n\n\n\n\n \n\n\n\n\n\nTanh 함수\n\n\n\n\n\n아래와 같이 표로 정리해보자.\n\n\n\n\n\n\n\n\n\n게이트\n업데이트 정보\nSigmoid\nTanh\n\n\n\n\nForget Gate\n장기 기억\n단기 기억, 인풋\n-\n\n\nInput Gate\n포겟 게이트의 장기 기억\n단기 기억, 인풋\n단기 기억, 인풋\n\n\nOutput Gate\n단기 기억\n단기 기억, 인풋\n인풋 게이트의 장기 기억\n\n\n\n\nForget Gate\n단기 기억과 인풋을 받아서 장기 기억을 할인한다.\n\n\nInput Gate\n인풋이 장기기억을 어떻게 형성하는지를 표현한다. 이때 전기의 단기 기억과 인풋이 사용된다. 인풋과 전기의 단기 기억이 장기 기억의 크기를 Tanh 함수를 통해서 결정하고, Sigmonoid 함수를 통해서 얼마나 장기 기억에 추가할지를 결정한다.\n앞서 Forget Gate에서 할인된 장기 기억에 이 값을 더해 새 장기기억이 결정된다.\n\n\nOutput Gate\n업데이트된 장기기억, 전기의 단기기억, 그리고 인풋 세 값이 단기기억을 업데이트한다. 장기 기억의 일부가 단기 기억으로 전환된다. 다만 앞서 인풋을 통해 장기기억을 업데이트했으므로 Output Gate에서 인풋과 전기의 단기기억은 단기 기억 자체의 크기에는 영향을 주지 않고 비율에만 영향을 준다."
  },
  {
    "objectID": "posts/the-lectures/2024-02-14-lstm.html#how-to-work",
    "href": "posts/the-lectures/2024-02-14-lstm.html#how-to-work",
    "title": "Long Short-Term Memory (LSTM) Network",
    "section": "How to Work",
    "text": "How to Work\n이렇게 하나의 유닛이 매 기에 들어오는 정보를 처리한다고 보면 된다. 아래 예시에서 1기에 정보가 세 단계의 LSTM 유닛을 거쳐서 처리되 이런 유닛들이 이어져 마지막 정보까지 처리된다.\n\n\n\n\n\n\n\n\n\nDay 1의 LSTM 처리\n\n\n\n\n \n\n\n\n\n\nDay4까지의 처리를 통해 Day 5 예측\n\n\n\n\n\n\n\n\nRNN의 문제점; KABOOM!!!은 explode, poof!!! vanish를 의미한다.\nLSTM의 아이디어\nLSTM의 기본 구조\n웨이트와 바이어스가 없는 장기 기억\nSigmoid 함수\nTanh 함수\nDay 1의 LSTM 처리\nDay4까지의 처리를 통해 Day 5 예측"
  },
  {
    "objectID": "posts/container/2022-04-26-k8s-personally.html",
    "href": "posts/container/2022-04-26-k8s-personally.html",
    "title": "Kubernetes As an Alternative to Docker",
    "section": "",
    "text": "Note\n\n\n\n\n이 포스팅은\n\n쿠버네티스에 관한 일반적인 해설, 설정 소개 등이 아닙니다.\n개발환경 일반을 다루지 않습니다.\n\n이 포스팅은\n\n도커-컴포즈 대신 Rancher Desktop을 활용해 쿠버네티스를 컨테이터 관리 툴로 사용한 경험을 소개합니다.\n데이터 관련 프로그램만 제한적으로 다룰 예정입니다."
  },
  {
    "objectID": "posts/container/2022-04-26-k8s-personally.html#alternatives",
    "href": "posts/container/2022-04-26-k8s-personally.html#alternatives",
    "title": "Kubernetes As an Alternative to Docker",
    "section": "Alternatives",
    "text": "Alternatives\n도커의 대안을 좀 검토해보기로 하겠다.\n\nWhy\n도커가 여러 문제점이 있지만 개인 툴로써 쓰기에는 큰 불편함이 없다. 하지만 도커 데스크탑 앱이 유료화된 후로 왠지 쓰기에 찜찜해진 것이 사실이다. 유료화 그리고 오픈소스 기반 쿠버네티스 진영의 컨테이너 기본 툴 변경 등을 무시하기도 힘들다. 컨테이너 도구로서 도커를 버린다고 해도, 버리기 힘든 도구가 도커-콤포즈다. 부팅이 잦은 데스크 탑에서 필요한 툴을 불러와서 각종 설정을 매번 도커로 해줄 수는 없다. 이떄 도커-콤포즈로 설정을 맞춰두고 한방에 필요한 모든 것을 띄우면 편리하다. 도커-콤포즈를 꼭 도커와 써야하는 것은 아니다. 앞서 소개한 내용처럼 podman과 함께 쓸 수도 있다. 그래도 궁금했다. 도커-콤포즈 없이 컨테이너를 관리할 수는 없을까?\n\nAcross Os\n다른 문제 하나는 운영 체제간 호환성이다. 윈도에서 WSL를 통해 리눅스를 쓰게 되면서 운영 체제를 가리지 않는 개발 도구(분석 도구) 운영이 가능해졌다. 다만 여기에도 문제는 있다. WSL은 서비스 매니저로 systemd를 쓰지 않기 때문에 systemd에 의존하는 도커-콤포즈를 쓰기 위해서는 별도의 설정이 필요하다. 이런 종류의 번거로움 없이 윈도우, mac os, 리눅스를 두루 걸쳐서 쓸 수 없을까?\n\n\n\nnerdctl\n우선 도커를 대체하기 위해서는 도커의 컨테이너 엔진 자체의 대안을 찾아야 한다. 다행스럽게 Cotainerd 표준 기반의 nerdctl이라는 녀석이 있다. 이 서비스는 도커의 명령어와 거의 완벽하게 호환되면서도 도커-컴포즈의 기능까지 구현한다. 여기에서 확인하듯이 도커 및 도커-콤포즈의 거의 모든 명령어가 호환되며 모든 OS를 가리지 않고 쓸 수 있다.\nnerdctl로 거의 모든 것이 해결될 것 같았으나 아쉽게도 그렇지는 않다. 도커 이미지를 쌓아둔 저장소(도커 레지스트리) 도커 허브에 있는 이미지 중 일부는 nerdctl과 제대로 작동하지 않는 녀석들이 있다. 원래 이미지 자체가 도커에 특화된 것이 아닐까 추측해보지만, 이런 내용을 다 따져가며 사용하는 것도 까다로운 일이다. 그래도 도커의 거의 모든 기능을 nerdctl로 대체할 수 있다는 점에서 nerdctl은 유용한 도구이다.\n\n\nKuberntes\n다음으로 컨테이너 오케스트레이션 도구인 쿠버네티스에 눈을 돌렸다. 사실 쿠버네티스를 이 용도로 쓰는 것은 닭 잡는데 소 잡는 칼을 쓰는 격이다. 쿠버네티스를 배운다는 개인적인 동기 부여를 제외한다면, 이 번거로운 것을 꼭 써야 하나? 윈도에서는 설치도 간단치 않았다.\n그때 Rancher Desktop을 알게 되었다. 리눅스 배포판을 만드는 회사인 SUSE에서 내 놓은 경량화된 쿠버네티스(K3s) 앱인데, 이 녀석이 아주 쓸만 했다. 원래는 nerdctl을 좀 편하게 써볼까 하는 용도로 설치했는데 사용성이 좋았다.\n\n\nRancher Desktop을 설치하면 플랫폼에 관계 없이 nerdctl이 설치된다.\n\n사용자 경험이 Docker Desktop과 비슷하다. 사용자는 OS별로 설치하면 OS별 커맨드라인 툴에 명령어들을 잘 사용할 수 있다. Windows(파워셀), WSL2, M1 기반의 macos에서 거의 동일한 경험을 제공한다.\n경량화된 쿠버네티스가 들어 있어서 minikube를 별도로 설치하지 않고 데스크탑에서 쉽게 쿠버네티스를 활용할 수 있다. 부팅 후에도 원래 올려 놓은 쿠버네티스 설정을 유지하고 있어서 개인용 PC에서 쓰기에도 적합하다.\n간력하지만 필요한 GUI를 갖추고 있다."
  },
  {
    "objectID": "posts/container/2022-04-26-k8s-personally.html#using-kubernetes",
    "href": "posts/container/2022-04-26-k8s-personally.html#using-kubernetes",
    "title": "Kubernetes As an Alternative to Docker",
    "section": "Using Kubernetes",
    "text": "Using Kubernetes\n\nInstallation\n우선 Rancher Desktop을 깔자.\n\nWindows라면 WSL과 같이 써야 하고 도커 데스크탑처럼 손쉬운 연동이 가능하다. 동작 방식은 Docker Desktop과 비슷하다. Rancher가 자신을 위한 VM을 띄우고 Windows 혹은 WSL이 이와 연동된다.\nMacos 역시 비슷하게 작동하는데, M1 기반 머신에서도 잘 돌아간다. 내부에서 qemu 기반의 lima를 활용한다고 한다.\n\n랜처 데스크탑을 깔면 윈도우의 경우 파워셸이나 터미널에서 그리고 macos의 경우 터미널에서 kubectl을 쓸 수 있다. 쿠버네티스의 경량 버전인 k3s가 설정되어 있으므로 기본적인 세팅은 완료된 상태다.\n\n\nImage build\n이미지를 빌드해보자. 도커-컴포즈가 좋은 이유는 도커 허브의 이미지를 끌어다가 필요에 맞춰 세팅을 한 후 이를 도커에 올려 사용할 수 있는 데 있다. 컨테이너를 빌드하는 단계와 컨테이너를 쿠버네티스에 올리는 단계로 나눠보자.\n이미지 빌드는 여러가지 방식으로 해도 된다. nerdctl를 통해 docker와 동일한 방식으로 빌드한 후 도커 리포지토리(도커 허브)로 올려서 쓰면 된다. 조금 더 쿠버네티스 친화적인 방식, 즉 nerdctl을 활용하지 않는 방식으로 이미지를 빌드할 수도 있다. Kaniko는 도커의 의존성 제거를 위해서 구글이 오픈소스로 내놓은 프로젝트다. 카니코는 쿠버네티스 컨테이너로 카니코 서비스를 끌어온 후 이 녀석이 컨테이너 내부에서 containerd 기반으로 이미지를 빌드한 후에 도커 레지스트리로 보내는 것까지 모두 알아서 한다. 쿠버네티스 안에서 작업할 수 밖에 없을 때 유용한 녀석이다. 다만 설정이 다소 복잡하다. 자세한 것은 여기를 참고하기 바란다.\n\n\n개인적으로 활용한 용례는 여기에 정리해두었다. 참고하시라.\n\n\nK8s에 서비스를 올려보자.\n이제 필요한 이미지를 빌드해서 도커 리포지토리(도커 허브)에 올렸다고 가정하자. 이 녀석을 쿠버네티스로 당겨오면 된다. 정확하지는 않지만 개인 사용자 수준에서 쉽게 말하면, docker-compose를 대체하는 것이 쿠버네티스라고 생각하면 되겠다. 다만 k8s이 원래 개인 용도로 개발된 녀석이 아니라서 다소 복잡하다.\n\n먼저 pod를 띄운다.\nservice를 개시한다.\n\n도커-콤포즈에서 파일 하나에 있던 내용을 k8s에서는 다수의 yaml로 분리할 수 있다. 먼저 pod를 띄우는 yaml을 올려야 한다. 그리고 이 pod와 접속할 수 있는 네트워크 정보 등을 담고 있는 service 관련 yaml을 실행한다. 1의 pod 관련 사항을 변경했더라더 2는 그대로 두면 된다. 반대도 마찬가지다.\n\n\n개인적인 용례는 여기를 참고하라. 본격적인 사용이라기보다는 내가 쓰는 데이터사이언스 툴을 띄우는 소박한 정도다.\n공식 가이드가 잘 되어 있으니 이쪽을 참고하면 되겠다."
  },
  {
    "objectID": "posts/container/2021-09-13-podman-1.html",
    "href": "posts/container/2021-09-13-podman-1.html",
    "title": "Enter the Podman!",
    "section": "",
    "text": "도커 데스크탑의 유료화 정책이 발표되었다. 대부분의 사용자나 회사에게는 해당 사항이 없겠지만, 오픈소스로 시작한 회사의 정책이라고 보기에는 뭔가 께름칙하다. 대안이 있는데도 굳이 고집할 필요는 없다. 여러 프로젝트가 복잡하게 의존하는, 즉 발목 잡힌 상황이 아니라면 다른 길을 찾으면 된다.\nWSL 내에서 컨테이너를 돌리고 이 서비스를 윈도우에서 웹브라우저로 끌어다 쓰는 형태가 내 일상적인 작업 환경이다. Docker Desktop이 중요한 역할을 하고 있지만 발목은 잡힐 것이 없기에 대안을 시도해보기로 했다. 사실 WSL 내에서 도커를 쓰면 약간 ’가짜’인 듯한 기분이 들 때가 있다. Docker Desktop은 WSL을 거의 완벽에 가깝게 지원한다. 그런데 구조를 뜯어보면 조금 복잡하다. Docker Desktop이 docker 엔진 활용을 위한 두 개의 자체의 컨테이너를 만들고, 이 둘이 WSL과 통신한다. 즉 도커 컨테이너가 WSL 안의 OS에서 돌고 있지 않다는 뜻이다. Windows 및 WSL 지원을 구현하기 위한 궁여지책을 사용하는 느낌이다.\ndocker 엔진 대신 나름 쓸만한 녀석이 podman이다. podman은 OCI(Open Container Initiative)의 표준을 준수하며 docker와 거의 모든 면에서 호환된다. docker의 명령어 뿐 아니라 docker에서 활용하는 이미지도 그대로 쓸 수 있다.\n\n\npodman에 관한 기술적 설명은 LINK, LINK를 참고하자.\n비유를 하자면 컨테이너를 운반하는 배가 바뀔 뿐 컨테이너 자체는 그대로 운용할 수 있다. 아울러 podman을 쓰면 앞서 말한 Docker Desktop의 복잡한 구조가 필요 없다. podman은 WSL 에 설치된 OS 안에서 운용된다. 그리고 podman은 엔진을 제외한 docker 생태계의 다른 요소들과 함께 쓸 수도 있다. 내 경우 작업 환경을 유지하는데 docker-compose가 중요한 역할을 한다. 이 녀석도 podman과도 잘 어울렸다. 각설하고 내용으로 바로 들어가보자.\n\n\n윈도에서 Docker Desktop 버전을 사용하는 대신 Docker CE 버전을 WSL-Ubuntu에 깔아서 사용할 수 있다. 이 글을 관심은 docker를 대체하는 데 있으니, 이에 관한 내용은 다루지 않는다."
  },
  {
    "objectID": "posts/container/2021-09-13-podman-1.html#assumptions",
    "href": "posts/container/2021-09-13-podman-1.html#assumptions",
    "title": "Enter the Podman!",
    "section": "Assumptions",
    "text": "Assumptions\n\nWSL 2가 잘 깔려 있고 설정되어 있다.\nUbuntu 20.04가 깔여 있고 업데이트도 잘 되어 있다.\nDocker Desktop이 깨끗하게 언인스톨되어 있다.\n\n이 가정에 관해서는 별도로 설명하지 않겠다. 구글 검색을 하시면 관련한 좋은 포스팅이 많이 나올 것이다. WSL에 관해서는 MS의 공식 가이드도 더할 나위 없이 잘 되어 있다.\npodman에 관해 내가 풀고 싶은 문제는 세 가지다.\n\ndocker를 podman으로 대체하기\npodman으로 nvidia gpu 부리기\npodman과 함께 docker-composer 쓰기\n\n1, 2의 방법은 Ubuntu 20.04에서 그대로 활용할 수 있다. 3의 경우 WSL이 지니는 OS 구조의 특성 때문에 몇 가지 추가적인 작업이 필요하다."
  },
  {
    "objectID": "posts/container/2021-09-13-podman-1.html#references",
    "href": "posts/container/2021-09-13-podman-1.html#references",
    "title": "Enter the Podman!",
    "section": "References",
    "text": "References\n\nLINK\n\n잘 되어 있지만 진행 순서에 살짝 오류가 있어서 아래 수정했다.\n\nLINK"
  },
  {
    "objectID": "posts/container/2021-09-13-podman-1.html#basics",
    "href": "posts/container/2021-09-13-podman-1.html#basics",
    "title": "Enter the Podman!",
    "section": "Basics",
    "text": "Basics\n최신 버전의 podman을 설치하기 위해서는 apt 저장소의 주소를 별도로 업데이트해줘야 한다. 20.10 이후부터는 podman을 공식적으로 지원하고 있다. 다음번 Ubuntu LTS 버전이 나오면 PPA를 추가하는 이슈는 해소될 듯 싶다.\ncat /etc/lsb-release\nDISTRIB_ID=Ubuntu\nDISTRIB_RELEASE=20.04\nDISTRIB_CODENAME=focal\nDISTRIB_DESCRIPTION=\"Ubuntu 20.04.2 LTS\"\n\nexport VERSION_ID=\"20.04\"\n\necho \"deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_${VERSION_ID}/ /\" | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list\ncurl -L https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_${VERSION_ID}/Release.key | sudo apt-key add -\nsudo apt-get update\nsudo apt-get -y upgrade\nsudo apt-get -y install podman\n\n셸 스크립트에서 cat..., export...라고 되어 있는 부분은 설명이 필요한 부분이다. 실행을 할 때는 $이후만 필요하다.\n\n\ncat...은 현재 설치된 Ubuntu의 버전 등을 알아내는 대목이다.\nexport...은 VERSION_ID 변수를 설정한다.\n\n\n나머지 부분은 PPA를 설정하고 패키지 저장소를 업데이트하고 포드맨을 설치하기 위한 작업이다."
  },
  {
    "objectID": "posts/container/2021-09-13-podman-1.html#setting",
    "href": "posts/container/2021-09-13-podman-1.html#setting",
    "title": "Enter the Podman!",
    "section": "Setting",
    "text": "Setting\n많은 가이드를 보면 아래 두 파일 중 하나의 내용을 수정할 것을 권고하고 있다. 후자의 파일은 없기 때문에 생성하면 된다.\n\n/usr/share/containers/containers.conf\n~/.config/containers/containers.conf\n\n수정 혹은 생성 내용은 아래와 같다.\n[engine]\nevents_logger=\"file\"\ncgroup_manager=\"cgroupfs\"\n\n그런데 굳이 고치지 않아도 컨테이너를 돌리는 데 큰 이슈는 없는 듯 싶다."
  },
  {
    "objectID": "posts/container/2021-09-13-podman-1.html#testrun",
    "href": "posts/container/2021-09-13-podman-1.html#testrun",
    "title": "Enter the Podman!",
    "section": "Testrun",
    "text": "Testrun\npodman이 잘 깔렸는데 아래와 같이 테스트해보자.\npodman run hello-world \ndocker의 hello-world를 테스트로 사용하면 된다. 잘 되었다면 잘 깔린 것이다."
  },
  {
    "objectID": "posts/container/2021-09-13-podman-1.html#references-1",
    "href": "posts/container/2021-09-13-podman-1.html#references-1",
    "title": "Enter the Podman!",
    "section": "References",
    "text": "References\n\nLINK\nLINK"
  },
  {
    "objectID": "posts/container/2021-09-13-podman-1.html#installation",
    "href": "posts/container/2021-09-13-podman-1.html#installation",
    "title": "Enter the Podman!",
    "section": "Installation",
    "text": "Installation\nnvidia 컨테이너 툴킷 설치를 위해서 먼저 PPA를 설정하자.\ncurl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID)\ncurl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list\nsudo apt-get update\n컨테이너 툴킷을 설치한다.\nsudo apt install -y nvidia-container-toolkit\n/usr/share/containers/oci/hooks.d/oci-nvidia-hook.json 파일이 있는지 확인해본다. 없으면 생성하고 아래의 내용을 담도록 하자.\n{\n    \"version\": \"1.0.0\",\n    \"hook\": {\n        \"path\": \"/usr/bin/nvidia-container-toolkit\",\n        \"args\": [\"nvidia-container-toolkit\", \"prestart\"],\n        \"env\": [\n            \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n        ]\n    },\n    \"when\": {\n        \"always\": true,\n        \"commands\": [\".*\"]\n    },\n    \"stages\": [\"prestart\"]\n}\n/etc/nvidia-container-runtime/config.toml 파일을 수정하도록 하자. 아래 코드를 통해, config.toml에서 필요한 부분을 수정하고 제대로 수정되었는지 조회한다. no-cgroups = true를 설정하는 것이 핵심이다. 파일을 에디터로 열어 직접 수정해도 된다.\n$ sudo sed -i 's/^#no-cgroups = false/no-cgroups = true/;' /etc/nvidia-container-runtime/config.toml\n$ cat /etc/nvidia-container-runtime/config.toml\n부팅을 다시 해주자. WSL에서 나갔다가 다시 들어가면 된다. 셸 자체를 껐다가 다시 켜도 된다."
  },
  {
    "objectID": "posts/container/2021-09-13-podman-1.html#testrun-1",
    "href": "posts/container/2021-09-13-podman-1.html#testrun-1",
    "title": "Enter the Podman!",
    "section": "Testrun",
    "text": "Testrun\n아래 예는 nvidia-smi 명령을 통해서 OS에 드라이버가 제대로 설정되어 있는지 확인하는 명령어이다. WSL이 깨끗하게 설치된 상태라면 WSL-Ubuntu에는 nvidia driver가 설치되어 있지 않다. 컨테이너를 통해서 드라이버가 설정된 이미지에 진입해 GPU를 부리는 것이라고 보면 되겠다. 단 하드웨어와 직접 소통하는 윈도 드라이버가 WSL2을 지원하는 버전인지 여부는 꼭 확인하시라. 최신 버전은 대체로 WSL2를 잘 자원한다.\npodman run --rm --security-opt=label=disable nvidia/cuda nvidia-smi\nCUDA를 활용한 nbody example도 돌려보자.\npodman run --env NVIDIA_DISABLE_REQUIRE=1 nvcr.io/nvidia/k8s/cuda-sample:nbody nbody -gpu -benchmark"
  },
  {
    "objectID": "posts/container/2021-09-13-podman-1.html#reference",
    "href": "posts/container/2021-09-13-podman-1.html#reference",
    "title": "Enter the Podman!",
    "section": "Reference",
    "text": "Reference\nLINK"
  },
  {
    "objectID": "posts/container/2021-09-13-podman-1.html#problem",
    "href": "posts/container/2021-09-13-podman-1.html#problem",
    "title": "Enter the Podman!",
    "section": "Problem",
    "text": "Problem\nWSL이 Ubuntu의 systemd를 처음부터 활성화하지 않는다. docker CE 버전을 데스크탑을 거치지 않고 WSL 안에서 깔아서 쓸 때 이게 문제가 된다. systemd를 먼저 활성화해야 한다."
  },
  {
    "objectID": "posts/container/2021-09-13-podman-1.html#solution",
    "href": "posts/container/2021-09-13-podman-1.html#solution",
    "title": "Enter the Podman!",
    "section": "Solution",
    "text": "Solution\n\nRuntime\n\n먼저 MS 런타임을 설치하자.\n\nwget https://packages.microsoft.com/config/ubuntu/20.04/packages-microsoft-prod.deb -O packages-microsoft-prod.deb\nsudo dpkg -i packages-microsoft-prod.deb\nrm packages-microsoft-prod.deb\n\n\nwsl-transdevian\n\n이 녀석을 설치하기 위해서 먼저 lsb를 설치하자.\n\nsudo apt-get install lsb \n\nsudo로 실행되어야 하는 항목에서 이를 타이핑하는 번거로움을 피하기 위해서 sudo -s를 실행하자. 이후 아래 스크립트를 실행한다.\n\nwget -O /etc/apt/trusted.gpg.d/wsl-transdebian.gpg https://arkane-systems.github.io/wsl-transdebian/apt/wsl-transdebian.gpg\nchmod a+r /etc/apt/trusted.gpg.d/wsl-transdebian.gpg\n\ncat &lt;&lt; EOF &gt; /etc/apt/sources.list.d/wsl-transdebian.list\ndeb https://arkane-systems.github.io/wsl-transdebian/apt/ $(lsb_release -cs) main\ndeb-src https://arkane-systems.github.io/wsl-transdebian/apt/ $(lsb_release -cs) main\nEOF\n\napt update\n\n\ngenie & docker-compose\n이제 마지막으로 genie와 docker-compose를 설치해준다.\n$ sudo apt update\n$ sudo apt install -y systemd-genie\n$ sudo apt install docker-compose\n\n\nSetting\n1$ systemctl --user start podman.socket\n2$ export DOCKER_HOST=unix://$XDG_RUNTIME_DIR/podman/podman.sock\n\nsystemctl... 명령을 통해서 podman의 소켓을 시작한다. 소켓의 상태를 보고 싶다면 start → status로 바뀌 실행해보자.\ndocker가 설치되지 않았기 때문에 docker-compose가 쓸 수 있는 가상화 앱을 지정해야 한다. 이를 위에 열어준 포드맨 소켓과 연결한다.\n\n여기까지 마치면 docker-compose가 잘 돌아간다.\n\nWSL-Ubuntu 부팅 시 자동으로 이 상태가 갖춰지길 원하면 1,2를 .bashrc에 넣으면 된다.\n\n단 wsl genie -s으로 실행한 상태가 아니라면 systemd 사용이 제한되기 때문에 아래 같은 경고 메시지를 볼 수 있다.\n\nFailed to connect to bus: No such file or directory"
  },
  {
    "objectID": "posts/container/2021-09-13-podman-1.html#testrun-2",
    "href": "posts/container/2021-09-13-podman-1.html#testrun-2",
    "title": "Enter the Podman!",
    "section": "Testrun",
    "text": "Testrun\n\n현재 위치(대체로는 유저 홈)에 아래와 같이 docker-compose.yml 파일을 생성하자.\n현재 위치에 data디렉토리를 생성하자.\n\nversion: '3'\n#\nservices:\n    tf-gpu:\n        image: tensorflow/tensorflow:latest-gpu-jupyter\n        environment:\n            - NVIDIA_DISABLE_REQUIRE=1\n            - GRANT_SUDO=yes\n            - JUPYTER_ENABLE_LAB=yes\n            - JUPYTER_TOKEN=1234\n        volumes:\n            - \"./data:/mnt/space/ml\"\n        ports:\n            - \"8888:8888\"\n        # deploy:\n        #     resources:\n        #         reservations:\n        #             devices:\n        #                 - driver: nvidia\n        #                   device_ids: ['all']\n        #                   capabilities: [gpu]\n        container_name: tf_gpu\n이제 다음을 실행하자.\n$ docker-compose up \n잘 실행되었다면 주피터 서버가 생성되었을 것이다. 접속 주소는 웹브라우저에서 localhost:8888을 치면 된다. 토큰(비밀번호)은 1234로 설정해두었다. GPU가 잘 돌아가고 있음을 직접 확인해보자. 노트북의 Cell을 열고 아래 내용을 실행해보자.\nimport tensorflow as tf\ntf.config.get_visible_devices(\n    device_type=None\n)\nCPU 이외에 GPU가 보이면 잘 설정된 것이다. 컨테이너 안에 담긴 fashion mnist 등의 예제를 마음껏 시험해보시라.\nyml 파일에서 눈치를 챘을지 모르겠지만, deploy 항목은 docker에서만 실행되는 항목이다. 이를 주석처리 하지 않고 podman에서 돌리면 에러가 발생한다."
  },
  {
    "objectID": "posts/container/2020-09-24-install-hangul-in-docker.html",
    "href": "posts/container/2020-09-24-install-hangul-in-docker.html",
    "title": "Docker 컨테이너 + 한글 폰트",
    "section": "",
    "text": "koreanize-matplotlib\n\n\n\nmatplotlib에서 한글을 쓸 때 문제가 없도록 하는 패키지가 등장했다. 개발자 분에게 무한 감사를 표하면서 repo를 깔아 쓰도록 하자."
  },
  {
    "objectID": "posts/container/2020-09-24-install-hangul-in-docker.html#다른-방법",
    "href": "posts/container/2020-09-24-install-hangul-in-docker.html#다른-방법",
    "title": "Docker 컨테이너 + 한글 폰트",
    "section": "다른 방법",
    "text": "다른 방법\n이 포스팅은 도커 컨테이너 안에서 한글 문제를 해결하는 다른 방법을 제시하고 있다. 같이 참고 하시라."
  },
  {
    "objectID": "posts/container/2020-09-24-install-hangul-in-docker.html#왜-필요한가",
    "href": "posts/container/2020-09-24-install-hangul-in-docker.html#왜-필요한가",
    "title": "Docker 컨테이너 + 한글 폰트",
    "section": "왜 필요한가?",
    "text": "왜 필요한가?\nJupyter 등에서 matplotlib을 쓸 때 라벨이 한글일 경우, 대부분 한글 출력에 문제를 겪게 된다. ㅁㅁㅁ형태로 출력되는데, 파이썬 환경에서 한글 폰트가 인식되지 않게 때문이다. 일반적인 환경이라면 웹 검색으로 찾을 수 있는 가이드를 통해 해결할 수 있다.\n그런데 도커 환경을 쓴다면 이런 가이드가 별 소용이 없다. 도커는 아래 그림과 같이 ’host os - 도커 - 컨테이너’의 구조로 돌아간다. 컨테이너(App x)가 각기 독자적인 os를 지니고 있기 때문에 해당 os에서 한글을 인식시켜줘야 특정 컨테이너 환경 안에서 한글을 쓸 수 있게 된다.\n\n\n\n\n\n\n \n\n\n\n\n\n컨테이너 개념도"
  },
  {
    "objectID": "posts/container/2020-09-24-install-hangul-in-docker.html#simple-solution",
    "href": "posts/container/2020-09-24-install-hangul-in-docker.html#simple-solution",
    "title": "Docker 컨테이너 + 한글 폰트",
    "section": "Simple Solution",
    "text": "Simple Solution\n방법은 간단하다. 컨테이너 환경 os에 직접 한글을 설치해주면 된다. 해당 os 내의 bash 혹은 상응하는 CLI에 들어가서 필요한 명령(스크립트)들을 실행하면 된다. 해당 명령들을 별도의 bash 스크립트로 만들고 필요한 경우 녀석들을 한방에 돌리면 살짝 더 편리할 것이다. 아래는 나눔 계열 폰트를 설치하는 스크립트다. 파일 이름을 install_nanum.sh로 하자.\n#!/bin/sh\n\nsudo sed -i 's/archive.ubuntu.com/ftp.daumkakao.com/g' /etc/apt/sources.list\nsudo apt-get update \nsudo apt-get install -y fonts-nanum*\nsudo fc-cache -fv\n나머지는 대체로 자명한 명령어다. 첫행의 sed는 ftp 주소를 국내로 바꿔주는 것이다. 업데이트 시 걸리는 시간을 단축하기 위해 사용했다. 터미널에서 스크립트 파일이 있는 디렉토리로 이동한 후 bash 스크립트를 실행하면 된다. bash 스크립트는 도커를 쓸 때 유용하다. 초기에 갖춰져야 하는 세팅이 있을 경우 스크립트로 만들어두고 도커 이미지를 새로 올렸을 때 실행해주면 되겠다. 약간 귀찮지만 못 견딜 정도는 아니다.\n&gt; ./install_nanum.sh ⏎\n윈도에서 파일을 편집할 경우 ^M이 달라 붙어 문제가 생기는 경우가 있다. OS의 개행 문자가 달라서 생기는 문제다. docker 내부 터미널에서 vim, nano 등으로 파일을 열어 해당 부분을 지우고 다시 저장하면 된다.\n이제 도커 컨테이너 안의 이용한 주피터 노트북에서 다음과 같이 실행하면 나눔고딕 폰트를 쓸 수 있게 된다.\n!./install_nanum.sh\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom matplotlib import rc, font_manager\nfont_fname = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\nprop = font_manager.FontProperties(fname=font_fname)\nmpl.rcParams['font.family'] = 'NanumGothic'\nmpl.rcParams['axes.unicode_minus']  = False\nfont_manager._rebuild()\n첫줄은 Jupyter 안에서 스크립트를 실행하는 명령어다. 혹시 잘 보이지 않으면, 커널을 한번 리프레시 해주면 된다. 다른 폰트를 설정하고 싶다면 비슷하게 응용해 활용하면 되겠다.\n\nUpdated\n2021년 5월 8일 기준으로 font_manager에서 _rebuild() 모듈이 없어졌더라. 현재 시점으로는 보이지 않았다. install_nanum.sh에서 sudo rm -fr ~/.cache/matplotlib를 추가로 하나 더 실행해주자. 캐시에 저장된 matplotlib의 폰트 리스트를 지워버리면 최초 실행될 때 자동으로 폰트 리스트를 빌드한다. 이때 설치한 일련의 나눔 폰트가 폰트 리스트에 잡힌다.\nDocker 컨테이너 내에 설치된 폰트를 확인하고 싶다면, 아래를 참고하라.\nfont_list = font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\nfont_list\n\n\n\n컨테이너 개념도"
  },
  {
    "objectID": "posts/walk-through/2023-11-03-definitive-guide-to-windows.html",
    "href": "posts/walk-through/2023-11-03-definitive-guide-to-windows.html",
    "title": "윈도 작업 환경을 기록한다",
    "section": "",
    "text": "윈도우에서 WSL(WIndows Subsystem for Linux) 작업 환경을 만드는 방법을 기록한다. 내용은 변화에 따라서 조금씩 변해갈 것이다."
  },
  {
    "objectID": "posts/walk-through/2023-11-03-definitive-guide-to-windows.html#tl-dr",
    "href": "posts/walk-through/2023-11-03-definitive-guide-to-windows.html#tl-dr",
    "title": "윈도 작업 환경을 기록한다",
    "section": "",
    "text": "윈도우에서 WSL(WIndows Subsystem for Linux) 작업 환경을 만드는 방법을 기록한다. 내용은 변화에 따라서 조금씩 변해갈 것이다."
  },
  {
    "objectID": "posts/walk-through/2023-11-03-definitive-guide-to-windows.html#넋두리",
    "href": "posts/walk-through/2023-11-03-definitive-guide-to-windows.html#넋두리",
    "title": "윈도 작업 환경을 기록한다",
    "section": "넋두리",
    "text": "넋두리\n앞서 윈도에 관한 여러 포스트를 게재했다. 그런데 그 내용 중에서 이제는 쓰지 않는 것도 있다. 이 글은 ’현재’를 바라보면서 윈도에서 어떤 작업환경을 유지하고 있는지를 기록하는 내용이다."
  },
  {
    "objectID": "posts/walk-through/2023-11-03-definitive-guide-to-windows.html#앱-설치-관리자",
    "href": "posts/walk-through/2023-11-03-definitive-guide-to-windows.html#앱-설치-관리자",
    "title": "윈도 작업 환경을 기록한다",
    "section": "앱 설치 관리자",
    "text": "앱 설치 관리자\n🔗 윈도 스토어 앱설치 관리자\nwinget으로 소프트웨어를 설치하고 관리하려면 “마이크로소프트 스토어”에서 앱설치 관리자를 설치하자. 꼭 winget을 깔아야 하는 것은 아니지만, 터미널에서 일관되게 관리할 수 있어서 꽤 편리하다.\nwinget으로 설치할 수 있는 소프트웨어 확인은 아래 웹 사이트를 참고하자.\nhttps://winget.run/\n# 윈도 앱 설치 목록 \n&gt; winget install -e --id Microsoft.PowerToys # 키보드 리매핑\n&gt; winget install -e --id Microsoft.PowerShell\n&gt; winget install -e --id GitHub.GitHubDesktop\n&gt; winget install -e --id Microsoft.VisualStudioCode"
  },
  {
    "objectID": "posts/walk-through/2023-11-03-definitive-guide-to-windows.html#터미널",
    "href": "posts/walk-through/2023-11-03-definitive-guide-to-windows.html#터미널",
    "title": "윈도 작업 환경을 기록한다",
    "section": "터미널",
    "text": "터미널\n터미널 앱은 당연히 윈도 터미널을 써야 한다. 다른 OS의 터미널 앱과 비교해도 이 만큼 편리하고 다재다능한 앱이 없다. 최근 윈도11 버전에는 기본으로 탑재가 되어 있다. 몇 가지 팁만 짚고 넘어가자.\n\nFont는 Hack Nerd Font를 쓰자. 여기서 다운받자.\n최근 버전에서는 settings.json 파일 고치지 않고도 UI를 통해 쉽게 설정을 바꿀 수 있다. 여기서 테마, 폰트 등을 바꾸면 된다.\n셸 공통 설정 뿐 아니라 개별 셸 설정도 세부적으로 지정할 수 있다."
  },
  {
    "objectID": "posts/walk-through/2023-11-03-definitive-guide-to-windows.html#wsl",
    "href": "posts/walk-through/2023-11-03-definitive-guide-to-windows.html#wsl",
    "title": "윈도 작업 환경을 기록한다",
    "section": "WSL",
    "text": "WSL\n윈도에서 개발 환경은 WSL을 쓰도록 하자. 네이티브 개발 환경도 사실 상당히 괜찮다. 하지만 아래와 같은 이유로 WSL을 쓰는 편이 조금 낫다고 본다.\n\n윈도의 레거시 요소(인코딩) 등이 방해하는 경우가 없지 않더라.\n\nWSL이 원본에 접근한 리눅스 환경을 제공한다. 여전히 많은 개발 환경들이 리눅스를 기초로 제공된다. 좋은 리눅스 환경이 있는데 쓰지 않을 이유가 있을까?\nWSL은 리눅스의 GUI도 제공하고 있다. 만일 리눅스 GUI 환경이 필요하다면 윈도 내에서 그냥 쓰면 된다.\n\n리눅스를 개발환경으로 쓴다고 해서 그 불편함까지 감수해야 하는 것은 아니다. 네이티브 환경의 UI/UX 및 필요한 앱들은 그대로 활용하면 된다. VS Code룰 통해 리눅스 환경에 원격 접속해 편리하게 코딩을 할 수 있고, 윈도 탐색기에서 리눅스 OS 안의 폴더로 접근할 수도 있다.\n\n설치\n과거 윈도11 버전에서는 WSL 기능을 활성화한 후 배포판을 별도로 다운로드 받아서 설치했다. 이제는 아래 명령어를 통해서 WSL 기능을 활성화하고 Ubuntu 디폴트 배포판까지 한번에 설치할 수 있다.\n&gt; wsl --install\n디폴트 배포판을 바꾸는 법, 배포판을 삭제하는 방법 등은 아래 링크를 참고하자.\n🔗 WSL MS 공식 설치 가이드\n# WSL 관련 명령어\n&gt; wsl --list --online # or wsl -l -o 설치 가능한 배포판 조회 \n&gt; wsl --install -d &lt;Distribution Name&gt; # 특정 배포판 설치 \n&gt; wsl --unregister &lt;Distribution Name&gt; # 특정 배포판 삭제\n\n\n\n수동으로 설치하기\n삭제 및 배포판 내리기"
  },
  {
    "objectID": "posts/walk-through/2023-11-03-definitive-guide-to-windows.html#ubuntu-관리-및-필수-앱-설치",
    "href": "posts/walk-through/2023-11-03-definitive-guide-to-windows.html#ubuntu-관리-및-필수-앱-설치",
    "title": "윈도 작업 환경을 기록한다",
    "section": "Ubuntu 관리 및 필수 앱 설치",
    "text": "Ubuntu 관리 및 필수 앱 설치\n아래 링크를 참고하자.\n🔗 Ubuntu를 깔고 먼저 해야 할 일들"
  },
  {
    "objectID": "posts/walk-through/2023-11-03-definitive-guide-to-windows.html#vs-code",
    "href": "posts/walk-through/2023-11-03-definitive-guide-to-windows.html#vs-code",
    "title": "윈도 작업 환경을 기록한다",
    "section": "VS Code",
    "text": "VS Code\nVS 코드는 이 협업의 핵심이다. VS 코드는 윈도에 있다. 하지만 이 녀석은 WSL의 리눅스와 윈도를 긴밀하게 연결한다. WSL 내 위치하는 어떤 폴더에서 코딩 작업을 하고 싶다면, WSL이 활성화된 터미널에서 아래와 같이 실행하자.\n# 원하는 폴더 내에서 \n&gt; code . \n이 명령어는 파일 &gt; 작업 영역에 폴더 추가를 한방에 실행해준다. 해당 폴더가 작업 영역에 추가되기 때문에 여러가지 작업을 편리하게 진행할 수 있다. 이렇게 윈도의 ’호사’와 함께 리눅스 환경의 코딩 작업이 가능하다."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-05-vector-geometry-1.html",
    "href": "posts/linear-algebra/2021-01-05-vector-geometry-1.html",
    "title": "Vector Geometrically, part 1",
    "section": "",
    "text": "벡터와 포인트를 오가는 방법을 배우자."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-05-vector-geometry-1.html#tl-dr",
    "href": "posts/linear-algebra/2021-01-05-vector-geometry-1.html#tl-dr",
    "title": "Vector Geometrically, part 1",
    "section": "",
    "text": "벡터와 포인트를 오가는 방법을 배우자."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-05-vector-geometry-1.html#concepts",
    "href": "posts/linear-algebra/2021-01-05-vector-geometry-1.html#concepts",
    "title": "Vector Geometrically, part 1",
    "section": "Concepts",
    "text": "Concepts\n편의상 3차원 공간으로 예시하도록 한다. \\(n\\) 차원으로 확장은 쉽게 된다.\n\n\\(p = (p_x, p_y, p_z)\\): \\(p \\in \\mathbb R^3\\) is a point\n\\(\\vec v = (v_x, v_y, v_z)\\): \\(\\vec v \\in \\mathbb R^3\\) is a vector\n\\(\\hat v = \\frac{v}{\\lVert v \\lVert}\\): Unit vector\n\n\nFirst thing first\n점과 벡터의 차이를 다시 새기고 가자.\n\n점은 공간에서 위치를 지니고 있다. 점의 특성은 위치 뿐이다.\n벡터는 크기와 방향을 지니고 있다. 벡터는 공간에서 위치를 지니고 있지 않다.\n\n\n\n\n점은 위치만을 지니고 벡터는 방향성과 크기를 지닌다.\n\n\n점과 벡터를 연결해보자. 위 그림에서 원점 \\(O\\)를 기준으로 하면 \\(P\\), \\(Q\\)가 정의될 것이다. 이때 \\(\\overrightarrow{OP}\\), \\(\\overrightarrow{OQ}\\)는 벡터가 된다. 이제 \\(\\vec v\\)를 \\(P\\)에서 \\(Q\\)로 가는 벡터라고 정의하자. 이는\n\\[\n\\vec v = Q - P\n\\]\n앞서 정의한 콘셉트에서 \\(\\vec v = (v_x, v_y, v_z)\\)에서 \\(v_k\\)는 포인트의 위치가 아니라 해당 축으로 움직이는(향하는) 크기를 나타낸다는 점을 다시 음미하시기를!\n\n\nVector\n\\(p_0\\)를 지나는 무한의 1차원 벡터는 다음과 같이 정의된다.\n\nParametric equation:\n\n\\[\nl : \\lbrace p_0 + t \\vec v, t \\in \\mathbb R \\rbrace\n\\]\n\n\n\n점에서 벡터를 생성해보자.\n\n\n위의 그림을 보면서 식을 도출해보자. 포인트 \\(P_0\\)를 (원점 기준) 벡터로 나타내면 \\(\\vec r_0\\)가 된다. 그리고 \\(P\\) 점을 벡터로 나타내면 \\(\\vec r\\)이 된다. 벡터 \\(\\overrightarrow{P_0\\, P}\\)와 수평인 벡터를 \\(\\vec v\\)라고 하자. 이 두 가지 사실을 조합하면 다음과 같다.\n\n\\(\\overrightarrow{P_0 \\, P} = \\overrightarrow{O \\, P} - \\overrightarrow{O \\, P_0} = \\vec r - \\vec r_0\\)\n\\(\\vec r - \\vec r_0 = t v\\)\n\n위 결과에 따라서 파라메트릭 식이 도출된다.\n\nCartesian(symetric) equation:\n\n\\[\nl: \\lbrace \\dfrac{x - p_{0x}}{v_x} = \\dfrac{y - p_{0y}}{v_y}  =  \\dfrac{z - p_{0z}}{v_z} \\rbrace\n\\]\n도출 과정은 아래와 같다. 앞서 파리메트릭 표현에서 임의 \\(P\\)의 좌표 \\((x, y, z)\\)는 다음과 같다.\n\\[\n\\vec r = (x, y, z) = ( p_{0x} + t v_x, p_{0y} + t v_y, p_{0z} + t v_z )\n\\]\n\\[\n\\dfrac{x - p_{0x}}{v_x} = \\dfrac{x - p_{0y}}{v_y} = \\dfrac{x - p_{0z}}{v_z} = t\n\\]\n\n\nPlane\n\\(p_0\\)를 지나는 무한 평면 P는 다음과 같이 정의된다. 평면을 평면을 표현하기 위해서는 벡터 두 개( \\(\\vec v, \\vec w\\) )가 필요하다. 먼저 평면을 표현하는 가장 일반적인 방정식을 살펴보자.\n\nGeneral equation: \\(P: \\lbrace Ax + By + Cz = D \\rbrace\\)\n\n이를 파라메트릭 식으로 표현하면 아래왁 같다.\n\nParametric equation: \\(P : \\lbrace p_0 + s \\vec v + t \\vec w~\\text{where}~s,t \\in \\mathbb R \\rbrace\\)\n\n마지막으로 기하학적으로 표현하는 방법은 아래와 같이 노멀 벡터를 활용하는 것이다.\n\nGeometric equation: \\(P : \\lbrace (x, y, z) \\in \\mathbb R^3 | \\vec n \\cdot [(x,y,z) - p_0] = 0 \\rbrace \\text{~with normal vector $\\vec n$}\\)\n\n\n\nNormal vector\n\n\n\n두 벡터의 크로스 프로덕트\n\n\n노멀 벡터는 아래 평면(plane) 혹은 벡터과 직교하는 성분의 벡터다. 이 녀석을 어떻게 구할까? 평면 \\(P\\)의 parametric 식을 보자. 2차원 플레인을 구성하는 두 벡터 \\(\\vec v\\), \\(\\vec w\\)가 있다. 노멀 벡터는 이 두 성분 모두와 직교하는 성분의 벡터이다. 이는 바로 크로스 프로덕트의 정의이다.\n\n\n크로스 프로덕트는 두 벡터와 직교하면서 두 벡터가 생성하는 면적이 길이가 되는 벡터를 생성한다. 닷 프로덕트가 스칼라 값을 생성하는 것과 다르다는 점에 주의하자. 위키를 참고하자.\n평면위의 어떤 세 점 \\(p, q, r\\)이 있다고 하자. 평면 위에 존재하는 벡터 두 개를 \\(\\vec v = q - p\\), \\(\\vec w = r - p\\)과 같이 만들자. 이 벡터와 직교하는 벡터 \\(\\vec n\\)은 다음과 같다.\n\\[\n\\vec n  = \\vec v \\times \\vec w = (q-p) \\times (r-p)\n\\]"
  },
  {
    "objectID": "posts/linear-algebra/2021-01-05-vector-geometry-1.html#distance",
    "href": "posts/linear-algebra/2021-01-05-vector-geometry-1.html#distance",
    "title": "Vector Geometrically, part 1",
    "section": "Distance",
    "text": "Distance\n거리 역시 세 가지로 나누어 이해해보자. 점과 점 사이의 유클리드 거리는 생략하겠다. 벡터와 점의 거리는 어떻게 구할까? 플레인과 점의 거리는 어떻게 구할까? 이 포스팅을 참고하라."
  },
  {
    "objectID": "posts/linear-algebra/2019-12-03-eigenvalue-eigenvector.html",
    "href": "posts/linear-algebra/2019-12-03-eigenvalue-eigenvector.html",
    "title": "Eigenvalues and Eigenvectors",
    "section": "",
    "text": "행렬 대각화를 이루는 방법 중 하나는 아이겐벡터와 아이겐밸류를 재구성하는 것이다.\n대각화가 가능한 행렬 \\(A\\)가 있고, 그 아이겐벡터를 열 벡터로 하는 행렬을 \\(Q\\)라고 하면\n\n\\[\n\\begin{aligned}\nA Q & = A[x_1, \\dotsc, x_n] \\\\\n& = [\\lambda_1 x_1, \\cdots, \\lambda_n x_n] \\\\\n&= Q \\boldsymbol{\\lambda}\n\\end{aligned}\n\\]\n\\[\nAQ Q^{-1} = A = Q \\boldsymbol{\\lambda}Q^{-1}\n\\]\n\n대각화가 가능하기 위해서는 우선 행렬 \\(Q\\)가 비특이(non-singular) 행렬이어야 한다. \\(Q\\)는 아이겐벡터의 조합이기 때문에 서로 다른 아이겐밸류를 지니거나 혹은 아이겐벡터의 선형독립이 성립해야 한다.\n대칭 행렬의 경우 모든 아이겐밸류가 실수이고, \\(Q\\)는 직교 행렬(orthogonal matrix)이 된다. 이 경우\n\n\\[\nA = Q\\boldsymbol{\\lambda}Q^T\n\\]"
  },
  {
    "objectID": "posts/linear-algebra/2019-12-03-eigenvalue-eigenvector.html#tl-dr",
    "href": "posts/linear-algebra/2019-12-03-eigenvalue-eigenvector.html#tl-dr",
    "title": "Eigenvalues and Eigenvectors",
    "section": "",
    "text": "행렬 대각화를 이루는 방법 중 하나는 아이겐벡터와 아이겐밸류를 재구성하는 것이다.\n대각화가 가능한 행렬 \\(A\\)가 있고, 그 아이겐벡터를 열 벡터로 하는 행렬을 \\(Q\\)라고 하면\n\n\\[\n\\begin{aligned}\nA Q & = A[x_1, \\dotsc, x_n] \\\\\n& = [\\lambda_1 x_1, \\cdots, \\lambda_n x_n] \\\\\n&= Q \\boldsymbol{\\lambda}\n\\end{aligned}\n\\]\n\\[\nAQ Q^{-1} = A = Q \\boldsymbol{\\lambda}Q^{-1}\n\\]\n\n대각화가 가능하기 위해서는 우선 행렬 \\(Q\\)가 비특이(non-singular) 행렬이어야 한다. \\(Q\\)는 아이겐벡터의 조합이기 때문에 서로 다른 아이겐밸류를 지니거나 혹은 아이겐벡터의 선형독립이 성립해야 한다.\n대칭 행렬의 경우 모든 아이겐밸류가 실수이고, \\(Q\\)는 직교 행렬(orthogonal matrix)이 된다. 이 경우\n\n\\[\nA = Q\\boldsymbol{\\lambda}Q^T\n\\]"
  },
  {
    "objectID": "posts/linear-algebra/2019-12-03-eigenvalue-eigenvector.html#definition",
    "href": "posts/linear-algebra/2019-12-03-eigenvalue-eigenvector.html#definition",
    "title": "Eigenvalues and Eigenvectors",
    "section": "Definition",
    "text": "Definition\n\\[\n\\underset{(n \\times n)}{\\boldsymbol{A}} \\underset{(n \\times 1)}{x} = \\lambda x, \\text{ for $x \\neq 0$}\n\\]\n\n\n고유치와 고유벡터는 아이겐밸류와 아이겐벡터로로 쓰기로 하자.\n벡터 \\(x(\\in {\\mathbb R}^n)\\)가 있다고 하자. \\(\\boldsymbol{A}\\)는 일종의 함수이고 이는 \\(x\\)를 변형시키게 된다. 이 변형이 그 다시 자신이 되고 벡터의 크기만 조정해주는 형태가 될 때, \\(\\lambda\\)를 아이겐밸류 그리고 그 벡터 \\(x\\)를 아이겐벡터라고 한다. 잠깐! 여기서 아이겐 벡터는 우 아이겐벡터다. 왜냐하면, 벡터가 매트릭스의 오른쪽에 곱해지기 때문이다. 우(right) 아이겐벡터를 보통 아이겐벡터라고 쓴다. 하지만 좌(left) 아이겐벡터도 있다. 일단 이 점만 지적해두도록 하자.\n\n\n좌 아이겐벡터와 우 아이겐벡터가 절묘하게 사용되는 사례는 마르코프 체인이다. 아이겐밸류 1이 존재하고, 그 아이겐벡터가 해당 상태의 극한 분포가 된다는 사실이 좌, 우 아이겐벡터를 번갈아 사용하면서 도출된다. 자세한 것은 여기를 참고하자.\n\nEigenspace\n벡터들의 집합 중에서 아래의 조건을 만족하면 이를 벡터 (부분) 공간이라고 부른다.\n\n영 벡터 \\(\\boldsymbol 0\\)가 원소이다.\n\\(x\\)가 원소일 때 \\(\\alpha x\\) (\\(\\alpha \\in \\mathbb{R})\\)도 원소다.\n\\(x\\), \\(y\\)가 원소일 때 \\(x + y\\)도 원소다.\n\n쉽게 말해서 벡터 (부분) 공간 위에서는 덧셈과 스칼라 곱셈이 정의된다. 아이겐벡터로 구성된 공간은 이런 벡터 공간이 될까?\n\n\\(A {\\boldsymbol 0} = \\lambda {\\boldsymbol 0}\\)\n\\(A(\\alpha x) = \\alpha(A x) = \\alpha (\\lambda x) = \\lambda(\\alpha x)\\)\n\\(A(x_1 + x_2) = A x_1 + A x_2 = \\lambda x_1 + \\lambda x_2 = \\lambda(x_1 + x_2)\\)\n\n3번의 경우 정의대로 하나의 아이겐밸류 \\(\\lambda\\)에 대해서 두 개 이상의 아이겐벡터가 대응될 때에 해당한다. 아이겐벡터를 원소로 하는 공간은 벡터 부분 공간이 되며, 이를 아이겐스페이스(eigenspace)라고 부른다.\n\n\n얼핏 생각하면 이런 경우가 있나 싶을 수 있다. 가장 좋은 사례는 항등 행렬, \\({\\boldsymbol I}_n\\)이다. 이 항등행렬의 경우 아이겐밸류는 1이고, 대응 가능한 어떤 벡터도 아이겐벡터가 된다."
  },
  {
    "objectID": "posts/linear-algebra/2019-12-03-eigenvalue-eigenvector.html#determinant-and-eigenvalues",
    "href": "posts/linear-algebra/2019-12-03-eigenvalue-eigenvector.html#determinant-and-eigenvalues",
    "title": "Eigenvalues and Eigenvectors",
    "section": "Determinant and Eigenvalues",
    "text": "Determinant and Eigenvalues\n아이겐밸류의 아이겐벡터를 구하는 과정은 다음과 같다.\n\\[\n|(\\boldsymbol{A} - \\lambda I)|  = 0\n\\]\n즉, 임의의 아이겐밸류, 아이겐벡터 정의에서 \\(\\boldsymbol 0\\) 벡터가 아닌 \\(x\\)를 \\(\\boldsymbol 0\\) 벡터로 만들기 위해서는 위의 행렬식 값이 0이어야 한다. 즉 \\((\\boldsymbol{A} - \\lambda I)\\)이 선형 종속이어야 한다. 이때 행렬식이 \\(\\lambda\\)의 \\(n\\) 차 방정식이고, \\(n\\)차 방정식의 근이 각각 아이겐밸류가 된다. 즉,\n\\[\n|(\\boldsymbol{A} - \\lambda {\\boldsymbol I})|  = (\\lambda_1 - \\lambda) \\cdot  (\\lambda_2 - \\lambda) \\dotsb  (\\lambda_n - \\lambda)\n\\]\n위의 식에서 두가지 사실을 알 수 있다.\n\n\\(\\boldsymbol{A}\\)의 행렬식은 아이겐밸류의 곱과 같다. 즉, \\(\\lambda = 0\\)을 넣으면 이 결과를 쉽게 얻을 수 있다.\n가역행렬(invertible matrix)이 될 조건, 즉 역행렬이 존재할 조건은 행렬식의 값이 0이 아닌 경우다. 1에 따르면 이는 모든 아이겐밸류의 값이 0이 아닌 조건과 동치다.\n\n\nTranspose\n원래 행렬의 행렬식과 전치행렬의 행렬식은 같다. 이를 아이겐밸류 계산에 응용해보자.\n\\[\n|\\boldsymbol{A}^T - \\lambda {\\boldsymbol I}| = |(\\boldsymbol{A}-\\lambda {\\boldsymbol I})^T| = |\\boldsymbol{A}-\\lambda {\\boldsymbol I}|\n\\]\n즉, 원래 행렬 \\(\\boldsymbol{A}\\)와 전치 행렬 \\(\\boldsymbol{A}^T\\)는 같은 아이겐밸류를 갖는다."
  },
  {
    "objectID": "posts/linear-algebra/2019-12-03-eigenvalue-eigenvector.html#diagonalization",
    "href": "posts/linear-algebra/2019-12-03-eigenvalue-eigenvector.html#diagonalization",
    "title": "Eigenvalues and Eigenvectors",
    "section": "Diagonalization",
    "text": "Diagonalization\n아이겐밸류와 아이겐벡터가 가장 많이 사용되는 경우는 행렬의 대각화이다. 여기서 대각화란, 정방 행렬의 대각에 위치한 원소, \\(a_{ii}\\)를 제외한 나머지 원소가 모두 0인 행렬, 즉 대각 행렬을 품는 변형을 의미한다. 대각 행렬은 여러가지로 쓸모가 많다. 특히 행렬의 \\(k\\) 제곱이 필요한 경우 대각행렬은 그냥 해당 대각원소의 \\(k\\) 제곱과 동일해진다. 행렬의 대각화를 살펴보자.\n\\[\ny = \\boldsymbol{A} x\n\\]\n기본적으로 행렬은 함수다. 즉, 벡터 \\(x\\)를 투입(input)으로 보면 이를 선형 결합을 통해서 다른 어떤 산출(output) 벡터로 보내는 것이다. 일단 설명의 편의를 위해서 \\(x\\)가 2차원 벡터라고 두고 설명해보자. 즉,\n\\[x =\n\\begin{bmatrix}  \nx_1 \\\\  \nx_2\n\\end{bmatrix}.\n\\]\n\\(\\boldsymbol{A}\\)에 의해 변형된 결과를 아이겐벡터 \\(v_1\\)과 \\(v_2\\)를 통해서 표현할 수 있다고 가정하자. \\(v_1\\), \\(v_2\\)를 통해 \\(x\\), \\(y\\)를 표현하면 다음과 같다.\n\\[\n\\begin{aligned}\nx & = w_1 v_1 + w_2 v_2 \\\\\ny & = z_1 v_1 + z_2 v_2\n\\end{aligned}\n\\]\n이때, \\(w_\\cdot\\), \\(z_\\cdot\\)은 스칼라 값임에 유의하자. 이를 매트릭스로 표시하면 다음과 같다.\n\\[\nx =\n\\boldsymbol{Q}\n\\begin{bmatrix}  \nw_1 \\\\  \nw_2\n\\end{bmatrix},~\ny =\n\\boldsymbol{Q}\n\\begin{bmatrix}  \nz_1 \\\\  \nz_2\n\\end{bmatrix}, \\text{where}\n\\]\n\\[\n\\boldsymbol{Q} =\n\\begin{bmatrix}  \nv_1, v_2\n\\end{bmatrix}\n\\]\n\\(v_i' v_i = 1(i = 1,2)\\) 이고, \\(v_1 \\cdot v_2 = 0\\) 이라고 가정하자. 즉, \\(Q\\)가 직교행렬이라고 가정하자.\n\\[\n\\begin{aligned}\n\\boldsymbol{Q}z & = \\boldsymbol{A} \\boldsymbol{Q} w \\\\\nz & = \\boldsymbol{Q}^{-1} \\boldsymbol{A} \\boldsymbol{Q} w \\\\\nz & = \\boldsymbol{Q}^T \\boldsymbol{A} \\boldsymbol{Q} w\n\\end{aligned}\n\\]\n직교행렬의 경우 \\(\\boldsymbol{Q}^{-1} = \\boldsymbol{Q}^T\\)가 성립한다. 이때\n\n\n직교행렬의 경우 \\(\\boldsymbol{Q}^T \\boldsymbol{Q} = \\boldsymbol{Q} \\boldsymbol{Q}^T = {\\boldsymbol I}\\)가 성립한다. 따라서 \\(\\boldsymbol{Q}^{-1} = \\boldsymbol{Q}^T\\)\n\\[\n\\boldsymbol{A} \\boldsymbol{Q} = [A v_1, A v_2] = [\\lambda_1 v_1, \\lambda_2 v_2] = [v_1, v_2]\n\\begin{bmatrix}  \n  \\lambda_1 & 0 \\\\  \n  0 & \\lambda_2\n\\end{bmatrix} = \\boldsymbol{Q} \\boldsymbol{\\lambda}.\n\\]\n따라서,\n\\[\nz = \\boldsymbol{Q}^T \\boldsymbol{Q} \\boldsymbol{\\lambda} w\n\\]\n여기서 대각화의 핵심은\n\\[\n\\boldsymbol{Q}^T \\boldsymbol{A} \\boldsymbol{Q} = \\boldsymbol{\\lambda}\\text{ or }\\boldsymbol{A} = \\boldsymbol{Q}\\boldsymbol{\\lambda}\\boldsymbol{Q}^T\n\\]\n즉, 어떤 매트릭스의 아이겐벡터가 서로 직교하면 이를 통해 직교행렬 \\(\\boldsymbol{Q}\\)를 얻을 수 있다. 이를 원래 매트릭스의 좌우로 곱하면 아이겐밸류를 대각원소로 갖는 대각행렬을 얻을 수 있다.\n\nGeneralization\n일반화 해보자. 대각화는 다음과 같다.\n\\[\n\\boldsymbol{AQ} = \\boldsymbol{A} [x_1, \\dotsc, x_n] = [\\lambda_1 x_1, \\dotsc, \\lambda_n x_n] = [x_1, \\dotsc, x_n]\n\\begin{bmatrix}\n\\lambda_1& \\dotsc & 0  \\\\\n\\vdots& \\ddots& \\vdots \\\\\n0& \\dotsc& \\lambda_n\n\\end{bmatrix} = \\boldsymbol{Q} \\boldsymbol{\\lambda}\n\\]\n행렬의 분해(factorization)은 다음을 의미한다.\n\\[\n\\boldsymbol{A} = \\boldsymbol{Q} \\boldsymbol{\\lambda} \\boldsymbol{Q}^{-1}\n\\]"
  },
  {
    "objectID": "posts/linear-algebra/2019-12-03-eigenvalue-eigenvector.html#diagonalizable",
    "href": "posts/linear-algebra/2019-12-03-eigenvalue-eigenvector.html#diagonalizable",
    "title": "Eigenvalues and Eigenvectors",
    "section": "Diagonalizable",
    "text": "Diagonalizable\n쉽게 생각하자. 우선 \\(Q^{-1}\\)이 존재해야 한다. 즉, \\(Q\\)가 비특이 행렬이어야 한다. \\(Q\\)가 비특이 행렬이 되기 위한 조건들은 일단 행렬 대각화를 위한 필요 조건이다.\n그런데 \\(Q\\)는 아이겐벡터들로 구성된 행렬이다. 따라서 \\(Q\\)가 비특이 행렬이 되기 위해서는 해당 아이겐밸류들이 모두 다르거나, 중복된 아이겐밸류가 있다면 아이겐벡터의 선형 독립이 성립해야 한다. 아이겐밸류가 모두 다르면, 즉 각기 다른 아이겐백터가 존재하면, 대각화가 가능하다. 만일 아이겐밸류가 중복이라면, 경우에 따라서 다르다.\n\n\n아이겐밸류가 중복인데 아이겐벡터가 서로 다를 수 있을까? 가장 좋은 예는 단위행렬이다. \\(\\mathbf I_n\\)은 1의 아이겐 밸류만을 지니며 모든 벡터 \\(x\\)가 아이겐벡터가 된다.\n\nSymmetric matrix\n행렬이 대칭이면 \\(Q\\)에 더 좋은 특성이 생긴다.\n\n\\(\\boldsymbol A\\) 의 아이겐밸류는 모두 실수이다.\n\\(Q\\)는 직교행렬이다. 즉, \\(Q^T = Q^{-1}\\) 가 성립한다.\n\n이를 종합하면 아래와 같다.\n\\[\n\\boldsymbol{A} = \\boldsymbol{Q} \\boldsymbol{\\lambda} \\boldsymbol{Q}^{-1} =  \\boldsymbol{Q} \\boldsymbol{\\lambda} \\boldsymbol{Q}^{T}\n\\]\n\n\nGraphic interpretation with vector space\n앞서의 식을 다시 음미해보자.\n\\[\nAQ = A[x_1, \\dotsc, x_n]\n\\]\n\\(A x_i\\)는 \\(A\\)라는 일종의 함수에 의해 선형 변형된 벡터를 나타낸다. 이러한 벡터를 모아 놓은 것이 \\(AQ\\)이다. 이는 벡터 (서브) 스페이스를 형성한다.\n\\[\nQ \\lambda = [x_1, \\dotsc, x_n] \\begin{bmatrix}\n\\lambda_1& \\dotsc & 0  \\\\\n\\vdots& \\ddots& \\vdots \\\\\n0& \\dotsc& \\lambda_n\n\\end{bmatrix}\n\\]\n이것 역시 벡터 (서브) 스페이스를 형성한다. 여기서 서브 스페이스의 축은 아이겐벡터가 되고, 그 길이를 좌우하는 것은 아이겐밸류가 된다. 이렇게 살펴보면, 왜 아이겐벡터-아이겐밸류가 선형 변환 함수 \\(A\\)의 축과 크기를 바꾸는 것인지 이해할 수 있다.\n\nPCA의 예를 들어보자. \\(x-y\\) 축 위에 찍힌 점들에 대해서 변동성(분산-공분산 행렬)이 큰 방향으로 축을 바꾸면 어떻게 될까? 위에서 보는 PCA의 새로운 축은 아이겐벡터의 방향을 중심으로 재정렬된 축을 나타낸다. 이 축에 할당된 변동성의 크기는 각각 축의 길이에 해당하는 아이겐밸류가 된다."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-06-vector-geometry-2.html",
    "href": "posts/linear-algebra/2021-01-06-vector-geometry-2.html",
    "title": "Vector Geometrically, part 2",
    "section": "",
    "text": "먼저 벡터 스페이스를 살펴보기 위해서 몇 가지 정의부터 보자.\n\n\\(V\\) is vector space\n\\(\\vec v \\in V\\)\n\\(W\\) is vector subspace \\(W \\subseteq V\\)\nspan: 벡터의 선형 결합을 통해 생성되는 벡터 집합 \\[\n\\text{span}(\\vec v_1, \\dotsc, \\vec v_n) = \\{\\vec v | \\vec v = \\alpha_1 \\vec v_1 + \\dotsb + \\alpha_n \\vec v_n, \\alpha_i \\in \\mathbb R \\}\n\\]\n\n행렬 \\(M \\in \\mathbb R^{m \\times n}\\)이 있다고 할 때\n\n\\(\\mathcal R(M) \\subseteq \\mathbb R^n\\): \\(M\\)의 로우 스페이스, 즉 \\(M\\)의 행들의 모든 가능한 선형 결합이 나타내는 벡터 공간\n\n\\[\n\\mathcal R (M) \\overset{\\rm def}{=} \\{ \\vec v \\in \\mathbb R^n | \\vec v = \\vec w^T M \\text{ for some } \\vec w \\in \\mathbb R^m \\}\n\\]\n\n\\(\\mathcal C(M) \\subseteq \\mathbb R^m\\): \\(M\\)의 컬럼 스페이스, 즉 \\(M\\)의 열들의 모든 가능한 선형 결합이 나타내는 벡터 공간\n\n\\[\n\\mathcal C (M) \\overset{\\rm def}{=} \\{ \\vec w \\in \\mathbb R^m | \\vec w = M v \\text{ for some } \\vec v \\in \\mathbb R^n \\}\n\\]\n\n\\(\\mathcal N(M) \\subseteq \\mathbb R^n\\): \\(M\\)의 널 스페이스. 즉, 오른쪽에 곱해졌을 때 \\(\\vec 0_{m}\\)이 되는 벡터의 집합 \\[\n\\mathcal N(M) \\overset{\\rm def}{=} \\{ \\vec v \\in \\mathbb R^n | M \\vec v = \\vec 0 \\}\n\\]\n\\(\\mathcal N(M^T) \\subseteq \\mathbb R^n\\): \\(M\\)의 좌 널 스페이스. 즉, 왼쪽에 곱해졌을 때 \\(\\vec 0_{n}\\)이 되는 벡터의 집합\n\n\\[\n\\mathcal N(M^T) \\overset{\\rm def}{=} \\{ \\vec w \\in \\mathbb R^m | \\vec w^T M  = \\vec 0^T \\}\n\\]\n혹은\n\\[\n\\mathcal N(M^T) \\overset{\\rm def}{=} \\{ \\vec w \\in \\mathbb R^m | M^T \\vec w = \\vec 0 \\}\n\\]\n\\(M\\)의 랭크는 컬럼 스페이스의 차원 그리고 로우 스페이스의 차원과 같다.\n\\[\nr(M) = \\dim(\\mathcal R (M)) = \\dim(\\mathcal C(M))\n\\]"
  },
  {
    "objectID": "posts/linear-algebra/2021-01-06-vector-geometry-2.html#vector-space",
    "href": "posts/linear-algebra/2021-01-06-vector-geometry-2.html#vector-space",
    "title": "Vector Geometrically, part 2",
    "section": "",
    "text": "먼저 벡터 스페이스를 살펴보기 위해서 몇 가지 정의부터 보자.\n\n\\(V\\) is vector space\n\\(\\vec v \\in V\\)\n\\(W\\) is vector subspace \\(W \\subseteq V\\)\nspan: 벡터의 선형 결합을 통해 생성되는 벡터 집합 \\[\n\\text{span}(\\vec v_1, \\dotsc, \\vec v_n) = \\{\\vec v | \\vec v = \\alpha_1 \\vec v_1 + \\dotsb + \\alpha_n \\vec v_n, \\alpha_i \\in \\mathbb R \\}\n\\]\n\n행렬 \\(M \\in \\mathbb R^{m \\times n}\\)이 있다고 할 때\n\n\\(\\mathcal R(M) \\subseteq \\mathbb R^n\\): \\(M\\)의 로우 스페이스, 즉 \\(M\\)의 행들의 모든 가능한 선형 결합이 나타내는 벡터 공간\n\n\\[\n\\mathcal R (M) \\overset{\\rm def}{=} \\{ \\vec v \\in \\mathbb R^n | \\vec v = \\vec w^T M \\text{ for some } \\vec w \\in \\mathbb R^m \\}\n\\]\n\n\\(\\mathcal C(M) \\subseteq \\mathbb R^m\\): \\(M\\)의 컬럼 스페이스, 즉 \\(M\\)의 열들의 모든 가능한 선형 결합이 나타내는 벡터 공간\n\n\\[\n\\mathcal C (M) \\overset{\\rm def}{=} \\{ \\vec w \\in \\mathbb R^m | \\vec w = M v \\text{ for some } \\vec v \\in \\mathbb R^n \\}\n\\]\n\n\\(\\mathcal N(M) \\subseteq \\mathbb R^n\\): \\(M\\)의 널 스페이스. 즉, 오른쪽에 곱해졌을 때 \\(\\vec 0_{m}\\)이 되는 벡터의 집합 \\[\n\\mathcal N(M) \\overset{\\rm def}{=} \\{ \\vec v \\in \\mathbb R^n | M \\vec v = \\vec 0 \\}\n\\]\n\\(\\mathcal N(M^T) \\subseteq \\mathbb R^n\\): \\(M\\)의 좌 널 스페이스. 즉, 왼쪽에 곱해졌을 때 \\(\\vec 0_{n}\\)이 되는 벡터의 집합\n\n\\[\n\\mathcal N(M^T) \\overset{\\rm def}{=} \\{ \\vec w \\in \\mathbb R^m | \\vec w^T M  = \\vec 0^T \\}\n\\]\n혹은\n\\[\n\\mathcal N(M^T) \\overset{\\rm def}{=} \\{ \\vec w \\in \\mathbb R^m | M^T \\vec w = \\vec 0 \\}\n\\]\n\\(M\\)의 랭크는 컬럼 스페이스의 차원 그리고 로우 스페이스의 차원과 같다.\n\\[\nr(M) = \\dim(\\mathcal R (M)) = \\dim(\\mathcal C(M))\n\\]"
  },
  {
    "objectID": "posts/linear-algebra/2021-01-06-vector-geometry-2.html#checklist",
    "href": "posts/linear-algebra/2021-01-06-vector-geometry-2.html#checklist",
    "title": "Vector Geometrically, part 2",
    "section": "Checklist",
    "text": "Checklist\n\nZero vector\n벡터 스페이스가 되려면 \\(\\vec 0\\)를 집합 내에 지니고 있어야 한다. 간단한 내용 같지만 참 중요하다. 일단 벡터 스페이스의 정의에서 \\(\\alpha \\vec v\\)가 들어가기 때문에 \\(\\alpha=0\\)의 조건에 따라서 \\(\\vec 0\\)이 포함되어야 한다.\n벡터 서브스페이스 역시 마찬가지로 \\(\\vec 0\\)을 포함해야 한다. 2차원 벡터로 이야기한다면, \\(y = 2x + 1\\) 같은 형태의 선, 즉 원점을 지나지 않는 직선은 벡터 (서브) 스페이스가 될 수 없다.\n\n\nSubset vs subspace\n부분집합은 원래 집합에 일정한 조건을 부여한 것이고, 이 점에서는 서브 스페이스 역시 부분 집합에 속한다. 다만 모든 부분 집합이 서브 스페이스가 되진 않는다. 이 점에서 서브 스페이스의 조건이 보다 제약적이다.\n다음과 같은 두 방정식의 해를 비교해보자. \\(A \\vec x = \\vec b\\), \\(A \\vec x = \\vec 0\\)\n\\(A \\vec v_1 = \\vec b\\)와 \\(A \\vec v_2 = \\vec b\\)를 생각해보자. \\(A(\\vec v_1 + \\vec v_2)\\)는 원래의 벡터 스페이스에 들어 있는가?\n\\[\nA(\\vec v_1 + \\vec v_2) = 2 \\vec b\n\\]\n\\(\\vec b = \\vec 0\\)가 아니라면, \\(\\vec v_1 + \\vec v_2\\)는 해가 될 수 없다. 조금 더 자세하게 표현해보자.\n\\(A \\vec v = \\vec b\\)의 해 공간은 다음과 같은 완전해의 집합이다.\n\\[\n\\{ \\vec c + \\vec v_n\\} \\text{ where }\\vec v_n \\in \\mathcal N (A)\n\\]\n즉, 해 공간은 특수해(particular solution) \\(\\vec c\\)와 널 스페이스에 속한 벡터의 합으로 구성된다. 해 공간의 원소 하나를 \\(\\vec x_1 = \\vec c + \\vec v_1\\)이라고 하고 다른 하나를 \\(\\vec x_2 = \\vec c + \\vec v_2\\)라고 하자. 이 둘을 더하면, \\(2 \\vec c + \\vec v_1 + \\vec v_2\\)가 된다. 이것이 해 공간 안에 있어야 하는데, \\(\\vec c \\neq 0\\)이면 성립하지 않는다.\n한편 \\(\\mathcal N(M)\\)은 자연스럽게 벡터 공간을 이룬다. 더한 것도 \\(\\vec 0\\)에 있고, 스칼라 곱 역시 마찬가지다. 참고로 아래에서 보겠지만, \\(\\mathcal R(M)\\), \\(\\mathcal C(M)\\), \\(\\mathcal N(M)\\), \\(\\mathcal N(M^T)\\)를 네 개의 근본 서브 스페이스라고 부른다. 네 개는 밀접한 연관을 지니고 있다.\n\n\nSolutions\n이 기회에 해의 종류를 한번 살펴보고 넘어가자.\n\nParticular solution (특수해): RREF에서 free variables를 모두 0으로 두고 찾은 해를 뜻한다.\nHomogenous solution (일반해): 일반해는 널 스페이스에 속하는 해를 뜻한다. 즉, \\(A \\vec x = 0\\)을 만족시키는 \\(\\vec x\\)를 의미한다.\nComplete solution (완전해): 완전해란 특수해와 일반해를 더한 형태이다. 즉, \\(x_c = x_p + c_h\\)\n\n이제 각각의 의미를 음미해보자.\n\\[\nA \\vec x = A x_c = A(x_p + x_h) = A x_p + A x_h = A x_p + \\vec 0_{m}\n\\]\n보다 자세한 사례는 여기를 참고하라. 약간의 직관적인 설명만 곁들이겠다. 특수해는 딱 그 위치에 있어야 하는 벡터다. 즉 free variable이 어떤 값이 오건 간에 이 벡터의 값은 고정되어 있다. 반면 일반해는 널 스페이스에 속한다. 앞서 널 스페이스는 부분 공간이라고 말했다. 이는 \\(\\vec 0\\)를 중심으로 각각 벡터가 지나가야 한다는 뜻이다. 따라서 free variable의 경우 하나를 구하기 위해서 나머지를 0으로 두고 구해야 한다. 그리고 이렇게 구해진 vector에 곱해지는 스칼라 값이 free variable에 해당한다."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-06-vector-geometry-2.html#system-of-linear-equations",
    "href": "posts/linear-algebra/2021-01-06-vector-geometry-2.html#system-of-linear-equations",
    "title": "Vector Geometrically, part 2",
    "section": "System of Linear Equations",
    "text": "System of Linear Equations\n다음 방정식의 해 공간을 생각해보자.\n\\[\nM \\vec x = \\vec b\n\\]\n먼저 \\(M\\)의 널 스페이스를 생각해보자. 여기 속한 \\(\\vec x\\)는 \\(\\mathbb R^n\\) 집합에 속한다. 정의상 \\(M \\vec x = 0\\)이므로 \\(\\vec x\\)를 어떤 해에 더하면 이 값 역시 해가 된다. 따라서, \\(M \\vec x = \\vec b\\)를 만족하는 \\(\\vec x = \\vec c\\)라고 하자. 이를 특수 해라고 부른다. 여기에 널 스페이스에 속한 임의의 원소를 더하면 완전해가 된다. 즉,\n\\[\n\\vec x = \\vec c + \\text{span}(\\vec v_1, \\dotsc, \\vec v_k) \\text{ where } \\text{span}(\\vec v_1, \\dotsc, \\vec v_k) = \\mathcal N(M)\n\\]\n\nRREF method\n연립방정식의 해를 구하는 가장 기초적인 방법, 즉 RREF, 기약 행사다리꼴 행렬을 만드는 과정이 이에 부합한다. 즉, \\([M \\lvert \\vec b]\\)를 RREF로 만들면, \\([\\text{rref}(M) \\vert \\vec c]\\)의 형태가 된다. 이때, \\(\\text{rref}(M)\\)는 \\(k\\) 개의 자유 변수를 \\(n-k\\) 개의 특수 해를 지니게 된다. 자유 변수에서 널 스페이스에 속하는 일반해를 얻을 수 있다."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-06-vector-geometry-2.html#two-transformation",
    "href": "posts/linear-algebra/2021-01-06-vector-geometry-2.html#two-transformation",
    "title": "Vector Geometrically, part 2",
    "section": "Two Transformation",
    "text": "Two Transformation\n\\(M \\in \\mathbb R^{m \\times n}\\)이 편리한 이유는 \\(M\\)이 \\(\\vec x \\in \\mathbb R^n\\)을 \\(\\vec y \\in \\mathbb R^m\\)으로 바꾸는 선형 변환 모두를 표현할 수 있기 때문이다. 그렇다면, \\(M^T\\)는 어떨까? 이는 같은 맥락에서 \\(\\vec a \\in \\mathbb R^m\\)을 \\(\\vec b \\in \\mathbb R^n\\)으로 바꾸는 선형 변환을 표현한다. 즉,\n\\[\n\\vec a^T M = \\vec b\n\\]\n이는 \\(M^T \\vec a= \\vec b^T\\)가 된다. 즉, \\(M^T\\)는 \\(M\\)의 좌 벡터 공간의 집합을 표현한다. 마찬가지로 \\(M\\)은 \\(M\\)의 우 벡터 공간의 집합을 표현한다. \\(M\\)의 좌 벡터 공간이 바로 로우 공간이고 우 벡터 공간이 컬럼 공간이다.\n이제, \\(\\mathcal N(M)\\)의 원소는 \\(\\mathbb R^n\\)에 속한다. 이와 직교하는 공간은 어떤 공간일까? 좌 벡터 공간일까? 우 벡터 공간일까? 쉽게 생각하자. 직교 하기 위해서는 서로 차원이 같아야 한다. 우 벡터 공간은 \\(\\mathbb R^m\\)에 속한다. 따라서 직교한다면 좌 벡터 공간과 한다. 확인해보자. \\(M \\vec v_n = \\vec 0_m\\) where \\(\\vec v_n \\in \\mathcal N(M)\\) 가 성립한다. 이제 양번에 \\(\\vec a^T\\)를 곱해보자.\n\\[\n\\underbrace{(M^T \\vec a)^T}_{\\text{left space}} \\vec v_n = \\vec a^T M\\vec v_n = \\vec a^T \\vec 0_m = 0\n\\]\n\\[\n\\mathcal R(M) \\oplus \\mathcal N(M) = \\mathbb R^n\n\\]\n한편 같은 논리로\n\\[\n\\mathcal C(M) \\oplus \\mathcal N(M^T) = \\mathbb R^m\n\\]\n앞서 보았듯이 \\({\\rm rank} (M) =\\dim(\\mathcal R(M)) = \\dim(\\mathcal C(M))\\)다. \\(\\dim(\\mathcal N(M)) = {\\rm nullity} (M)\\)이라고 하면,\n\\[\n{\\rm rank} (M) + {\\rm nullity} (M) = n = \\dim(\\mathbb R^n)\n\\]\n이 모든 걸 그림 하나로 정리하면 다음과 같다! 아래 보듯이 특수해(particular solution) \\(x_r\\)은 로우 스페이스에서 생성되는 해이다. 일반해(homogeneous solution) \\(x_n\\)은 널 스페이스에서 생성되는 해다. 이 둘을 합치면 완전해(complete solution)가 된다. 아래 그림에서 보듯이\n\\[\n\\begin{aligned}\nAx_r & \\rightarrow \\mathcal C(M) \\\\\nAx_n & \\rightarrow \\mathcal N(M) \\\\\nAx_c = A(x_r + x_n) & \\rightarrow \\mathcal C(M)\n\\end{aligned}\n\\]\n\n보통 homogenous라는 말이 들어가면 \\(Ax = 0\\)과 같은 형태의 연립방정식을 의미 의미한다."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-18-Eigenspace-2.html",
    "href": "posts/linear-algebra/2021-01-18-Eigenspace-2.html",
    "title": "Eigenspace, part 2",
    "section": "",
    "text": "\\(A \\in \\mathbb C^{m \\times n}\\)을 생각해보자. 이런 조건에서 아이겐 분해를 어떻게 활용할 수 있을까? 일단 \\(A\\)를 정방행렬로 만들어주어야 할 것이고, 이에는 두 가지 방법이 있다.\n\\[\n\\underbrace{A^T A}_{n \\times n}, \\overbrace{A A^T}^{m \\times m}\n\\]\n아울러, \\((A^T A)^T = A^T A\\), \\((AA^T)^T = A A^T\\)가 성립하기 때문에 두 매트릭스 모두 normal 매트릭스다. 따라서 아래와 같은 개념화가 가능하다.\n\\[\nA =\n\\underbrace{\n\\begin{bmatrix}\n\\vert & \\dotsb & \\vert \\\\\nu_1 & \\dotsb & u_m \\\\\n\\vert & \\dotsb & \\vert \\\\\n\\end{bmatrix}}_{m \\times m}\n\\overbrace{\n\\begin{bmatrix}\n\\sigma_1 & 0 & \\dotsb \\\\\n0 & \\sigma_2 & \\dotsb \\\\\n0 & 0 & \\dotsb \\\\\n\\end{bmatrix}}^{m \\times n}\n\\underbrace{\n\\begin{bmatrix}\n-- & v_1^T & -- \\\\\n-- & \\vdots & -- \\\\\n-- & v_n^T & -- \\\\\n\\end{bmatrix}}_{n \\times n} =\nU \\Sigma V^T\n\\]\n\\(U\\)를 통해 분해되는 부분을과 \\(V\\)를 통해 분해되는 부분을 다음과 같이 나타내보자.\n\\[\n\\begin{aligned}\nA A^T & = U \\Lambda_l U^T \\\\\nA^T A & = V \\Lambda_r V^T \\\\\n\\end{aligned}\n\\]\n소문자의 \\(l\\)와 \\(r\\)은 각각 left, right를 뜻한다. \\(U\\)와 \\(V^T\\)를 명시적으로 적어보자.\n\\[\nU =\n\\begin{bmatrix}\n\\vert & \\dotsb & \\vert \\\\\nu_1 & \\dotsb & u_m \\\\\n\\vert & \\dotsb & \\vert \\\\\n\\end{bmatrix}, \\text{~where}\n\\{ (\\lambda_i, u_i) = \\text{eigenvects}(A A^T) \\}\n\\]\n\\[\nV =\n\\begin{bmatrix}\n-- & v_1^T & -- \\\\\n-- & \\vdots & -- \\\\\n-- & v_n^T & -- \\\\\n\\end{bmatrix}, \\text{~where}\n\\{ (\\lambda_i, v_i) = \\text{eigenvects}(A^T A) \\}\n\\]\n이제 유사 대각행렬 \\(\\Sigma\\)를 보자. 이 행렬은 \\(m \\times n\\) 형태다.\n\\[\n\\sigma_i = \\sqrt{\\lambda_i}, \\text{ where } \\lambda_i = \\text{eigenvals}(A A^T) = \\text{eigenvals}(A^T A)\n\\]\n\n\n기저를 바꾸는 관점에서 다시 음미해보자.\n\\[\n\\vec y = A \\vec x = U \\Sigma V^T \\vec x\n\\]\n\n\\(V^T \\vec x\\): \\(V^T = \\phantom{}\\_{B\\_{SVD}}[1]\\_{B_S}\\). 즉, \\(B_{SVD} \\leftarrow B_S\\)를 수행한다.\n\\(\\Sigma\\): 유사 대각행렬을 곱해 각 기저의 크기를 조절한다.\n\\(U\\): \\(U = \\phantom{}\\_{B_{S}}[1]\\_{B\\_{SVD}}\\): \\(B_{S} \\leftarrow B_{SVD}\\)\n\n즉, \\(B_S \\leftarrow B_{SVD} \\leftarrow B_S\\)를 수행한다.\n\n\n\n외적의 관점에서 이해하는 것도 흥미롭다. 일단 외적에 관해서 간단히 살펴보자. 벡터 \\(u \\in \\mathbb R^m\\), \\(v \\in \\mathbb R^n\\)이 있다고 할 때,\n\\[\nu v^T \\in \\mathbb R^{m \\times n}\n\\]\n외적의 rank는 어떻게 될까? 1이다. 직관적으로는 이해가 안될 수 있다.\n\\[\n{\\rm rank} (AB) \\leq \\min({\\rm rank}(A), {\\rm rank} (B)) =  1\n\\]\nSVD 식을 다시 조립해보자. 일단 \\(m \\geq n\\)을 가정하자.\n\\[\nU \\Sigma =\n\\begin{bmatrix}\n\\vert & \\dotsb & \\vert \\\\\nu_1 & \\dotsb & u_m \\\\\n\\vert & \\dotsb & \\vert \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 & 0 & \\dotsb \\\\\n0 & \\sigma_2 & \\dotsb \\\\\n0 & 0 & \\dotsb \\\\\n\\end{bmatrix}\n\\]\n\\[\n\\begin{aligned}\nA & = U \\Sigma V^T \\\\\n& =\n\\underbrace{\n\\begin{bmatrix}\n\\sigma_1 u_1, \\dotsb,  \\sigma_n u_n, \\dotsc,  0 u_m\n\\end{bmatrix}}_{U \\Sigma}\n\\begin{bmatrix}\n-- & v_1^T & -- \\\\\n-- & \\vdots & -- \\\\\n-- & v_n^T & -- \\\\\n\\end{bmatrix} \\\\\n& =  \\sigma_1 u_1 v_1^T + \\dotsb + \\sigma_n u_n v_n^T + \\dotsb + 0 u_m v_m^T\n\\end{aligned}\n\\]\n\\(u_i v_i^T\\)는 각각 1의 rank를 지니고 앞에 곱해진 singular value의 기저로 이해할 수 있다. 해당 기저들의 선형 결합으로 매트릭스 \\(A\\)를 다시 분해할 수 있다.\n\n\n\n이렇게 대각화를 할 때 어떤 이득이 있을까? 앞서 유사 행렬을 활용하면 행렬의 곱이 간단해진다는 점을 보았다. SVD에도 비슷한 이점이 있다. 이 외에 SVD를 써서 할 수 있는 중요한 이득이 있다. 계산량을 줄이는 것이다.\n\\(M \\in \\mathbb R^{1000 \\times 2000}\\)의 변환이 있다고 하자. 이 변환의 싱귤러 밸류들 많아야 1000개가 나올 것이다. 만일 이 1000개 중에서 3개를 제외하고 나머지 값이 0에 가깝다고 하자.\n\\(M\\)이라는 변환의 근사값을 구하고 싶다면, 0에 가까운 값을 모두 0으로 둔다. 이렇게 바꾸면,\n\\[\nM \\approx \\hat M = \\hat U \\hat \\Sigma \\hat V^T\n\\]\n\n\\(\\hat U \\in \\mathbb R^{1000 \\times 3}\\)\n\\(\\hat \\Sigma \\in \\mathbb R^{3 \\times 3}\\)\n\\(\\hat V^T \\in \\mathbb R^{3 \\times 2000}\\)\n\n이렇게 근사값을 구하면 계산량이 많이 줄어들 것이다. \\(M\\)와 \\(\\hat M\\) 사이의 힐베르트-슈미트 거리를 구하면,\n\\[\n\\Vert M - \\hat M \\Vert_{\\rm HS} = \\sqrt{\\sum_{i=4}^{1000} \\sigma_i^2}\n\\]\n이 값이 크지 않다면, \\(M \\approx \\hat M\\)으로 간주할 수 있다. 실제로 이미지 압축 등에서 많이 사용되는 방법이다."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-18-Eigenspace-2.html#singluar-value-decomposition",
    "href": "posts/linear-algebra/2021-01-18-Eigenspace-2.html#singluar-value-decomposition",
    "title": "Eigenspace, part 2",
    "section": "",
    "text": "\\(A \\in \\mathbb C^{m \\times n}\\)을 생각해보자. 이런 조건에서 아이겐 분해를 어떻게 활용할 수 있을까? 일단 \\(A\\)를 정방행렬로 만들어주어야 할 것이고, 이에는 두 가지 방법이 있다.\n\\[\n\\underbrace{A^T A}_{n \\times n}, \\overbrace{A A^T}^{m \\times m}\n\\]\n아울러, \\((A^T A)^T = A^T A\\), \\((AA^T)^T = A A^T\\)가 성립하기 때문에 두 매트릭스 모두 normal 매트릭스다. 따라서 아래와 같은 개념화가 가능하다.\n\\[\nA =\n\\underbrace{\n\\begin{bmatrix}\n\\vert & \\dotsb & \\vert \\\\\nu_1 & \\dotsb & u_m \\\\\n\\vert & \\dotsb & \\vert \\\\\n\\end{bmatrix}}_{m \\times m}\n\\overbrace{\n\\begin{bmatrix}\n\\sigma_1 & 0 & \\dotsb \\\\\n0 & \\sigma_2 & \\dotsb \\\\\n0 & 0 & \\dotsb \\\\\n\\end{bmatrix}}^{m \\times n}\n\\underbrace{\n\\begin{bmatrix}\n-- & v_1^T & -- \\\\\n-- & \\vdots & -- \\\\\n-- & v_n^T & -- \\\\\n\\end{bmatrix}}_{n \\times n} =\nU \\Sigma V^T\n\\]\n\\(U\\)를 통해 분해되는 부분을과 \\(V\\)를 통해 분해되는 부분을 다음과 같이 나타내보자.\n\\[\n\\begin{aligned}\nA A^T & = U \\Lambda_l U^T \\\\\nA^T A & = V \\Lambda_r V^T \\\\\n\\end{aligned}\n\\]\n소문자의 \\(l\\)와 \\(r\\)은 각각 left, right를 뜻한다. \\(U\\)와 \\(V^T\\)를 명시적으로 적어보자.\n\\[\nU =\n\\begin{bmatrix}\n\\vert & \\dotsb & \\vert \\\\\nu_1 & \\dotsb & u_m \\\\\n\\vert & \\dotsb & \\vert \\\\\n\\end{bmatrix}, \\text{~where}\n\\{ (\\lambda_i, u_i) = \\text{eigenvects}(A A^T) \\}\n\\]\n\\[\nV =\n\\begin{bmatrix}\n-- & v_1^T & -- \\\\\n-- & \\vdots & -- \\\\\n-- & v_n^T & -- \\\\\n\\end{bmatrix}, \\text{~where}\n\\{ (\\lambda_i, v_i) = \\text{eigenvects}(A^T A) \\}\n\\]\n이제 유사 대각행렬 \\(\\Sigma\\)를 보자. 이 행렬은 \\(m \\times n\\) 형태다.\n\\[\n\\sigma_i = \\sqrt{\\lambda_i}, \\text{ where } \\lambda_i = \\text{eigenvals}(A A^T) = \\text{eigenvals}(A^T A)\n\\]\n\n\n기저를 바꾸는 관점에서 다시 음미해보자.\n\\[\n\\vec y = A \\vec x = U \\Sigma V^T \\vec x\n\\]\n\n\\(V^T \\vec x\\): \\(V^T = \\phantom{}\\_{B\\_{SVD}}[1]\\_{B_S}\\). 즉, \\(B_{SVD} \\leftarrow B_S\\)를 수행한다.\n\\(\\Sigma\\): 유사 대각행렬을 곱해 각 기저의 크기를 조절한다.\n\\(U\\): \\(U = \\phantom{}\\_{B_{S}}[1]\\_{B\\_{SVD}}\\): \\(B_{S} \\leftarrow B_{SVD}\\)\n\n즉, \\(B_S \\leftarrow B_{SVD} \\leftarrow B_S\\)를 수행한다.\n\n\n\n외적의 관점에서 이해하는 것도 흥미롭다. 일단 외적에 관해서 간단히 살펴보자. 벡터 \\(u \\in \\mathbb R^m\\), \\(v \\in \\mathbb R^n\\)이 있다고 할 때,\n\\[\nu v^T \\in \\mathbb R^{m \\times n}\n\\]\n외적의 rank는 어떻게 될까? 1이다. 직관적으로는 이해가 안될 수 있다.\n\\[\n{\\rm rank} (AB) \\leq \\min({\\rm rank}(A), {\\rm rank} (B)) =  1\n\\]\nSVD 식을 다시 조립해보자. 일단 \\(m \\geq n\\)을 가정하자.\n\\[\nU \\Sigma =\n\\begin{bmatrix}\n\\vert & \\dotsb & \\vert \\\\\nu_1 & \\dotsb & u_m \\\\\n\\vert & \\dotsb & \\vert \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n\\sigma_1 & 0 & \\dotsb \\\\\n0 & \\sigma_2 & \\dotsb \\\\\n0 & 0 & \\dotsb \\\\\n\\end{bmatrix}\n\\]\n\\[\n\\begin{aligned}\nA & = U \\Sigma V^T \\\\\n& =\n\\underbrace{\n\\begin{bmatrix}\n\\sigma_1 u_1, \\dotsb,  \\sigma_n u_n, \\dotsc,  0 u_m\n\\end{bmatrix}}_{U \\Sigma}\n\\begin{bmatrix}\n-- & v_1^T & -- \\\\\n-- & \\vdots & -- \\\\\n-- & v_n^T & -- \\\\\n\\end{bmatrix} \\\\\n& =  \\sigma_1 u_1 v_1^T + \\dotsb + \\sigma_n u_n v_n^T + \\dotsb + 0 u_m v_m^T\n\\end{aligned}\n\\]\n\\(u_i v_i^T\\)는 각각 1의 rank를 지니고 앞에 곱해진 singular value의 기저로 이해할 수 있다. 해당 기저들의 선형 결합으로 매트릭스 \\(A\\)를 다시 분해할 수 있다.\n\n\n\n이렇게 대각화를 할 때 어떤 이득이 있을까? 앞서 유사 행렬을 활용하면 행렬의 곱이 간단해진다는 점을 보았다. SVD에도 비슷한 이점이 있다. 이 외에 SVD를 써서 할 수 있는 중요한 이득이 있다. 계산량을 줄이는 것이다.\n\\(M \\in \\mathbb R^{1000 \\times 2000}\\)의 변환이 있다고 하자. 이 변환의 싱귤러 밸류들 많아야 1000개가 나올 것이다. 만일 이 1000개 중에서 3개를 제외하고 나머지 값이 0에 가깝다고 하자.\n\\(M\\)이라는 변환의 근사값을 구하고 싶다면, 0에 가까운 값을 모두 0으로 둔다. 이렇게 바꾸면,\n\\[\nM \\approx \\hat M = \\hat U \\hat \\Sigma \\hat V^T\n\\]\n\n\\(\\hat U \\in \\mathbb R^{1000 \\times 3}\\)\n\\(\\hat \\Sigma \\in \\mathbb R^{3 \\times 3}\\)\n\\(\\hat V^T \\in \\mathbb R^{3 \\times 2000}\\)\n\n이렇게 근사값을 구하면 계산량이 많이 줄어들 것이다. \\(M\\)와 \\(\\hat M\\) 사이의 힐베르트-슈미트 거리를 구하면,\n\\[\n\\Vert M - \\hat M \\Vert_{\\rm HS} = \\sqrt{\\sum_{i=4}^{1000} \\sigma_i^2}\n\\]\n이 값이 크지 않다면, \\(M \\approx \\hat M\\)으로 간주할 수 있다. 실제로 이미지 압축 등에서 많이 사용되는 방법이다."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-18-Eigenspace-2.html#lu",
    "href": "posts/linear-algebra/2021-01-18-Eigenspace-2.html#lu",
    "title": "Eigenspace, part 2",
    "section": "LU",
    "text": "LU\n\\(n \\times n\\) 정방 행렬에 대해서 \\(A = LU\\)를 수행할 수 있다. \\(L\\)과 \\(U\\)는 하방삼각 행렬과 상방삼각 행렬이다. 이렇게 매트릭스를 쪼개는 이유를 각각에 관해서 역행렬을 구하기 힘들기 때문이다. 즉,\n\\[\nA \\vec x = LU \\vec x = b \\Leftrightarrow U \\vec x = L^{-1}b \\Leftrightarrow \\vec x = U^{-1}L^{-1}b\n\\]\n우선 LU가 가능하라면 \\(A\\)가 RREF으로 열의 교환 없이 환원될 수 있어야 한다.\n\nCholesky\n\\(A\\)가 대칭이고 PSD 매트릭스라면 \\(LU\\) 분해는 더욱 단순해진다.\n\\[\nA = L L^T \\text{ or } A = U^T U\n\\]"
  },
  {
    "objectID": "posts/linear-algebra/2021-01-18-Eigenspace-2.html#qr",
    "href": "posts/linear-algebra/2021-01-18-Eigenspace-2.html#qr",
    "title": "Eigenspace, part 2",
    "section": "QR",
    "text": "QR\n\\(A \\in \\mathbb R^{n \\times n}\\)일 때 이 매트릭스를 쪼개는 강력한 방법은 G-S 알고리듬을 활용하는 것이다.\n\\[\nA = O U\n\\]\n\n\\(O\\): orthogonal matrix\n\\(U\\): Upper triangluar matrix\n\n보통 \\(U\\)를 right-triangular matrix로도 쓰기 때문에, 이를 \\(QR\\)로 표기하기도 한다. \\(R\\)의 경우 \\(O\\)의 컬럼 벡터를 하나씩 추가해가면서 계산하게 된다. 이는 G-S 알고리듬에서 하나씩 벡터를 빼가면서 계산하는 것을 구현할 수 있게 해준다.\n\nExample\n실제로는 어떻게 하는지 살펴보자. 먼저 \\(A\\)의 각 컬럼들을 두고, 두번째 열은 첫번째에 직교하게, 세번째는 첫번째와 두번째에 직교하게 행렬을 변형한다.\n\\[\nA =\n\\begin{bmatrix}\na_{11} & a_{12} & a_{13} \\\\\na_{21} & a_{22} & a_{23} \\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix}\n\\]\n\\(O\\) 혹은 \\(Q\\)를 구해보자. G-S 알고리듬을 활용하자.\n\\[\nA = [a_1, a_2, a_3]\n\\]\n\\(a_1\\)과 직교하는 \\(e_2\\)를 구하면 아래와 같다.\n\\[\ne_2 = a_2 - \\dfrac{a_2 \\cdot a_1}{\\Vert a_1 \\Vert^2}\n\\]\n다음으로 \\(e_3\\)는 \\(a_1\\)과 직교하고 동시에 \\(e_2\\)와 직교해야 한다. 따라서,\n\\[\ne_3 = a_3 - \\dfrac{a_3 \\cdot a_1}{\\Vert a_1 \\Vert^2} - \\dfrac{a_3 \\cdot e_2}{\\Vert e_2 \\Vert^2}\n\\]\n이를 다시 길이 1로 표준화하면 \\(Q\\)를 구할 수 있다. 그리고\n\\[\nQ^T A = Q^T Q R = 1 R\n\\]\n따라서 \\(R\\)은 \\(Q^T A\\)로 구할 수 있다."
  },
  {
    "objectID": "posts/the-books/2023-03-13-voltage-effect-list.html",
    "href": "posts/the-books/2023-03-13-voltage-effect-list.html",
    "title": "존 리스트, “스케일의 법칙”",
    "section": "",
    "text": "경제학 혹은 행동 경제학의 기본적인 개념을 응용하기에는 좋다.\n저자의 우버에서의 경험이 ’날 것’으로 들어가 있지는 않더라."
  },
  {
    "objectID": "posts/the-books/2023-03-13-voltage-effect-list.html#tl-dr",
    "href": "posts/the-books/2023-03-13-voltage-effect-list.html#tl-dr",
    "title": "존 리스트, “스케일의 법칙”",
    "section": "",
    "text": "경제학 혹은 행동 경제학의 기본적인 개념을 응용하기에는 좋다.\n저자의 우버에서의 경험이 ’날 것’으로 들어가 있지는 않더라."
  },
  {
    "objectID": "posts/the-books/2023-03-13-voltage-effect-list.html#학술을-다루는-책의-어떤-흐름",
    "href": "posts/the-books/2023-03-13-voltage-effect-list.html#학술을-다루는-책의-어떤-흐름",
    "title": "존 리스트, “스케일의 법칙”",
    "section": "학술을 다루는 책의 어떤 흐름",
    "text": "학술을 다루는 책의 어떤 흐름\n학술 분야의 대중서가 지니는 뚜렷한 특징이 하나 있다. 최근 들어 등장하는 많은 학술 대중서를 보면, 일가를 이룬 연구자가 자신의 연구를 책에 집대성하면서 동시에 절반쯤 자서전을 겸하는 경우가 많다. 책의 중간중간 등장하는 개인사가 중요한 학술적인 성취를 엿보는 창이 되기도 한다. 이런 말랑말랑한 학술서가 딱딱한 교과서 혹은 본격 학술서에 비해 재미 있고 접근성도 좋다. 이런 포맷의 ’시초’라고 할 만한 “괴짜 경제학”의 엄청난 성공 때문일까도 싶다.\n그런데 나는 이런 형식이 이제 그리 좋게 보이지 않는다. 이런 책이 읽을 때는 재미있지만, 읽고 나면 기억에 남는 것이 별로 없다. 교과서나 솔직한 학술서를 읽으면 주요 개념 한두 개쯤은 챙겨갈 수 있는데, 이런 책은 도통 ’재미있더라’는 인상 빼고는 챙길 게 없더라."
  },
  {
    "objectID": "posts/the-books/2023-03-13-voltage-effect-list.html#존-리스트의-볼티지-효과",
    "href": "posts/the-books/2023-03-13-voltage-effect-list.html#존-리스트의-볼티지-효과",
    "title": "존 리스트, “스케일의 법칙”",
    "section": "존 리스트의 “볼티지 효과”",
    "text": "존 리스트의 “볼티지 효과”\n존 리스트의 “스케일의 법칙”도 이러한 흐름에 속하는 책이다. 저자는 상아탑 경제학자로서는 드물게 기업의 현장 그것도 떠오르는 스타트업에 뛰어들어 ’규모의 경제’를 설계하는 일에 참여했다. 리스트 교수는 최근 노벨 경제학상 후보의 앞자리에 항상 오를 만큼 경제학계의 업적도 탄탄한 인물이다.\n나는 우버와 리프트에서 겪은 사업의 경험을 보다 내밀하게 “규모의 경제” 혹은 “네트워크 효과”와 연결하는 내용을 기대했다. 규모의 경제를 다루는 많은 책이 있지만, 본질을 솔직하게 제대로 치고 나가는 책이 생각보다 드물다. Varian & Shapiro가 20년 전에 썼던 책이 여전히 메력이라고 생각하기에 보다 갱신된 내용이 경제학적으로 잘 다뤄졌으면 싶었다.\n\n\nInformation Rules; 이 책은 번역 출간되었으나, 현재는 절판 상태이다."
  },
  {
    "objectID": "posts/the-books/2023-03-13-voltage-effect-list.html#기대와는-달랐다",
    "href": "posts/the-books/2023-03-13-voltage-effect-list.html#기대와는-달랐다",
    "title": "존 리스트, “스케일의 법칙”",
    "section": "기대와는 달랐다…",
    "text": "기대와는 달랐다…\n이 책은 관련된 경제학을 꼼꼼히 다루는 대신 자기계발서와 비슷한 형태를 취하고 있다. 이론 혹은 실험 결과를 상세하기 소개하기보다는 그 논리와 결과를 밑밥으로 깔면서 비즈니스 혹은 삶의 교훈을 끌어내는 식이다.\n1부에서는 규모의 확장을 가로막는 5가지 장애물을 소개한다. 행동 경제학, 실험 경제학, 인과 추론, 재현성의 위기 등의 학술 논쟁에서 다뤄진 내용이 적당히 버무려져서 소개된다. 2부는 규모 확장을 위해 필요한 경제학의 도구를 소개한다. 인센티브, 한계적 사고(marginal thinking), 기회비용(opportunity cost)에 기반한 포기 시점의 판단, 문화의 중요성을 다루고 있다.\n나는 2부가 더 실망스러웠다. 우선 리스트 교수의 가르침이라는 게 ’경제학 101’의 내용과 크게 다르지 않다. 태양 아래 새로운 것이 없다면 좋은 가르침을 여러 영역에서 확인할 수 있다면, 그것으로 충분할지 모르겠다. 새롭다고 인지되는 현상을 먼저 잘 포획하고 이를 기존 경제학의 가르침으로 끌고 오는 방식이면 어땠을까 싶다. 저자가 이런 접근을 취하고 있지는 않더라.\n저자의 개인사와 관련된 에피소드 역시 경제학을 전공하는 사람이라면 모를까 일반인이 크게 관심을 가질 만한 내용일까 싶다. 우버의 부상 및 추락과 관련해서 흥미로운 대목이 더 있었을 듯 싶다. 저자가 경험한 회사 생활이 그 정도였기 때문인지 아니면 감추려고 그랬던 것인지는 알 수 없지만, ’좋은 게 좋은 것’이라는 식으로 넘어가는 경우가 많더라."
  },
  {
    "objectID": "posts/the-books/2023-03-13-voltage-effect-list.html#최후의-일언",
    "href": "posts/the-books/2023-03-13-voltage-effect-list.html#최후의-일언",
    "title": "존 리스트, “스케일의 법칙”",
    "section": "최후의 일언",
    "text": "최후의 일언\n일반적인 경제학의 가르침이 규모 확장(scalability)에도 핵심이라면 굳이 ‘규모’(볼티지)라는 대목을 강조할 필요가 있었을까? 이 책에 던지는 나의 근본 질문 혹은 회의이다."
  },
  {
    "objectID": "posts/the-books/2023-03-13-voltage-effect-list.html#부록",
    "href": "posts/the-books/2023-03-13-voltage-effect-list.html#부록",
    "title": "존 리스트, “스케일의 법칙”",
    "section": "부록",
    "text": "부록\nReminders by the Content"
  },
  {
    "objectID": "posts/econ-simple/2024-02-14-larry-summers.html",
    "href": "posts/econ-simple/2024-02-14-larry-summers.html",
    "title": "현실( 정치)에서 경제학자의 역할",
    "section": "",
    "text": "래리 서머스의 ECONOFACT 대담 중에서 경제학자의 현실 (정치)에서의 역할 혹은 임무에 관해 좋은 대목이 있어서 그대로 옮겨 본다.\n\n명확하게 제시된 단단한 분석은 시간이 지날수록 중요해집니다. 제가 들어 본 것 중에서 실제의 영향력에 관한 그리고 경제학자가 사고하는 방법과 과정에 관한 가장 정교한 논의는 오래 전 밀턴 프리드먼의 사례입니다. 밀턴 프리드먼의 정책적 견해를 믿든 믿지 않든 그 분석은 신뢰할 수 있습니다. 실제로 일이 진행될 때 중요한 것은 그의 정치력과 개성이었습니다. 관련된 사람들에게 건넨 그의 경제학적인 조언이 어느 정도 도움은 되었겠지만, 문제의 본질은 아니었지요.\n\n\n하지만 경제학 연구자의 역할은 여전히 잘 다듬어진 아이디어의 목록이 그곳에 존재하도록 애쓰는 것에 있습니다. 그래야 정치적 기회가 열렸을 때 이 아이디어를 펼쳐볼 수 있습니다. 예를 들어 프리드먼 자신은 당시만해도 엉터리 아이디어로 여겨지던 모병제의 편에 섰던 사람입니다. 그리고 베트남 전쟁은 이 문제를 둘러싼 모든 판도를 바꾸어 놓았고, 이후 세심하게 준비된 모병제 관한 일련의 제안들이 쏟아져 나왔습니다. 통화주의는 일종의 외로운 십자군 전쟁이었습니다. 1970 년대에 인플레이션이 급격히 상승하고 당시 경제학의 정설이 통하지 않자, 비록 프리드만 자신조차 많은 세부 사항을 믿지는 않았겠지만, 통화주의는 폴 볼커가 인플레이션에 저항하는 데 필요한 조처를 취할 수 있는 사고의 틀을 제공했습니다.\n\n\n단순히 직접 통제(command-control) 기반의 규제에 의존하는 대신 오염에 대해서 비용을 부과하자는 경제학자의 아이디어는, 여러분이나 제가 원하는 만큼 많이 채택되지는 않았지만, 세계적으로 엄청난 영향을 끼치고 있으며, 탄소 가격 설정은 기후 변화 정책의 핵심 중 하나입니다. 과학적 진보를 촉진하기 위한 보상과 조달에 대한 아이디어는 “오퍼레이션 워프 스피드”와 상당한 관련이 있고, 코로나 기간 동안 지구적으로 큰 이익을 가져온 미국이 잘한 일의 하나일 것입니다.\n\n\n그래서 저는 이렇게 봅니다. 정부와 일하는 경제학자들은 당면 현안과 진행 중인 법안 그리고 규제의 평가 및 설계에 초점을 맞춰 일해야 합니다. 하지만, 정부와 일하지 않는 경제학자들은 문제를 드러내고 그 원인을 이해하며 이 문제들을 가장 잘 다룰 수 있는 모델 및 해결책을 고민하는 데 애쓰면서, 정치적인 기회가 열리기를 기다려야 합니다. 제가 워싱턴에서 일할 때 꽤 분명하게 알게 된 점이 있습니다. 생각조차 하지 못했던 경우가 불가피한 무엇으로 바뀌는 순간은 실제로 올 수 있고 꽤 극적으로 그렇게 된다는 것이지요. 물론 이 순간이 언제 올지는 아무도 예측할 수 없지요."
  },
  {
    "objectID": "posts/computer-tool/2022-09-25-latex-vscode.html",
    "href": "posts/computer-tool/2022-09-25-latex-vscode.html",
    "title": "\\(\\rm\\LaTeX\\) + VS Code",
    "section": "",
    "text": "Tiny\\(\\rm\\TeX\\)을 씁시다!\n이 포스트의 조금 더 실용적인 접근이다."
  },
  {
    "objectID": "posts/computer-tool/2022-09-25-latex-vscode.html#tl-dr",
    "href": "posts/computer-tool/2022-09-25-latex-vscode.html#tl-dr",
    "title": "\\(\\rm\\LaTeX\\) + VS Code",
    "section": "",
    "text": "Tiny\\(\\rm\\TeX\\)을 씁시다!\n이 포스트의 조금 더 실용적인 접근이다."
  },
  {
    "objectID": "posts/computer-tool/2022-09-25-latex-vscode.html#rmlatex의-추억",
    "href": "posts/computer-tool/2022-09-25-latex-vscode.html#rmlatex의-추억",
    "title": "\\(\\rm\\LaTeX\\) + VS Code",
    "section": "\\(\\rm\\LaTeX\\)의 추억",
    "text": "\\(\\rm\\LaTeX\\)의 추억\n아카데미 종사자가 아니라면 \\(\\rm\\LaTeX\\)을 일상적으로 쓰지는 않을 것이다. 아카데미를 스쳐간 사람들이라면 한 때의 기억이리라. 논문을 쓸 때 좋았던 혹은 나빴단 기억이 함께 떠올랐지만, 역시 \\(\\rm\\TeX\\)은 아름다운 문서 조판 도구다. 얼마나 쓸지는 모르겠지만, 그래도 한번 정리해두고 넘어가자. 이 글의 목표는 다음과 같다.\n\n모든 OS에서 동일하게 쓴다.\n\nVS Code를 에디터로 쓴다.\n텍라이브(\\(\\rm\\TeX\\)Live)는 설치하지 않는다.\n\n\n\n텍라이브가 설치도 까다롭고 도구도 크다. 많이 쓰지 않는 소프트웨어다보니 미러 사이트에서 파일을 당겨오는 데에도 시간이 제법 소요된다."
  },
  {
    "objectID": "posts/computer-tool/2022-09-25-latex-vscode.html#tinyrmtex",
    "href": "posts/computer-tool/2022-09-25-latex-vscode.html#tinyrmtex",
    "title": "\\(\\rm\\LaTeX\\) + VS Code",
    "section": "Tiny\\(\\rm\\TeX\\)",
    "text": "Tiny\\(\\rm\\TeX\\)\n이 목표에 딱 부합하는 도구가 Tiny\\(\\rm\\TeX\\)이다. 원래는 R의 \\(\\rm\\LaTeX\\) 활용을 위해 만들어 졌으나, 제작자가 별도의 도구로 만들어 \\(\\rm\\LaTeX\\)을 부리는 데 활용하기에 부족하지 않다.\nhttps://github.com/rstudio/tinytex-releases\n위 깃헙에 여러가지 배포 버전을 만들어 두었다. TinyTeX-0는 텍라이브를 쓰기 위한 커맨드라인 도구 정도만을 지니고 있다. TinyTeX-2는 풀 버전이다. 이름과 달리 작지 않은 버전이다. 선택은 각자의 몫이겠지만, 표준 버전 TinyTeX 정도를 설치해도 좋을 것이다.\nLinux, Macos 버전을 sh 명령어를 다운받아서 이를 실행하도록 하자. 만일 특정한 배포 판을 깔고자 한다면, 설치 전에 환경 변수를 설정하면 된다. 여기를 참고하자.\n\nTiny\\(\\rm\\TeX\\) for Windows\n플랫폼이 다소 이질적인 윈도 버전의 설치만 조금 더 살펴보자. 어찌보면 윈도 버전의 설치가 제일 쉽다! 공식 가이드 대로 PS 스크립트를 통한 설치가 정석이겠지만, 아래와 같이 하는 것이 더 편하다.\n\n릴리즈 링크에서 필요한 윈도용 압축 파일을 다운로드 받는다.\n\n해당 파일을 %APPDATA%/TinyTeX에 압축을 푼다. 압축을 풀면 TinyTeX이 기본 디렉토리로 설정되기 떄문에 해당 파일은 %APPDATA%에 두고 압축을 풀면 된다.\n\n환경 변수에서 %APPDATA%/TinyTeX 패스를 추가한다. 패스를 추가하는 방법은 여기를 참고한다.\n패스 인식을 위해서 재부팅 한다.\n\n\n\n%APPDATA%란 윈도 사용자의 홈 아래 해당 디렉토리가 위치한다는 뜻이다. 탐색기에서 찾아간다면 C:\\Users\\{USER NAME}\\AppData\\에 해당한다. 만일 AppData 폴더가 보이지 않는다면 감춘 폴더, 파일을 표시하지 않도록 설정되어 있는 것이다. 이를 바꿔주면 보일 것이다. 윈도11을 기준으로 탐색기의 “보기” 메뉴에서 표시로 가면 “숨긴 항목” 여부를 확인할 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2022-09-25-latex-vscode.html#설치-확인",
    "href": "posts/computer-tool/2022-09-25-latex-vscode.html#설치-확인",
    "title": "\\(\\rm\\LaTeX\\) + VS Code",
    "section": "설치 확인",
    "text": "설치 확인\n텍라이브 커맨드라인 도구가 잘 동작하는지 확인하면 된다.\n$ tlmgr --version\n버전이 잘 뜬다면, 앞으로 tlmgr 명령을 통해서 \\(\\rm\\TeX\\) 관련 패키지를 설치하고 삭제할 수 있다. tlmgr의 활용에 관해서는 여기를 참고하자."
  },
  {
    "objectID": "posts/computer-tool/2022-09-25-latex-vscode.html#vs-code-extension",
    "href": "posts/computer-tool/2022-09-25-latex-vscode.html#vs-code-extension",
    "title": "\\(\\rm\\LaTeX\\) + VS Code",
    "section": "VS Code Extension",
    "text": "VS Code Extension\n이제 VS Code에서 \\(\\rm\\TeX\\)을 부리기 위한 익스텐션을 설치하자.\nhttps://marketplace.visualstudio.com/items?itemName=James-Yu.latex-workshop\n익스텐션을 설치한 후 몇 가지 설정을 손보도록 하자. 어떤 컴파일 엔진을 쓰는지에 따라서 설정을 손봐야 한다. PDF\\(\\rm\\LaTeX\\)을 쓰는 경우만 사례로 살펴보자.\n\nF1을 누른다.\nsettings.json을 검색해, 나온 파일을 클릭한다. “사용자 설정”을 열도록 하자.\n해당 json 파일을 수정한다. 아주 게으른 설정이다. pdflatex을 컴파일을 위해서 latex-workshop-tools, latex-workshop.latex.recipes를 수정한다. 찾기로 검색해서 찾으면 편리하다.\n\n\"latex-workshop.latex.tools\" : [\n    {\n      \"name\": \"pdflatex\",\n      \"command\": \"pdflatex\",\n      \"args\": [\n        \"-synctex=1\",\n        \"-interaction=nonstopmode\",\n        \"-file-line-error\", \n        \"%DOCFILE%\"\n      ]\n    }\n  ],\n  \"latex-workshop.latex.recipes\": [\n    {\n      \"name\": \"tex to pdf\",\n      \"tools\": [\n        \"pdflatex\", \n        \"pdflatex\"\n      ]\n    }\n  ]\n\n\n\n\n\n\n \n\n\n\n\n\nVS Code에 .tex 파일을 올렸을 때 (클릭시 확대)\n\n\n\n\n \n\n\n\n위 스크린 샷에서 보듯이 .tex 파일을 읽으면 확장에 관련 탭이 자동으로 추가된다. 앞서 settings.json에 설정한 대로 컴파일 레서피에 “tex to pdf”가 추가되어 있다. 컴파일은 해당 창 상단 오른쪽의 세모 버튼으로 할 수 있으며 PDF 보기는 돋보기 버튼을 누르면 된다.\n왜 VS Code를 써야 할까? IDE를 통합적으로 활용한다는 의미도 있지만, 최근 가장 강력한 개발 보조 수단이 된 GitHub Copilot을 활용할 수 있기 때문이다. 여러 명령어를 쳐야 하는 텍 문서에서도 코파일럿의 편리함이 쏠쏠하다.\n\n\n당연히 TexShop 등 여타 텍 전용 에디터를 써도 된다."
  },
  {
    "objectID": "posts/computer-tool/2022-09-25-latex-vscode.html#references",
    "href": "posts/computer-tool/2022-09-25-latex-vscode.html#references",
    "title": "\\(\\rm\\LaTeX\\) + VS Code",
    "section": "References",
    "text": "References\nKTUG의 문서가 잘 되어 있다. 여기서 부족하다고 느낀 대목은 이 문서를 참고하시라.\n\n\n\nVS Code에 .tex 파일을 올렸을 때 (클릭시 확대)"
  },
  {
    "objectID": "posts/computer-tool/2022-05-14-blogging-with-quarto.html",
    "href": "posts/computer-tool/2022-05-14-blogging-with-quarto.html",
    "title": "Blogging with Quarto",
    "section": "",
    "text": "독립 블로깅 툴을 고민하고 있는 당신, Quarto로 오라."
  },
  {
    "objectID": "posts/computer-tool/2022-05-14-blogging-with-quarto.html#tl-dr",
    "href": "posts/computer-tool/2022-05-14-blogging-with-quarto.html#tl-dr",
    "title": "Blogging with Quarto",
    "section": "",
    "text": "독립 블로깅 툴을 고민하고 있는 당신, Quarto로 오라."
  },
  {
    "objectID": "posts/computer-tool/2022-05-14-blogging-with-quarto.html#why",
    "href": "posts/computer-tool/2022-05-14-blogging-with-quarto.html#why",
    "title": "Blogging with Quarto",
    "section": "Why",
    "text": "Why\n블로깅 툴은 관리가 편한 게 제일 좋다. 다만 상용 툴에는 내 취향에 어긋나는 몇 가지 제약이 있다.\n\n\\(\\rm \\LaTeX\\) 수식의 생성이 쉽지 않다.\n생각보다 깔끔한 툴이 별로 없다.\n왠지 모를 종속된 느낌적 느낌\n\n별도의 서버를 호스팅해서 워드프레스 같은 툴을 깔아서 쓸 용기는 부족하니 적당한 선에서 타협이 필요하다. 이 요구를 딱 맞는 것이 github(깃헙)의 스태틱 웹 서비스 Github Pages다. 스테틱 웹이란 html 페이지를 호출한 브라우저에 html을 띄워주는 단순한 서비스를 의미한다. 내가 작성한 포스팅을 html로 생성하는 일관된 방법만 있다면 스태틱이라는 사실 자체가 문제는 아니다. 페이지를 생성하는 약간의 귀찮음이 더해지는 정도라고 보면 될 것이다.\n\n\n깃헙 페이지스는 스태틱 페이지를 생성하고 관리하는 프레임워크 Jekyll을 품고 있다. 일정한 구조에 맞춰서 콘텐츠를 떨구면 알아서 블로그를 생성한다. 경우에 따라서는 생각보다 편리한 기능이다."
  },
  {
    "objectID": "posts/computer-tool/2022-05-14-blogging-with-quarto.html#tools",
    "href": "posts/computer-tool/2022-05-14-blogging-with-quarto.html#tools",
    "title": "Blogging with Quarto",
    "section": "Tools",
    "text": "Tools\n\nHistory of lostineconomics.com\n스태틱 웹을 이용할 수 있게 해주는 도구는 대체로 다른 도구에 종속되어 있었다. 이 블로그의 최초 버전은 RStudio에서 제공하는 Blogdown이라는 도구를 활용했다. 작동하는 방식은 여느 스태틱 웹을 생성하는 툴과 비슷하다. 사용하기에 부족함이 없지만, RStudio에 종속되어 있다는 것이 내내 마음에 들지 않았다.\n두번째 버전에서는 ’꼼수’를 써 봤다. 깃헙의 각 리포지토리(리포) 별로 html 호스팅이 가능하다는 점에 착안했다. 포스팅 별로 각각 리포를 두고 html을 생성한다. 이 html의 링크를 모아 블로그의 홈을 만들었다. 개별 포스팅을 용도에 맞게 특화할 수 있다는 장점이 있었지만, 별도의 깃헙 리포로 된 구조 때문에 포스팅이 늘어가면서 관리가 번거로워졌다.\n세번째 버전은 fastpages를 활용했다. fastpages는 깃헙 액션스의 빌드 기능을 활용한다. 사용자는 .md로 콘텐츠를 전달하고 나머지 빌드는 모두 깃헙 위에서 이루어진다. 별도의 로컬 프로세스가 없다는 점에서 편리한 접근이다. 하지만 디자인의 요소가 많이 아쉽고, 시간이 흐를 수록 프로젝트의 지원이 부족해지는 점이 불안했다.\n\n\nfastpages 활용은 여기를 참고하자.\n\n\nQuarto\n이 프로젝트의 홈에 따르면 Quarto는 ’과학 문서(scientific document)’의 작성을 위해 고안된 의존성을 최소화한 도구다. 앞서 소개한 BlogDown과 같은 툴이 RStudio와 같은 특정 도구에 의존한다면 이 녀석은 Jupyter, VS Code, RStudio 및 여느 범용 에디터와도 함께 쓸 수 있다.\n\n\nQuarto는 사절지를 의미한다. 책을 조판할 때 큰 종이에 인쇄해서 네번 접어 조판하는 방식을 뜻한다.\nQuarto 프로젝트는 아직 초기지만 상당한 기대와 지지를 받고 있다. 이 프로젝트의 장점은 아래와 같다.\n\n마크 다운 기반의 문서 작성, 스태틱 웹 도구 그리고 계산 기반 문서 작성 도구의 기능을 부족하지 않게 두루 갖추고 있다.\n각종 기능에 관한 문서화가 체계적으로 잘 되어 있다.\nCLI 기반이라서 도구 의존성이 낮다.\n\n프로젝트가 초기여서 안정성이 떨어지는 경우가 있고, 아직 쓰는 사람이 많지 않아 구글링을 통해 필요한 정보를 충분히 얻기 힘든 경우가 있다. 이러한 불편함은 시간이 흐르면 빠르게 해결될 것으로 생각한다. 아울러 Quarto가 머지 않아 Jekyll과 같이 github의 기본 빌드 옵션이 되기를 바라보자."
  },
  {
    "objectID": "posts/computer-tool/2022-05-14-blogging-with-quarto.html#application",
    "href": "posts/computer-tool/2022-05-14-blogging-with-quarto.html#application",
    "title": "Blogging with Quarto",
    "section": "Application",
    "text": "Application\n이제 Quarto를 이용해 기존 fastpages 기반 블로그를 대체해보자. 기존 블로그 포스팅은 어떻게 가져올 수 있을까? 포스팅의 양이 많지 않을 경우 반복 작업을 해도 되고, 필요하면 간단한 스크립트를 통해서 일괄해서 바꿀 수 있다.\n\nGithub 리포 생성\n깃헙 페이지스를 활용할 깃헙 리포를 생성하자. 그리고 이 녀석을 로컬로 클론해두면 준비가 끝난다. 아래의 사항을 주의하자.\n\n리포의 종류는 private이 아닌 public이어야 한다. 그래야 블로그가 서빙된다.\n깃헙 페이지스 기능을 활성화 해두자.\n\n\n\n블로그 페이지 생성\nQuarto - Creating a Blog\n먼저 전체적인 블로그의 구조를 생성해야 한다. 터미날에서 아래와 같이 입력하자.\n$ quarto create-project {YOUR-BLOG-DIR} --type website:blog\nYOUR-BLOG-DIR 은 앞서 지정한 깃허브 리포의 디렉토리에 해당한다. 생성하고자 하는 디렉토리 안에 있다면 생략해도 된다. 이 명령을 실행하면 해당 디렉토리에 블로그를 서비스하기 위해 필요한 파일들이 생성된다. /home/tmp/ 디렉토리 아래 블로그의 뼈대를 생성한다면 아래와 같이 실행된다.\n\n\n\n작업 순서상 깃허브와 연동된 리포를 먼저 만들고 그 디렉토리 안에 quarto 프로젝트를 생성하는 것이 자연스럽다.\n생성된 파일, 디렉토리 중에서 중요한 내용을 간단히 짚어보자.\n\n\n\nFile\nDesc\n\n\n\n\n_quarto.yml\n블로그 설정 yml\n\n\nindex.qmd\nindex.html 설정\n\n\nabout.qmd\nabout 페이지 내용\n\n\nposts/\n포스팅이 담길 디렉토리\n\n\nstyles.css\n개별 스타일 css\n\n\n\nposts 디렉토리에 .qmd 확장자를 지닌 포스팅 파일을 넣는다. 나머지 파일들에 관한 설명은 공식 문서에 잘 되어 있다.\n\n_quarto.yml은 기본 설정된 항목을 필요에 따라서 고쳐도 충분하다. 보다 많은 설정이 필요하다면 여기 내용을 참고하자.\n나머지 설정은 위 표에 링크된 내용을 참고하면 된다.\n\n\n\n렌더링\n\n페이지 준비와 설정이 잘 되었으면 렌더링을 하면 된다.\n\n$ quarto render \n$ quarto preview \nrender 명령어는 페이지를 렌더링하고 preview는 페이지를 미리 보여준다.\nVS Code의 Quarto extension을 쓰면 해당 과정을 편리하게 진행할 수 있다. VS 코드와 쓰면 좋은 이유가 하나 더 있다. 터미널에서 위 명령을 실행하면 페이지 전체를 전부 생성한다. VS 코드에서 쓰면 수정한 페이지의 내용만 골라서 생성한다.\n다시 강조한다. Quarto는 스태틱 웹에 기반한 도구다. 새로운 포스팅을 포함하여 새로운 변경 사항이 로컬에서 발생했다면, 이를 render한 후 이 녀석을 깃헙 리포에 동기화 해야 최종적으로 웹 블로그에 반영된다. 렌더링을 잊지 말자."
  },
  {
    "objectID": "posts/computer-tool/2022-05-14-blogging-with-quarto.html#customization",
    "href": "posts/computer-tool/2022-05-14-blogging-with-quarto.html#customization",
    "title": "Blogging with Quarto",
    "section": "Customization",
    "text": "Customization\n\nstyles.css\n앞서 언급했듯이 _quarto.yml에서 별도의 .css 파일을 설정할 수 있다. 취향에 따라서 원하는 만큼 커스터마이즈를 할 수 있다. 내 경우는 아래 두 가지 요소를 조정했다.\n\n한글의 경우 기본 폰트 이외 추가 폰트를 쓰고 싶을 때\n각 구성 요소별로 크기를 조정하고 싶을 때\n\n/* css styles */\n@import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css');\n@import url('https://cdn.rawgit.com/moonspam/NanumSquare/master/nanumsquare.css');\n@import url(\"https://cdn.jsdelivr.net/gh/wan2land/d2coding/d2coding-ligature-subset.css\");\n\nh1, h2, h3, h4, h5, h6 {\n    font-family: 'NanumSquare' !important;\n    font-weight : 600;\n  }\n\nh1 {\n    font-size: 155%\n}\n\nh2 {\n  font-size: 135%\n}\n\nh3 {\n  font-size: 115%\n}\n\nh4, h5, h6 {\n  font-size: 100%\n}\n\nul, li, ol{\n    font-family: 'pretendard' !important;\n    font-size: 100%;\n   }\n\np {\n    font-family: 'pretendard' !important;\n    font-size: 95%;\n    font-weight: 400; \n}\n\n.category {\n  font-size: 90%;\n}\n\n.sourceCode {\n  font-family: 'D2Coding', monospace !important;\n  font-size: 95%;\n}\n\n@import... | 폰트를 로딩한다. 이 블로그에는 프리텐다드, 나눔스퀘어, D3코딩 글꼴이 활용되었다.\n\n나머지는 디자인 관련 설정이다. 아주 간단한 css 설정으로 잘 보면 의미를 하는 데에는 큰 어려움이 없을 것이다.\n\n\n\n디렉토리 관리\nposts/ 내 별도의 디렉토리를 만들어 포스팅을 구별할 수도 있다. 다만, 포스팅 .qmd을 작성할 때 별도의 .html을 삽입했다면, 해당 .html을 각 디렉토리마다 넣어줘야 한다. 예를 들어 google analytics의 html을 포함시켰다면 해당 파일을 각 디렉토리 별로 넣어주자.\n\n\nQuarto의 기능은 생각보다 유연하고 다양하다. css나 js에 관한 지식이 부족해도 유용하게 활용할 다양한 기능을 갖추고 있다. 여기 소개된 그림 배치에 관한 기능이 한 사례인데, 홈페이지에 authoring 항목을 살펴보도록 하자.\n\n\n기타\n원본에서 조금 더 손 본 부분은 이 블로그의 깃헙 리포 anarinsk/lostineconomics_quarto에서 직접 확인하기를 바란다."
  },
  {
    "objectID": "posts/computer-tool/2022-05-10-how-to-make-cv.html",
    "href": "posts/computer-tool/2022-05-10-how-to-make-cv.html",
    "title": "How to make a manageable C.V.",
    "section": "",
    "text": "Markdown으로 관리 가능한 이력서를 빌드해보자."
  },
  {
    "objectID": "posts/computer-tool/2022-05-10-how-to-make-cv.html#tl-dr",
    "href": "posts/computer-tool/2022-05-10-how-to-make-cv.html#tl-dr",
    "title": "How to make a manageable C.V.",
    "section": "",
    "text": "Markdown으로 관리 가능한 이력서를 빌드해보자."
  },
  {
    "objectID": "posts/computer-tool/2022-05-10-how-to-make-cv.html#why",
    "href": "posts/computer-tool/2022-05-10-how-to-make-cv.html#why",
    "title": "How to make a manageable C.V.",
    "section": "Why?",
    "text": "Why?\n이력서를 만드는 방법은 다양하다. 정해진 포맷이 있다면 채워 넣으면 될 일이지만, 그렇지 않은 경우 여러가지 선택지를 고민하게 된다. 아카데미에 있는 분이라면 \\(\\rm \\LaTeX\\)으로 이력서를 만드는 데 익숙할 것이다. 요즘은 Notion(노션)으로도 꽤 근사한 이력서를 만들 수 있다.\n이력서 제작에 중요한 가치는 아마 아래의 세 가지가 아닐까 싶다.\n\n최적의 정보 전달\n시각적인 심미성\n관리의 편의\n\n일단 2는 제외하도록 하겠다. 미감이 부족한 나는 최소주의를 지향한다. 즉, 좋은 템플릿을 선택해서 텍스트를 잘 배치하는 정도를 고민하는 게 내게 최선이다. 템플릿을 따를 경우 1 역시 고민이 크게 줄어든다. 그렇다면 관심은 3에 집중된다."
  },
  {
    "objectID": "posts/computer-tool/2022-05-10-how-to-make-cv.html#도구-그것이-문제로다",
    "href": "posts/computer-tool/2022-05-10-how-to-make-cv.html#도구-그것이-문제로다",
    "title": "How to make a manageable C.V.",
    "section": "도구 그것이 문제로다",
    "text": "도구 그것이 문제로다\n\n노션은 왜 사랑 받을까?\n3의 문제를 조금 더 뜯어보자. 관리의 편의성은 두 개로 나눌 수 있다. 하나는 이력의 변경 및 수정을 쉽게 할 수 있는지, 즉 이력서 관리의 문제다. 다른 하나는 이렇게 만들어진 이력서를 잘 배포할 수 있는지에 관한 것이다.\n배포의 경우 과거에는 큰 문제가 없었다. PDF 등 일정한 포맷의 문서 파일이면 충분했다. 하지만 요즘은 많은 정보를 웹 또는 모바일 웹으로 접한다. 이에 부응하려면 html로 배포하는 것이 좋다. 첨부 파일이 아니라 html 이력서를 의도에 맞게 호스팅해주는 적절한 서비스가 있다면 더 좋을 것이다. 노션이 이력서 배포의 도구로 최근 각광받는 이유가 여기에 있다. 노션을 사용하면 WYSIWYM으로 다양한 형태의 편집을 지원하고 작성된 내용을 바로 웹으로 배포할 수 있다. 이 점에서 노션은 좋은 선택지다.\n\n\nWYSIWYM = What You See Is What You Mean, 즉 별도의 컴파일 없이 변화된 내용이 어떻게 구현되는지를 바로 볼 수 있는 형태의 소프트웨어 구현 방식을 지칭한다. 쉽게 워드, 아래아 한글을 생각하면 된다.\n\n\nPDF라면 \\(\\rm \\LaTeX\\)!\n정형화되고 디자인이 멋진 PDF 문서를 만들어 내는 데에는 \\(\\rm \\LaTeX\\)만한 것이 없다. 아카데미에서 주로 사용하는 도구로서 논문 이력 관리를 \\(\\rm Bib\\TeX\\)으로 하고 있다면 제법 편리하고 멋진 이력서를 얻을 수 있다. 다만 \\(\\rm \\LaTeX\\)은 진입 장벽이 꽤 높다. 일반적인 용도로 쓰기에는 버겁고 게다가 비효율적이다(느리다). 게다가 \\(\\rm \\LaTeX\\) 기반 문서로는 그럴 듯한 html 파일을 생성하기가 쉽지 않다.\n\n\nMarkdown은 어떨까?\nhtml, \\(\\rm \\LaTeX\\)과 같은 스크립트 도구와 노션과 같은 WYSIWYM의 장점을 적절하게 결합한 것이 markdown이다. 나는 거의 모든 문서를 마크다운으로 쓰고 있다. 아울러 마크다운의 .md 파일은 pandoc을 통해 다른 포맷(.tex, .html, .docx 등)으로 쉽게 변환된다. 이력서 역시 마크다운으로 직접 보면서 만든 후에 이를 html로 변환하고 이를 웹에서 호스팅할 수 있다면, 작성과 관리라는 두 장점을 모두 취할 수 있는 편리한 작업 흐름이 되지 않을까?\nmd가 html로 변환되기 때문에 html 및 css의 기술을 활용할 수 있다면 원하는 만큼 디자인을 손볼 수도 있다. 즉, 웹을 다루는 기술만 있다면 마크다운으로 충분한 수준의 커스터마이즈를 이뤄낼 수 있다. 물론 이 글은 그런 능력자를 위한 것이 아니다. 심미적 최소주의를 지향하면서 게으르게 만들어 낼 수 있는 그리고 관리 가능성을 최우선에 두는 이력서 제작이 이 포스팅의 목적이다."
  },
  {
    "objectID": "posts/computer-tool/2022-05-10-how-to-make-cv.html#tools",
    "href": "posts/computer-tool/2022-05-10-how-to-make-cv.html#tools",
    "title": "How to make a manageable C.V.",
    "section": "Tools",
    "text": "Tools\n우리의 목표는 마크다운을 통해 쓸 만한 이력서를 만들고 이 이력서를 웹에 호스팅해서 쉽게 접근할 수 있게 만드는 것이다. 이를 위해 아래 두 가지가 필요하다.\n\nmd를 편집할 수 있는 도구\ngithub\n\n편집 도구의 경우 각자에게 맞는 에디터를 쓰면 된다. 특별한 선호가 없다면 VS Code를 권한다. 마크다운의 경우 편리한 웹 에디터들도 많이 있다.\n\n\n대표적으로 https://stackedit.io/\n\nGithub\n깃허브(이하 깃헙)은 소스를 온라인으로 보관하고 이에 기반해 깃 기반의 (공동) 작업을 구현하는 서비스다. 깃헙에 붙여 있는 편리한 기능의 하나가 스태틱 웹을 배포해주는 것헙 페이지다. 쉽게 말해서 정적인 웹페이지를 호출한 사용자의 브라우저에 해당 페이지를 띄워주는 것이다. 주소 체계 역시 직관적이이서 이용하는 입장에서는 이 정도의 좋은 도구가 드물다. (게다가 무료!)\n깃헙의 html 배포 서비스를 이용하는 자세한 방법은 여기를 참고하자.\n간략하게 설명하면 이렇다. 리포의 루트에 index.html을 떨궈 놓고 깃헙 페이지를 활성화하면 특정 주소의 url을 호출받았을 때 이 index.html을 웹 브라우저에 띄워준다. 다만 이렇게 작업할 경우는 html까지 내가 만들어야 한다. md에서 html을 만드는 일이 어려운 작업은 아니지만 이 또한 귀찮고 약간의 거슬리는 점들이 있다.\n깃헙은 자체 블로그/웹페이지 툴로 jekyll을 활용하고 있다. 리포에 변경이 생겼을 때 github actions 라는 녀석이 작동해서 변화된 md 파일을 디자인 포맷에 맞게 html로 변경해 하당 파일을 호스팅할 수 있는 상태로 만든다. 이 jekyll을 활용하면 사용자는 그냥 md, 즉 내용만 고치고 html 변환부터 호스팅까지 모든 일을 깃헙이 맡는다."
  },
  {
    "objectID": "posts/computer-tool/2022-05-10-how-to-make-cv.html#a-walk-through",
    "href": "posts/computer-tool/2022-05-10-how-to-make-cv.html#a-walk-through",
    "title": "How to make a manageable C.V.",
    "section": "A Walk-through",
    "text": "A Walk-through\n\nFork\n나는 아래 링크의 리포를 참고했다. 일단 해당 리포를 나의 리포로 포크하도록 하자. 이 리포에 설명이 잘 되어 있어서 대부분은 생략해도 되겠다. 시작할 때 깃헙 페이지의 브랜치를 master로 바꾸는 것을 잊지 말자. 디폴트 상태에서는 gh-pages라는 브랜치의 내용, 즉 아래 리포의 README.md가 웹으로 호스팅된다.\nelipapa/markdown-cv\n문서는 깔끔하게 잘 되어 있다. html의 빌드는 깃헙 액션스를 이용해도 되고, 로컬에 Jekyll을 깔아서 해도 된다. 게으름을 지향하는 나는 당연히 깃헙 액션스를 선호한다!\n\n\nCustomization\n문서의 디렉토리에서 바뀌야 할 것을 살펴보자.\n\n_config.yml\nindex.md\n_layout/cv.html\nmedia/\n\n\n_config.yml\nmarkdown: kramdown\nstyle: davewhipp\n손 댈 것이 많지는 않다.\n\nstyle | 이력서의 디자인 형식을 나타는 일종의 접두어다.\n\nstyle 항목은 media 내에 있는 css 파일의 접두 단위를 지정하면 된다. 위 리포의 경우 davewhipp, jkhealy 두 개가 들어 있다. css를 잘 다룰 수 있다면 필요에 따라서 커스터마이즈를 하면 된다.\n\n\n\n\nindex.md\n이력서의 내용이 들어간 파일이다. 무려 아이작 뉴턴의 이력이 작성되어 있으니 이를 참고해서 적절하게 작성하면 된다. 건드리지 말아야 할 것은 헤더이다.\n---\nlayout: cv\ntitle: Junsok Huhh's CV\n---\n\nlayout | 그대로 두자.\ntitle | 문서의 타이틀이 아니라 브라우저의 제목에 표시되는 이름이다. 적절하게 바꾸면 된다.\n\n\n\n_layout/cv.html\n이 파일은 이력서 html 파일을 생성할 때 바탕이 되는 일종의 템플릿이다. index.md 파일의 내용이 html 안에 들어간다고 보면 된다. html을 커스터마이즈하고 싶다면 해당 파일의 &lt;head&gt;...&lt;/head&gt; 태그 사이에 필요한 내용을 넣어야 한다.\n&lt;link  href=\"media/styles.css\"  type=\"text/css\"  rel=\"stylesheet\"  media=\"screen\"&gt;\n&lt;link  href=\"media/styles.css\"  type=\"text/css\"  rel=\"stylesheet\"  media=\"print\"&gt;\n\n&lt;!-- mathjax --&gt;\n&lt;script  type=\"text/x-mathjax-config\"&gt;\nMathJax.Hub.Config({\ntex2jax: {\ninlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\nprocessEscapes: true\n}\n});\n&lt;/script&gt;\n&lt;script  type=\"text/javascript\"  async\nsrc=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML\"&gt;&lt;/script&gt;\n\n&lt;link... | 이 두 줄은 커스텀 디자인을 담고 있는 특화된 css 파일을 삽입하기 위한 용도이다. 해당 파일의 이름은 styles.css이다.\n&lt;!-- mathjax... | 원래 리포에 \\(\\rm \\LaTeX\\) 기호 출력을 위한 준비가 되어 있지 않다. mathjax는 자바 스크립트(js)로 웹에서 \\(\\rm \\LaTeX\\) 출력 관련을 담당한다. math engine으로 mathjax 이외에 katex과 같이 더 빠른 js를 쓸 수 있지만, 이력서에서 텍을 과도하게 쓸 이유가 없다면 mathjax로 충분하다.\n\n\n\nmedia/\n이 디렉토리에는 일종의 디자인 설정이 들어 있다. 스타일 두 개가 각각 screen, print의 css 파일을 갖고 있다. 자신의 원하는 특화된 설정이 필요하면 별도의 파일을 만들고 이를 앞서 본 cv.html에서 읽어오면 된다. 내가 사용하는 styles.css의 내용 중에서 중요한 내용 몇 가지만 보고 가자.\n/* css styles */\n\n/* @import url('https://fonts.googleapis.com/css2?family=Nanum+Gothic&display=swap'); */\n@import  url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css');\n@import  url('https://cdn.rawgit.com/moonspam/NanumSquare/master/nanumsquare.css');\n@import  url(\"https://cdn.jsdelivr.net/gh/wan2land/d2coding/d2coding-ligature-subset.css\");\n\nh1, h2, h3, h4, h5, h6 {\n    font-family: 'NanumSquare'  !important;\n    font-weight : 600;\n}\n\nh1 {\n    font-size: 180%;\n}\n\nul, li, ol, a{\n    font-family: 'pretendard'  !important;\n    font-size:95%;\n}\n\np {\n    font-family: 'pretendard'  !important;\n    font-size: 100%;\n    font-weight: 400;\n}\n\n@import | 한글 폰트를 로딩 하는 과정이다. 기본 폰트 외에 특화된 한글 글꼴을 쓰기 위해서는 별도의 로딩이 필요하다. 여기서는 제목으로는 ’나눔스퀘어’를 본문으로는 ’프리텐다드’를 사용했다. 로딩은 CDN을 활용하는데, 약간의 시간이 필요하지만 활용에 지장을 줄 정도는 아니다.\n나머지 부분은 각 성분의 폰트와 크기 등을 필요에 맞게 적절하게 조정한 부분이다.\n\n\n\n\nPush, build and deploy\n\n이렇게 해당 부분을 필요에 따라서 수정한 후 깃헙으로 푸시 하면 깃헙 액션스가 html을 빌드하고 해당 문서를 깃헙 페이지로 배포한다. 배포 주소는 {깃헙아이디}.github.io/{깃헙리포}/"
  },
  {
    "objectID": "posts/computer-tool/2022-05-10-how-to-make-cv.html#bottomline",
    "href": "posts/computer-tool/2022-05-10-how-to-make-cv.html#bottomline",
    "title": "How to make a manageable C.V.",
    "section": "Bottomline",
    "text": "Bottomline\n이렇게 만들어진 내 게으른 결과물은 아래와 같다.\n\n소스 | anarinsk/markdown-cv\n배포된 CV | Junsok Huhh’s CV"
  },
  {
    "objectID": "posts/computer-tool/2023-08-15-julia-quicksilver.html",
    "href": "posts/computer-tool/2023-08-15-julia-quicksilver.html",
    "title": "Julia + VS Code",
    "section": "",
    "text": "Julia를 빠르게 세팅하는 방법 (Windows/Macos)"
  },
  {
    "objectID": "posts/computer-tool/2023-08-15-julia-quicksilver.html#tl-dr",
    "href": "posts/computer-tool/2023-08-15-julia-quicksilver.html#tl-dr",
    "title": "Julia + VS Code",
    "section": "",
    "text": "Julia를 빠르게 세팅하는 방법 (Windows/Macos)"
  },
  {
    "objectID": "posts/computer-tool/2023-08-15-julia-quicksilver.html#넋두리",
    "href": "posts/computer-tool/2023-08-15-julia-quicksilver.html#넋두리",
    "title": "Julia + VS Code",
    "section": "넋두리",
    "text": "넋두리\n생성 AI 덕분에 프로그래밍 언어가 필요없어진 시대라지만 이럴 수록 취미 삼아(?) 프로그래밍 언어를 배우기 좋은 시절이 아닐까? 평소 가장 뛰어난 high-level 컴퓨터 언어라고 생각해온 Julia를 윈도와 Macos에서 빠르게 설치하고, VS Code에서 Jupyter를 통해 활용하고, 줄리아의 편리한 패키지 관리 방법을 간단히 소개한다.\n역시 이 포스팅은 이 내용을 곧 망각할 멀지 않은 미래의 ’나 놈’을 위한 것이다!"
  },
  {
    "objectID": "posts/computer-tool/2023-08-15-julia-quicksilver.html#설치",
    "href": "posts/computer-tool/2023-08-15-julia-quicksilver.html#설치",
    "title": "Julia + VS Code",
    "section": "설치",
    "text": "설치\n설치는 아래 공식 사이트에서 OS별로 다운로드 받아서 설치하면 된다.\nhttps://julialang.org/\n조금 특이하게 하고 싶다면, 윈도의 경우는 winget을 맥의 경우에는 brew를 쓰면 되겠다.\n&gt; winget install --id=Julialang.Julia  -e # For Windows PowerShell\n&gt; brew install julia # For Macos \n\n\n특이하긴 하지만 이 방법을 권한다. winget이든 brew든 OS 별로 앱을 일관된 방식으로 활용하고 관리할 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2023-08-15-julia-quicksilver.html#repl-설정",
    "href": "posts/computer-tool/2023-08-15-julia-quicksilver.html#repl-설정",
    "title": "Julia + VS Code",
    "section": "REPL 설정",
    "text": "REPL 설정\nREPL이란 Read-Evaluate-Print Loop를 의미한다. 인간이 입력한 내용을 기계가 읽고 처리하고 이를 인쇄하는 한번의 순환을 의미하는데, 그냥 프로그래밍 언어와 인간이 소통하기 위한 터미널 형태의 인터페이스라고 퉁치고 넘어가자.\nMacos에서는 별다른 작업 없이 설치 후 터미널 리부팅 후 바로 사용할 수 있다.\n\nFor Windows\n윈도에서는 앱 설치 후 파워셸 등의 터미널에서 자동으로 인식이 되지 않는다. 범용 앱의 경우 대체로 별도의 전용 REPL을 제공하고 있지만 터미널 안에서 함께 쓰는 게 여러모로 편하다. 이를 구현하기 위해서 Julia 실행 파일의 경로를 지정해주면 된다.\n\n\nJulia를 포함해 git 등의 범용 앱이 호환성을 위해서 별도의 터미널 앱을 제공한다. 사용자가 어떤 환경에서 쓸지 모르기 때문에 제공하는 편이물인 셈이다. 윈도우11+윈도터미널의 환경이라면 그냥 함께 쓰는 것이 제일 편하다. 이 경우 해당 앱의 실행 파일의 위치를 경로로 잡아주면 터미널 내에서 쉽게 쓸 수 있다. 경로로 잡는다는 것은 해당 실행 파일의 실행이 터미널에서 이루어질 수 있도록 만드는 조치로 이해하면 되겠다.\n그런데 줄리아 설치시 실행 파일의 경로에 버전이 따라 붙는다. 버전이 바뀔 때마다 경로(path)를 다시 지정해주어야 하는 불편함이 있다.\n경로 설정이 익숙하지 않다면, 여기를 참고하여 julia 관련 실행 파일이 담긴 폴더의 주소를 경로로 지정하면 된다. 이후 셸을 리부팅하면 기본 셸에서 사용할 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2023-08-15-julia-quicksilver.html#vs-code",
    "href": "posts/computer-tool/2023-08-15-julia-quicksilver.html#vs-code",
    "title": "Julia + VS Code",
    "section": "VS Code",
    "text": "VS Code\nVS Code는 줄리아용 익스텐션을 제공하고 있다. 다만 이 익스텐션 대신 익숙한 Jupyter를 쓸 수도 있다. 사실 Jupyter가 더 편하다. Jupyter를 쓸 때는 실행 커널로 Julia를 선택하면 끝이다.\n\nOS 문제\nVS Code에서 줄리아를 쓸 때 한 가지 큰 단점이 있다. OS별로 경로 설정을 구분해서 지정할 수 없다. VS Code에서 줄리아 커널을 인식시키기 위해서는 줄리아 실행 파일의 경로 지정이 필요한데, 이 경로가 당연히 OS 별로 다르다.\nVS Code의 환경을 동기화해 놓고 윈도우와 맥OS를 번갈아 가며 쓴다면, OS를 바꿀 때마다 줄리아의 실행 경로를 찾지 못했다는 메시지를 보게 될 것이다. OS를 변경할 때마다 매번 경로를 지정해야 하는 불편을 감수해야 할까?\n\n\n역시 익스텐션으로 해결하자\n다행히 플랫폼 별 설정 관리를 제어하는 VS Code 확장이 있다. 이 녀석을 부리도록 하자. VS Code의 정식 기능으로 넣어도 좋을 듯 싶다.\nVS Code Extensions: Platform Settings\n해당 패키지를 설치하고, settings.json을 수정하면 된다. 아래의 내용을 넣어주자.\n\n\nsettings.json을 어떻게 띄워야 할지 모르겠다면 다음과 같이 해보자. 왼쪽 하단의 톱니 클릭 → 설정 → 찾기 창에 “julia” 아래 적당한 항목에서 settings.json애서 편집 선택\n\"platformSettings.platforms\": {\n  \"win32\": {\n    \"julia.executablePath\": \"C:/Users/사용자-계정-이름/AppData/Local/Programs/Julia-1.9.2/bin/julia.exe\"\n  },\n  \"darwin\": {\n    \"julia.executablePath\": \"/opt/homebrew/bin/julia\"\n  }\n\n위 코드에서 구체적인 경로를 각자의 환경에 맞게 바꿔야 한다."
  },
  {
    "objectID": "posts/computer-tool/2023-08-15-julia-quicksilver.html#julia의-패키지-관리",
    "href": "posts/computer-tool/2023-08-15-julia-quicksilver.html#julia의-패키지-관리",
    "title": "Julia + VS Code",
    "section": "Julia의 패키지 관리",
    "text": "Julia의 패키지 관리\n줄리아의 패키지 관리는 정말 간단하다. Python의 다양하고 혼란스러운 방법과 비교하면, 간단해서 당황스러울 정도이다.\n전체적인 패키지 운용 방식은 최근 각광받은 Python의 Poetry 그리고 이 블로그에서 소개한 Rye와 유사하다. 다만 실행을 위한 버전 별 바이너리와 버전 별 패키지를 각 프로젝트 별로 따로 설치하지 않는다는 점에서 파이썬 가상 환경에 비해 낭비가 덜한 형태이다.\n\n프로젝트 개시\nhttps://pkgdocs.julialang.org/v1/environments/\nREPL 창에서 ]을 입력하면 패키지(Pkg) REPL로 진입한다. 줄리아는 자체적인 인터페이스를 통해 별도로 패키지 관리할 수 있다. 만일 다시 줄리아 REPL로 가고 싶으면 백스페이스를 누르자.\n\n\n줄리아 REPL 안에서도 명령을 통해서도 패키지를 관리할 수 있다. 다만, 별도의 Pkg REPL에서 관리하는 게 편한 경우가 있으니 적극적으로 활용하도록 하자.\nPkg REPL에서 여러가지를 할 수 있지만 여기서는 프로젝트를 시작하는 방법 정도만 알아보자. 아래 보는 것은 tutorial이라는 이름의 프로젝트 개시를 예시한 것이다. 해당 폴더가 하위 폴더에 있다면 그 안에 프로젝트가 생성된다.\n(@v1.8) pkg&gt; activate tutorial\n  [ Info: activating new environment at `~/tutorial/Project.toml`.\n최초로 패키지 모드에 진입하면 위와 유사한 터미널 창을 보게 된다. (@v1.8) 현재 Pkg REPL이 바라보고 있는 환경을 의미한다. 이는 디폴트 환경으로 해당 환경은 \\Users\\{PC-아이디}\\.julia\\ 혹은 이와 유사한 줄리아 디폴트 공유 환경을 바라보게 된다.\nJulia REPL에서 해당 폴더로 이동하고 싶다면,\njulia&gt; cd(\"C:\\\\가고싶은-폴더\") # 윈도우에서 \njulia&gt; cd(\"C:\\가고싶은-폴더\") # Macos, Ubuntu \n해당 폴더 안에서 환경을 액티베이트하고 싶다면,\n(@v1.8) pkg&gt; activate .\nActivating project at `D:\\GitHub\\{프로젝트-폴더}`\n(프로젝트-폴더) pkg&gt; st\nStatus `C:\\프로젝트-폴더\\Project.toml`\n...\n위에 보는 것처럼 줄리아가 프로젝트-폴더를 환경으로 바라보고 있다는 점을 잘 알 수 있다. 프로젝트의 개시와 함께 해당 폴더에 Manifest.toml, Project.toml이 생성된다. 두 파일에 용도에 대해서는 상세하게 다루지는 않겠다. Manifest.toml는 해당 폴더의 프로젝트를 진행하기 위한 패키지의 세목(버전, 의존성 등)이 담겨 있다. Project.toml은 프로젝트의 메타 데이터를 담고 있다. 자세한 내용은 아래 링크를 참고하자.\nhttps://pkgdocs.julialang.org/v1/toml-files/\n\n\n가져온 환경 활성화\n내가 생성한 환경 뿐 아니라 다른 사람이 만들어둔 환경을 가져와서 해당 환경과 동일한 환경을 구축할 수 있다. 상세한 내용은 아래 링크를 참고하자. 특히 다른 실행 환경을 가져와 그대로 재현할 수 있는 대목은 Julia 가상 환경의 큰 장점 중 하나이다.\nhttps://pkgdocs.julialang.org/v1/environments/\n가져온 환경을 어떻게 활성화하는지 간락하게 알아보자. 먼저 필요한 환경을 가져온다.\nshell&gt; git clone https://github.com/JuliaLang/Example.jl.git\nCloning into 'Example.jl'...\n줄리아 패키지 모드에서 해당 환경을 활성화하자. 해당 폴더에 들어가서 활성화하면 편하다.\n(@v1.8) pkg&gt; activate .\nActivating project at `~/Example.jl`\n다음으로 패키지 모드에서 환경을 활성화한다.\n(Example) pkg&gt; instantiate\n  No Changes to `~/Example.jl/Project.toml`\n  No Changes to `~/Example.jl/Manifest.toml`\n\n\ngithub를 통해 .gitignore를 설정하면 manifest.toml이 제외되도록 설정되어 있다. 따라서 일반적으로 github의 리포를 클론해왔다면 별도의 패키지 설치 과정을 거쳐야 할 수 있다. 패키지 REPL에서 add 명령어를 활용하면 된다.\n\n\n환경 관련 패키지 제거\n먼저 project.toml을 열어보자. 아래 예시는 Example이라는 환경에 ThinkJulia라는 패키지 셋을 설치한 상황을 가정한 것이다. 패키지 설치 방법은 아래와 같다.\n\n\n이 패키지는 “Think Julia” 책을 위해 제작된 패키지다. 자세한 것은 여기를 참고하라.\n(Example) pkg&gt; add https://github.com/BenLauwens/ThinkJulia.jl\n이제 패키지 설치가 끝난 이후 Project.toml을 열어보면 아래와 같다.\nname = \"Example\"\nuuid = \"7876af07-****-****-ab0e-********\"\nversion = \"0.5.4\"\n\n[deps]\nThinkJulia = \"a7f2b756-****-4c7f-****-*********\"\n\n[compat]\njulia = \"1\"\n\n[extras]\nTest = \"*******-e22c-****-****-65c5234f0b40\"\n\n[targets]\ntest = [\"Test\"]\n[deps] 항목에 환경이 의존하는 패키지 ThinkJulia가 기록되어 있다.\n(Example) pkg&gt; rm ThinkJulia\n위 명령을 통해 환경과 관련된 항목들이 제거된다. 가끔 gc 명령의 실행이 필요할 수 있다. REPL에 출력된 내용을 참고하자. 제거한 후 Project.toml을 확인해보면 [deps] 항목이 제거되었음을 알 수 있다. 이렇듯 Project.toml과 Manifest.toml은 환경에 발생하는 패키지 및 바이너리의 변화를 알아서 기록하고 추적한다. 이 얼마나 편리한가!"
  },
  {
    "objectID": "posts/computer-tool/2023-05-11-powershell.html",
    "href": "posts/computer-tool/2023-05-11-powershell.html",
    "title": "Power to Powershell!",
    "section": "",
    "text": "파워셸의 힘으로 윈도11을 폼나게 써보자.\n\n\n\n\n파워셸 이용법\n윈도11 설치하기\n\n\n\n\n\n파워셸을 이용해 주요 소프트웨어 설치\nconda, ohmyposh 설정하기"
  },
  {
    "objectID": "posts/computer-tool/2023-05-11-powershell.html#tl-dr",
    "href": "posts/computer-tool/2023-05-11-powershell.html#tl-dr",
    "title": "Power to Powershell!",
    "section": "",
    "text": "파워셸의 힘으로 윈도11을 폼나게 써보자.\n\n\n\n\n파워셸 이용법\n윈도11 설치하기\n\n\n\n\n\n파워셸을 이용해 주요 소프트웨어 설치\nconda, ohmyposh 설정하기"
  },
  {
    "objectID": "posts/computer-tool/2023-05-11-powershell.html#powershell을-써야-하는-이유",
    "href": "posts/computer-tool/2023-05-11-powershell.html#powershell을-써야-하는-이유",
    "title": "Power to Powershell!",
    "section": "Powershell을 써야 하는 이유",
    "text": "Powershell을 써야 하는 이유\n파워셸(이하 PS)은 원래 윈도의 CLI 도구였으나, 현재는 OS에 상관 없이 범용으로 활용할 수 있는 형태로 진화했다. PS를 반드시 써야만 하는 것은 아니지만, 적어도 윈도를 쓴다면 피할 이유도 없다. 윈도11부터 MS에서 “앱 설치 관리자”라는 녀석을 제공하는데, 이 녀석을 쓰면 macos의 brew, Ubuntu의 apt와 같은 스타일로 winget을 통해 셸을 통해 패키지 관리를 할 수 있다. 다소 아쉬운 대목이 있지만 윈도의 거의 모든 프로그램을 winget을 통해 관리하면 꽤 편리하다. 윈도에서 셸을 쓰게 된다면, PS를 한번 써보면 어떨까?\n\n\n이 글은 어쩌다가 윈도11을 다시 깔게 된 나 놈을 위해 남기는 글이다. 훗날 현재 과정을 기억하지 못하게 될 것이기 때문에…"
  },
  {
    "objectID": "posts/computer-tool/2023-05-11-powershell.html#install",
    "href": "posts/computer-tool/2023-05-11-powershell.html#install",
    "title": "Power to Powershell!",
    "section": "Install",
    "text": "Install\n\nPrelim\n윈도11을 갓 설치했다고 하자. 여기에는 “Windows Powershell”이 설치되어 있다. 이 녀석을 계속 쓰지는 않을 것이다. 우선 아래의 두 개 도구를 확인하도록 하자. 설치하는 방법은 구글링을 하면 되겠다.\n\nWindows Terminal: “명령 프롬프트” 대신 쓸 터미널 앱\n“앱 설치 관리자”: winget 활성화\n\n둘 모두 MS Store에서 찾아 설치하면 된다. 이왕이면 기본 터미널 앱 자체를 “명령 프롬프트”에서 이 녀석으로 바꾸도록 하자.\n\n\n설치\n이제 터미널로 들어가서 “명령 프롬프트” 혹은 “Windows Powershell” 둘 중 하나에서 파워셸을 깔아보자.\n&gt; winget install --id=Microsoft.PowerShell  -e\n\n\nPost-job\n설치가 완료된 이후 “설정” 항목에서 몇 가지 후처리를 하면 좋다.\n\n기본 프로필을 “Windows Powershell”에서 “Powershell”로 바꾸자.\n최신 버전에서는 “관리자 권한 실행” 옵션이 있다. 이 녀석도 켜도록 하자.\n“모양” 항목을 찾아서 몇 가지 폰트 설정을 해줘야 한다. 폰트 선택은 취향을 따르면 된다. 내가 쓰는 폰트는 아래와 같다.\n\nHack Nerd, D2Coding Nerd"
  },
  {
    "objectID": "posts/computer-tool/2023-05-11-powershell.html#install-apps",
    "href": "posts/computer-tool/2023-05-11-powershell.html#install-apps",
    "title": "Power to Powershell!",
    "section": "Install Apps",
    "text": "Install Apps\n이제 필요한 앱들을 명령을 통해 설치하면 된다. json을 만들어서 일괄 설치할 수도 있지만 문제가 생기면 대응이 필요하니 필요한 앱을 일단 하나씩 까는 것도 괜찮다. 아래는 내가 쓰는 앱들이다.\nwinget install --id=Microsoft.PowerToys  -e\nwinget install --id=Git.Git  -e\nwinget install --id=GitHub.GitHubDesktop  -e\nwinget install --id=Anaconda.Miniconda3  -e\nwinget install --id=JanDeDobbeleer.OhMyPosh  -e\nwinget install --id=Microsoft.VisualStudioCode  -e\nwinget install --id=Obsidian.Obsidian  -e\nwinget install --id=Posit.Quarto  -e\n금새 눈치 챘겠지만 install 명령어 뒤에 해당 앱의 id를 넣어 주는 식으로 구성되어 있다. 내게 필요한 앱이 winget을 통한 설치 경로를 제공하는지 알고 싶다면 여기를 방문해서 검색하면 된다.\n설치 파일을 다운받아서 깔았던 거의 대부분의 앱들을 winget을 통해 설치할 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2023-05-11-powershell.html#conda-설정",
    "href": "posts/computer-tool/2023-05-11-powershell.html#conda-설정",
    "title": "Power to Powershell!",
    "section": "Conda 설정",
    "text": "Conda 설정\n다른 것들은 설치 이후에 대체로 쓰던대로 쓰면 된다. 별도의 언급이 필요한 두 개가 miniconda와 OhMyPosh이다. 하나씩 살펴보자. 이왕 터미널을 쓸 바에야 anaconda 대신 miniconda3를 쓰는 것이 낫다. 아래에서는 미니콘다를 콘다로 부르도록 하자.\n콘다를 설치한 이후 초기화가 필요하다. 설치 이후 터미널을 재시작하고 아래와 같이 입력한다.\n&gt; conda init powershell\n\n\n이 부분은 여기를 참고했다.\n콘다가 터미널의 종류 별로 필요한 설정을 생성한다. 화면에 표시되는 정보 중에서 아래 두 줄이 개인 프로필 관련 설정이 담김 폴더이다. 해당 폴더가 제대로 설정되어 있는지 확인하려면 아래를 실행하자.\n&gt; test-path $profile\n여기서 false가 뜬다면 프로필을 로드하는 경로에 문제가 생긴 것이다. conda init powershell을 다시 실행해보자. 자세히 보면(아마도 맨 끝에 두 개), .PS1을 로드하는 경로 중에 깨진 것이 존재할 것이다. 이 경우 $profle을 로드하는 경로를 강제로 설정해줘야 한다. 이 문제 해결은 옆의 link의 내용을 참고하면 된다. $profile의 경로를 강제로 설정한 후 conda init powershell을 다시 실행하자. 만일 경로에 문제가 없다면 PS로 돌아와서 가상 환경이 잘 설정되어 있는지 확인하면 된다.\n\n\n해당 위치에 프로필 파일이 여러 개 있어도 된다. 파일 이름이 달라도 .ps1 확장자를 지닐 경우 PS로드 시 읽어온다. conda init powershell로 설정한 프로필 파일은 profile.ps1으로 저장된다. 파일을 노트패드 등으로 열어보자. conda 관련 설정 스크립트가 들어 있다. 만일 여전히 가상환경이 잘 보이지 않는다면 profile.ps1의 내용이 제대로 로드되지 않은 것이다. conda init은 셸 별로 필요한 스크립트를 생성하는 과정이다. 내용을 참고해서 적절한 조치를 취해주면 된다. conda 설치 자체에 문제가 있는 것은 아니다."
  },
  {
    "objectID": "posts/computer-tool/2023-05-11-powershell.html#oh-my-posh-설정",
    "href": "posts/computer-tool/2023-05-11-powershell.html#oh-my-posh-설정",
    "title": "Power to Powershell!",
    "section": "Oh-my-posh 설정",
    "text": "Oh-my-posh 설정\nHome | Oh My Posh\nwinget으로 설치한 이후 필요한 테마를 테스트하면 된다.\noh-my-posh init pwsh --config \"$env:POSH_THEMES_PATH/jandedobbeleer.omp.json\" | Invoke-Expression\n테마가 잘 먹는지 일단 확인해볼 수 있다. 원하는 테마를 항상 띄우려면 프로필을 하나 생성해주면 된다.\n&gt; notepad $profile\n파일이 없으면 생성된다. 여기에 필요한 테마를 올려주면 된다. 예를 들어 나는 “powerlevel10k_modern” 테마를 좋아한다. 그러면 해당 프로필 파일에 아래와 같이 넣으면 된다.\n&gt; oh-my-posh init pwsh --config \"$env:POSH_THEMES_PATH/powerlevel10k_modern.omp.json\" | Invoke-Expression\n만일 $env:POSH_THEMES_PATH를 쓰지 않고 특정한 디렉토리의 설정 json 파일을 가져오고 싶다면, 해당 디렉토리를 직접 지정하면 된다.\n\n업데이트 시 테마가 초기화되는 문제\n$env:POSH_THEMES_PATH의 위치에 따라서 업데이트 시 테마까지 함께 업데이트가 된다. 만일 해당 테마의 json 파일을 바꾸었다면 업데이트가 되면서 초기화된다. 어차피 테마 파일의 위치는 자유롭게 바꿀 수 있으니까 자신이 커스텀한 테마 파일의 위치를 바꾸고 녀석을 로드하면 된다.\n\n\nPython 가상 환경이 안보이는 경우\n테마에서 conda, python의 가상 환경이 안보일 때가 있다. 테마에서 python을 표현하는 부분에 이 부분이 빠져 있어서 그렇다. 해당 테마의 json 파일에서 python이 표시되는 분을 찾는다. 적당한 부분에 아래 코드를 넣자.\n\"properties\": {\n    \"fetch_virtual_env\": true,\n    \"display_mode\": \"environment\",\n    \"home_enabled\": true\n  },\n  \"template\": \"\\ue235 {{ if .Error }}{{ .Error }}{{ else }}{{ if .Venv }}{{ .Venv }} {{ end }}{{ .Full }}{{ end }}\",\n  \"trailing_diamond\": \"\\ue0b4 \",\n  \"type\": \"python\"\nproperties가 중요한 부분이고 나머지 템플릿은 적당히 바꾸면 된다."
  },
  {
    "objectID": "posts/computer-tool/2023-05-11-powershell.html#사후-관리",
    "href": "posts/computer-tool/2023-05-11-powershell.html#사후-관리",
    "title": "Power to Powershell!",
    "section": "사후 관리",
    "text": "사후 관리\nwinget으로 설치한 패키지를 업데이트하고 싶다면\n&gt; winget update --all # or\n&gt; winget update --all --include-unknown\n이렇게 하면 알아서 업데이트가 진행된다."
  },
  {
    "objectID": "posts/computer-tool/2023-05-29-rye.html",
    "href": "posts/computer-tool/2023-05-29-rye.html",
    "title": "Rye",
    "section": "",
    "text": "Rye를 이용해 편리하게 가상 환경을 구축해보자."
  },
  {
    "objectID": "posts/computer-tool/2023-05-29-rye.html#tl-dr",
    "href": "posts/computer-tool/2023-05-29-rye.html#tl-dr",
    "title": "Rye",
    "section": "",
    "text": "Rye를 이용해 편리하게 가상 환경을 구축해보자."
  },
  {
    "objectID": "posts/computer-tool/2023-05-29-rye.html#어딘가-부족한-python-가상-환경",
    "href": "posts/computer-tool/2023-05-29-rye.html#어딘가-부족한-python-가상-환경",
    "title": "Rye",
    "section": "어딘가 부족한 Python 가상 환경",
    "text": "어딘가 부족한 Python 가상 환경\n파이썬 용 가상 환경은 어딘가 하나씩 아쉽다. Venv, virtualenv, conda 등 다양한 선택지가 있지만 생각 없이 두루 쓸 수 있는 툴이 없다. 그나마 conda를 쓰고는 있으나 패키지 의존성 관리 등의 대목이 모자란다. 이상적인 파이썬 가상 환경이 갖추어야 하는 주요 기능은 두 가지다.\n\n파이썬 버전 관리\n패키지 의존성 및 버전 관리\n\n파이썬 버전을 관리하는 pyenv와 패키지 의존성을 관리하는 poetry를 함께 부릴 수도 있다. 다만 이 녀석들을 별도로 다루는 게 그리 직관적이지 않고 활용할 수 있는 OS에도 제약이 존재한다. conda 정도의 편리함과 범용성을 지니는 Python 가상 환경은 없을까?\nRye는 파이썬 버전 관리에서 패키지 설치의 의존성 관리까지 필요한 내용을 손쉽게 지원한다. 아울러 프로젝트와 가상 환경이 함께 따라 다니기 때문에 환경 자체를 별도로 관리해야 하는 conda 보다 관리가 수월하다. 유일한 단점이라면 프로젝트가 극히 초기라는 것인데, 이 정도의 사용성이라면 빠르게 자리를 잡지 않을까 기대해본다.\nhttps://rye-up.com\n\n\n여기 내용을 참고하자. 링크 글에서 보듯이 conda를 쓰면 환경이 쉽게 꼬인다. 그리고 이 상태가 되면 수습이 쉽지 않다."
  },
  {
    "objectID": "posts/computer-tool/2023-05-29-rye.html#설치-및-앱-관리",
    "href": "posts/computer-tool/2023-05-29-rye.html#설치-및-앱-관리",
    "title": "Rye",
    "section": "설치 및 앱 관리",
    "text": "설치 및 앱 관리\nOS에 맞게 Rye를 설치해주자. 윈도의 경우는 winget을 통한 설치는 불가능하다.Macos에서는 공식 가이드에는 없지만 brew로 설치할 수 있다.\n\n\n설치 항목을 참고하자.\nRye 앱 자체에 관한 업데이트와 삭제는 아래와 같다.\n&gt; rye self update # Rye 업데이트 \n&gt; rye self uninstall # Rye 삭제"
  },
  {
    "objectID": "posts/computer-tool/2023-05-29-rye.html#프로젝트-개시-및-패키지-설치",
    "href": "posts/computer-tool/2023-05-29-rye.html#프로젝트-개시-및-패키지-설치",
    "title": "Rye",
    "section": "프로젝트 개시 및 패키지 설치",
    "text": "프로젝트 개시 및 패키지 설치\n프로젝트를 생성할 상위 폴더에서 아래와 같이 생성 명령어를 실행한다.\n&gt; rye init {프로젝트-이름}\n만일 이미 폴더가 만들어져 있다면 해당 폴더 안에서 rye init을 실행하면 된다. 이제 프로젝트의 폴더에 들어가서 설치하려는 패키지를 add하고 sync로 이를 설치한다. ipykernel 패키지는 VS Code 등에서 .ipynb 파일을 불러와 작업하고자 할 때 필요한 패키지다. 이 패키지를 깔지 않으면 ipynb 파일 작업시 커널이 선택되지 않는다.\nipykernel과 pandas를 아래와 같이 설치해보자.\n&gt; rye add ipykernel pandas \n&gt; rye sync \n필요한 패키지가 있다면 rye add...↔︎rye sync 사이클로 설치하면 된다.\n가상 환경의 개별 설정은 pyproject.toml 파일을 통해서 관리된다. 만일 github 등을 통해서 pyproject.toml을 임포트했다면 rye sync로 필요한 패키지를 한방에 설치할 수 있다.\n\n\n버전 관리 등의 자세한 내용은 공식 문서를 참고하자.\n\n패키지 의존성 관리\n패키지 의존성 관리의 좋은 예를 소개한다. pytorch의 cuda 버전이 필요하다고 가정하자. Rye의 디폴트 패키지 리포에는 해당 버전이 없다. 따라서 해당 whl을 끌고 오기 위해서는 별도의 저장소를 저장해줘야 한다. 파이토치 홈페이지에 따르면 cuda 버전의 설치 방법은 다음과 같다.\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n--index-url https://download.pytorch.org/whl/cu118에 해당하는 부분을 Rye에서 별도로 설정할 수 있다. 자세한 내용은 여기를 확인하도록 하자."
  },
  {
    "objectID": "posts/computer-tool/2023-05-29-rye.html#vs-code에서-.ipynb-작업하기",
    "href": "posts/computer-tool/2023-05-29-rye.html#vs-code에서-.ipynb-작업하기",
    "title": "Rye",
    "section": "VS Code에서 .ipynb 작업하기",
    "text": "VS Code에서 .ipynb 작업하기\n프로젝트 폴더와 연동해서 VS Code를 열어주자. 터미널에서 code .을 실행하면 된다. 이제 해당 프로젝트의 파이썬 커널과 VS Code의 Jupyter 환경을 연결해보자.\n\n\n\nVS Code 커널 선택 (클릭하면 확대); (오른쪽) 커널 선택 &gt; 다른 커널 선택 &gt; Python 환경 &gt; .venv... 순으로 선택하면 된다.\n\n\n스크린 샷에서 보듯이 커널 선택 &gt; 다른 커널 선택 &gt; Python 환경 &gt; .venv...를 택하면 된다. 해당 프로젝트 폴더 아래 .venv 폴더 안에 있는 파이썬 환경을 가져오게 되면, 해당 프로젝트의 파이썬 커널과 설치된 패키지가 VS Code의 Jupyter 환경과 연결된다."
  },
  {
    "objectID": "posts/computer-tool/2023-05-29-rye.html#터미널에서-작업하기",
    "href": "posts/computer-tool/2023-05-29-rye.html#터미널에서-작업하기",
    "title": "Rye",
    "section": "터미널에서 작업하기",
    "text": "터미널에서 작업하기\n가상 환경으로 Venv 패키지를 쓰고 있기 때문에 터미널에서 작업해야 한다면 해당 환경을 활성화하면 된다. 여기를 참고하자. 해당 프로젝트의 디렉토리에서\n# Windows \n&gt; .venv\\Scripts\\activate # for activation \n&gt; deactivate # for deactivation\n\n# Unix \n&gt; . .venv\\Scripts\\activate # for activation \n&gt; deactivate # for deactivation"
  },
  {
    "objectID": "posts/computer-tool/2023-05-29-rye.html#in-short",
    "href": "posts/computer-tool/2023-05-29-rye.html#in-short",
    "title": "Rye",
    "section": "In Short!",
    "text": "In Short!\n\nrye init, rye add..., rye sync의 순으로 rye 설정\nVS Code에서 쓴다면, ipykernel 패키지를 rye 환경에 설치하도록 하자.\n프로젝트 폴더에서 code .을 통해 VS Code를 열거나, 아니면 이후 해당 폴더를 작업 폴더로 설정하자.\nkernel 선택 시 프로젝트 폴더 아래 깔린 .venv 환경을 선택한다.\n\n\n\n\nVS Code 커널 선택 (클릭하면 확대); (오른쪽) 커널 선택 &gt; 다른 커널 선택 &gt; Python 환경 &gt; .venv... 순으로 선택하면 된다."
  },
  {
    "objectID": "posts/computer-tool/2021-11-19-python-in-browser.html",
    "href": "posts/computer-tool/2021-11-19-python-in-browser.html",
    "title": "Python in the Browser",
    "section": "",
    "text": "이런 상황을 생각해보자.\n\n파이썬을 갑자기 써야 한다!\n그런데 조건상 클라이언트에 깔 상황이 안 된다!\n\n이럴 때 쓸 수 있는 도구가 몇 개 있다. 대표적으로 아래 구글 코랩이 있다.\n\n구글 드라이브와 연동되는 구글 코랩\n\n그런데 많은 회사에서 구글 서비스를 막아두는 경우가 있다. 그렇다면 어떻게 할까?"
  },
  {
    "objectID": "posts/computer-tool/2021-11-19-python-in-browser.html#dev-모드-진입",
    "href": "posts/computer-tool/2021-11-19-python-in-browser.html#dev-모드-진입",
    "title": "Python in the Browser",
    "section": "dev 모드 진입",
    "text": "dev 모드 진입\ngithub를 dev 모드로 돌린다. 웹 브라우저 리포지터리 창에서 . 버튼을 누르거나 .dev 주소로 접근하면 된다. 익숙한 vs code 화면에 보일 것이다.\n이제 아래 왼쪽 탭 화면에서 extension을 찾으면 된다. 아래 그림처럼 생겼다.\n\n\n\nVS 코드 확장 버튼"
  },
  {
    "objectID": "posts/computer-tool/2021-11-19-python-in-browser.html#extension-설치",
    "href": "posts/computer-tool/2021-11-19-python-in-browser.html#extension-설치",
    "title": "Python in the Browser",
    "section": "extension 설치",
    "text": "extension 설치\n검색에서 아래 익스텐션을 찾아서 설치해준다.\nexteion: vscode-pyodide\n\n이 익스텐션은 주피터에서 브라우저 기반으로 파이썬을 돌리는 Pyodide를 구현한다."
  },
  {
    "objectID": "posts/computer-tool/2021-11-19-python-in-browser.html#do-your-work",
    "href": "posts/computer-tool/2021-11-19-python-in-browser.html#do-your-work",
    "title": "Python in the Browser",
    "section": "Do your work!",
    "text": "Do your work!\n이제 .ipynb 확장자 파일을 만들고 늘상 쓰듯이 jupyter를 쓰면 된다. 아주 특이하거나 무거운 환경이 아닌 이상, 어지간한 간단한 작업은 쾌적하게 수행할 수 있다. 익스텐션을 깔면, 인터페이스는 Jupyter에 적합하게 알아서 변한다. 물론 한계도 있다. 브라우저에 올라간 파이썬 엔진인 만큼 로컬이나 서버에 깔린 python처럼 ‘많은’ 일을 할 수는 없다."
  },
  {
    "objectID": "posts/computer-tool/2020-04-09-wsl2-walkthru.html",
    "href": "posts/computer-tool/2020-04-09-wsl2-walkthru.html",
    "title": "wsl 2, a walk-thru",
    "section": "",
    "text": "격세지감이다. 적으로 삼고 아웅다웅하던 윈도가 리눅스를 두 팔로 품었다. (마치 macos에서 처럼) 윈도에서 터미널을 켜고 리눅스를 네이티브로 쓸 수 있을 것이라고 누가 생각했을까. 그런데 그런 날이 왔네. MS, 대단하다.\nWSL(Windows Subsystem for Linux)의 두 번째 버전(이하 wsl 2)은 좋다. 그냥 좋다. wsl 2을 통해 모든 리눅스의 장점을 네이티브로 누릴 수 있다. wsl 2는 이 글을 작성하는 현재 시점까지 별도로 신청해야 하는 윈도 프리뷰를 통해서 사용할 수 있다. 상반기에 예정된 2004 업데이트에 정식으로 포함될 예정이다.\n이 포스트는 그간 짬짬이 써오면서 알아왔던 내용을 한방에 정리하기 위한 용도다. 역시나 친절한 가이드, 이런 것과는 거리가 멀고 몇 달 후의 ’나놈’을 위한 것임을 밝혀둔다."
  },
  {
    "objectID": "posts/computer-tool/2020-04-09-wsl2-walkthru.html#ubuntu-18.04-설치",
    "href": "posts/computer-tool/2020-04-09-wsl2-walkthru.html#ubuntu-18.04-설치",
    "title": "wsl 2, a walk-thru",
    "section": "Ubuntu 18.04 설치",
    "text": "Ubuntu 18.04 설치\n\n여기를 참고하면 되겠다.\n다른 리눅스를 써도 좋다. 일단 가장 대중적인 Ubuntu로 가보자."
  },
  {
    "objectID": "posts/computer-tool/2020-04-09-wsl2-walkthru.html#windows-terminal",
    "href": "posts/computer-tool/2020-04-09-wsl2-walkthru.html#windows-terminal",
    "title": "wsl 2, a walk-thru",
    "section": "Windows Terminal",
    "text": "Windows Terminal\n\n이전에 CLI 도구로 Cmder를 추천한 바 있다. 그런데, 1004 버전부터 MS가 공식 터미널 앱을 넣어 놓았다. Windows Terminal 하나면 PowerShell, Windows cmd, Unbuntu를 탭으로 자유롭게 오갈 수 있다. 속도도 빠르고 커스터마이징도 어렵지 않게 가능하다. 안 쓸 이유가 없다.\n한가지 단점. 복붙이 자유롭지 않다고 바로 느낄텐데, 터미널 안에서는 CRTL-C/V 대신 CRTL+SHIFT-C/V로 다시 키매핑이 되었다. 터미널 외부에서는 기존 방식이고 안에서는 SHIFT가 더해진 방식이다. 살짝 의아하지만 못 쓸 정도는 아니니까 참고 넘어가자.\n커스터마이즈는 VS Code를 활용해서 쉽게 구현할 수 있다. 여기를 참고하자.\n\n\nSome command\nwsl -l -v # in Powershell or cmd \nwsl.exe -l -v # in Ubuntu terminal \n\n\n\n만일 PowerShell(PS)이나 cmd 안에서 친다면 위와 같이, 그리고 Ubuntu 터미널 안에서 친다면 아래와 같이 치면 된다. 자신이 쓰고 있는 가상 OS의 이름과 버전을 확인할 수 있다. 보시는것처럼 wsl version 2로 잘 나타나야 한다.\n\n하나 알 수 있는 사실. Ubuntu 터미널 안에서 윈도우 앱도 실행할 수 있다.\n\n아래 두 명령어를 통해서는 버전을 설정하거나 혹은 사용중인 배포판을 디폴트로 설정할 수 있겠다.\nwsl --set-version (distro name) 2\nwsl --set-default &lt;distro name&gt;\n예컨대, Ubuntu-18.04를 기본 배포판으로 설정하고 싶다면 아래와 같이 PS에서 실행하면 된다.\nwsl --set-default Ubuntu-18.04"
  },
  {
    "objectID": "posts/computer-tool/2020-04-09-wsl2-walkthru.html#docker-desktop",
    "href": "posts/computer-tool/2020-04-09-wsl2-walkthru.html#docker-desktop",
    "title": "wsl 2, a walk-thru",
    "section": "Docker Desktop",
    "text": "Docker Desktop\n\n만일 Ubuntu를 유일한 OS로 쓰고 있다면 docker, kubernetes(k8s)를 별도로 설치해야 한다. wsl 2에서는 그럴 필요가 없다.\ndocker desktop for windows의 엣지버전 v 2.2.3.0(43965) 이상을 깔면 윈도 상에서 리눅스 터미널을 쓸 때 docker와 k8s이 자연스럽게 설정된다. 그냥 터미널을 열고 쓰면 된다!\n\n\n\n\n여러 버전의 리눅스가 깔려 있을 경우 윈도의 도커 앱에서 위 첫번째 화면에서처럼 선택해서 사용할 수 있다.\n\n보다 상세한 내용은 여기를 참고하자.\n\n\nHello-world for docker\n\ndocker가 잘 돌고 있는지 확인하고 싶다면 헬로우월드를 돌려보면 되겠다.\n\n~$ sudo docker run hello-world\n\n내가 docker를 Ubuntu에 깐 적이 없어도 아래 같이 잘 출력될 것이다. 리눅스 배포판에 맞춰서 연동되는 개념이라고 여기면 되겠다."
  },
  {
    "objectID": "posts/computer-tool/2020-04-09-wsl2-walkthru.html#testing-kubernetes",
    "href": "posts/computer-tool/2020-04-09-wsl2-walkthru.html#testing-kubernetes",
    "title": "wsl 2, a walk-thru",
    "section": "Testing Kubernetes",
    "text": "Testing Kubernetes\n\n쿠버네티스도 잘 도는지 확인해보자. 여기에서 가져왔다.\n\n~$ kubectl cluster-info\n최초로 포드를 세팅하는 것이라면 아래의 코드를 실행해주자.\n~$ kubectl run hello-minikube --image k8s.gcr.io/echoserver:1.10 --port 8080\n~$ kubectl expose deployment hello-minikube --type NodePort\n돌고 있는 서비스의 정보를 확인하자.\n~$ kubectl describe service hello-minikube\n여기서 NodePort를 확인해서 웹 브라우저에서 localhost:XXXXX라고 쳐주면 아래와 같이 떠야 한다."
  },
  {
    "objectID": "posts/computer-tool/2020-04-09-wsl2-walkthru.html#best-practices-for-python",
    "href": "posts/computer-tool/2020-04-09-wsl2-walkthru.html#best-practices-for-python",
    "title": "wsl 2, a walk-thru",
    "section": "Best Practices for python",
    "text": "Best Practices for python\n\nwsl 2에 파이썬을 넣고 쓴다면 아래와 같은 두 가지 원칙을 유지하면 좋다.\n\nconda 같은 배포판 말고 그냥 파이썬을 쓰자.\n디폴트 가상 환경 venv를 활용하자.\n\n이 두가지 원칙을 예시한 아래의 포스팅을 참고하시라.\n\n네이티브 파이썬 설치\npython venv 활용\n\n도커로 특정 파이썬 환경을 끌어와 쓰는 것도 가능하다. 예를 들어 tensorflow 설정이 복잡하다면 그냥 docker로 끌어다쓰면 된다."
  },
  {
    "objectID": "posts/computer-tool/2020-04-09-wsl2-walkthru.html#git-also-natively",
    "href": "posts/computer-tool/2020-04-09-wsl2-walkthru.html#git-also-natively",
    "title": "wsl 2, a walk-thru",
    "section": "git, also natively",
    "text": "git, also natively\n\ngit도 모양 빠지게 윈도우 용을 별도로 깔 필요가 없다! 만세! wsl 2 ubuntu에 탑재된 녀석을 쓰면 된다.\n윈도 폴더에는 어떻게 접근하면 될까? 친절하게도 /mnt/c, /mnt/d와 같은 식으로 이미 Ubuntu root 디렉토리에 마운트가 되어 있다. wsl 내에서도 원도용 폴더로도 쉽게 접근할 수 있다.\n\n\ngithub login\n\n하나 문제가 될 만한 것은 github의 로그인이다. 매번 아이디/패스워드를 쳐 넣기 귀찮을 수 있다.\n좋은 해결책은 rsa 공개키를 생성해서 ssh로 로그인 터널을 만들어두는 것이다. git별로 클론할 때 한번만 해두면 되니 꽤 편리하다. 자세한 것은 여기를 참고하자.\n단 사내 네트워크 같은 곳에 물려 있을 경우 ssh 접근이 원활하지 않을 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2022-12-06-jupyterlite-githubpages.html",
    "href": "posts/computer-tool/2022-12-06-jupyterlite-githubpages.html",
    "title": "JupyterLite + GitHub Pages",
    "section": "",
    "text": "인스톨 없이 주피터 노트북을 사용할 수 있다굽쇼?\n\n\n\n\nJupyter, jupyterlite에 대해서 상세히 다루지 않는다.\nGithub Pages에 대해서 상세히 다루지 않는다.\n\n\n\n\n\n별도의 인스톨 없이 손 쉽게 웹 브라우저에서 Jupyter 코딩 환경을 구현하는 JupyterLite를 소개한다.\njupyterLite를 github pages에 올리는 방법을 다룬다."
  },
  {
    "objectID": "posts/computer-tool/2022-12-06-jupyterlite-githubpages.html#tl-dr",
    "href": "posts/computer-tool/2022-12-06-jupyterlite-githubpages.html#tl-dr",
    "title": "JupyterLite + GitHub Pages",
    "section": "",
    "text": "인스톨 없이 주피터 노트북을 사용할 수 있다굽쇼?\n\n\n\n\nJupyter, jupyterlite에 대해서 상세히 다루지 않는다.\nGithub Pages에 대해서 상세히 다루지 않는다.\n\n\n\n\n\n별도의 인스톨 없이 손 쉽게 웹 브라우저에서 Jupyter 코딩 환경을 구현하는 JupyterLite를 소개한다.\njupyterLite를 github pages에 올리는 방법을 다룬다."
  },
  {
    "objectID": "posts/computer-tool/2022-12-06-jupyterlite-githubpages.html#jupyterlite",
    "href": "posts/computer-tool/2022-12-06-jupyterlite-githubpages.html#jupyterlite",
    "title": "JupyterLite + GitHub Pages",
    "section": "Jupyterlite",
    "text": "Jupyterlite\n보통 파이썬 작업을 하기 위해서는 사전 설치가 필요하다. 아마도,\n\n로컬 PC에 필요한 소프트웨어를 설치한다.\n원격 PC에 필요한 소프트웨어를 설치하고, 여타 클라이언트(주로 웹 브라우저)에서 접속해 활용한다.\n\n두 가지 방법 모두 소프트웨어를 어딘가에 까는 과정이 포함된다.\n가끔은 ’공통 환경’이 필요할 때가 있다. 강의나 구현물의 시현을 해야 한다면 동일한 결과를 얻는 것이 필요하다. 결과물을 얻은 컴퓨터를 사용하거나 원격 접속을 설정하지 않고 이러한 수준의 공동 환경을 만들 수 있을까? 즉 .ipynb, .py 등의 파일을 교환하는 수준을 넘어선 ’호환성’을 게으르고 편리하게 보장할 수 있을까?\n만일 웹 브라우저만 구동해서 이 공통 환경을 빠르게 만들어낼 수 있다면 어떨까? 이를 실현한 것이 jupyterLite이다.\n주피터라이트는 가벼운 노트북 환경을 구현하는 것을 목표로 한다. 이 녀석은 아직 시험 단계의 프로젝트지만 많은 주목을 받고 있다. 이때 ’가벼운 노트북’이란 주피터 환경을 구현하는 데 있어 웹 브라우저와 단순한 스태틱 웹 페이지 이외에 어떤 것도 필요하지 않다는 뜻이다.\n웹어셈블리(WASM)로 구현된 파이썬 인터프리터를 통해서 브라우저만 있으면 아주 단순한 웹 페이지 하나로 주피터라이트가 파이썬과 주피터(IDE)의 마법을 부린다. 원래 주피터 노트북이라는 녀석이 서버-클라이언트를 전제로 만들어진 것인데, 여기서 서버가 빠진 가벼운 변종이 주피터라이트다.\n\n패키지 설치\n여기까지 들으면 ‘웹 브라우저에서 도는 것은 좋은데 패키지 설치는 가능해?’ 라고 묻고 싶어질 터. 답부터 말하면, 가능하지만 전부 가능한 것은 아니다. ’일반적’으로 많이 쓰는 패키지인 pandas, numpy, scipy, scikit-learn 등은 거의 주피터라이트 위에 쉽게 올라간다. 대단한 복잡도를 지닌 앱이 아니라 개념을 입증하는 프로토타입 특히 교육용으로 주피터를 쓰려는 용도라는 주피터라이트로 충분하다.\n\n\n패키지 설치는 주피터 노트북에서 매직 코멘트(%)를 활용한다. 예를 들어 python %pip install koreanize-matplotlib 한 가지 주의 사항 확인하자. 루트 디렉토리에 있는 requirements.txt에 속지 말자. 이 녀석은 jupyterlab, jupyterlite 그리고 두 개에 필요한 요소를 설치하기 위한 파일이다. 주피터라이트 내에서 돌아가는 파이썬 패키지 설치와는 무관하다. 주피터라이트는 WASM으로 브라우저 안에서 독립적으로 구현된 IDE 환경이다.\n직접 체험해보시는 편이 훨씬 낫다; JupyterLite\n위의 예에서 보듯이 노트북의 UI로는 주피터랩(기본), 레트로, REPL(Read-Evaluate-Print Loop)를 자유롭게 쓸 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2022-12-06-jupyterlite-githubpages.html#github-pages",
    "href": "posts/computer-tool/2022-12-06-jupyterlite-githubpages.html#github-pages",
    "title": "JupyterLite + GitHub Pages",
    "section": "Github Pages",
    "text": "Github Pages\n이제 이렇게 만들어진 페이지를 웹을 통한 전달할 경로가 필요하다. 만일 별도로 서버를 복잡하게 세팅해야 한다면 주피터라이트의 장점도 거의 사라질 것이다.\n웹어셈블리는 css, js만 사용한다. 이는 스태틱 웹을 통해서도 주피터라이트가 돌아간다는 의미이다. 그리고 스태틱 웹을 호스팅하는 현존하는 가장 저렴하고 편리한 방식은 GitHub Pages다.\n\n\n테스트로 빌드한 리포는 여기를 참고하자. python-notebooks 디렉토리가 포함되어 있는데, 여기 matplotlib 한글을 구현하는 노트북 등 몇 가지 활용에 참고할 만한 간단한 예제를 넣어 두었다.\n빌드하고 연동하는 방법이 공식 페이지에 잘 소개되어 있다. 호스팅을 위해서는 GitHub Actions를 통한 빌드의 과정이 필요한데, 이용자가 크게 신경 쓸 것은 없다. 소개된대로 템플릿을 가져와서 사용하면 된다. 해당 리포의 변형이 있을 떄마다 푸시를 하면 Actions를 통한 build -&gt; Pages를 통한 depoly 과정이 자동으로 발생한다. 주의 사항만 몇가지 적어두자.\n\nSettings &gt; General에서 “Danger Zone”\n\n“Change repository visibility”를 “public”으로 설정\nPro 회원이라면 Private 상태에서도 Pages를 호스팅할 수 있다. 일반 회원의 경우 소스가 공개되어 있어야 Pages 호스팅이 가능하다.\n\nSettings &gt; (왼쪽 탭에서) GitHub Pages에서\n\n“Build and deployment” 항목\n“Source”를 “Github Actions”로 설정하도록 하자.\n\n\n설정은 이게 전부이다. 빌드가 잘 되었는지 확인하기 위해서는 상단 탭에서 “Actions”를 선택하자. 빌드가 진행중인지 끝났는지를 확인할 수 있을 것이다. 발드가 끝났다면, 이제 Pages를 방문하도록 하자. 주소는 아래와 같다.\n\n\n\n\n\n\nGitHub Pages 주소\n\n\n\n{이용자-깃헙계정}.github.io/{이용자-리포이름}\n👉http://anarinsk.github.io/demo_jupyterlite\n\n\n\n자세히 들여다 본 빌드 과정\n깃허브 디렉토리의 감춰진 디렉토리를 보이게 설정하자. 해당 디렉토리 안에 .github/workflows로 들어가면 deploy.yml이 있다. 이 녀석이 깃허브 액션스의 빌드 순서 및 명렁을 구성한다. 내용을 전부 설명할 필요는 없다. 필요한 부분만 살펴보자.\n- name: Setup Python\n    uses: actions/setup-python@v4\n    with:\n        python-version: '3.10'\n- name: Install the dependencies\n    run: |\n        python -m pip install -r requirements.txt\n- name: Build the JupyterLite site\n    run: |\n        cp README.md content\n        jupyter lite build \\\n            --XeusPythonEnv.packages=scikit-learn,matplotlib,pandas,plotly,ipywidgets,openpyxl \\\n            --contents content --output-dir dist\n- name: Upload artifact\n    uses: actions/upload-pages-artifact@v1\n    with:\n        path: ./dist\n\n\n\n\n\n\nCode Tips\n\n\n\n\n-name: | 액션스를 행동을 구분하는 단위의 이름을 지정한다.\n-name: Setup Python | 깃헙 리포에서 파이썬을 쓰겠다고 선언한다. 버전도 구별할 수 있다.\n-name: Install the dependencies | 빌드를 위한 파이썬 관련 패키지 설치\n-name: Build the JupyterLite site | jupyterlite를 빌드한다. 빌드 명령어는 jupyter lite build...에서 확인항 수 있다.\n\n이 명령은 기본으로 pyodide 기반의 pyolite 파이썬 커널을 설치한다.\nXeusPythonEnv.packages= | xeus-python 커널이 추가로 설치되며, 해당 커널에 필요한 패키지를 올린다. 공식 페이지 절차대로 템플릿을 복사해서 썼다면 이 대목이 없을 것이다. 필요하면 deploy.yml에 추가하면 된다.\n--contents content | 빌드에 사용할 노트북 파일이 들어있는 디렉토리를 지정한다.\n--output-dir dist | 빌드 결과물이 저장될 디렉토리를 지정한다.\n\n\n\n\n별도로 로컬에서 빌드할 때와 명령어 자체는 동일하다. 그 앞 뒤로 깃허브 액션스에 맞는 설정이 들어간다고 보면 되겠다."
  },
  {
    "objectID": "posts/computer-tool/2022-12-06-jupyterlite-githubpages.html#github-actions-없이-빌드하고-싶다면",
    "href": "posts/computer-tool/2022-12-06-jupyterlite-githubpages.html#github-actions-없이-빌드하고-싶다면",
    "title": "JupyterLite + GitHub Pages",
    "section": "GitHub Actions 없이 빌드하고 싶다면?",
    "text": "GitHub Actions 없이 빌드하고 싶다면?\n가능하다. 그리 어렵지도 않다. 아래 링크를 참고하자.\nhttps://github.com/anarinsk/test_jupyterlite-build"
  },
  {
    "objectID": "posts/computer-tool/2022-12-06-jupyterlite-githubpages.html#몇-가지-더",
    "href": "posts/computer-tool/2022-12-06-jupyterlite-githubpages.html#몇-가지-더",
    "title": "JupyterLite + GitHub Pages",
    "section": "몇 가지 더",
    "text": "몇 가지 더\n\n커널 관련(outdated)\n위 빌드 과정에서 보듯이 두 개의 파이썬 커널을 설치했다. 범용성은 pyodide 기반의 pyolite 커널이 낫다. 다만 네트워크 기능을 제대로 쓰기 위해서는 xeus-python이 편리하다. 예를 들어 scikit-learn 패키지에서 데이터를 인터넷으로 끌어오는 fetch 계열의 명령은 XePython 커널에서 제대로 작동한다. pyolite는 네트워크를 네이티브 파이썬 환경처럼 다루지 않는다.\n\n\n네트워크와 관련한 보다 상세한 내용은 여기를 참고하도록 하자.\n\n\n커널 관련(updated)\n꼭 xeus-python을 써야 하나 싶다. Python의 네트워크 관련 명령들이 pyodide-http 패키지로 거의 완전하게 해결이 된다. 이 패키지는 기존 명령어를 주피터라이트에 맞게 패치한다. 아래 코드를 참고하자.\n%pip install -q pyodide-http\nimport pyodide_http \npyodide_http.patch_all() # 기존 http 관련 명령어 패치 \n\n\npyodide에 관한 보다 상세한 내용은 해설 1, 해설 2를 참고하도록 하자.\n\n\n몇 가지 핵심 활용법\ncontent/python-notebooks 안에 믾이 쓸 것 같은 필요한 활용 용례를 몇 가지 넣어 두었다. 자세한 것은 README를 참고하면 된다."
  },
  {
    "objectID": "posts/computer-tool/2021-02-02-all-vs-code.html",
    "href": "posts/computer-tool/2021-02-02-all-vs-code.html",
    "title": "All into VS Code",
    "section": "",
    "text": "각자 언어에 맞는 IDE가 있다. 예를 들어 R에는 RStudio가 가장 잘 어울린다. 언어 별로 별도의 IDE 보다는 모든 것을 한방에 해결할 수는 없을까? 이러한 목적에 복무하는 코더를 위한 좋은 에디터들이 많이 있다. 하지만 설정이 쉽지 않고 아무래도 나 같은 문송한 존재들에게는 접근성이 떨어진다. 그리고 대체로 유료다! 이 사이에서 타협할 수 있는 제품이 없을까?\nMS에서 제공하는 무료 (만능) 에디터 VS Code는 여기서 제법 괜찮은 대안이다. 각설하고 파이썬, 줄리아, R을 VS code로 부리는 데 필요한 준비물을 살펴보자."
  },
  {
    "objectID": "posts/computer-tool/2021-02-02-all-vs-code.html#필요-조건",
    "href": "posts/computer-tool/2021-02-02-all-vs-code.html#필요-조건",
    "title": "All into VS Code",
    "section": "필요 조건",
    "text": "필요 조건\n\nWindows 10 with WSL 2\nVS Code\n\nGlobal extension\n\nRemote-Container\n\nContainer extension\n\nJulia\nJupyter\nPython\nR\nR LSP Client\nRadian\n\n\nDocker Desktop\njupyter/datascience-notebook:latest (from dockerhub)\n\n개별 소프트웨어를 로컬 머신에 깔아서 쓸 수도 있고, 이 경우 역시 아래를 참고해 설정하는 데 어려움이 없으리라 본다. 여기서는\n\nWSL 2를 통해 docker를 활성화하고\njupyter 개발자가 직접 관리하는 Data Science 노트북을 끌어와\n\nVS Code를 통해 부리는 방법을 소개한다. 위의 적은 두 가지 사항은 이 포스팅을 참고하자. 간단히 결론만 요약하면 다음과 같다. 도커를 쓰면 별도의 인스톨이 필요 없고 뭔가 꼬였을 때 해당 컨테이너만 날려버리면 된다. 위에 소개한 jupyter/datascience 컨테이너는 다소 큰 용량이지만 잘 갖춰진 파이썬, 줄리아, R의 프리셋을 제공한다."
  },
  {
    "objectID": "posts/computer-tool/2021-02-02-all-vs-code.html#핵심",
    "href": "posts/computer-tool/2021-02-02-all-vs-code.html#핵심",
    "title": "All into VS Code",
    "section": "핵심",
    "text": "핵심\n\n\n\n컨테이너 원격 접속\n\n\n\nVS Code의 익스텐션 Remote-Container 컨테이너 접속 기능을 활용해 datascience-notebook 컨테이너 접속한다.\n\n오른쪽 하단에 &gt;&lt; 표시된 부분을 클릭하자. 위의 그림을 볼 수 있다. 여기에서 “Remote-Containers: Attach to Running Container…”를 클릭하면 현재 돌아가고 있는 docker 컨테이너를 볼 수 있다. 미리 docker를 통해 돌려 둔 datascience 컨테이너를 선택하자.\n이 컨테이너는 안에 python, jupyterlab, R, Julia를 모두 갖고 있다. 따라서 이 녀석 하나만 도커에 올리면 된다.\n\n각각의 언어에 접근하기 위해서 필요한 VS Code Extension을 설치한다.\n\nJulia, Python의 경우 공식 확장이 있어서 그대로 쓰면 된다.\nR의 경우 비공식 확장이지만 약간의 세팅을 거치면 꽤 근사하게 사용할 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2021-02-02-all-vs-code.html#for-julia",
    "href": "posts/computer-tool/2021-02-02-all-vs-code.html#for-julia",
    "title": "All into VS Code",
    "section": "For Julia",
    "text": "For Julia\n\n필요한 줄리아 작업 파일을 .jl 확장자로 만든다.\nVS Code가 알아서 잘 잡아서 줄리아 커널과 연결시켜준다.\n간략한 실행 명령 체계를 살펴보자. 자세한 내용은 여기를 참고하자.\n\n코드 셀 구분은 ##\nCTRL + ENTER 해당 라인 실행\nALT + ENTER 코드 블럭 실행 (드래그앤드롭 선택)\nSHIFT + ENTER 코드 셀 실행\n\n패키지 설치는 두가지로 가능하다.\n\nJulia 콘솔에서 ]를 치면 패키지 관리 모드로 들어간다.\n\n&gt;(pkg) add SOMETHING\n\n이렇게 설치할 경우는 별도로 Pkg를 호출하지 않도 설치가 가능하다.\n\n\n아래와 같이 설치할 수도 있다.\n\nusing Pkg \nPkg.add(\"Plots\")\nPkg.add(\"PyPlot\") \nJulia는 JIT를 쓰기 때문에 패키지를 설치하고 명령을 구동하는 데 시간이 오래 걸린다. 이 과정을 작업을 시작하기 전에 미래 해두는 것이 좋다. 즉, 필요한 경우 미리 컴파일을 해놓는 것이 좋다.\nQuantEcon에 소개된 사례를 따르자."
  },
  {
    "objectID": "posts/computer-tool/2021-02-02-all-vs-code.html#for-python",
    "href": "posts/computer-tool/2021-02-02-all-vs-code.html#for-python",
    "title": "All into VS Code",
    "section": "For Python",
    "text": "For Python\n\n필요한 파일을 .py 확장자로 만든다.\n간략한 명령어\n\nCode 블럭의 구별은 #%%\nPython은 VS Code에서 거의 완벽하고 편리하게 지원이 된다.\n별다른 설명이 필요하지 않다."
  },
  {
    "objectID": "posts/computer-tool/2021-02-02-all-vs-code.html#for-rstat",
    "href": "posts/computer-tool/2021-02-02-all-vs-code.html#for-rstat",
    "title": "All into VS Code",
    "section": "For Rstat",
    "text": "For Rstat\n\n익스텐션 두 개를 깐다.\n\nR Support\nR LSP Client\n\n다음으로 R 내에서 LSP와 연결할 패키지를 설치한다.\n\nremotes::install_github(\"REditorSupport/languageserver\")\n\n마지막으로 Rstat에서 편리하게 사용할 터미널 앱을 깐다. 파이썬으로 제작되었다. 다행스럽게도 DS 도커는 이미 파이썬을 잘 지원하기 때문에 쉽게 쓸 수 있다. 주의할 것은 Rstat 내부가 아니라 그냥 docker의 bash에 접속한 상태에서 깔아야 한다는 것이다. Radian은 텍스트 상에서 모든 정보를 편리하게 보여주기 때문에 VS Code의 부족함을 잘 메워준다.\n\npip install -U radian \n\n이제 VS Code에서 설정 몇 가지를 바로 잡아 줘야 한다.\n\nFile &gt; Preferences &gt; Settings로 가자\n옆에 탭을 보면 Extensions가 있을 것이다. 여기서 R로 찾아가자.\nExtension의 설정을\n\nUser, Remote, Workspace 등 상황에 맞게 다양하게 정할 수 있다.\n여기서는 Workspace에 하도록 하겠다.\n\nR: Bracketed Paste 항목 체크\nR › Rterm: Linux\n\n/opt/conda/bin/radian\n\nR: Session Watcher 항목 체크\n\n\n\n설정 항목에서 json 파일로 한방에 해결할 수도 있다."
  },
  {
    "objectID": "posts/computer-tool/2021-02-02-all-vs-code.html#jupyterlab",
    "href": "posts/computer-tool/2021-02-02-all-vs-code.html#jupyterlab",
    "title": "All into VS Code",
    "section": "Jupyterlab",
    "text": "Jupyterlab\n\nipynb를 확장자로 해서 노트북을 쓰고 싶다면, 그냥 만들어 쓰면 된다!\nVS Code에 Jupyter 확장이 있기 때문에 보통의 웹 브라우저에서 쓰는 Jupyter 노트북과 거의 동일한 기능을 제공한다. 웹 노트북에서와 마찬가지로 파이썬, 줄리아, R의 커널을 선택하면 된다 (아래 그림의 오른쪽 상단 박스). jupyterlab과 거의 비슷한 인터페이스를 지니고 있다. 오히려 주피터에 비해 복잡하지 않아서 좋다고 느낄지도 모르겠다.\n\n\n\n\n주피터 노트북"
  },
  {
    "objectID": "posts/computer-tool/2021-02-02-all-vs-code.html#setting-for-remote-connection",
    "href": "posts/computer-tool/2021-02-02-all-vs-code.html#setting-for-remote-connection",
    "title": "All into VS Code",
    "section": "Setting for Remote Connection",
    "text": "Setting for Remote Connection\n앞서 보았듯이 도커를 활용하면 윈도우 혹은 다른 플랫폼의 VS Code를 통해 네트워크로 도커 내의 컨테이너로 접근하게 된다. 따라서 작업을 마치고 나오게 되면 매번 해당 컨테이너에 다시 접속을 해주고 워크 스페이스 등 여러가지 작업을 해줘야 하는 번거로움이 있다. 항상 도커 컨테이너를 거쳐 작업한다면 그냥 한방에 작업하던 환경이 뜨는 편이 나을 것이다. 아래와 같이 하자.\n\n\n\n리모트 익스플로러\n\n\n\n만일 위와 같은 화면에 Remote Exlorer에서 뜨지 않는다면 컨테이너가 부착되지 않는 것이다. 컨테이너를 부착하면 된다.\n\n\n\n\n컨테이너 부착\n\n\n\nExtension &gt; REMOTE EXPLORER &gt; DETAILS 탭에서 가운데 설정 모양이 “Open Container Configuration File”이다.\n옆 에디터 창에 json 형식의 설정이 뜬뜬다. 여기서 관련 extension 등의 설정을 지정할 수 있다. 이렇게 설정을 해두면 해당 컨테이너를 부착할 때 설정한 대로 자동으로 옵션들이 적용된다. 매우 편리하다.\n\n{\n    \"extensions\": [\n        \"Ikuyadeu.r\",\n        \"julialang.language-julia\",\n        \"ms-python.python\",\n        \"ms-toolsai.jupyter\",\n        \"REditorSupport.r-lsp\"\n    ],\n    \"workspaceFolder\": \"/home/jovyan/github-anari\",\n    \"forwardPorts\": [\n        43463,      \n    ],\n    \"settings\": {\n        \"jupyter.alwaysTrustNotebooks\": true,\n        \"r.bracketedPaste\": true,\n        \"r.sessionWatcher\": true,\n        \"r.rterm.linux\": \"/opt/conda/bin/radian\"\n    }\n}\n\n\n\n리모트 워크스페이스 설정\n\n\n\nFile &gt; Perefences &gt; Settings에서도 설정에 접근할 수 있다.\nVS Code의 설정은 두가지 축을 지닌다. 하나는 설정 전체를 담은 json 파일이다. 왼쪽 &gt; 표시된 항목에서처럼 카테고리 별로 구별되어 쉽게 접근할 수 있다. 이 하나의 설정을 위 그림에서 보듯이 User, Remote(컨네이터), Workspace 별로 별도로 지정해 활용할 수도 있다."
  },
  {
    "objectID": "posts/computer-tool/2024-04-03-r_with_pixi.html",
    "href": "posts/computer-tool/2024-04-03-r_with_pixi.html",
    "title": "Pixi와 쓰는 R과 Julia",
    "section": "",
    "text": "Pixi로 R도 부릴 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2024-04-03-r_with_pixi.html#tl-dr",
    "href": "posts/computer-tool/2024-04-03-r_with_pixi.html#tl-dr",
    "title": "Pixi와 쓰는 R과 Julia",
    "section": "",
    "text": "Pixi로 R도 부릴 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2024-04-03-r_with_pixi.html#왜-pixi인가",
    "href": "posts/computer-tool/2024-04-03-r_with_pixi.html#왜-pixi인가",
    "title": "Pixi와 쓰는 R과 Julia",
    "section": "왜 pixi인가?",
    "text": "왜 pixi인가?\n나는 픽시를 사랑한다. 픽시를 쓰면서 파이썬 패키지를 깔거나 세팅을 할 때 고민하지 않는다. (알 수 없는 이유로) 꼬이면 지우고 다시 깔면 그만이다. R을 이렇게 파이썬처럼 운용할 수 없을까? 문득 이런 생각이 들더라. Pixi의 베이스가 되는 conda에 R이 있다. 그렇다면 pixi를 통해 R을 깔 수 있지 않을까?\n\n\n다만 매 프로젝트마다 파이썬과 필요한 패키지를 깔아야 하는 것이 불만족스러운 혹은 불가능한 환경이 있을 수 있다.\n이런 생각으로 쭉 해보니 의외로 잘 되더라. 이 포스팅은 (전적으로!) 이 내용을 까먹고 헤맬 미래의 나 놈을 위한 것이다."
  },
  {
    "objectID": "posts/computer-tool/2024-04-03-r_with_pixi.html#얻는-것과-잃는-것",
    "href": "posts/computer-tool/2024-04-03-r_with_pixi.html#얻는-것과-잃는-것",
    "title": "Pixi와 쓰는 R과 Julia",
    "section": "얻는 것과 잃는 것",
    "text": "얻는 것과 잃는 것\nR의 IDE로 VS Code를 쓴다면 천군만마와도 같은 GitHub Copilot을 부릴 수 있다. 엄청난 장점이다. 잃는 것은 R과 최고의 궁합을 자랑하는 RStudio이다. RStudio에 임의의 R 커널을 연결할 수 있으면 좋겠는데 좀 더 비싼 기업용 버전인 workbench에서만 해당 기능을 지원하는 듯 싶다.\nRStudio는 아쉽지만 VS Code + pixi를 쓰는 것의 장점이 아쉬움 이상이다."
  },
  {
    "objectID": "posts/computer-tool/2024-04-03-r_with_pixi.html#pixi-setting",
    "href": "posts/computer-tool/2024-04-03-r_with_pixi.html#pixi-setting",
    "title": "Pixi와 쓰는 R과 Julia",
    "section": "Pixi setting",
    "text": "Pixi setting\n다음과 같은 사용 환경을 전제한다.\n\nOS\n\nWindows 11 WSL 2 + Ubutu 22.04 LTS\nMacos (Sonoma, Silicon)\n\npixi\n\n일단 R에 관해서 쭉 설명을 하고 Julia에 관한 내용을 더하겠다. R에 비하면 Julia 설치는 별 문제가 없다.\nR을 깔고자 하는 디렉토리에서 아래와 같이 실행한다.\n&gt; pixi init # 픽시 초기화 \n&gt; pixi add python=3.11 r-base radian # 파이썬, r-base, radian 추가 \n위 명령어를 실행하면 [pixi 코드를 품은 디렉토리]/.pixi/envs/default 폴더 아래 파이썬, R-base 그리고 radian이 설치된다. radian은 파이썬으로 작성된 일종의 대안 터미널이다. 꽤 쓸만하다. 그리고 해당 경로를 사용하는 셸의 PATH로 지정하자. 그래서 radian과 R을 터미널에서 실행할 수 있다. nano ~/.zshrc 등을 실행해 아래 구절을 넣고 저장하고 셸을 다시 불러오면 된다.\nexport PATH=\"$PATH:[pixi가 깔린 디렉토리]/.pixi/envs/default/bin\""
  },
  {
    "objectID": "posts/computer-tool/2024-04-03-r_with_pixi.html#miniforge",
    "href": "posts/computer-tool/2024-04-03-r_with_pixi.html#miniforge",
    "title": "Pixi와 쓰는 R과 Julia",
    "section": "Miniforge",
    "text": "Miniforge\npixi 자체가 Conda에 의존한다. 따라서 Conda를 설치하는 게 좋다. 커뮤니티 버전인 Miniforge를 설치하자. Miniforge는 Macos에서는 brew로 설치할 수 있고, Ubuntu에서는 별도의 설치 파일을 받아서 설치하면 된다.\n\nMacOSUbuntu\n\n\n&gt; brew install miniforge\n\n\n&gt; curl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"\n&gt; bash Miniforge3-$(uname)-$(uname -m).sh\n\n\n\n미니포지를 통해 gfortran을 설치하자. 이를 설치하지 않으면 R의 패키지 설치 과정에서 많은 문제가 생길 것이다.\n&gt; conda install -c conda-forge gfortran\n아래 환경 설정을 마친 후 시험삼아서 아래 두 패키지를 설치해보자. VS Code에서 R을 쓰기 위해서 아래 두 패키지를 설치해야 한다.\n&gt; install.packages(\"languageserver\")\n&gt; install.packages(\"httpgd\")"
  },
  {
    "objectID": "posts/computer-tool/2024-04-03-r_with_pixi.html#r을-위한-실행-환경",
    "href": "posts/computer-tool/2024-04-03-r_with_pixi.html#r을-위한-실행-환경",
    "title": "Pixi와 쓰는 R과 Julia",
    "section": "R을 위한 실행 환경",
    "text": "R을 위한 실행 환경\nR을 패키지로 설치하지 않았기 때문에 몇 가지 설정이 필요하다. R의 설정을 위해 필요한 파일은 .Renviron, .Rprofile 두 가지이다. 이 두 파일을 $HOME에 생성하도록 하자.\n\n.Renviron.Rprofile\n\n\n## macrtools - gfortran: start\n# PATH=${PATH}:/opt/gfortran/bin\n## macrtools - gfortran: end\n\n# Setting LIB location\n\nR_LIBS_SITE=\"[pixi가 깔린 디렉토리]/.pixi/envs/default/lib/R/library\"\n\n\n# Setting CRAN Server\n\nlocal({r &lt;- getOption(\"repos\")\n       r[\"CRAN\"] &lt;- \"https://cloud.r-project.org\"\n       options(repos=r)})\n\n\n\n.Renviron 파일에서는 R의 라이브러리 위치를 지정하고, Rpofile에서는 CRAN 서버를 지정한다.\nR에서 .libPaths()를 패키지가 설치되는 위치를 확인할 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2024-04-03-r_with_pixi.html#vs-code-설정",
    "href": "posts/computer-tool/2024-04-03-r_with_pixi.html#vs-code-설정",
    "title": "Pixi와 쓰는 R과 Julia",
    "section": "VS Code 설정",
    "text": "VS Code 설정\n먼저 R의 extension을 받아서 설치하자. 해당 확장을 설치한 후 몇 가지 설정을 바꿔야 한다. VS Code의 확장 설정으로 가자(Figure 1). 이후 필요한 설정을 바꾸면 된다.(Figure 2)\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: 익스텐션의 설정으로 가자.\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: 두 개 모두 적절한 위치로 바꿔 사용하자.\n\n\n\n\n\n\n이외에 httpgd를 쓰는 것을 체크하자."
  },
  {
    "objectID": "posts/computer-tool/2024-04-03-r_with_pixi.html#vs-code로-r-쓰기",
    "href": "posts/computer-tool/2024-04-03-r_with_pixi.html#vs-code로-r-쓰기",
    "title": "Pixi와 쓰는 R과 Julia",
    "section": "VS Code로 R 쓰기",
    "text": "VS Code로 R 쓰기\nhttps://code.visualstudio.com/docs/languages/r\n전체적인 지침은 링크에 잘 정리가 되어 있다."
  },
  {
    "objectID": "posts/computer-tool/2024-04-03-r_with_pixi.html#packages-설치-시-유의사항",
    "href": "posts/computer-tool/2024-04-03-r_with_pixi.html#packages-설치-시-유의사항",
    "title": "Pixi와 쓰는 R과 Julia",
    "section": "Packages 설치 시 유의사항",
    "text": "Packages 설치 시 유의사항\n패키지 설치 시 만날 수 있는 몇 가지 에러 유형을 패키지 별로 정리해보자.\n\nsystemfonts\nsystemfonts 패키지가 대체로 잘 설치되지 않는다. 이 패키지가 없으면 languageserver, devtools 등등 이에 의존하는 주요 패키지가 설치되지 않는다. 발생하는 에러 메시지를 잘 보면서 OS 별로 대응하면 된다. 하지만 때로는 시키는대로 해도 해결되지 않는 경우가 있다. 그럴 땐 어떻게 할까? R 설치에서 이 문제는 C++ 컴파일러와 관련된 이슈다. 가장 깔끔하게 해결하려면 pixi shell로 접근해서 해당 패키지를 설치하면 된다. 즉,\n# pixi가 설정된 해당 디렉토리에서 \n&gt; pixi shell \n&gt; radian \n# In radian \n&gt; install.packages(\"systemfonts\")\n이렇게 설치하면 OS 상관 없이 대체로 잘 설치가 된다. 패키지를 업데이트하지 않는 이상 이상 설치된 이후 활용에는 pixi shell 환경이 필요하지 않다.\n\n\ntidyverse\nMatrix 패키지가 버전이 맞지 않아서 설치가 안된다.\nhttps://github.com/cran/Matrix/releases\n(이 글을 쓰는 시점에서) 1.6-5 버전의 Source Code의 링크를 복사한 후 devtools를 통해 설치한다.\n&gt; devtools::install_url(\"https://github.com/cran/Matrix/archive/refs/tags/1.6-5.zip\") \n\n\nMASS\n위와 같은 방법으로 접근하면 된다.\nhttps://github.com/cran/MASS/releases\n(이 글을 쓰는 시점에서) MASS 7.3-60 버전이 설치 가능했다."
  },
  {
    "objectID": "posts/computer-tool/2024-04-03-r_with_pixi.html#julia-설치하기",
    "href": "posts/computer-tool/2024-04-03-r_with_pixi.html#julia-설치하기",
    "title": "Pixi와 쓰는 R과 Julia",
    "section": "Julia 설치하기",
    "text": "Julia 설치하기\nR에 비하면 훨씬 깔끔하고 운용이 쉽다. 다만 약간의 우회로가 필요하다. Conda를 이용해 Julia를 바로 설치해보면, OS에 따라서 설치가 되지 않는 경우가 있다. Juliaup을 먼저 설치하고 Pixi의 셸 환경 안에서 이를 이용해서 Julia를 설치하면 된다.\n\n\nJulia를 써보면 이 언어가 다른 어떤 고수준 프로그래밍 랭귀지에 비해서 “모던”하다는 사실을 느낄 수 있다. 우선 언어 자체의 설치가 간편하고, 패키지 설치 관리가 toml을 통해 이뤄진다.\n&gt; pixi add juliaup\n&gt; pixi shell \n&gt; juliaup add release # 최신 버전을 설치한다. \n&gt; juliaup install 1.10.3 # 특정 버전을 설치한다.\nVS Code에서 Julia 확정을 설치하고 확장 설정에서 Julia: Executable Path를 찾아서 .pixi 아래 설치된 줄리아의 실행 디렉토리를 설정한다. 터미널에서 julia를 실행하고 싶으면, .zshrc에 해당 디렉토리를 추가하면 된다.\n\n\n\nFigure 1: 익스텐션의 설정으로 가자.\nFigure 2: 두 개 모두 적절한 위치로 바꿔 사용하자."
  },
  {
    "objectID": "posts/computer-tool/2024-03-18-lazy-dashboard.html",
    "href": "posts/computer-tool/2024-03-18-lazy-dashboard.html",
    "title": "게으르게 만드는 대시보드",
    "section": "",
    "text": "Quarto Dashboards를 활용해서 개인용 보드를 만들어 보자.\n🔗LINK와 함께 보자."
  },
  {
    "objectID": "posts/computer-tool/2024-03-18-lazy-dashboard.html#tl-dr",
    "href": "posts/computer-tool/2024-03-18-lazy-dashboard.html#tl-dr",
    "title": "게으르게 만드는 대시보드",
    "section": "",
    "text": "Quarto Dashboards를 활용해서 개인용 보드를 만들어 보자.\n🔗LINK와 함께 보자."
  },
  {
    "objectID": "posts/computer-tool/2024-03-18-lazy-dashboard.html#왜-정적-웹static-web인가",
    "href": "posts/computer-tool/2024-03-18-lazy-dashboard.html#왜-정적-웹static-web인가",
    "title": "게으르게 만드는 대시보드",
    "section": "왜 정적 웹(static web)인가?",
    "text": "왜 정적 웹(static web)인가?\n대시보드로 활용할 수 있는 도구는 다양하다. 본격적으로 웹 프로그래밍을 활용하지 않아도 파이썬으로 부릴 수 있는 streamlit, gradio를 비롯해 다양한 서비스들이 있다. 그런데 이러한 본격적인 서비스들에는 몇 가지 ‘개인적’ 단점이 있다.\n\n서비스를 올리려면 ‘다소’ 전문적인 웹 서버가 필요하다. 자체적인 방식으로 서비스 호스팅을 구축하거나 해당 회사에서 제공하는 무료 티어를 쓸 수 있다.\n다소 느리다. 개인 용도로 쓸 때 느리다는 것 자체가 문제는 아니다. 대시보드의 기능을 제한하더라도 좀 더 팍팍 뜨면 좋겠다는 의미이다.\n\n이 단점이 그리 대단한 것은 아니다. 스트림릿에서 제공하는 기본 서비스로도 많은 것들을 구현할 수 있다. 하지만 더 간단하고 더 게으르게 뭔가 하고 싶은 나 같은 인간에게는 여전히 복잡하고 거추장스러워 보이기도 한다.\n사실 (개인용) 대시보드를 쓸 때 뭔가를 인터랙티브하게 선택하는 경우는 드물다. 대체로 주요 용도는 내가 보고 싶은 정보를 한번에 모아서 본다는 데 있다. 그 용도가 보는 데에만 있다면 미리 렌더링된 정보를 보여주는 정적 웹(static web)으로 충분하지 않을까? 정적 웹은 Github pages를 비롯해 공짜로 활용할 수 있는 다양한 서비스가 있어 선택의 범위도 넓다!\n\n\n인터렉티비티가 아주 없는 것은 아니다. 여기를 참고하자."
  },
  {
    "objectID": "posts/computer-tool/2024-03-18-lazy-dashboard.html#quarto-dashboards",
    "href": "posts/computer-tool/2024-03-18-lazy-dashboard.html#quarto-dashboards",
    "title": "게으르게 만드는 대시보드",
    "section": "Quarto Dashboards",
    "text": "Quarto Dashboards\n정적인 웹 페이지로 인터랙티비티가 제한된 대시보드(사실상의 웹 페이지)를 만들기로 했다면 툴을 골라보자. 딱 좋은 툴이 있으니 문서 작성 도구 Quarto에서 제공하는 Quarto Dashboards이다. 쿼토에 익숙한 사람이라면 링크의 내용을 보고 그 장점을 쉽게 파악할 수 있을 것이다. 자세한 설명은 생략한다.\n\n\n정적 웹이라고 해서 인터랙티비가 전혀 없는 것은 아니다. 소개되어 있듯이, Plotly, Leaflet, Jupyter Widgets, htmlwidgets 등을 쓸 수 있어서 제한된 수준에서 인터랙티브한 요소를 구현할 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2024-03-18-lazy-dashboard.html#두-가지-문제-그리고-해결책",
    "href": "posts/computer-tool/2024-03-18-lazy-dashboard.html#두-가지-문제-그리고-해결책",
    "title": "게으르게 만드는 대시보드",
    "section": "두 가지 문제 그리고 해결책",
    "text": "두 가지 문제 그리고 해결책\n이렇게 대시보드를 만드는 것까지는 좋은데 당장 떠오르는 두 가지 아쉬운 대목이 있다. (로그인을 포함한) 인증 시스템과 데이터 업데이트의 자동화가 그것이다. 일단 (아쉬운대로 불완전한) 두 가지 해결책을 제시해보자.\n\n최소한의 암호화\n정적 웹은 기본적으로 html 문서로 구성된다. 인증은 해당 문서의 열람 앞에 존재하는 것이고 따라서 그 부재를 탓할 수 없다. 그래도 아쉽다! 깃허브 기준으로 private repo에서 pages를 만들면 전체 공개로 외부에 제공된다. 데이터 업데이트에 필요한 credentials과 같은 민감한 정보는 리포를 private로 만들어 감출 수 있다. 하지만 대시 보드의 내용 자체가 민감한 정보라면 어떻게 해야 할까? 최소한 페이지에 암호라도 있다면 좋을 것이다. 이메일로 전달되는 각종 고지서에 적용된 암호화 정도면 충분한 경우도 있다.\nStaticrypt는 이를 구현해주는 도구다. 이 녀석을 쓰면 html 문서에 암호를 걸 수 있다. 해당 페이지 호출할 때 암호를 먼저 입력해야 내용을 볼 수 있다. 이것이 제대로 된 로그인 시스템이라고 할 수는 없지만 개인적인 용도의 안전 장치로는 족하다.\n\n\n데이터 업데이트\n활용하는 데이터가 변하지 않는다면 해당 데이터를 한번 읽어서 대시보드를 제공하면 그만이다. 하지만 대시보드가 필요한 상황과 맥락에서 데이터가 이렇게 고정되는 상황은 별로 없을 것이다. 데이터를 일정한 주기로 업데이트해야 한다면 어떻게 해야할까? 필요할 때마다 깃허브를 호출해서 페이지를 수동으로 말아도 되겠지만 그리 좋은 방법은 아니다.\n데이터가 고빈도(high frequency)로 변하는 상황이라면 스트림릿과 같은 본격적인 대시보드 도구를 부리는 게 좋다. 업데이트의 빈도가 충분히 낮다면, 깃허브 Actions의 스크립트를 활용해 데이터의 자동 업데이트를 손쉽게 구현할 수 있다.\n깃허브 액션스를 활용하면 리포의 .github/workflows에 들어 있는 yml 파일을 통해 원하는 순서로 리포 내에서 여러가지 작업을 수행할 수 있다. 데이터 업데이트를 위해서 지시할 작업은 간단하다. 이용자가 미리 정해둔 시간 간격으로 문서를 다시 생성하면 된다. 이떄 코드도 같이 실행될텐데 해당 코드에서 업데이트된 데이터를 불러오면 된다.\n\n\n여기서 깃허브 액션스를 자세하게 다루지는 않겠다. 개념은 OS(주로 Ubuntu)를 불러와서 해당 OS 하에서 여러가지 작업을 자동화할 수 있는 도구다. Ubuntu를 좀 써봤다고 쉽게 생각하면 큰 코 다칠 수 있다. 예를 들어 깃헙 페이지스 하나 퍼블리시하는 데에도 여러가지 행동 조합이 필요하다. 따라서 개인지 작성하기 보다는 이미 작성된 actions를 가져다가 쓰는 것이 좋다. yml 코드를 보면 uses: actions/checkout@v4, uses: actions/setup-python@v4와 같은 내용을 볼 수 있다. 사전에 정의된 액션스를 가져다가 쓰는 것이고 필요할 경우 with 구문을 통해서 나에게 맞는 설정을 추가할 수 있다. 이런 식으로 기존에 검증된 actions 스크립트를 쓰는 것이 압도적으로 편리하고 안전하다. 깃허브 페이지스의 퍼블리싱과 관련해서는 여기를 참고하라.\n여기를 보면 GitHub Actions를 통해서 Quarto 문서를 생성하고 퍼블리싱하는 방법이 잘 소개되어 있다. 일정한 시간 단위로 자동화하고 싶다면 코드의 맨 윗 부분을 아래와 같이 수정하면 된다.\non:\n  #schedule:\n    # 실제 스케쥴 작업이 시작될 cron을 등록하면 됩니다.\n    # 크론은 https://crontab.guru/ 여기서 확인하면 좋을 것 같습니다.\n    # 이 크론은 매 4시간 마다 00분 기준으로 실행됩니다.\n    #- cron: '0 */4 * * *'  \n  #workflow_dispatch:    \n  #push:\n  #  branches: main\n  schedule:\n    #- cron: '*/30 * * * *' # 매 30분마다 실행\n    - cron: '0 */3 * * *' # 매 3시간마다 00분 기준으로 실행 \n\n\n\n\n\n\nCode Note\n\n\n\n\non: 어떤 조건에서 스크립트를 실행하는지를 지정한다.\nworkflow_dispatch는 github 웹 페이지에서 수동 실행 버튼을 활성화한다.\npush가 있다면 푸시가 발생했을 때 실행된다.\nschedule이 있다면 일정한 시간 혹은 시간 간격으로 스크립트를 실행할 수 있다. cron은 크론탭의 규칙을 따르고, 유연하게 실행 간격의 룰을 정할 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2024-03-18-lazy-dashboard.html#데이터-업데이트-암호화",
    "href": "posts/computer-tool/2024-03-18-lazy-dashboard.html#데이터-업데이트-암호화",
    "title": "게으르게 만드는 대시보드",
    "section": "데이터 업데이트 + 암호화?",
    "text": "데이터 업데이트 + 암호화?\n앞서 살펴본 두 개의 요소를 조합하는 것도 가능하다! 위의 문서 생성 및 퍼블리시 과정과 압호화 과정을 깃허브 액션스의 스크립트로 구현하면 된다. 깃헙 액션스는 정말로 강력한 기능이다! 액션스를 통해서 아래와 같은 두 가지 과정을 구현할 수 있다.\n\n필요한 데이터 업데이트 반영 후 대시보드 html 생성 및 퍼블리싱\ngh-pages 브랜치에 서브되는 html 페이지의 암호화\n\n해당 두가지 명령을 구현한 코드와 예시 대시보드는 아래와 같다.\n\n예시 리포\n대시 보드\n\n두 번째의 암호는 0000이다. 리포의 Actions의 staticrypt 대목을 뜯어보시면 암호를 설정하는 부분이 있다. 0000 대신 필요한 암호로 바꾸시라. 리포를 포크하거나 복제한 후 private으로 바꿔 사용하면 된다.\n\n\n\n\ncrontab을 설정할 수 있다면 초단위로 해두면 빠른 처리가 가능하지 않을까, 라고 생각할지 모르겠다. 깃허브는 최대 빠른 간격을 5분으로 제한하고 있다. 더 짧은 주기로 크론탭을 설정해도 5분 단위로 돌아간다."
  },
  {
    "objectID": "posts/computer-tool/2020-03-07-blogging-with-fastpages.html",
    "href": "posts/computer-tool/2020-03-07-blogging-with-fastpages.html",
    "title": "Build Your Blog on Github, Easily",
    "section": "",
    "text": "Note\n\n\n\n현재는 fastpages를 활용하고 있지 않습니다. 이유는 두 가지입니다.\n\nfastpages의 지원의 미비\n커스터마이징의 미비함"
  },
  {
    "objectID": "posts/computer-tool/2020-03-07-blogging-with-fastpages.html#tldr",
    "href": "posts/computer-tool/2020-03-07-blogging-with-fastpages.html#tldr",
    "title": "Build Your Blog on Github, Easily",
    "section": "tl;dr",
    "text": "tl;dr\n\n깃헙에서 가장 쉽게 블로그를 빌드할 수 있는 방법을 알아보자.\n디자인은 포기하시라, 마. (지금으로도 사실 훌륭하니까!)"
  },
  {
    "objectID": "posts/computer-tool/2020-03-07-blogging-with-fastpages.html#blogging-with-github",
    "href": "posts/computer-tool/2020-03-07-blogging-with-fastpages.html#blogging-with-github",
    "title": "Build Your Blog on Github, Easily",
    "section": "Blogging with Github",
    "text": "Blogging with Github\n깃헙을 통해 static web 기반의 블로그 / 홈페이지를 운영할 수 있다. 많은 분들이 이미 그렇게 하고 있다. Hugo, Jekyll의 도구를 잘 사용하면 상용 수준의 블로그 운영도 가능하다. 물론 이 도구들을 쓸 경우 관리를 위해서는 약간의 번거로움을 감수해야 한다. Hugo의 경우 R의 BlogDown 패키지를 활용할 수 있다. Jekyll의 경우 Ruby 기반으로 제작되어서 블로그 관리를 위해서는 local에서 해줘야 하는 작업이 있다.1\n이상적인 형태의 블로그 툴이란 무엇일까? 내 생각은 이렇다.\n\n최초의 설정 및 초기 디자인 요소를 제외하면 코드를 수정할 필요가 없어야 한다.\nhtml을 되도록 쓰지 않고, md 형태로 작성한 후 바로 반영이 되어야 한다.\n무료로 제한 없이 호스팅이 가능해야 한다.\n\n3은 깃헙으로 가볍게 해결된다. 1, 2는 사실 좀 어려운 부분이었다. 깃헙을 블로그 툴로 쓰기 위한 일종의 트레이드오프랄까… 2\n이 글에서 소개할 fastpages는 깃헙의 기본 웹툴인 Jekyll을 기반으로 1,2를 구현해주는 이상적인 서비스다. 게다가 fastpages는 ipynb 형태의 노트북, word 파일도 알아서 블로그 페이지로 바꿔준다. 문송한 나로서는 참으로 반가운 서비스다.\n\nBefore we go\n\n이하의 글에서 [your-x-id]라고 표기된 부분은 x라는 서비스의 각자 계정명 등의 정보를 바꿔서 설정해야 하는 부분이다. 그냥 복붙하지 마시라는 말씀.\n[repo root]는 해당 리퍼지토리의 최상위 디렉토리를 나타낸다."
  },
  {
    "objectID": "posts/computer-tool/2020-03-07-blogging-with-fastpages.html#fastpages-by-fast.ai",
    "href": "posts/computer-tool/2020-03-07-blogging-with-fastpages.html#fastpages-by-fast.ai",
    "title": "Build Your Blog on Github, Easily",
    "section": "fastpages by fast.ai",
    "text": "fastpages by fast.ai\n일단 별도의 인스톨 과정이 필요 없다! 사전에 준비해야 할 것은 깃헙 계정 뿐.\n\n페이지 생성\nhttps://github.com/fastai/fastpages/generate\n\n깃헙에 로그인한 상태에서 이 곳에 접속해 페이지를 생성한다. 페이지를 생성한 후 내 깃헙 계정에서 조금 기다리면 “Pull Request”(PR) 메시지가 날아온다.\n\n\n\nPR\nPR을 하기 전에 SSH 키를 생성하는 작업을 해줘야 한다. 메시지에 친절하게 설명이 되어 있으니 그대로 따라하면 된다.\n\n\n링크를 눌러 웹 페이지에서 private key와 public 키를 생성한다. RSA, 4069를 선택하도록 하다.\n두번째의 링크를 눌러 새 sceret을 생성하고 private key를 넣어준다. 이름은 반드시 SSH_DEPLOY_KEY로 해야 한다.\n세번째의 링크를 눌러 deploy key를 생성하고 여기에 public key를 넣어주면 된다. 이름은 임의로 지정하면 된다.\n\n마지막으로 PR를 수락하고 이를 아래 화면 같이 merge하면 준비가 완료된다. 깃헙이 작업을 하는 동안 잠시 기다리면 된다. 작업 상태가 궁금하면 github actions 탭을 확인하면 된다. 이후 몇 가지를 더 묻는데 대충 진행해도 문제 없다.\n\n설치가 끝나면 아래와 같이 생성된 페이지를 확인할 수 있다. 아래는 위의 절차에 따라서 테스트계정(test-fastpages)에 페이지를 생성한 결과다.\nhttps://anarinsk.github.io/test-fastpages/"
  },
  {
    "objectID": "posts/computer-tool/2020-03-07-blogging-with-fastpages.html#customize-yours",
    "href": "posts/computer-tool/2020-03-07-blogging-with-fastpages.html#customize-yours",
    "title": "Build Your Blog on Github, Easily",
    "section": "Customize yours",
    "text": "Customize yours\n이제 각자의 취향에 맞게 몇 가지 커스터마이즈를 거치면 된다. 대체로 md를 고치면 되기 때문에 크게 어려운 대목은 없다.\n\nhome\n\nrepo root의 index.md를 적당히 수정하면 된다.\n\nabout\n\n[repo root]/_pages/about.md 를 수정하면 된다.\n\ncomments\n\nutterances 앱을 깔면, github의 issue 기능을 활용해 코멘트를 관리할 수 있다.\n인스톨 페이지의 안내대로 하면 된다.\n별도로 뭘 까는 것은 아니고 github 계정의 해당 repo를 설정하면 끝.\n다만 코멘트를 달기 위해서는 github 계정이 필요하다.\n\nfavicon\n\n[repo root]/images의 favicon.ico를 고치면 된다.\n\n그림 관리\n\n[repo root]/images에 적절한 디렉토리를 만들어 관리하면 된다.\n그림 링크는 ![](https://raw.githubusercontent.com/anarinsk/lostineconomics-v2-1/master/images/git-cmder/fig_3.png) 식으로 { site.baseurl }로 시작하면 된다.\n\ncss\n\ncss를 다룰 줄 안다면 블로그의 많은 것은 커스터마이즈할 수 있다.\n[repo root]/_sass/minima안에 보면 custom-styles.scss와 fastpages-styles.scss 두 개가 있다. custom-styles.scss에 부가 내용을 수정하면 스타일을 바꿀 수 있다. 필요한 폰트를 로딩해 설정한다든가 하는 디자인 수정 사항을 여기에 넣으면 된다.\n예를 들어 기본 텍스트의 크기를 바꾸고 싶다면,\n\n\n.post-content  p, .post-content  li {\n    font-size: 15px; //원래값은20px\n    color: #515151;\n    }\n\ngoogle analytics\n\n먼저 google analytics id가 필요하다. 알아서 발급 받으시라.\n\n구글 페이지에도 안내가 되어 있지만, gs 모듈을 활용하기 위해서 [repo root]/_include에 google_analytics.html과 같은 파일을 만들어 아래의 내용을 넣는다. 물론 자신의 analytics id로 바꿔 넣어야 한다.\n\n\n&lt;!-- Global site tag (gtag.js) - Google Analytics --&gt;\n&lt;script  async  src=\"https://www.googletagmanager.com/gtag/js?id=[your-ga-id]\"&gt;&lt;/script&gt;\n&lt;script&gt;\n    window.dataLayer = window.dataLayer || [];\n    function  gtag(){dataLayer.push(arguments);}\n    gtag('js', new  Date());\n    gtag('config', '[your-ga-id]');\n    gtag('set', {'user_id':  'USER_ID'}); // 로그인한 User-ID를 사용하여 User-ID를 설정합니다.\n&lt;/script&gt;\n\n[repo root]/_include의 custom_head.html의 적당한 줄에 아래 코드를 넣어준다.\ngoogle analytics의 ‘실시간’ 항목에서 작동 여부를 확인할 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2020-03-07-blogging-with-fastpages.html#활용",
    "href": "posts/computer-tool/2020-03-07-blogging-with-fastpages.html#활용",
    "title": "Build Your Blog on Github, Easily",
    "section": "활용",
    "text": "활용\n\nPost 작성\n통상적인 md 파일로 작성하면 된다. 두 가지만 주의하면 된다. 우선 파일 이름을 년도-월-일-이름.md 형태로 넣어야 한다. 그래야 fastpages가 컴파일을 할 수 있다. 예를 들어 이 포스팅의 파일 이름은 2020-03-07-blogging-with-fastpages.md다.\n둘째, 포스팅 만 앞에 yml을 넣어 해당 포스트에 관한 정보를 지정해야 한다.\n---\nlayout: post # 글의 레이아웃, 보통이라면 post로 두면 된다. \ntoc: false # 목차 출력 여부 \ncomments: true # 코멘트 기능 사용 여부 \ntitle: Free Your Blog with Github # 제목 \ndescription: github에서 무료 블로그를! # 제목 아래 부제목 \ncategories: [coding-tool, web-tool] # tag 혹은 카테고리 \n---\n---으로 감싼 후 안에 정보를 넣으면 된다.\n\n\nfastpage의 몇가지 장점\n\n보통 github 기반의 블로그를 만들면, [your-git-id].github.io만을 주소로 가지게 된다. fastpages를 쓰면 repo 수준의 홈페이지를 운영할 수 있다. 예를 들어, 이 블로그의 주소는 anarinsk.github.io/lostineconomics-v2-1다.\n강력한 장점은 ipynb 확장자의 노트북 파일을 그대로 포스팅으로 바꿔준다는 것이다. [repo root]/_notebooks에 파일을 넣어주면 된다.\n\n디자인은 포기하라. css나 html을 잘 안다면 커스터마이즈할 여지가 있지만, 그럴 수 있는 사람이라면 Hugo나 Jekyll을 직접 쓰는 편이 나을 수도 있겠다.\n\nfastpages가 사용하는 Jekyll 테마는 minima다.\n\n매번 markdown을 에디터에 올려쓰는 것이 불편하다면 웹 에디터를 활용할 수 있다.\n\nstackedit의 경우 github 저장을 지원하기 때문에 해당 repo의 _posts/ 아래의 md 문서를 동기화해두면 웹에서 수정 후 동기화하는 것만으로도 포스트의 수정을 쉽게 할 수 있다. stackedit의 활용에 관해서는 이 포스팅을 참고하면 좋겠다. 사실 웹에서 이렇게 수준 높은 마크다운 에디터를 제공한다는 사실이 고맙고 놀랍다. (그래서 나는 이 회사에 매년 기부한다!)\n\nfastpages의 경우 commit이 발생하면 자동으로 블로그의 빌드에 들어간다.\n\n따라서 웹 에디터에서 글을 수정한 후 적절한 주소를 지정해주고 동기화를 하면, 즉 커밋을 하면 바뀐 내용을 반영해 블로그가 다시 빌드 된다."
  },
  {
    "objectID": "posts/computer-tool/2020-03-07-blogging-with-fastpages.html#update는-어떻게-하지",
    "href": "posts/computer-tool/2020-03-07-blogging-with-fastpages.html#update는-어떻게-하지",
    "title": "Build Your Blog on Github, Easily",
    "section": "Update는 어떻게 하지?",
    "text": "Update는 어떻게 하지?\n블로그 자체의 Jekyll 기반 코드들도 업데이트될텐데, 이건 어쩌나 생각하셨다면 걱정할 필요가 없다. 깃헙에서 제공하는 PR 기능을 활용해서 내 리포지토리까지 거의 자동으로 업데이트해준다. 다만 커스터마이즈를 많이 했다면 지원이 안될 수도 있다는 점에 유념하시라. - issues &gt; New issue &gt; Get started를 누르면 아래의 그림을 볼 수 있다.\n\n여기서 아무 것도 바꾸지 말고 Submit new issue를 하면 업데이트 요청이 들어가고 업데이트 사항이 없을 경우는 이슈가 그낭 종결되고 있을 경우는 그대로 따라가면 된다. 처음 페이지를 깔 때처럼 PR을 해주는 형태로 진행된다. 꽤나 영리한 업데이트 방법이다.\n\n바뀌는 파일들\n아직까지는 사소한 업데이트만 진행되는 듯 싶다. PR을 완료한 이후 커밋 메시지에 “upgrade fastpages”라고 적혀 있는 부분을 확인해서 커스터마이즈한 부분을 적당히 바꾸면 된다. _pages/about.md, |includes/custom_head.html 와 같이 커스터마이즈해둔 파일들도 바뀌게 되는 경우가 종종 있으므로 항상 백업본을 어딘가 로컬에 유지해두는 편이 좋겠다."
  },
  {
    "objectID": "posts/computer-tool/2020-03-07-blogging-with-fastpages.html#footnotes",
    "href": "posts/computer-tool/2020-03-07-blogging-with-fastpages.html#footnotes",
    "title": "Build Your Blog on Github, Easily",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n자세한 내용은 여기을 참고하라. 미리 말하면 fastpages는 이런 로컬의 작업을 깃헙 서버에게 대신 시키고 완성된 html은 바로 깃헙 페이지(깃헙의 무료 웹호스팅 서비스)로 보여주는 방식으로 돌아간다. 참으로 은혜로운 서비스다.↩︎\n이 블로그의 v1을 html로 만든 이유이기도 하다. v1은 html까지 완성한 후 이를 깃헙이 호스팅하도록 하는 원시적인 방법을 썼다. 이에 관해서는 이 포스팅을 참고하라.↩︎"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Who am I?\n허준석 Junsok Huhh | Ph.D. in Economics  Currently works as a data scientist (Pangyo, South Korea).\n\n안녕하세요. 허준석의 블로그입니다. 쓸데 없고 목적 없는 블로그입니다. 뭐라도 도움이 되면 좋겠습니다. 이 블로그는 네번째 버전입니다. 이전 블로그의 역사는 아래 “History of lostineconomics.com”에서 확인하실 수 있습니다.\n블로그의 이름 “lost in economics”는 현재 저의 처지와 같습니다. 경제학에서 길을 잃었지만 여전히 그 안에 빠져 있습니다. 블로그는 Quarto로 제작되었고, 페이지 호스팅은 Github Pages를 이용합니다.\nHi, I’m Junsok Huhh. If you are interested in me, check my c.v. and contact. The blog name, “lost in economics” has double-edge meaning. In one way, I lost my way in economics, but I am still finding a way in it. This blog is serviced by Quarto and Github Pages.\n\n\n\nC.V.\nBrief | Long\n\n\n\nHistory of lostineconomics.com\n\nv3 built with Quarto and Github Pages ⛧⛧⛧\nv2 built with fastpages and Github Pages\nv1 built with markdown and Github\nv0 built with BlogDown and Github Pages\n\n🐈 🐈 🐈 삽화는 Bing의 이미지 작성자에서 a cat lost in something, digital art 키워드로 생성되었습니다. 🐈 🐈 🐈 폰트는 SUIT, SUITE, D2Coding의 웹폰트를 사용합니다."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "This is the page where research papers and research notes written by Junsok Huhh are listed. If you have any question/comment, please contact me\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecomposing Sales by ARPPU and PU\n\n\n\n\n\n\nmobile-game\n\n\n\nA deep dive into the sales of a mobile game, breaking down the revenue change by the changes of Average Revenue Per Paying User(ARPPU) and Paying Users(PU).\n\n\n\n\n\nMay 23, 2024\n\n\nJunsok Huhh\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "lostineconomics.com",
    "section": "",
    "text": "Google Sheet와 파이썬 연동하기\n\n\n\n\n\n\ncomputer-tool\n\n\ngoogle-sheet\n\n\ndashboard\n\n\n\n데이터 앱 만들기의 시작\n\n\n\n\n\nJun 6, 2024\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nPixi와 쓰는 R과 Julia\n\n\n\n\n\n\ncomputer-tool\n\n\nr-stat\n\n\npixi\n\n\n\n꼬이면 지우고 말지!\n\n\n\n\n\nApr 3, 2024\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\n게으르게 만드는 대시보드\n\n\n\n\n\n\ncomputer-tool\n\n\ndocument-tool\n\n\nquarto\n\n\n\n소박하고 개인적인\n\n\n\n\n\nMar 18, 2024\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\np값? 너무 믿지 마세요\n\n\n\n\n\n\nstatistics\n\n\nstats-simple\n\n\n\n영가설을 기각하기에 충분한 근거일까?\n\n\n\n\n\nFeb 28, 2024\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nMatrix Algebra and Neural Networks\n\n\n\n\n\n\nthe-lectures\n\n\nmachine-learning\n\n\n\n선형 대수는 어떻게 표현을 간략하게 만드는가?\n\n\n\n\n\nFeb 22, 2024\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nAttention Model\n\n\n\n\n\n\nthe-lectures\n\n\nmachine-learning\n\n\n\n관심은 어떻게 네트워크에 반영될까?\n\n\n\n\n\nFeb 16, 2024\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nSequence to Sequence Model\n\n\n\n\n\n\nthe-lectures\n\n\nmachine-learning\n\n\n\nEncoder-Decoder 구조를 알아보자.\n\n\n\n\n\nFeb 15, 2024\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\n현실( 정치)에서 경제학자의 역할\n\n\n\n\n\n\neconomics\n\n\necon-simple\n\n\n\n기회가 왔을 때 쓸 수 있는 아이디어를 벼려야\n\n\n\n\n\nFeb 14, 2024\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nLong Short-Term Memory (LSTM) Network\n\n\n\n\n\n\nthe-lectures\n\n\nmachine-learning\n\n\n\nRNN의 문제를 해결해보자.\n\n\n\n\n\nFeb 14, 2024\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nRecurrent Neural Network\n\n\n\n\n\n\nthe-lectures\n\n\nmachine-learning\n\n\n\nRNN에 대해서 알아보자.\n\n\n\n\n\nFeb 14, 2024\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nTransformer\n\n\n\n\n\n\nthe-lectures\n\n\nmachine-learning\n\n\n\nTransformer 찍먹하자.\n\n\n\n\n\nFeb 13, 2024\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nBusy Person’s Intro to LLMs\n\n\n\n\n\n\nthe-lectures\n\n\nmachine-learning\n\n\n\nLLM에 관해 알아야 할 두세 가지 것들\n\n\n\n\n\nFeb 8, 2024\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nWord2Vec\n\n\n\n\n\n\nthe-lectures\n\n\nmachine-learning\n\n\n\nWord2Vec에 대한 기본 이해\n\n\n\n\n\nFeb 7, 2024\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\n이한, “조선사 쩐의 전쟁”\n\n\n\n\n\n\nthe-books\n\n\n\n조선은 ’조선’이 아니야!\n\n\n\n\n\nFeb 5, 2024\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\n렌조 미키히코, “백광”\n\n\n\n\n\n\nthe-books\n\n\n\n놀라운 추리 소설\n\n\n\n\n\nJan 30, 2024\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\n윈도 작업 환경을 기록한다\n\n\n\n\n\n\nwalk-through\n\n\npc-install\n\n\n\nWindows와 Linux의 컬래버\n\n\n\n\n\nNov 3, 2023\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nUbuntu를 깔고 먼저 해야 할 일들\n\n\n\n\n\n\ncomputer-tool\n\n\npc-install\n\n\nos\n\n\n\n우분투 설치 후 이것부터!\n\n\n\n\n\nNov 3, 2023\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\n양성관, “마약 하는 마음, 마약 파는 사회”\n\n\n\n\n\n\nthe-books\n\n\n\n재미는 있지만, 좀 장황하다\n\n\n\n\n\nOct 27, 2023\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nPerfectly Codespaces\n\n\n\n\n\n\ncomputer-tool\n\n\ncoding\n\n\n\n거의 완벽한 클라우드 코딩 환경\n\n\n\n\n\nOct 20, 2023\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\n소박한 가정용 웹서버\n\n\n\n\n\n\ncomputer-tool\n\n\nwalk-through\n\n\n\n싸게 만들어보자.\n\n\n\n\n\nSep 21, 2023\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\npixi\n\n\n\n\n\n\ncomputer-tool\n\n\ncoding\n\n\npixi\n\n\n\n의존성 지옥을 벗어날 또 다른 방법\n\n\n\n\n\nAug 27, 2023\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nJulia + VS Code\n\n\n\n\n\n\ncomputer-tool\n\n\ncoding\n\n\n\nJulia를 빠르게 찍먹해보자\n\n\n\n\n\nAug 15, 2023\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\n조건 명제 그리고 부정\n\n\n\n\n\n\nmath-simple\n\n\n\n\\(\\implies\\)를 따져보자\n\n\n\n\n\nJun 26, 2023\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nRye\n\n\n\n\n\n\ncomputer-tool\n\n\ncoding\n\n\n\n꽤 편리한 Python 가상 환경\n\n\n\n\n\nMay 29, 2023\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nQuick Ready for Python in Windows\n\n\n\n\n\n\ncomputer-tool\n\n\ncoding\n\n\n\n파이썬 작업환경을 빠르게 구축하기\n\n\n\n\n\nMay 16, 2023\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nPower to Powershell!\n\n\n\n\n\n\ncomputer-tool\n\n\npc-install\n\n\n\n윈도11에서 PS 잘 쓰기\n\n\n\n\n\nMay 11, 2023\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\n존 리스트, “스케일의 법칙”\n\n\n\n\n\n\nthe-books\n\n\n\n그냥 또 하나의 경제학책?\n\n\n\n\n\nMar 13, 2023\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\n내 도메인을 GitHub Pages에 연결하자.\n\n\n\n\n\n\ncomputer-tool\n\n\nweb\n\n\n\n도메인을 도메인 답게!\n\n\n\n\n\nDec 22, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nJupyterLite + GitHub Pages\n\n\n\n\n\n\ncomputer-tool\n\n\ncoding\n\n\n\n인스톨이 필요 없는 주피터 노트북!\n\n\n\n\n\nDec 6, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nmatplotlib + 한글 Redux\n\n\n\n\n\n\ncomputer-tool\n\n\ncoding\n\n\n\n마지막으로 정리해봅시다!\n\n\n\n\n\nDec 4, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nShannon’s Entropy\n\n\n\n\n\n\nmachine-learning\n\n\n\n섀넌 엔트로피를 슬쩍 본다.\n\n\n\n\n\nNov 29, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nParadox of Friendship\n\n\n\n\n\n\nmath-simple\n\n\n\n역설을 수학적으로 풀어보자\n\n\n\n\n\nOct 5, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nRSA, Simply Explained\n\n\n\n\n\n\nmath-simple\n\n\n\n나 놈을 위한 RSA 정리\n\n\n\n\n\nOct 3, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\rm\\LaTeX\\) + VS Code\n\n\n\n\n\n\ncomputer-tool\n\n\ndocument-tool\n\n\n\nTiny\\(\\rm\\TeX\\)으로 모든 OS에서 쉽게!\n\n\n\n\n\nSep 25, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\n단순하고 깔끔한 윈도 분석 환경\n\n\n\n\n\n\ncomputer-tool\n\n\nos\n\n\n\nwinget으로 일관되게 쓰자\n\n\n\n\n\nAug 13, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nPresentation with Reveal.js\n\n\n\n\n\n\ncomputer-tool\n\n\ndocument-tool\n\n\nquarto\n\n\n\nQuarto로 편하게!\n\n\n\n\n\nJul 7, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nCantor’s Theorem\n\n\n\n\n\n\nmath-simple\n\n\n\n칸토어의 정리를 증명해 보자.\n\n\n\n\n\nJul 3, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nBerkson’s Paradox with Regression\n\n\n\n\n\n\nregression\n\n\nstats-simple\n\n\n\n어떤 변인을 고려하지 말아야 할까?\n\n\n\n\n\nJun 6, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nSimpson’s Paradox with Regression\n\n\n\n\n\n\nregression\n\n\nstats-simple\n\n\n\n펭귄의 부리로 직접 계산해보자.\n\n\n\n\n\nJun 5, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nMarkov and Chebyshev Inequalities\n\n\n\n\n\n\nstats-simple\n\n\n\n\n\n\n\n\n\nMay 30, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\n정규성에 집착하지 말자.\n\n\n\n\n\n\nregression\n\n\n\n만일 당신의 표본 크기가 충분하다면…\n\n\n\n\n\nMay 28, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nSample Statistics and Standard Error\n\n\n\n\n\n\nstatistics\n\n\nstats-simple\n\n\n\n기본 용어 정리한다.\n\n\n\n\n\nMay 27, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\n전체와 부분\n\n\n\n\n\n\nregression\n\n\n\nConfounder, Collider, Simpson’s and Berkson’s Paradox\n\n\n\n\n\nMay 26, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nPyTorch + WSL\n\n\n\n\n\n\ncomputer-tool\n\n\nmachine-learning\n\n\ncoding\n\n\n\n이보다 더 좋을 수 있을까?\n\n\n\n\n\nMay 25, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nTrilemma, Lately\n\n\n\n\n\n\neconomics\n\n\n\n거시 경제의 트릴레마와 스테이블 코인의 트릴레마\n\n\n\n\n\nMay 16, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nBlogging with Quarto\n\n\n\n\n\n\ncomputer-tool\n\n\ndocument-tool\n\n\nquarto\n\n\n\nQuarto로 블로그를\n\n\n\n\n\nMay 14, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nHow to make a manageable C.V.\n\n\n\n\n\n\ncomputer-tool\n\n\ndocument-tool\n\n\n\nmarkdown으로 이력서를 만들어보자.\n\n\n\n\n\nMay 10, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\n수입은 GDP에 영향을 주는가?\n\n\n\n\n\n\neconomics\n\n\necon-simple\n\n\n\nGDP 항등식을 오해하지 말자\n\n\n\n\n\nApr 29, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nHappy Git-ing!\n\n\n\n\n\n\ngit\n\n\n\n모든 플랫폼에서 git과 github 잘 쓰기\n\n\n\n\n\nApr 27, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nKubernetes As an Alternative to Docker\n\n\n\n\n\n\ncontainer\n\n\n\nDocker의 대안으로 K8s를 써보자!\n\n\n\n\n\nApr 26, 2022\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nPython in the Browser\n\n\n\n\n\n\ncomputer-tool\n\n\ncoding\n\n\n\n브라우저에서 python을 돌린다굽쇼?\n\n\n\n\n\nNov 19, 2021\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nEnter the Podman!\n\n\n\n\n\n\ncontainer\n\n\n\nDocker Desktop 없이 WSL에서 Podman으로 콘테이너를 써보자\n\n\n\n\n\nSep 13, 2021\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nDocker + Jupyter + 한글 폰트\n\n\n\n\n\n\ncontainer\n\n\ncomputer-tool\n\n\n\n빌드할 때 Jupyter의 한글 문제도 같이 해결하자!\n\n\n\n\n\nMay 9, 2021\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nAll into VS Code\n\n\n\n\n\n\ncomputer-tool\n\n\ncoding\n\n\n\nPython, Julia, R을 하나의 도구로 코딩하자.\n\n\n\n\n\nFeb 2, 2021\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nEigenspace, part 2\n\n\n\n\n\n\nlinear-algebra\n\n\n\n아이겐 공간을 이해하자.\n\n\n\n\n\nJan 18, 2021\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nEigenspace, part 1\n\n\n\n\n\n\nlinear-algebra\n\n\n\n아이겐 공간을 이해보자.\n\n\n\n\n\nJan 10, 2021\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nBasis\n\n\n\n\n\n\nlinear-algebra\n\n\n\n두서 없이 정리\n\n\n\n\n\nJan 8, 2021\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nMatrix as Linear Transformation\n\n\n\n\n\n\nlinear-algebra\n\n\n\nMatrix as Linear Transformation\n\n\n\n\n\nJan 7, 2021\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nVector Geometrically, part 2\n\n\n\n\n\n\nlinear-algebra\n\n\n\n벡터 공간의 기하적 특성\n\n\n\n\n\nJan 6, 2021\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nVector Geometrically, part 1\n\n\n\n\n\n\nlinear-algebra\n\n\n\n벡터 공간의 기하적 특성\n\n\n\n\n\nJan 5, 2021\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nProjection and Distance\n\n\n\n\n\n\nlinear-algebra\n\n\n\n프로젝션과 거리 측정에 관해 알아보자.\n\n\n\n\n\nDec 16, 2020\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Log-Linear Regression Model\n\n\n\n\n\n\nregression\n\n\n\n로그 선형 모델의 베타를 어떻게 볼까?\n\n\n\n\n\nNov 11, 2020\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nViva, Binder!\n\n\n\n\n\n\ncomputer-tool\n\n\ncoding\n\n\n\n코드 셰어링, 이제 걱정 끝\n\n\n\n\n\nOct 27, 2020\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\rm\\LaTeX\\) in Modern Ways\n\n\n\n\n\n\ncomputer-tool\n\n\ndocument-tool\n\n\n\n\\(\\rm\\LaTeX\\)을 다시 써볼까?\n\n\n\n\n\nOct 24, 2020\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nThe Best Terminal App for Windows\n\n\n\n\n\n\ncomputer-tool\n\n\n\n윈도 터미널 잘 쓰기\n\n\n\n\n\nSep 26, 2020\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nDocker 컨테이너 + 한글 폰트\n\n\n\n\n\n\ncontainer\n\n\ncomputer-tool\n\n\n\n컨테이너 안에서도 한글을 써보자\n\n\n\n\n\nSep 24, 2020\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nDocker, 소박한 사용법\n\n\n\n\n\n\ncontainer\n\n\n\n문과생이 도커를 쓰는 법\n\n\n\n\n\nSep 23, 2020\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian Inference with MCMC\n\n\n\n\n\n\nmath-of\n\n\n\nMCMC 기억 되살리기\n\n\n\n\n\nJul 3, 2020\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nMetrics for Binary Classification\n\n\n\n\n\n\nmachine-learning\n\n\n\n이항 분류 지표 정리합니다.\n\n\n\n\n\nApr 19, 2020\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nwsl 2, a walk-thru\n\n\n\n\n\n\ncomputer-tool\n\n\nos\n\n\n\nwsl 2의 열기를 느껴보아요!\n\n\n\n\n\nApr 9, 2020\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nStreamlit + Heroku\n\n\n\n\n\n\ncomputer-tool\n\n\n\n이제는 쓰지 않는 낡은 내용입니다…\n\n\n\n\n\nMar 9, 2020\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nBuild Your Blog on Github, Easily\n\n\n\n\n\n\ncomputer-tool\n\n\n\n이제는 쓰지 않는 낡은 내용입니다…\n\n\n\n\n\nMar 7, 2020\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Git ‘Smoothly’ in Windows 10\n\n\n\n\n\n\ngit\n\n\n\n이제는 쓰지 않는 낡은 내용입니다…\n\n\n\n\n\nMar 5, 2020\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nThe College Wealth Divide\n\n\n\n\n\n\neconomics\n\n\n\n미국 대졸자와 비대졸자의 투자 행태에 따른 부의 불평등\n\n\n\n\n\nJan 22, 2020\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nPageRank as Markov Chain\n\n\n\n\n\n\nmath-of\n\n\n\n마르코프 체인에서 페이지랭크를 보다.\n\n\n\n\n\nDec 24, 2019\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nPerron-Frobenius Theorem, part 2\n\n\n\n\n\n\nmath-of\n\n\n\n페론-프로베니우스 정리 살펴보기\n\n\n\n\n\nDec 20, 2019\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nPerron-Frobenius Theorem, part 1\n\n\n\n\n\n\nmath-of\n\n\n\n페론-프로베니우스 정리 살펴보기\n\n\n\n\n\nDec 11, 2019\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nEigenvalues and Eigenvectors\n\n\n\n\n\n\nlinear-algebra\n\n\n\n고유치와 고유벡터에 관해 알아보자.\n\n\n\n\n\nDec 3, 2019\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Logit Regression\n\n\n\n\n\n\nregression\n\n\n\n로지스틱 회귀를 이해해봅시다!\n\n\n\n\n\nNov 10, 2019\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Regression\n\n\n\n\n\n\nregression\n\n\n\n회귀 분석, 기하학적으로 한 방에 깨우치기\n\n\n\n\n\nOct 25, 2019\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nDot Product with Geometry\n\n\n\n\n\n\nmath-simple\n\n\n\n기하학적으로 내적을 살펴보자.\n\n\n\n\n\nJul 18, 2019\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson as Binormial Distribution\n\n\n\n\n\n\nmath-simple\n\n\n\n이항 분포의 관점에서 푸아송 분포 이해하기\n\n\n\n\n\nJul 13, 2019\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nMath Behind PCA\n\n\n\n\n\n\nmath-of\n\n\n\nPCA의 수학적 이해\n\n\n\n\n\nMay 17, 2019\n\n\nJS HUHH\n\n\n\n\n\n\n\n\n\n\n\n\nMathematics of Support Vector Machine\n\n\n\n\n\n\nmath-of\n\n\n\nSVM의 수학\n\n\n\n\n\nMay 6, 2019\n\n\nJS HUHH\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "Mostly Useless\n대부분 쓸모 없는 개인 프로젝트 저장소입니다. 역시 뭐라도 도움이 될 수 있다면 저는 기쁠 따름!\n\n\n\nEconomic Index Board\n⛧ Ouput: Anari Sees US Economy\n개인적으로 보려고 만든 경제 지표 보드입니다. 고급스럽게 웹 개발을 하면 좋았겠지만 Quarto Dashboards를 초보적으로 활용했습니다.\n\n\nJupyterLite\n⛧ Ouput: Customized JupyterLite | Post: LINK\nJupyterLite는 Wasm(웹 어셈블리)로 구현되는 경량화된 쥬피터IDE + Python 개발 환경입니다. 사용성에 제한이 있지만 파이썬 코딩 경험이 말할 수 없이 빨리지고 편리해집니다!\n\n\nPresentation with Quarto & Reveal.js\n⛧ Ouput: Useless PT | Post: LINK\nQuarto는 Reveal.js를 부릴 수 있습니다. Quarto를 이용한 PT 제작에는 다음과 같은 장점이 있습니다.\n\nhtml로 구성되어 있어서 웹 브라우저 이외에 별도의 소프트웨어가 필요하지 않습니다.\nGitHub Pages를 통해서 퍼블리시할 수 있습니다.\n이런 저런 ’디자인 지옥’에 고통받지 않을 수 있습니다!\n\n⛧ Ouput: More on Quarto + Reveal.js\n\n위 프로젝트의 자매품입니다. 몇 가지 추가적인 기능을 다루었습니다.\n\n\n\nGenerating CV in GitHub\n⛧ Oputput: short CV | Post: LINK\n깃허브의 markdown과 Pages 기능을 활용해 자동으로 CV를 생성하고 웹으로 배포할 수 있습니다. 아직 100% 만족스럽지 않지만 게으르게 쓸만한 할 정도 됩니다.\n 🐈 🐈 🐈 삽화는 Bing의 이미지 작성자에서 many old statues of tiny gods, digital art 키워드로 생성되었습니다."
  },
  {
    "objectID": "posts/computer-tool/2023-05-16-workflow-with-vscode.html",
    "href": "posts/computer-tool/2023-05-16-workflow-with-vscode.html",
    "title": "Quick Ready for Python in Windows",
    "section": "",
    "text": "윈도11 환경에서 powershell, conda 가상환경, VS Code로 빠르게 Python 환경을 설정하기\n\n\n\n\n각각의 프로덕트에 대한 상세한 소개와 이용법\n\n\n\n\n\n윈도에서 편리하게 파이썬 작업 환경에 이르는 길"
  },
  {
    "objectID": "posts/computer-tool/2023-05-16-workflow-with-vscode.html#tl-dr",
    "href": "posts/computer-tool/2023-05-16-workflow-with-vscode.html#tl-dr",
    "title": "Quick Ready for Python in Windows",
    "section": "",
    "text": "윈도11 환경에서 powershell, conda 가상환경, VS Code로 빠르게 Python 환경을 설정하기\n\n\n\n\n각각의 프로덕트에 대한 상세한 소개와 이용법\n\n\n\n\n\n윈도에서 편리하게 파이썬 작업 환경에 이르는 길"
  },
  {
    "objectID": "posts/computer-tool/2023-05-16-workflow-with-vscode.html#왜-powershell-miniconda-vs-code를-써야-하는가",
    "href": "posts/computer-tool/2023-05-16-workflow-with-vscode.html#왜-powershell-miniconda-vs-code를-써야-하는가",
    "title": "Quick Ready for Python in Windows",
    "section": "왜 PowerShell, miniconda, VS Code를 써야 하는가?",
    "text": "왜 PowerShell, miniconda, VS Code를 써야 하는가?\nPowerShell(PS) + miniconda + VS Code 묶음이 ’최선’의 선택이 아니다. 내 기준에서 이 앱들은 윈도11 환경에서 일관되고 단순한 Python 환경을 만드는 데 필요한 최소 집합이다.\n\nPowerShell: 셸을 써서 miniconda를 통해 기본적인 파이썬 환경을 제어할 것이다. 따라서 PS가 기본적으로 필요하다.\nminiconda: 본격적인 개발 용도라면 conda 가상 환경이 충분하지 않다. 하지만 개인 프로젝트 용도로 이 만큼 편리한 것도 없다. 불필요한 앱들이 따라 붙는 anaconda 대신 우리는 단촐하게 miniconda를 쓸 것이다.\nVS Code: Python 개발 환경과 Jupyter 환경 모두를 편리하게 부릴 수 있다. 다른 선택의 여지를 돌아볼 필요조차 없을 만큼 윈도에서는 최강의 에디터이다."
  },
  {
    "objectID": "posts/computer-tool/2023-05-16-workflow-with-vscode.html#prelim",
    "href": "posts/computer-tool/2023-05-16-workflow-with-vscode.html#prelim",
    "title": "Quick Ready for Python in Windows",
    "section": "Prelim",
    "text": "Prelim\n\nPS 설치 및 세팅 완료\nminiconda 설치 완료\nVS Code 설치 완료 및 각종 extension 설치"
  },
  {
    "objectID": "posts/computer-tool/2023-05-16-workflow-with-vscode.html#가상-환경-생성",
    "href": "posts/computer-tool/2023-05-16-workflow-with-vscode.html#가상-환경-생성",
    "title": "Quick Ready for Python in Windows",
    "section": "가상 환경 생성",
    "text": "가상 환경 생성\n먼저 conda에서 가상 환경을 생성해보자.\n&gt; conda create -n {가상환경-이름} python={파이썬 버전}\n이 명령을 통해 특정 버전의 파이썬을 백엔드로 하는 가상환경을 만들 수 있다. 생성 후 원하는 환경이 잘 생성되었는지를 확인해보자.\n❯ conda env list\n# conda environments:\n#\nbase                     C:\\Users\\junsokhuhh\\Miniconda3\npandas=2.0_python=3.11  *  C:\\Users\\junsokhuhh\\Miniconda3\\envs\\pandas=2.0_python=3.11\ntorch=2.0_python=3.11     C:\\Users\\junsokhuhh\\Miniconda3\\envs\\torch=2.0_python=3.11\n예시에서 보듯이 생성된 환경의 이름과 경로 그리고 활성화된 환경이 *로 표기된다. 해당 환경을 복사하거나 지우고 싶다면 conda 명령어를 활용할 수 있다. 보다 직관적으로 편리한 방법은 저 폴더에 대해서 직접 복사하거나 지워서 환경을 복제, 삭제하는 것이다. 폴더 구조만 유지되면 conda에서 가상 환경으로 잘 인식된다.\n\n\n각자 환경의 이름을 짓는 법을 고민해두면 좋다. 내 경우 대 분류를 _로 구별하고 그 앞에 쓰는 주요 패키지의 버전을 위 예시처럼 명시한다. 이렇게 해두면 나중에 봤을 떄 혼란이 덜 발생한다.\n해당 환경을 활성화하려면 conda activate {가상환경-이름}, 비 활성화는 conda deactivate다.\n환경을 활성화한 후 필요한 패키지를 설치하면 된다. Jupyter를 활용할 예정이라면 꼭 주피터를 깔어주도록 하자.\n&gt; pip3 install jupyter"
  },
  {
    "objectID": "posts/computer-tool/2023-05-16-workflow-with-vscode.html#jupyter-vs-code",
    "href": "posts/computer-tool/2023-05-16-workflow-with-vscode.html#jupyter-vs-code",
    "title": "Quick Ready for Python in Windows",
    "section": "Jupyter + VS Code",
    "text": "Jupyter + VS Code\n파이썬을 부리기 위해서 VS Code에서 깔아야 하는 Extension은 Python, Pylance, Jupyter 확장이다. 모두 Microsoft에서 제공하는 것이니 의심 없이 설치하면 된다. 각각 필요한 몇 가지 확장이 함께 깔리게 되니 이 점 유의하시라. 설치 후에 VS Code에서 .ipynb을 열어보자. 이전에 설정된 kernel이 없다면 Jupyter에서 부릴 커널을 새로 설정해야 한다.\n커널을 선택을 누르면, “파이썬 환경”과 “기존 Jupyter 서버” 중 하나를 선택할 수 있다. 전자를 택하면 앞서 설정한 miniconda의 환경이 잘 보인다. 필요한 환경을 선택하고 녀석을 VS Code의 Jupyter 환경으로 작업하면 된다. 아래 스크린 샷을 보면 순서대로 1(현재 이용 중인 커널), 2(커널 선택), 3(주피터 파이썬 환경 선택), 4(파이썬 환경 선택)의 화면에서 필요한 내용을 선택하면 된다.\n\n\n\nVS Code 커널 선택 (클릭하면 확대)\n\n\n기존 주피터 환경보다는 단순한 형태지만, VS Code에서는 GitHub Copilot을 함께 쓸 수 있다. 모든 단점을 상쇄하고도 남는다.\n\n\n\nVS Code 커널 선택 (클릭하면 확대)"
  },
  {
    "objectID": "posts/computer-tool/2022-05-25-pytorch.html",
    "href": "posts/computer-tool/2022-05-25-pytorch.html",
    "title": "PyTorch + WSL",
    "section": "",
    "text": "파이토치를 Windows + WSL2 조합으로 설치하는 법을 간단하게 안내한다."
  },
  {
    "objectID": "posts/computer-tool/2022-05-25-pytorch.html#tl-dr",
    "href": "posts/computer-tool/2022-05-25-pytorch.html#tl-dr",
    "title": "PyTorch + WSL",
    "section": "",
    "text": "파이토치를 Windows + WSL2 조합으로 설치하는 법을 간단하게 안내한다."
  },
  {
    "objectID": "posts/computer-tool/2022-05-25-pytorch.html#pytorch",
    "href": "posts/computer-tool/2022-05-25-pytorch.html#pytorch",
    "title": "PyTorch + WSL",
    "section": "PyTorch",
    "text": "PyTorch\n파이토치는 기계 학습을 위한 라이브러리이다. 대체로 구글에서 만드는 제품을 선호하다보니 텐서플로를 주로 썼다. 최근 들어 텐서플로를 쓰기 싫어진 이유가 작업 환경이 복잡하고 다양해진 탓이다. 회사에서 윈도 기반 컴퓨터를, 집에서 M1 맥북을 쓰다보니 좀 통일된 작업 환경이 있었으면 싶었다. 텐서플로의 경우 M1에서 쓸 때 많은 제약을 받는다. M1 GPU를 이용하기 위해서 메탈 관련 설치를 하는 것이야 하드웨어의 특성상 그렇다고 쳐도 2.X 버전을 쓰지 못하는 것이나 파이썬 버전의 제약 등이 이유 없이 찜찜하더라. 이용 환경이 파편화된 느낌을 받았다.\n이때 개발자 커뮤니티에서 파이토치가 좋은 평가를 받는다는 사실을 알게 되었다. 내 수준에서 기계 학습 프레임워크 간의 차이는 크게 문제가 되지 않는다. 텐서가 인풋으로 들어가는 것은 마찬가지이고 모델링 역시 크게 다를 것이 없겠다 싶어서 설치해서 써보기로 했다."
  },
  {
    "objectID": "posts/computer-tool/2022-05-25-pytorch.html#일관된-설치-방법",
    "href": "posts/computer-tool/2022-05-25-pytorch.html#일관된-설치-방법",
    "title": "PyTorch + WSL",
    "section": "일관된 설치 방법",
    "text": "일관된 설치 방법\nhttps://pytorch.kr/get-started/locally/\n위 링크를 통해 설치 방법이 일관되게 안내된다. 플랫폼과 상황 별로 잘 나뉘어 있으니 원하는 대로 설정을 하면 된다. 윈도 이용자라면 윈도 네이티브보다는 WSL에 설치하는 것을 권장한다. 관리나 정신 건강 상의 이유도 있겠지만, 퍼포먼스가 체감상 조금 나은 듯 싶다.\n\n\nConda 환경을 쓴다면 윈도라고 크게 다를 것은 없을 듯 싶다."
  },
  {
    "objectID": "posts/computer-tool/2022-05-25-pytorch.html#pytorch-m1-gpu",
    "href": "posts/computer-tool/2022-05-25-pytorch.html#pytorch-m1-gpu",
    "title": "PyTorch + WSL",
    "section": "PyTorch + M1 GPU",
    "text": "PyTorch + M1 GPU\nMacos + M1의 경우라도 설치 페이지를 통해 쉽고 일관된 방식으로 설치할 수 있다. 만일 GPU를 쓰고 싶다면 PyTorch 빌드 항목에서 “Preview(Nightly)”를 택하면 된다.\n\n\n자세한 것은 여기를 참고하자.\n파이토치의 경우 별다른 설정 없이 conda를 통해 설치하면, M1의 GPU를 활용이 가능하다."
  },
  {
    "objectID": "posts/computer-tool/2022-05-25-pytorch.html#pytorch-wsl-cuda",
    "href": "posts/computer-tool/2022-05-25-pytorch.html#pytorch-wsl-cuda",
    "title": "PyTorch + WSL",
    "section": "PyTorch + WSL + CUDA",
    "text": "PyTorch + WSL + CUDA\nWSL 2가 이제 표준이 되었으니 이를 그냥 WSL로 부르도록 하자. 위 링크의 선택지에서 OS 종류를 Linux, Windows 어느 것으로 해도 설치 방식이 동일하다. 패키지 설치를 conda가 맡고 있기 때문이다. 엔비디아의 GPU를 활용하는 CUDA 버전 역시 11.3으로 선택하면 별 문제 없이 설치에 필요한 conda 명령어 셋을 보여준다.\n\nConda 환경 생성\n콘다에서 환경(env)을 만들어 그 안에 쓰면 여러모로 편리하다. 혹시 문제가 생겼을 때 생성된 환경만 날려버리면 된다.\n? conda create -n YOUR-ENV-NAME python=3.10\n? conda env list \n? conda activate YOUR-ENV-NAME\n\nconda create -n은 YOUR-ENV-NAME으로 환경을 만들라는 명령이고, python=3.10은 파이썬 3.10을 설치하라는 명령이다.\nconda env list는 현재 설치된 환경을 보여준다.\nconda activate YOUR-ENV-NAME는 해당 환경을 선택한다.\n\n이렇게 해놓고 파이토치를 설치하면 된다.\n\n\nCUDA 설정\nWSL 초기에는 CUDA 설정이 무척 까다로웠다. 최신 버전에서는 그런 문제가 없다. 엔비디아의 CUDA를 지원하는 GPU라면 최신 드라이버를 깔고 최신 버전의 WSL을 이용하면 된다. 모든 작업이 화면 뒤에서 잘 이루어진다. 편해도 너무 편하다."
  },
  {
    "objectID": "posts/computer-tool/2022-05-25-pytorch.html#testing-code",
    "href": "posts/computer-tool/2022-05-25-pytorch.html#testing-code",
    "title": "PyTorch + WSL",
    "section": "Testing Code",
    "text": "Testing Code\n모든 설치를 마쳤다면 이제 테스트를 돌려볼 차례다. 테스트 코드로 간단한 신경망 정도를 돌려보면 될 것이다. 작업시 취향에 맞는 IDE를 택하면 된다. Jupyter를 깔아서 웹에서 작업해도 되고 VS 코드로 WSL에 원격 접속해서 작업해도 된다. 이 경우에도 Jupyter 설치는 필요하다. 필요한 요소를 VS 코드가 알려주니, 화면에 지시를 따르면 되겠다.\nPython 커널을 선택할 때 앞서 만들어 놓은 환경에 속한 파이썬을 택해야 한다. 엉뚱한 커널과 연결되어 있으면 당연히 돌아가지 않을 수 있다.\n\nA code to test\n튜토리얼\n튜토리얼의 코드를 실행하면서 에러가 떴다면, 설치 과정에서 뭔가 잘못된 것이다. 특별히 복잡한 것은 없으니 다시 잘 살펴보면 된다. 다른 부분은 생략하고 학습에 활용할 장치를 선택하는 부분만 간략하게 언급하겠다.\n# 학습에 사용할 CPU나 GPU 장치를 얻습니다.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using {device} device\")\n\ndevice를 선택하는 부분은\n\n“cpu”: 플랫폼 별 CPU 활용\n“cuda”: 엔비디아 GPU\n“mps”: M1 GPU"
  },
  {
    "objectID": "posts/computer-tool/2022-05-25-pytorch.html#as-good-as-it-gets",
    "href": "posts/computer-tool/2022-05-25-pytorch.html#as-good-as-it-gets",
    "title": "PyTorch + WSL",
    "section": "As Good as It Gets",
    "text": "As Good as It Gets\n모든 과정이 너무 순탄해서 감동이었다. 이제 다른 기계 학습 프레임워크는 못 쓸 것 같…"
  },
  {
    "objectID": "posts/computer-tool/2020-10-27-viva-binder.html",
    "href": "posts/computer-tool/2020-10-27-viva-binder.html",
    "title": "Viva, Binder!",
    "section": "",
    "text": "내가 보고 있는 것을 남이 그대로 봐야 의사 소통이 온전해지는 경우가 있다. 아마도 코드를 나누는 경우가 그렇지 않을까 싶다. 이 점에서 Github은 꽤 좋은 코드 나눔 도구다. 그런데 문제가 하나 있다. Github을 통해 배포하는 것이 패키지라면 각자 땡겨가서 쓰면 되겠지만, 특정하게 실현된 결과물이라면?\n예를 들어보자. Python으로 특정한 결과를 도출하는 코드를 짰다고 하자. 당연히 내가 작업한 환경에 의존할 것이다. 다른 환경에서 돌아갈지 아닐지 모르지만 어쨌든 의존성은 피할 수 없다. 상대를 불러서 내 컴퓨터에서 돌아가는 모습을 보여줄 수 있다면 좋겠지만 그럴 수 없는 경우가 많다. 내가 돌려본 환경을 그대로 상대가 볼 수 있게 할 수는 없는 것일까?\n당장 떠오르는 솔루션이 클라우드다. 클라우드에 소프트웨어 환경을 세팅하고 내가 테스트해본다. 원하는 상대에게 url을 주고 같은 테스트를 반복 체험하게 한다. 물론 좋다. 사실 AWS 같은 곳에 Linux 서버를 깔고 주피터 관련 패키지나 RStudio 등을 설치하기는 쉽다. AWS를 비롯해 많은 클라우드 업체에서 원스톱 서비스까지 제공한다. 그런데, 문제가 있다. 비용이 든다. 사용량이 많아서 뽕을 뽑을 수 있다면 덜 아깝겠지만 코드 공유하고 결과를 확인하는 정도가 족하다면 많이 아깝다.\n이런 용도로 활용할 수 있는 ‘무료’ 서비스가 Binder이다.\nhttps://mybinder.org"
  },
  {
    "objectID": "posts/computer-tool/2020-10-27-viva-binder.html#turn-a-git-repo-into",
    "href": "posts/computer-tool/2020-10-27-viva-binder.html#turn-a-git-repo-into",
    "title": "Viva, Binder!",
    "section": "Turn a Git repo into!",
    "text": "Turn a Git repo into!\n서비스 참 시원시원하다. 로그인도 필요 없다. 깃헙 레포에 있는 코드를 받아서 가상 머신 위에 해당 결과를 구현해준다. R, Python, Julia를 지원한다. 세 언어 모두 기본 베이스로 Jupyter허브를 활용한다. 간편한 연동을 위해서는 깃헙 리포를 public으로 설정해야 한다.\n\n\nGitHub: 깃헙 주소를 넣는다.\nGit branch, tag or commit: 관련된 깃 브렌치, 태그, 커밋 등을 넣는다.\nPath to a notebook file: ipynb 파일이 깃 내에 서브 디렉토리에 있다면 여기서 노트북 파일의 위치등을 지정해주면 된다.\n\nRStudio나 Shiny를 쓰고 싶다면, “File” 대신 “URL”로 바꾸고 rstudio, shiny 등을 지정해주면 된다.\n\nR의 경우 r-2020-10-26 식으로 날짜가 적힌 runtime.txt 파일 그리고 패키지를 미리 인스톨하는 install.R 파일 두 개를 준비하면 된다.\n\n\n\n아래 공유를 위한 주소도 떠 있으니 공유를 할 때는 해당 주소만 던져주면 된다. 이제 launch 버튼을 누르자. 상당히 오랜 시간 동안 뭔가가 설치된다. 설치되는 내용을 보면 소프트웨어 구동에 필요한 개별 이미지를 빌드한 후 이를 클라우드에 띄워 구동한다.\n\n\n장점은 충분히 많다. 코드가 제대로 구현되는지 확인하는 수준이거나 코드를 가끔 짧은 시간 동안 실행해야 하는 정도라면 더 이상 바랄 게 없다. 단점이라면 도커 이미지를 빌드하고 녀석을 푸시해 실행할 때까지 시간이 좀 걸린다는 것인데, 뭐 이 정도 시간 비용 쯤이야!"
  },
  {
    "objectID": "posts/computer-tool/2020-10-24-classy-latex.html",
    "href": "posts/computer-tool/2020-10-24-classy-latex.html",
    "title": "\\(\\rm\\LaTeX\\) in Modern Ways",
    "section": "",
    "text": "박사 논문을 \\(\\rm\\LaTeX\\)(이하 그냥 레이텍 혹은 텍이라고 쓰겠다)으로 썼지만… 역시 안 쓰면 잊는다. 갑자기 텍을 다시 써볼까, 라는 생각이 드는 순간 갑갑하더라. 윈도를 쓰건 맥을 쓰건 용량이 적지 않고 관리가 쉽지 않은 텍라이브를 깔게 되지는 않는다. 물론 당신이 논문을 쓰고 있다면…\n이 두 가지를 놓고 해결책을 찾아봤다. 세 가지 정도 해법이 있더라."
  },
  {
    "objectID": "posts/computer-tool/2020-10-24-classy-latex.html#tinytex-with-r",
    "href": "posts/computer-tool/2020-10-24-classy-latex.html#tinytex-with-r",
    "title": "\\(\\rm\\LaTeX\\) in Modern Ways",
    "section": "tinytex with R",
    "text": "tinytex with R\nR의 문서 관련 패키지를 거의 혼자 만들고 있는 谢益辉(사익휘, 시에-이-휘)가 R에서 텍을 컴파일할 수 있도록 아주 가벼운 패키지 tinytex을 만들었다. R을 쓴다면 RStudio를 쓸 것이고, 이 녀석은 편집기로서 역할 역시 모자라지 않다.\ninstall.packages('devtools')\ndevtools::install_github('yihui/tinytex')\ntinytex::install_tinytex()\n\ndevtools 패키지를 설치한다.\n깃헙에서 tinytex이라는 R패키지를 설치한다.\ntinytex 패키지를 통해서 tinytex을 설치한다.\n\n간략하게 잘 컴파일 되는지 확인해보자.\nwriteLines(c(\n    '\\\\documentclass{article}',\n    '\\\\begin{document}', 'Hello world!', '\\\\end{document}'\n    ), 'test.tex')\n\ntinytex::pdflatex('test.tex')\n\ntest.tex이라는 파일을 쓰고\n예를 pdflatex으로 컴파일 한다.\n\n\nCompling .tex directly\n이제 .tex 파일을 직접 컴파일 해보자. 테스트할 용도의 파일은 다음과 같다. 적당한 이름으로 아래의 tex 파일을 적당한 디렉토리에 생성하자.\n\\documentclass{article}\n\\usepackage{kotex}\n\\begin{document}\nHello world! 한글은 어떠함?\n\\end{document}\n.tex 파일을 RStudio에서 열면 위에 pdf를 생성하는 버튼을 볼 수 있다. 이걸 실행해보도록 하자. 아마도 컴파일하면 에러를 만나게 될 것이다. 한글 패키지가 제대로 설치되어 있지 않기 때문이다. 텍도 마찬가지로 패키지들을 설치해야 할 때가 많다. 몇가지 방법이 있지만, 편리한 방법을 소개하겠다.\ntinytex::parse_install(\n    text = \"! LaTeX Error: File `kotex.sty' not found.\"\n)\nR로 돌아와서 발생한 에러 메시지를 text의 인자로 넣으면 어떤 패키지가 필요한지 인식해서 texlive에서 끌어와 설치한다. 설치 후 tex 패키지를 업데이트하자.\ntinytex::tlmgr_update()\n이제 tinytex::pdflatex('test.tex')을 실행하면 pdf가 잘 생성될 것이다. 다시 .tex 파일로 와서 pdf 버튼을 눌러보자. 아마도 에러가 뜰 것이다. 방법 패키지를 설치했는데 왜 에러가 뜰까? 해법은 간단하다. 메뉴에서 다음과 같은 순서로 찾아들어가자.\nTools &gt; Global Options &gt; Sweave\n“Use tinytex when compling .tex files”을 체크해주자."
  },
  {
    "objectID": "posts/computer-tool/2020-10-24-classy-latex.html#wsl-tinytex-vs-code",
    "href": "posts/computer-tool/2020-10-24-classy-latex.html#wsl-tinytex-vs-code",
    "title": "\\(\\rm\\LaTeX\\) in Modern Ways",
    "section": "WSL + Tinytex + VS Code",
    "text": "WSL + Tinytex + VS Code\n사이휘는 tinytex을 R에서만 쓰도록 만들지 않았다. 리눅스 인스톨러를 제공한다. 이 블로그를 보신 분은 잘 알고 계시리라. 나는 WSL의 광팬이다! WSL에 tinytex을 깔고 녀석을 VS Code에 붙여서 쓰면 된다. 물론 맥OS, 윈도 인스톨러도 제공하니 관심이 있으시면 직접 확인을 하시면 되겠다. 홈페이지 인스톨 섹션에서 확인하면 되겠다.\nWSL 터미널에서 다음과 같이 실행하자.\nwget -qO- \"https://yihui.org/tinytex/install-bin-unix.sh\" | sh\n기타 패키지 설치 등은 tlmgr 명령을 활용하면 된다. 위 홈페이지를 참고하면 되겠다.\nVS Code에서는 어떤 확장을 쓰면 될까? Latex Workshop이 어떤 전용 에디터 못지 않은 풍부하고 다양한 확장 기능을 제공한다. extension의 settings.json을 통해 다양한 컴파일 옵션도 제공하니 자세한 것은 위 페이지의 안내를 참고하면 되겠다. 일단 pdflatex을 쓴다고 가정하자.\nVS Code에서의 활용은 아래 섹션을 참고하자."
  },
  {
    "objectID": "posts/computer-tool/2020-10-24-classy-latex.html#texlive-with-docker",
    "href": "posts/computer-tool/2020-10-24-classy-latex.html#texlive-with-docker",
    "title": "\\(\\rm\\LaTeX\\) in Modern Ways",
    "section": "TexLive with Docker!",
    "text": "TexLive with Docker!\n본격적으로 텍을 쓰는 사람이라면 어찌해야 하나? Tinytex이 많이 부족해 보일 수 있다. Texlive를 온전하게 쓰고 싶다면 역시 OS 별로 텍라이브를 까는 방법 밖에 없나? 이럴 때 손쉽게 동원할 수 있는 게 docker이다. 비슷한 계열의 OS라도 텍라이브를 전부 까는 것이 편하지는 않다. 윈도는 더 부담스럽다. 그냥 필요할 때 불러서 쓰고 잊을 수 있다면 좋지 않을까? 도커는 이런 용도로 쓰기에도 좋다.\n내가 검색해본 바로는 공인 이미지는 없는 것 같다. 다양한 사용자 이미지 중에서 꽤 관리가 잘되는 것을 골라서 쓰면 되겠다. 내가 활용하는 이미지는 다음과 같다.\nhttps://hub.docker.com/r/thomasweise/docker-pandoc/\n녀석을 도커에 마운트하자. WSL에서 도커를 쓰는 법은 이 글을 참고하라.\n​docker run -v /mnt/[YOUR-LOCAL]:/doc/ -t -i thomasweise/docker-pandoc\n\nWSL이 /mnt 디렉토리 아래 윈도의 디스크를 마운트한다. 따라서 저 아래 로컬 폴더의 주소를 넣으면 된다. 예를 들어, C의 doc라는 이름이라면, c/doc를 넣으면 된다. 이렇게 두면 해당 폴더가 도커의 /doc 아래 연결된다.\n\n초기에 이것저것 깔아주고 초기화해야 하는 것들이 있다. 이 녀석들을 셸스크립트(sh)로 만들어두자. install_kotex.sh 라는 스크립트는 아래와 같이 만들어보자. 해당 스크립트는 위에 마운트하는 폴더에 넣어두면 좋다. 그러면 도커 이미지가 올라갔을 때 해당 스크립에 쉽게 접근할 수 있다.\n#!/bin/sh\ntlmgr init-usertree\n#\ntlmgr repository add https://cran.asia/KTUG/texlive/tlnet/ ktug\n#tlmgr pinning add ktug \"*\"\ntlmgr install collection-langkorean\nupdmap -sys\nupdmap -sys\ntlmgr update --all\n상태를 초기화하고 한글을 까는 명령어들을 모아둔 것이다. 실행 중인 도커 내에서 해당 디렉토리로 이동해서 ./install_kotex.sh로 명령을 실행하자.\n이제 VS Code로 가자. 필요한 Extension은 앞서 살펴본 Latex workshop과 더불어 Remote-Container를 설치하자. 이 녀석을 설치하면 WSL 내에서 돌아가는 컨테이너 안에도 VS Code를 통해 바로 접속할 수 있다.\n - 아래 &gt;&lt;으로 된 부분을 클릭하면 상단에 메뉴가 뜬다.\n - “attach to running container”를 실행해서 실행중인 도커 콘테이너를 부착한다.\n\n\n부착하면 새 창이 뜨면서 아래 녹색 창이 콘테이너 부착되었음을 알려준다.\n콘테이너 내부에 Latex Workshop 확장(extension)을 설치해야 한다.\n\n\n\n설치 후 해당 Extension의 설정을 고쳐주자.\n위에 찾기창에서 디폴트로 떠 있는 내용 뒤에 “pdf” 치면 pdf에 관련된 설정만 필터링된다.\n\n\n\n위 항목을 찾아서 적당한 포워딩 포트를 넣어준다.\n포트가 잘 포워딩 된다면, 아래와 같이 VS Code에서 PDF 뷰어를 활성화할 수 있다.\n포트 포워딩 설정은 Latex Workshop 확장의 미비함 때문에 필요하다. 이후 해당 확장의 업데이트를 통해 해결될 것으로 기대한다.\n\n\nActivating PDF Viewer\n확장의 PDF 뷰어의 작동 방식 때문에 포트포워딩 선택을 해줘야 한다.\n\nPort Forward\n일단 확장 설정에서 적당히 포워딩될 포트를 설정해야 한다.\n\n\nContainer Setting\n콘테이너에서 해당 포트가 잘 포워딩되고 있는지 확인하자.\n\n\n옆에 원으로 표시해 둔 곳은 Remote-Container 확장으로 바로 가는 단축 아이콘이다.\n위 그림처럼 35556 포트를 통해 잘 포워딩되고 있음을 알 수 있다.\n\n만일 포워딩이 되고 있지 않다면, 마우스 우클릭으로 포워딩을 해주도록 하자.\n\n\n이제 VS Code에서 텍 파일을 열고 문서를 작성하고 컴파일하면 된다. Latex Workshop이 설치되어 있다면, .tex 파일에 알아서 반응하니 걱정 마시라."
  },
  {
    "objectID": "posts/computer-tool/2020-10-24-classy-latex.html#references",
    "href": "posts/computer-tool/2020-10-24-classy-latex.html#references",
    "title": "\\(\\rm\\LaTeX\\) in Modern Ways",
    "section": "References",
    "text": "References\n\ntinytex\ntexlive 도커 이미지\nkotex 리눅스 설치\nVS Code Remote-Cotainer 포트 포워딩\n컴파일에 활용된 파일은 여기를 참고하라.\n\nhttps://github.com/anarinsk/test-vscode-latex"
  },
  {
    "objectID": "posts/computer-tool/2022-08-13-clean-use-of-windows.html",
    "href": "posts/computer-tool/2022-08-13-clean-use-of-windows.html",
    "title": "단순하고 깔끔한 윈도 분석 환경",
    "section": "",
    "text": "winget을 씁시다!"
  },
  {
    "objectID": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#tl-dr",
    "href": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#tl-dr",
    "title": "단순하고 깔끔한 윈도 분석 환경",
    "section": "",
    "text": "winget을 씁시다!"
  },
  {
    "objectID": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#윈도는-쓸수록-지저분해진다",
    "href": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#윈도는-쓸수록-지저분해진다",
    "title": "단순하고 깔끔한 윈도 분석 환경",
    "section": "윈도는 쓸수록 지저분해진다?",
    "text": "윈도는 쓸수록 지저분해진다?\n윈도 환경은 빠르게 지저분해진다. 윈도의 역사를 고려하면 마이크로소프트가 다소 억울할 수도 있겠다. 윈도가 다양한 생태계를 오랫동안 유지, 포용, 확장해 온 탓이다. 인스톨러의 설치 방식 역시 조금씩 달라서, 여러 앱이 깔리면서 환경은 꼬이기 마련이다. 이런 ‘윈도’ 엔트로피의 증가 경향을 막을 수는 없겠지만, 가속할 필요는 없지 않을까?\n개발 환경에 관한 것이라면 윈도 안에서 리눅스를 거의 완벽하게 구현한 WSL2라는 훌륭한 물건이 있다. 하지만 분석 용도로 쓰기에 WSL2가 지나치게 ’번잡하다’는 느낌을 종종 받는다. 이번 포스팅에서는 Windows Terminal + PowerShell + winget을 이용해 데이터 분석을 위한 일관된 윈도 환경 구축에 관해 다뤄보겠다. 여기 소개할 환경은 윈도 뿐 아니라 MacOS, Linux에서도 동일하게 구축할 수 있다. Unix 기반 OS에서는 구축이 더 쉽다. 윈도 구축을 무사히 마쳤다면, 다른 OS에서는 (어쩌면 Google의 도움을 약간 받아서?) 더 쉽게 구축할 수 있을 것이다."
  },
  {
    "objectID": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#출발선",
    "href": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#출발선",
    "title": "단순하고 깔끔한 윈도 분석 환경",
    "section": "출발선",
    "text": "출발선\n내가 확인한 작동 환경은 아래와 같다.\n\nWindows 11 Version 22H2\n\n윈도11 버전 이외에 윈도를 설치해 쓰는 환경이라면 특별한 호환성 문제는 없을 것이다."
  },
  {
    "objectID": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#winget-설치",
    "href": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#winget-설치",
    "title": "단순하고 깔끔한 윈도 분석 환경",
    "section": "winget 설치",
    "text": "winget 설치\n공식 문서\n공식 문서가 여러모로 완벽해서 덧붙일 것이 없다. 공식 문서에서 있는 링크를 누르면 윈도 스토어의 “앱 설치 관리자”가 뜬다. winget을 쓰기 위해서는 이 녀석을 설치해야 한다."
  },
  {
    "objectID": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#windows-terminal-설치",
    "href": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#windows-terminal-설치",
    "title": "단순하고 깔끔한 윈도 분석 환경",
    "section": "Windows Terminal 설치",
    "text": "Windows Terminal 설치\n만일 윈도 터미널(WT)이 이미 설치되어 있고 잘 설정되어 있다면 이 단계를 건너 뛰어도 된다. 아직 설치 전이라면 익숙하고 불편한 윈도 CMD 창, 즉 커맨드셸을 켜자. 커맨드셸에서 winget을 통해 기초가 되는 앱 두 개를 설치할 예정이다.\n\n\n윈도에서 커맨드 창을 여는 가장 쉬운 방법은 “검색”에서 “커맨드”라고 검색하는 것이다. 그러면 “명령 프롬프트” 검색된다.\n\nWindows Terminal\nPowerShell (Core 버전, 크로스플랫폼 버전)\n\n어떻게 설치하면 될까? 아래 사이트 중 하나로 가자.\n\nhttps://winstall.app\nhttps://winget.run\n\n위 웹사이트의 검색창에 “Windows Terminal”을 넣고 엔터를 누르자. 아래 검색 결과에 정식 본과 preview 버전 두 개가 뜰 것이다. 특별한 이유가 없다면 정식 버전을 설치하도록 하자. 클릭해서 들어가면 아래와 같은 스크린 샷이 보인다.\n\n\n\n\n\n\n \n\n\n\n\n\n박스를 복붙해 넣자.\n\n\n\n\n \n\n\n\n박스 친 부분을 클릭으로 복사할 수 있다. 이대로 copy-paste(복붙)를 해주면 된다. CTRL-V로는 커맨드셸에서는 제대로 붙지 않을 수 있다. 복사 후 마우스 우버튼 클릭으로 붙여녛기를 선택하면 잘 들어갈 것이다. 다 안되면 직접 타이핑하자.\n&gt;_ winget install --id=Microsoft.WindowsTerminal  -e\n이렇게 winget을 통해서 필요한 앱들을 터미널을 통해 설치할 수 있다. Winget은 Debian의 apt 혹은 Mac의 brew와 거의 같은 방식으로 작동한다.\nPowershell 역시 같은 방식으로 설치하자.\n&gt;_ winget install --id=Microsoft.PowerShell  -e\n\n\nWT를 설치하면 윈도용 PowerShell이 깔려 있다. 크로스플랫폼으로 개발된 PowerShell Core를 추가로 깔도록 하자."
  },
  {
    "objectID": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#windows-terminal-설정",
    "href": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#windows-terminal-설정",
    "title": "단순하고 깔끔한 윈도 분석 환경",
    "section": "Windows Terminal 설정",
    "text": "Windows Terminal 설정\nWT는 여느 터미널 앱에 뒤지지 않을 만큼의 다양한 커스터마이징이 가능하다. 그 내용을 여기서 자세히 다루지 않겠다. WT의 폰트 설정, 윈도에서 기본셸로 쓸 파워셸(PS)의 외관 바꾸기 두 개만 보도록 하자. WT는 맥 OS의 iTerm2, 그리고 PS은 bash 혹은 zsh 정도라고 생각해도 무방하다.\n\n\nWT은 다양한 방식으로 커스마이징을 지원한다. 기본적으로 settings.json을 활용하지만, 최선 버전은 GUI를 통한 설정도 가능하다. 일반 설정, 외형, 세부 설정을 참고하자.\n\nFont 설정\n폰트 설정은 코딩 환경을 좌우한다. PS를 잘 쓰려면 Nerd 패치가 된 폰트를 써야 한다. 아래 두 폰트를 추천한다.\n\nD2Coding Nerd Patched: LINK\nHack Nerd Patched: LINK에서 Hack을 찾아서 다운로드\n\n\n\nHack의 zip을 다운받아 압축을 풀면, 윈도용과 비 윈도용 그리고 보통, 이탤릭, 볼드, 이탤릭 볼드 폰트가 구별되어 있다. 용도별로 필요한 폰트를 깔면 된다.\n윈도 터미널은 아직 다중 폰트, 즉 한글 폰트와 영문 폰트의 분리 적용을 지원하지 않는다. 한글의 활용이 높다면 D2Coding을 그렇지 않다면 Hack이 좋다. D2Coding의 경우 Nerd Font 매핑에 조금 문제가 있지만, 사용이 불가능할 정도는 아니다.\n\n\nLigature 버전과 그렇지 않은 버전 두 가지가 있다. 리거쳐란 - + &gt;와 같은 합자를 →의 단일 글자로 바꾸는 폰트를 의미한다.\n폰트를 설치한 후 WT 설정 → PS 설정 → 모양 안에서 앞서 설치한 폰트를 선택하면 된다."
  },
  {
    "objectID": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#powershell-꾸미기",
    "href": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#powershell-꾸미기",
    "title": "단순하고 깔끔한 윈도 분석 환경",
    "section": "PowerShell 꾸미기",
    "text": "PowerShell 꾸미기\n기본 PS는 그리 사용성이 좋지 않다. 다행스럽게도 리눅스나 맥의 “Oh-My-Zsh” 같은 것이 PS에도 있다. “Oh-My-Posh”, 즉 “오 마이 파워셸”이다. 마찬가지로 winget을 통해 설치하도록 하자. 다만 PS의 모양새가 제대로 돌아가려면 앞서 언급한 Nerd 폰트가 필요하다.\n&gt;_ winget install --id=JanDeDobbeleer.OhMyPosh  -e\n설치 후 필요한 여러가지 테마를 골라 설정할 수 있다. 자세한 것은 LINK를 참고하자."
  },
  {
    "objectID": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#앱-설치-i",
    "href": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#앱-설치-i",
    "title": "단순하고 깔끔한 윈도 분석 환경",
    "section": "앱 설치 I",
    "text": "앱 설치 I\n이제 데이터분석 작업을 위해 필요한 앱들을 설치할 것이다. 우선 잘 알려진 앱부터 깔도록 하자.\n\nVisual Studio Code\nGit\nGitHub Desktop\n\n절차는 다음과 같다.\n\nWT에서 PowerShell을 실행하자.\nwinistall.app 사이트에서 필요한 앱을 검색한다.\n설치를 위한 명령을 (복붙으로) 실행한다.\n\n&gt;_ winget install --id=Microsoft.VisualStudioCode  -e\n&gt;_ winget install --id=Git.Git  -e\n&gt;_ winget install --id=GitHub.GitHubDesktop  -e\n이렇게 설치하는 앱과 해당 서비스에서 직접 인스톨러를 다운받아서 설치하는 것이 많이 다를까? 기본적으로 동일하다. 다만 경우에 따라서는 설치 디렉토리 등이 보다 일관성 있게 유지된다는 점, 그리고 보다 체계적인 업데이트가 가능하다 등의 장점이 있다."
  },
  {
    "objectID": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#앱-설치-ii",
    "href": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#앱-설치-ii",
    "title": "단순하고 깔끔한 윈도 분석 환경",
    "section": "앱 설치 II",
    "text": "앱 설치 II\n이제 데이터 분석을 위해서 필요한 앱을 설치하자. 아래 명령은 winstall.app에서 가져온 것이다.\n\n\n\n\n\n\n\nApp\nWinget command\n\n\n\n\nMiniforge3 for Python\n&gt;_ winget install --id=CondaForge.Miniforge3  -e\n\n\nR\n&gt;_ winget install --id=RProject.R  -e\n\n\nJulia\n&gt;_ winget install --id=Julialang.Julia  -e\n\n\nQuarto\n&gt;_ winget install --id=RStudio.quarto  -e\n\n\n\nMiniforge3를 제외하고 다른 소프트웨어는 설치와 실행에 문제가 없었다. Miniforge3에는 약간의 설정이 필요하다.\n\nMiniforge3 (for Python)\n파이썬의 경우 네이티브로 깔아서 써도 된다. 다만 여러모로 conda 환경 아래 쓰는 것이 편리하다. 그리고 conda를 쓴다면 우리는 쓸모없이 크고 비효율적인 원본 아나콘다 대신 파이썬 환경 및 패키지 관리에 특화된 미니콘다를 설치할 것이다. 최근 아나콘다의 전 제품이 200 인 이상 단체에 대해서 유료화되었다. Miniforge3는 라이센스 이슈가 없는 별도의 커뮤니티 버전이다. winstall.app에서 miniforge3를 검색하자.\n&gt;_ winget install --id=CondaForge.Miniforge3  -e\n아쉽게도 Miniforge3의 실행 경로가 윈도 path에 기본으로 잡혀있지 않다. 즉 커멘드셸에서 conda를 쳐도 해당 폴더에 있지 않는 이상 실행되지 않는다.\n\n환경 변수 설정\n아래 그림과 같이 윈도 태스크바의 검색 창에서 “환경 변수”라고 치면 아래 그림과 같은 검색 결과 비슷한 것이 뜰 것이다. “계정의 환경 변수 편집”을 선택하도록 하자.\n\n\n\n\n\n\n \n\n\n\n\n\n환경 변수 편집을 찾아가자!\n\n\n\n\n \n\n\n\n\n\n\n\n계정의 환경 변수(클릭시 확대)\n\n\n\n\n \n\n\n\n\n\npath 추가(클릭시 확대)\n\n\n\n\n\n왼쪽 그림과 같은 창이 뜨면 path 항목 위에서 더블클릭을 하자. 그러면 오른쪽 화면이 뜬다. 여기에 miniforge3의 “윈도용 명령어 경로”를 넣어주면 된다. 설치 경로는 컴의 조건과 상황에 따라서 차이가 날 수 있다. 개인사용자 대부분은 C:\\Users\\{USER NAME}\\miniforge3에 설치될 것이다. 일부 조직에서 관리하는 컴퓨터 같은 경우 C:\\Users\\{USER NAME}\\AppData\\Local\\miniforge3에 설치될 수 있다.\n\n\n한글 윈도의 경우 탐색기에서 Users가 “이용자”라고 보일 것이다. “이용자”가 Users다. 해당 폴더로 들어가서 찾으면 된다. 기우로 적으면, {USER NAME}은 각 이용환경에서 특정 이용자의 이름에 해당한다. 문자 그대로 저 글자를 찾지는 마시라.\n\n윈도용 명령어 경로: 설치 경로 + \\Script\n\nScript 폴더는 conda를 위한 윈도용 명령어들을 담고 있는 폴더다. 명령어 경로를 path에 설정하고 WT을 다시 실행하자. 일단 PS이 아니라 커맨드셸이 필요하다. 커맨드셸을 열고 conda --version을 넣어 보자. 버전 숫자가 나오면 잘 설치된 것이다. 이제 miniforge3를 PS에서 부리기 위한 명령을 실행하자.\n&gt;_ conda init powershell\n조금 기다리면 PS을 위한 콘다 환경이 세팅된다. WT를 다시 실행한 후 PS에서 conda --version을 실행해보자. 버전이 뜨면 설정이 완료된 것이다. 이제부터 ‘익숙한’ conda 환경 그대로다!\n\n\nMiniforge3 대신 Miniconda를 설치한다면, 위 과정을 응용하면 된다. Miniconda도 winstall.app에서 찾을 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#설치-앱-업그레이드",
    "href": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#설치-앱-업그레이드",
    "title": "단순하고 깔끔한 윈도 분석 환경",
    "section": "설치 앱 업그레이드",
    "text": "설치 앱 업그레이드\nwinget을 설치했다면 터미널에서 간단하고 일관되게 작업할 수 있다. 별 생각하기 싫다면, 아래와 같이 하자.\n&gt;_ winget upgrade --all\n자세한 내용은 여기를 참고하자."
  },
  {
    "objectID": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#vs-code-as-ide",
    "href": "posts/computer-tool/2022-08-13-clean-use-of-windows.html#vs-code-as-ide",
    "title": "단순하고 깔끔한 윈도 분석 환경",
    "section": "VS Code as IDE",
    "text": "VS Code as IDE\n이제 개별 데이터 분석 도구(언어)를 부릴 IDE로 VS Code를 쓸 것이다. VS Code가 편리한 이유는 다음과 같다.\n\n크로스 플랫폼, 크로스 랭귀지\n\n다양하고 풍부한 Extension 지원\nJupyter 활용 가능\nQuarto를 통해 일관된 문서 작성 가능\n\nR 이용자에게 RStudio는 정말 뛰어난 IDE이지만, 그 안에서 다른 언어와 운용하기는 쉽지 않다. VS Code가 개별 언어를 위한 최선의 환경은 아닐지 몰라도 차선 쯤은 된다. 사용하는 언어에 맞게 필요한 아래 VS Code 익스텐션을 설치하도록 하자.\n\nExtenstions\n\n\n\nLanguage\nExtension\nDesc\n\n\n\n\nPython\nPython, Pylance\nhttps://code.visualstudio.com/updates/v1_70\n\n\nR\nR\nhttps://code.visualstudio.com/docs/languages/r\n\n\nJulia\nJulia\nhttps://code.visualstudio.com/docs/languages/julia\n\n\nJupyter\nJuputer, Jupyter Keymap\nhttps://code.visualstudio.com/docs/datascience/jupyter-notebooks\n\n\nQuarto\nQuarto\nhttps://marketplace.visualstudio.com/items?itemName=quarto.quarto\n\n\n\n\n\nSome Tips for Jupyter in VS Code\n\n폰트 운용\nVS Code 설정에서 폰트를 바꿀 수 있다. VS Code는 두 개 이상의 폰트를 쓸 수 있고, 우선 순위가 자연스러운 방식으로 구현된다. 만일 Hack NF와 D2Coding을 함께 설치했다면, 폰트 설정 항목에 \"Hack NF\", \"D2Coding ligature\"와 같은 식으로 차례로 넣어주면 된다.\n\n\nJupyter 모듈 설치\nJupyter를 실행할 때 만일 해당 언어 환경에 Jupyter가 깔려 있지 않다면 어떻게 될까? 똑똑한 VS Code는 무엇을 깔아야 하는지 알려준다. 아래 그림과 같은 메시지에서 설치 관련 명령을 복사헤서 붙여 넣고 실행하자. VS Code에서 하단에 커맨드셸을 활성화하려면 CTRL-J를 누르도록 하자. 혹은 오른쪽 상단의 아이콘 중에서 하단 바가 색칠된 형태의 아이콘을 눌러도 된다.\n\n\n\n\n\n\n \n\n\n\n\n\nVS Code는 설치한 필요한 패키지를 알아서 알려준다!\n\n\n\n\n \n\n\n\n\n\nJupyter 인터프리터 선택\n보통 주피터 환경에서는 인터프리터, 즉 어떤 언어 설정에서 명령을 실행할지는 선택할 수 있다. 콘다의 가상 환경을 쓸 때 혹은 주피터를 여러 언어 환경에서 쓸 때 유용한 기능인데 VS Code에도 그대로 구현되어 있다.\n\nF1 클릭\n검색창에서 Python을 칠 때 나오는 것 중에서 “Python:인터프리터 선택” 클릭\n아래 그림과 같은 창에서 인터프리터를 선택하면 된다. 만일 보이지 않으면 리프레시 버튼을 눌러서 다시 환경을 갱신해보자. Conda 가상 환경까지 잘 찾아준다.\n\n\n\n\n\n\n\n \n\n\n\n\n\nJupyter Runtime을 선택할 수 있다. Python 뿐 아니라 다른 언어 환경도 선택할 수 있다.\n\n\n\n\n \n\n\n\n간혹 내가 miniforge3를 설치한 위치의 python 환경이 보이지 않을 수 있는데, 그럴 때는 VS Code를 재시작하고 위 과정을 반복하면 된다. 뭔가 안될 때는 일단 재시작이다.\n\n\nQuarto 환경\nQuarto의 장점은 문서 내의 코드를 그대로 실행해 결과를 보여주는 데 있다. 이 장점을 살리기 위해서는 몇 가지 설정이 필요하다.\n\n문서를 컴파일하기 전에 코드가 실행될 (특정 환경에 속한) 파이썬 인터프리터를 선택하자.\n선택한 후 VS Code 내에서 에디터를 띄우면 conda activate를 통해서 적당한 환경이 자동으로 설정된다. 만일 외부의 PS에서 실행한다면 해당 환경까지 알아서 진입해야 한다.\nipykernel이 해당 환경에 설치되어 있어야 한다. 앞서 jupyter notebook을 VS Code에서 실행하기 위해 필요했던 ipykernel이 해당 환경에 설치되어 있어야 한다. 설치가 되어 있지 않다면 다시 확인하자. {YOUR-CONDA-ENV}는 이용자의 가상환경의 이름을 뜻한다.\n\n&gt;_ ({YOUR-CONDA-ENV}) conda install -n {YOUR-CONDA-ENV} ipykernel --update-deps --force-reinstall\n\n이제 마지막으로 콘다 환경에 아래 두 개의 패키지를 더 설치하면 된다.\n\n&gt;_ ({YOUR-CONDA-ENV}) conda install nbformat nbclient\n4를 설치하지 않고 Quarto 문서(.qmd)를 컴파일하면 nbformat과 nbclient를 설치할 것을 안내해준다. 3을 설치하지 않고 실행하면 [WinError 2]... 에러가 뜬다. 간혹 ipykernel을 설치를 했는데도 qmd 문서 컴파일 시 에러가 뜬다면 아래의 방법으로 다시 설치하자.\n&gt;_ ({YOUR-CONDA-ENV}) python -m ipykernel install --user\n\n\n\n박스를 복붙해 넣자.\n계정의 환경 변수(클릭시 확대)\npath 추가(클릭시 확대)\nVS Code는 설치한 필요한 패키지를 알아서 알려준다!\nJupyter Runtime을 선택할 수 있다. Python 뿐 아니라 다른 언어 환경도 선택할 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2020-03-09-Streamlit-Heroku.html",
    "href": "posts/computer-tool/2020-03-09-Streamlit-Heroku.html",
    "title": "Streamlit + Heroku",
    "section": "",
    "text": "Note\n\n\n\n현재는 streamlit에서 꽤 좋은 조건으로 자체 클라우드를 운영한다. 특별한 이유가 없는 이상 여기 소개한 것과 같이 Heroku를 쓰는 것은 불필요하다."
  },
  {
    "objectID": "posts/computer-tool/2020-03-09-Streamlit-Heroku.html#들어가며",
    "href": "posts/computer-tool/2020-03-09-Streamlit-Heroku.html#들어가며",
    "title": "Streamlit + Heroku",
    "section": "들어가며",
    "text": "들어가며\n구슬이 서 말이라도 꿰어야 보배다. 당연하다. 데이터 분석은\n\n스마트한 노가다\n갈고 닦은 모델링\n환상적인 시각화\n\n의 삼위 일체다. 물론 이 모든 과정에 화룡점정은 “전달”이다. 이 세 개를 어떻게 묶어서 전달하느냐에 따라서 분석을 받아들이는 그 사람의 판단이 달라진다. 어떻게 하면 잘 전달하는 것일까?\n지구상의 많은 인구가 손 안에 컴퓨터를 하나씩 들고 다니는 시대다. 안타깝게도 PC에서 많이 쓰던 PDF는 모바일에 적절하지 않다. 문서의 확대, 축소가 동적이지 않기 때문이다. 아울러 새로운 정보를 계속 주고 받을 수 있다는 점을 생각하면 결국은 ‘웹’, html이 데이터 분석을 전달하는 새로운 합의점이 되지 않을까 싶다. 아니 이미 그런 시대다."
  },
  {
    "objectID": "posts/computer-tool/2020-03-09-Streamlit-Heroku.html#streamlit",
    "href": "posts/computer-tool/2020-03-09-Streamlit-Heroku.html#streamlit",
    "title": "Streamlit + Heroku",
    "section": "Streamlit",
    "text": "Streamlit\nPython은 이제 자타가 공인하는 데이터 사이언스의 주요 도구다. Python에는 이미 좋은 웹 개발 도구들이 있다. Django, Flask가 그렇다. 하지만 역시 나 같은 문송한 자들이 쓰기는 쉽지 않다. 아마도 네트워크 관련 지식이나 웹 관련 지식에 익숙하지 않은 탓이다. 그냥 pandas, numpy 정도만 배울 용이가 있는 사람들에게는 넘기 쉽지 않은 장벽이다. 어쩌면 닭잡고 싶은데 소잡는 칼을 휘두르는 법을 배워야 해서 그럴지도 모르겠다.\n이런 웹 개발 프레임워크들은 “데이터 혹은 그 시각화를 인터랙티브하게 공유한다,”라는 기본 목적에 비추어보면 살짝 과한 면도 있다. 비슷한 필요를 느낀 사람들이 많았는지 작년에 Streamlit라는 반가운 프로젝트가 등장했다.\nR에는 이미 Shiny라는 비슷한 프로젝트가 있다. R의 기능을 활용해 데이터를 처리하고 별도의 웹 개발 없이 R의 기능을 그대로 시각화로 구현할 수 있는 툴이다. Python에도 비슷한 기능을 구현하는 시도는 많았으나 어딘가 불편했다. Streamlit는 이런 2%의 부족함을 꽤 잘 해결했다. 어떤 면에서는 Shiny보다도 쓰기가 편리한 듯도 싶다. 다만 잃는 것도 있다. Shiny의 ’미감’에는 미치지 못하고 기능도 살짝 부족하다. 하지만 통상적인 데이터 탐색 및 시각화의 용도로는 충분하다.\n\nWorkflow\n여기서 Streamlit를 자세히 설명하지는 않겠다. Python을 써보면 사람이면 예제를 쉽게 따라해보면 된다. 페이지의 설명대로 아래 명령만 실행해봐도 느낌을 한번에 받을 수 있다. 아래와 같이 설치하고 hello를 띄울 수 있다.\n$ pip install streamlit \n$ steamlit hello\n대략의 워크플로우는 아래와 같다.\n\nPython으로 작업한다.\nStreamlit로 interactive하게 처리될 부분을 간단히 설계한다.\n터미널에서 streamlit run [앱이름].py\n\n각자의 컴퓨터, 즉 로컬에서 실행하면 알아서 브라우저 앱이 뜬다. 디자인이 다소 허접해보일 수 있지만, 미니멀을 좋아하는 사람이라면 ’본질’에 집중할 수 있는 점을 칭찬할 것이다. R의 Shiny와 마찬가지로 어지간한 Python 비주얼 라이브러리(matplotlib, Vega, Plotly 등등)는 모두 구현이 가능하다."
  },
  {
    "objectID": "posts/computer-tool/2020-03-09-Streamlit-Heroku.html#how-to-deploy-to-web",
    "href": "posts/computer-tool/2020-03-09-Streamlit-Heroku.html#how-to-deploy-to-web",
    "title": "Streamlit + Heroku",
    "section": "How to deploy to web…",
    "text": "How to deploy to web…\n로컬에서 Steamlit를 이용해 그럴 듯한 앱을 만들었다. 이제 이 녀석을 어떻게 배포할까? 즉 이걸 남들에게 어떻게 보여줄까?\n일단 배포를 위해서는 전용 웹 서비스가 있어야 한다. AWS의 무료 티어를 활용해서 배포할 수도 있지만 세팅이 간단하지는 않다. 솔직히 말하면 이 마저 귀찮고 살짝 겁난다. 이런 사람들이 쉽게 쓸 수 있는 서비스가 salesforce에서 제공하는 Heroku다. 원래 Ruby로 제작된 웹 앱만 서비스 했으나, 최근 쓰임새가 늘어나면서 다양한 랭귀지를 지원하고 있다. 당연히 Python도 포함된다. 작업의 전체적인 개념은 다음과 같다.\n\nHeroku 계정 생성\nCLI 설치\nStreamlit 앱 제작\nHeroku 빌드를 위한 파일 생성\nStreamlit 작업 디렉토리를 Heroku로 push\nPush와 동시에 웹 빌드 및 자동 배포\n\n필요한 과정을 간략하게 살펴보자.\n\nHeroku 계정 생성 및 CLI 설치\n홈페이지에 들어가서 가입하면 된다. CLI, 즉 터미널 툴은 왜 필요할까? 터미널에서 작업을 하면 좀 더 편하다. CLI를 설치해야 제대로 Heroku를 사용할 수 있다. 아래와 같이 터미널에서 로그인을 한다.\n$ heroku login \n\n\n앱 디렉토리에 깃 생성\ngit을 통해 heroku를 관리하는 게 편하다. git을 쓸 줄 모른다면, 야매로라도 얼른 배우고 오시라. git으로 작업을 브랜치에서 commit 한 후 heroku로 푸시하는 것으로 일종의 작은 CI/CD가 달성된다.\n\n\n빌드를 위한 파일 생성\nHeroku로 제작한 Streamlit 앱을 푸시하면 자동으로 빌드가 진행된다. 이를 위해서 제작한 앱의 최상위 디렉토리에 아래의 파일을 넣어주자.\nproject \n├── app.py (제작한 앱)\n├── requirements.txt  \n├── setup.sh  \n└── Procfile\n\nrequirements.txt\n설치해야 하는 Python 패키지를 지정해준다. 아래의 예와 같다.\n numpy==1.16.4 \n streamlit==0.52.1 \n seaborn==0.9.0 \n pandas==0.25.1 \n matplotlib==3.1.1 \n scikit_learn==0.22\n이 파일을 자동으로 생성하는 pipreqs를 이용해도 된다.\n\n\nsetup.sh\nmkdir -p ~/.streamlit/\n\necho \"\\\n[general]\\n\\\nemail = \\\"your-email@domain.com\\\"\\n\\\n\" &gt; ~/.streamlit/credentials.toml\n\necho \"\\\n[server]\\n\\\nheadless = true\\n\\\nenableCORS=false\\n\\\nport = $PORT\\n\\\n\" &gt; ~/.streamlit/config.toml\nsh 명령을 실행할 내용을 담고 있다.\n\n\nProcfile\nweb: sh setup.sh && streamlit run app.py\nsh 명령을 실행하고 streamlit를 띄우는 명령어를 담고 있다.\n\n\nruntime.txt\n특정 Python 버전이 필요하다면 이 파일을 추가할 수 있다. 파일 안에 담긴 내용은 아래와 같다.\npython-3.7.3\n\n\n\nCreate and Just push\n이제 heroku로 나갈 앱을 만들고 보내면 끝이다. master에서 작업했다면 아래와 같이 명령어를 실행하면 된다.\n$ heroku create\n$ git push heroku master"
  },
  {
    "objectID": "posts/computer-tool/2020-03-09-Streamlit-Heroku.html#protips",
    "href": "posts/computer-tool/2020-03-09-Streamlit-Heroku.html#protips",
    "title": "Streamlit + Heroku",
    "section": "Protips",
    "text": "Protips\n\n한글이 안나와요~\nstreamlit는 웹에서 즉 브라우저 위에서 돌아가기 때문에 한글이 잘 나오는 것이 정상이다. 문제는 Python 내에서 그래프에 한글을 렌더링할 경우 이것이 제대로 표현되지 않는다는 것이다. 보통 matplotlib과 같은 패키지들을 써본 사람이라면 해당 내용을 한번 검색해본 기억이 있을 것이다. 대략 로컬에서는 폰트를 찾은 후 이를 matplotlib이 쓸 수 있도록 인식시켜주는 것으로 간단히 끝난다.\n왜 Heroku에서는 이것이 안될까? 간단하다. Heroku는 외부의 웹서버이고 그 웹 서버에 한글 폰트가 없는 것이다. 웹 서버에 한글 폰트를 심어주면 될 것이다. 하지만 어떻게 심을까? 간단하다. 작업 중인 앱의 루트 디렉토리에 다음과 같은 시스템 디렉토리를 하나 생성한다.\n/.fonts \n이 디렉토리 안에 필요한 한글 폰트를 넣으면 된다. 그러면 해당 앱이 Heroku로 푸시되었을 때 시스템 폰트로 디렉토리 안의 폰트들이 잘 등록된다."
  },
  {
    "objectID": "posts/computer-tool/2020-03-09-Streamlit-Heroku.html#예제",
    "href": "posts/computer-tool/2020-03-09-Streamlit-Heroku.html#예제",
    "title": "Streamlit + Heroku",
    "section": "예제",
    "text": "예제\nhttps://morning-depths-10545.herokuapp.com/\n\n앱 안에 비교적 자세한 설명을 달아 두었으니 별도의 과정은 생략하도록 하겠다.\n\n데이터 정리 등의 지저분한 코드는 생략하고 위 Heroku 앱을 구현하는 데 동원된 코드는 다음과 같다.\nhttps://github.com/anarinsk/adp-st-kap_1"
  },
  {
    "objectID": "posts/computer-tool/2020-03-09-Streamlit-Heroku.html#참고자료",
    "href": "posts/computer-tool/2020-03-09-Streamlit-Heroku.html#참고자료",
    "title": "Streamlit + Heroku",
    "section": "참고자료",
    "text": "참고자료\nhttps://github.com/Taxuspt/heroku_streamlit_nginx\nhttps://towardsdatascience.com/quickly-build-and-deploy-an-application-with-streamlit-988ca08c7e83\nhttps://blog.jcharistech.com/2019/10/24/how-to-deploy-your-streamlit-apps-to-heroku/"
  },
  {
    "objectID": "posts/computer-tool/2020-09-26-windows-terminal.html",
    "href": "posts/computer-tool/2020-09-26-windows-terminal.html",
    "title": "The Best Terminal App for Windows",
    "section": "",
    "text": "마소가 리눅스 생태계를 품으려고 진심으로 노력하고 있다. 보통 윈도에서 터미널을 쓰려면 cmd를 쳐서 들어간다. 일단 모양이 별로일 뿐만 아니라 불편하다. 그래서 보통 서드파티에서 제작한 터미널 앱을 별도로 쓰곤 한다. 이 앱들로도 부족한 것이 없다. cmder도 높은 수준의 커스터마이즈와 뛰어난 사용성을 보장한다.\nWSL을 통해 윈도에 설치하는 리눅스의 경우 기본으로 CLI(Command Line Interface)를 활용하게 된다. 따라서 좋은 터미널 앱은 필수적이다. 간편하면서도 심미적으로도 유려한 그런 앱이 하나 있었으면 싶은데, MS는 이미 그런 앱을 제공하고 있다.\nWindows 10 기준으로, Microsoft Store에 들어가서 “terminal”을 검색해보자. “Windows Terminal”과 “Windows Terminal Preview” 두 개를 찾을 수 있다. 전자는 안정 버전이고 후자는 실험적인 기능을 구현한 버전이다. 어느 것을 써도 괜찮다.\n공식 가이드 https://docs.microsoft.com/ko-kr/windows/terminal/\n왠만한 내용은 공식 가이드에 잘 정리되어 있으므로 몇 가지 팁만 적도록 하자."
  },
  {
    "objectID": "posts/computer-tool/2020-09-26-windows-terminal.html#설정",
    "href": "posts/computer-tool/2020-09-26-windows-terminal.html#설정",
    "title": "The Best Terminal App for Windows",
    "section": "설정",
    "text": "설정\nVS Code도 그렇고 윈도 터미널도 그렇고 설정이 settings.json 파일로 되어 있다. GUI가 아니라서 처음엔 어색할 수 있겠지만, 쓰다보면 이게 훨씬 편하다는 것을 알게 될 것이다.\n{: style=“textalign:center;” width=“500”}\n{: style=“textalign:center;” width=“500”}\n\n테마\n엄청나게 다양한 테마를 손쉽게 구현할 수 있다.\nhttps://windowsterminalthemes.dev/\n원하는 테마를 바꿔가며 확인할 수 있다. 마음에 드는 녀석을 “Get theme” 버튼을 눌러 클립보드에 복사하도록 하자. 녀석을 어디에 붙여 넣어야 할까?\nsettings.json 파일을 자세히 보면, 아래 \"schemes\":라는 항목이 있다. 여기에 클립보드에서 복사한 내용을 {} 안에 붙여 넣도록 하자. 그리고 설정 파일의 위로 이동하면 \"profiles\" - \"defaults\"라는 항목이 보일 것이다. 여기에는 터미널 앱을 띄웠을 때 어떤 세팅으로 시작할 것인지를 넣을 수 있다. 여러가지 항목을 넣을 수 있는데, 이중 colorScheme 항목에 방금 붙여 넣은 테마의 이름을 넣어주면 된다. 저장을 하면 테마가 바로 적용되며, 뭔가 문제가 있을 경우에는 에러가 뜬다. 이 경우 설정 파일을 다시 고치면 된다. 내가 사용중인 default는 아래와 같다.\n\"defaults\":\n{\n    \"fontFace\" : \"D2Coding\",\n    \"fontSize\" : 10,\n    \"historySize\" : 9001,\n    \"colorScheme\" : \"Monokai Vivid\",\n    \"cursorColor\" : \"#FFFFFF\",\n    \"cursorShape\" : \"vintage\",\n    \"padding\" : \"2, 2, 0, 0\",\n    \"snapOnInput\" : true,\n    \"useAcrylic\" : true,\n    \"acrylicOpacity\" : 0.95,\n    \"antialiasingMode\":\"cleartype\"\n    // Put settings here that you want to apply to all profiles\n}\n\n폰트는 D2Coding을 썼다. 폰트 크기 등등은 쭉 생략하고, 안티얼라이어싱 모드로 cleartype을 쓴 정도가 특징이다. 폰트는 한글 폰트를 써야 한글이 잘 나온다는 점만 기억하자."
  },
  {
    "objectID": "posts/computer-tool/2023-08-27-pixi.html",
    "href": "posts/computer-tool/2023-08-27-pixi.html",
    "title": "pixi",
    "section": "",
    "text": "의존성이라는 지옥을 벗어나보자."
  },
  {
    "objectID": "posts/computer-tool/2023-08-27-pixi.html#tl-dr",
    "href": "posts/computer-tool/2023-08-27-pixi.html#tl-dr",
    "title": "pixi",
    "section": "",
    "text": "의존성이라는 지옥을 벗어나보자."
  },
  {
    "objectID": "posts/computer-tool/2023-08-27-pixi.html#넋두리",
    "href": "posts/computer-tool/2023-08-27-pixi.html#넋두리",
    "title": "pixi",
    "section": "넋두리",
    "text": "넋두리\n심각한 프로젝트를 하지 않는다면 ’의존성’이 문제가 되지 않을 수 있다. 하지만 습관을 잘 들여놓아야 심각한 상황이 왔을 때 대처가 가능한 법이다. 지난 번 소개했던 Rye와 유사한 의존성 관리 도구 pixi를 소개한다. 아직 초기 프로젝트지만 개인 프로젝트인 Rye와 달리 pixi는 조금 더 체계적인 지원 체계를 갖출 듯 싶다. OS 플랫폼 별로 별도의 의존성 등을 할당할 수 있는 대목이 가장 마음에 들었다.\n파이썬을 위한 많은 의존성 관리 도구가 있지만 선택이 간단하지는 않다. 일단 많은 도구가 OS를 탄다. 그리고 의존성 관리에 필수적인 가상 환경에도 (안타깝지만) ’대세’가 없다. 이렇다보니 조합이 이래저래 복잡해진다. 본격적으로 쓰려면 Poetry 같은 녀석을 부려야 하겠지만, 내가 타협할 수 있는 (문과적 수준의) 선택지가 있었으면 했다. Rye와 pixi가 딱 그 용도로 적합하다.\n단점이 아예 없는 것은 아니다. 서비스가 anaconda 패키지 관리 시스템에 의존하기 때문에 필요한 패키지가 사용 환경에서 아나콘다 생태계에 없다면 어쩔 수 없이 타협해야 한다. 0.8 버전부터 PyPI 패키지를 설치할 수 있다. 물론 PyPI 설치의 경우 초기 개발 단계라서 버그가 많다. 그래도 개인 프로젝트를 위한 의존성 관리 도구로는 충분하다.\n\n\n개발팀은 Rust의 cargo 명령어를 지향한다고 하며, pixi가 언어에 종속되지는 않으나 의존성 지옥에 가장 취약한 python과 궁합이 잘 맞을 것이라고 밝히고 있다. conda-forge를 기본 패키지 저장소로 쓴다는 점부터 pixi가 python을 위한 의존성 관리 도구라는 것을 알 수 있다. 혹시나 해서 julia를 태워 봤다. conda-forge를 통해서 지원되는 julia는 intel macos와 linux다. 이 환경에서는 잘 돌아가고 WSL에서도 잘 설치된다. 콘다-포지의 줄리아 리포지토리에는 Windows와 Silicon mac용 설치 파일이 없다."
  },
  {
    "objectID": "posts/computer-tool/2023-08-27-pixi.html#설치",
    "href": "posts/computer-tool/2023-08-27-pixi.html#설치",
    "title": "pixi",
    "section": "설치",
    "text": "설치\nhttps://prefix.dev/docs/pixi/overview#installation\nOS에 따라서 설치 방법이 제공된다. macos나 linux라면 brew를 쓰는 것을 권장한다.\nbrew install pixi # for Macos or linux\niwr -useb https://pixi.sh/install.ps1 | iex # For Windows PowerShell"
  },
  {
    "objectID": "posts/computer-tool/2023-08-27-pixi.html#활용",
    "href": "posts/computer-tool/2023-08-27-pixi.html#활용",
    "title": "pixi",
    "section": "활용",
    "text": "활용\nRye와 거의 비슷하다.\n\n환경을 프로젝트 폴더 안에 활성화한다.\n활용한 언어를 포함해서 필요한 패키지를 add한다.\n코딩한다.\n\n\n\nRye든 pixi든 사실 문법 자체는 대체로 Poetry를 따르고 있다.\npixi의 경우 다음과 같은 특징을 지닌다.\n\nconda 환경을 따른다.\n별도의 셸 환경을 제공한다.\n\n예를 들어보자. 원하는 폴더에 파이썬 환경을 만들고 여기에 pandas와 plotly를 설치하고 싶다고 하자. 해당 폴더를 만들고 터미널을 통해 해당 폴더에 들어가자.\n&gt; pixi init .  # 폴더를 생성하고 싶다면 pixi init {프로젝트-이름}\n&gt; pixi add python pandas plotly \npixi가 필요한 패키지를 콘다 리포지터리에서 끌어와 설치한다. 만일 터미널에서 활용하고 싶다면 pixi shell을 치면 된다. pixi를 치면 필요한 명령어를 보여준다."
  },
  {
    "objectID": "posts/computer-tool/2023-08-27-pixi.html#multi-platform",
    "href": "posts/computer-tool/2023-08-27-pixi.html#multi-platform",
    "title": "pixi",
    "section": "Multi platform",
    "text": "Multi platform\npixi의 장점은 os별로 구별해서 패키지를 관리할 수 있다는 것이다. 환경을 담고 있는 pixi.toml을 열어보면 이 점을 쉽게 알 수 있다.\n[project]\n# Default project info....\n# A list of platforms you are supporting with your package.\nplatforms = [\"win-64\", \"linux-64\", \"osx-64\", \"osx-arm64\"]\npixi.toml을 열어보면 프로젝트의 메타 데이터로 플랫폼이 있다. 여기에 정의되어 있지 않은 환경에서 .toml에 정의된 패키지를 인스톨해보자.\n❯ pixi install\n  × the project is not configured for your current platform\n   ╭─[pixi.toml:6:1]\n 6 │ channels = [\"conda-forge\"]\n 7 │ platforms = [\"osx-arm64\"]\n   ·             ────────────────┬────────────────\n   ·                             ╰── add 'win-64' here\n 8 │\n   ╰────\n  help: The project needs to be configured to support your platform (win-64).\n이렇게 메시지를 띄워준다. pixi.toml 파일을 열어 해당 플랫폼을 추가한 후 다시 pixi install을 실행하면 된다. 만일 에러가 뜬다면 셸 창을 다시 실행하자. 플랫폼 별 의존성을 세밀하게 정의해 설치하거나 이를 pixi.toml에 지정할 수 있다. 바로 이어서 살펴볼 것이다.\n\n\n자세한 것은 여기를 참고하도록 하자.\nGitHub를 통해 여러 플랫폼에서 코드를 반복 사용하는 경우를 생각해보자. .pixi/env 아래 폴더에 바이너리 및 패키지가 저장된다. 만일 GitHub를 통해 .ignore를 설정했다면 env 아래 폴더가 모두 무시되므로 플랫폼 별로 다른 바이너리가 GitHub로 동기화되지는 않는다.\n\nExample\n아마도 멀티플랫폼 지원이 pixi의 가장 큰 장점이 아닐까 싶다. pytorch를 인스톨하는 경우를 떠올려보자.\n\n플랫폼A: Windows + Nvidia GPU\n플랫폼B: macos + Silicon mac\n\n하나의 pixi.toml 파일을 통해서 각기 다른 플랫폼에서 파이토치 프로젝트를 유지하는 것이 목표이다. 특히 플랫폼A에서는 cuda를 활용할 예정이다.\n\n\npixi.toml\n\n[project]\nname = \"pixi_pytorch\"\nversion = \"0.1.0\"\ndescription = \"Add a short description here\"\nauthors = [\"Junsok Huhh &lt;anarinsk@gmail.com&gt;\"]\nchannels = [\"pytorch\", \"nvidia\", \"conda-forge\"]\nplatforms = [\"win-64\", \"osx-arm64\"]\n\n[tasks]\n\n[target.win-64.dependencies]\npytorch-cuda = \"11.8.*\"\ntorchaudio = \"2.0.2.*\"\npytorch = \"2.0.1.*\"\ntorchvision = \"0.15.2.*\"\n\n[target.osx-arm64.dependencies]\npytorch = \"2.0.1.*\"\ntorchvision = \"0.15.2.*\"\n\n[dependencies]\njupyter = \"1.0.0\"\n\n\ntarget은 플랫폼별로 특화된 분기를 지정할 수 있다.\n\n.이후 플랫폼, 그리고 지정할 pixi 영역이 붙는다.\n지정 가능한 pixi 영역은 activation, dependencies, tasks 세 가지이다.\n\n위 예시 파일을 살펴보자.\n\npixi.toml을 플랫폼A에서 실행하면 .pixi\\ 폴더 아래 cuda 기반의 파이토치가 설치된다. 플랫폼B에는 .pixi/ 아래 실리콘 맥 기반의 MPS를 활용한 파이토치가 설치된다.\n채널은 플랫폼 별로 구별할 필요가 없다. 플랫폼A는 pytorch, nvidia를 쓰고 플랫폼B는 pytorch 채널을 쓴다."
  },
  {
    "objectID": "posts/computer-tool/2023-08-27-pixi.html#pypi-패키지-설치",
    "href": "posts/computer-tool/2023-08-27-pixi.html#pypi-패키지-설치",
    "title": "pixi",
    "section": "PyPI 패키지 설치",
    "text": "PyPI 패키지 설치\nconda 리포가 대체로 문제가 되지 않지만, matplotlib, stargazer 등은 현재로서는 PyPI로만 설치할 수 있다. 다행히 0.8 버전부터 PyPI 패키지를 설치할 수 있게 되었다. 방법은 두 가지다. (결국은 같은 방법이긴 하다.) 아래 같이 toml 파일을 업데이트하고, pixi install을 실행한다.\n\n\nPyPI 패키지란 파이썬 패키지 인덱스를 의미한다. 파이썬에서 표준적으로 패키지를 설치하는 명령어인 pip를 통해 설치되는 패키지를 의미한다.\n\n\npixi.toml\n\n[pypi-dependencies]\nkoreanize-matplotlib = \"==0.1.1\"\nstargazer = \"*\"\n\n아직 실험적인 개발 단계라서 버전 지정 방법 등이 conda와 다르다. *의 경우 최신 버전을 설치한다.\n아니면 터미널 창에서 아래와 같이 실행하자. 이 내용은 pixi add --help로도 확인할 수 있다.\n$ pixi add --pypi koreanize-matplotlib stargazer"
  },
  {
    "objectID": "posts/computer-tool/2023-08-27-pixi.html#유연함",
    "href": "posts/computer-tool/2023-08-27-pixi.html#유연함",
    "title": "pixi",
    "section": "유연함",
    "text": "유연함\npixi init을 실행하면 .pixi/가 .gitignore 포함된다. 즉 작업 환경의 메타 데이터만 남고 해당 작업 환경 자체는 git에 동기화되지 않는다.\n필요한 경우 리포를 동기화한 후 pixi install을 실행하면 해당 환경이 그대로 복원된다. 디렉토리 별로 나누어 운용할 수도 있기 때문에 매우 가볍고 유연하게 작업 환경을 부릴 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2023-08-27-pixi.html#vs-code",
    "href": "posts/computer-tool/2023-08-27-pixi.html#vs-code",
    "title": "pixi",
    "section": "VS Code",
    "text": "VS Code\nVS Code에서 .ipynb로 작업하고 싶다면 간단하다. 윈도의 경우 해당 폴더가 작업 폴더로 잡혀 있다면 커널 선택 시 .pixi... 아래 설치된 커널이 바로 선택가능할 것이다. 만일 그렇지 않다면 커널을 직접 선택해주면 된다.\n\n\nVS Code에서 파일 &gt; 작업 영역에 폴더 추가를 통해 작업 폴더를 지정할 수 있다. 터미널의 해당 폴더에서 code .을 실행해도 된다.\n\n\n\n\n\n\n인터프리터 경로 설정\n\n\n\nF1 &gt; Python: 인터프리터 선택 &gt; +인터프리터 경로 입력...\n\n\n해당 프로젝트 폴더 안에 .pixi로 가자. OS 별로 구별해서 파이썬 바이너리 혹은 스크립트를 선택하면 된다.\n\n(macos) .pixi/env/bin/pyhon\n(windows) .pixi\\env\\python.exe"
  },
  {
    "objectID": "posts/computer-tool/2023-08-27-pixi.html#실제-응용",
    "href": "posts/computer-tool/2023-08-27-pixi.html#실제-응용",
    "title": "pixi",
    "section": "실제 응용",
    "text": "실제 응용\n아래 리포에서 pixi.toml을 살펴보시라.\n\nPytorch OS 플랫폼 별 인스톨 및 테스트\nPyPI 패키지 설치"
  },
  {
    "objectID": "posts/computer-tool/2023-08-27-pixi.html#references",
    "href": "posts/computer-tool/2023-08-27-pixi.html#references",
    "title": "pixi",
    "section": "References",
    "text": "References\nhttps://prefix.dev/blog/launching_pixi"
  },
  {
    "objectID": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html",
    "href": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html",
    "title": "Ubuntu를 깔고 먼저 해야 할 일들",
    "section": "",
    "text": "우분투 설치하고 먼저 해야 할 일들을 정리해보자."
  },
  {
    "objectID": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#tl-dr",
    "href": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#tl-dr",
    "title": "Ubuntu를 깔고 먼저 해야 할 일들",
    "section": "",
    "text": "우분투 설치하고 먼저 해야 할 일들을 정리해보자."
  },
  {
    "objectID": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#넋두리",
    "href": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#넋두리",
    "title": "Ubuntu를 깔고 먼저 해야 할 일들",
    "section": "넋두리",
    "text": "넋두리\nWSL이 생기면서 윈도에서도 리눅스를 제대로 쓸 수 있게 되었다. 리눅스(아마도 우분투)를 쓸 일이 많아진 만큼, 우분투 설치하고 (내 기준에서) 해야 할 일을 정리해보려 한다. 물론 이 포스트 멀지 않은 미래에 모든 걸 까먹을 나 놈을 위한 것이다."
  },
  {
    "objectID": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#meta",
    "href": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#meta",
    "title": "Ubuntu를 깔고 먼저 해야 할 일들",
    "section": "Meta",
    "text": "Meta\n딱히 Ubuntu에 해당하는 내용은 아니지만 WSL에서 Ubuntu 설치하는 방법은 간단하게 다루고 넘어가겠다. 윈도 파워셸이나 명령 프롬프트에서 실행 가능하다.\n&gt; wsl -l # 설치된 WSL 목록 확인\n&gt; wsl -l -o # 설치할 수 있는 배포판 확인 \n\n# 아래에서 \"UBUNTU\"는 특정 배포판(distro)의 이름을 의미한다. \n# 예를 들어, \"Ubuntu-20.04\" 등이 될 수 있다.\n\n&gt; wsl --install -d UBUNTU # Ubuntu 설치\n&gt; wsl --shutdown UBUNTU # Ubuntu 종료\n&gt; wsl --unregister UBUNTU # Ubuntu 삭제"
  },
  {
    "objectID": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#터미널",
    "href": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#터미널",
    "title": "Ubuntu를 깔고 먼저 해야 할 일들",
    "section": "터미널",
    "text": "터미널\n보통 우분투를 설치하고 그 기기에 키보드와 마우스를 연결해서 쓰는 일은 드물지 않을까 싶다.\nWSL을 예로 들어 보자. 윈도와 나란히 설치되어 독립적으로 운용되는, 즉 윈도 내부에 있지만 사실상 독립된 형태로 돌아가는 리눅스 서버가 WSL이다. 윈도에서 WSL을 쓴다면 해당 서버에 접속해 활용하게 된다. 이렇게 다른 OS(Windows, Macos)에서 우분투 서버에 접속해서 쓸 때는 관문 역할을 하는 터미널 앱이 중요하다. 윈도에서는 윈도 터미널이 Macos에서는 iTerm2이 좋다.\n접속하는 OS에 취향껏 터미널에서 쓸 폰트를 설치하면 된다.\n\nHACK Nerd 폰트 좋다. 폼나틑 폰트다.\n가볍게 쓰고 싶다면, 아범의 ligalex mono 폰트를 쓰자. IBM의 모노 플렉스 폰트에 리거쳐 문자를 더한 폰트다.\n\n\n\n요즘은 여러가지 이모지가 많이 활용되는데, 이를 제대로 쓰려면 Nerd 계열의 폰트를 설치하자. Hack Nerd 폰트는 여기서 다운로드하자."
  },
  {
    "objectID": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#리포지토리-주소-변경",
    "href": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#리포지토리-주소-변경",
    "title": "Ubuntu를 깔고 먼저 해야 할 일들",
    "section": "리포지토리 주소 변경",
    "text": "리포지토리 주소 변경\n우분투 업데이트에 필요한 리포지토리 주소를 바꾸도록 하자. 만일 WSL을 통해 설치했다면 우분투 메인 리포(http://archive.ubuntu.com/ubuntu)로 설정되어 있을 것이고, iso 이미지로 설치했다면, archive 앞에 kr.이 앞에 붙어 있을 것이다. apt 패키지 업데이트를 위한 주소는\n\n22.04 LTS까지 /etc/apt/sources.list\n24.04 LTS부터 /etc/apt/sources.list.d/ubuntu.sources\n\n파일을 직접 편집하면 된다. 편집용 에디터는 취향껏 쓰면 된다. 편리한 nano로 예를 들자.\n&gt; sudo nano /etc/apt/sources.list # or\n&gt; sudo nano /etc/apt/sources.list.d/ubuntu.sources\n기본 저장소보다는 카카오의 미러 저장소가 국내에서 빠르다. 해당 파일을 적당한 편집기로 열어 기본 패키지 저장소가 어떻게 되어 있는지 살펴보자. 파일 내의 모든 저장소 URL을 찾아 http://archive.ubuntu.com/ubuntu 또는 http://kr.archive.ubuntu.com/ubuntu 등의 주소를 http://mirror.kakao.com/ubuntu로 변경하면 된다. 둘 중 뭘로 되어 있는지 모르니 확인 후 작업하는 것을 권한다. nano 앱에서 crtl-w &gt; crtl-r로 해당 부분을 찾아서 바꾸자."
  },
  {
    "objectID": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#zsh-관련-설치",
    "href": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#zsh-관련-설치",
    "title": "Ubuntu를 깔고 먼저 해야 할 일들",
    "section": "zsh 관련 설치",
    "text": "zsh 관련 설치\n아래 터미널 명령어로 zsh를 설치하자.\n&gt; sudo apt update # 이미 실행했다면 건너 뛰자 \n&gt; sudo apt install zsh # zsh 설치\n&gt; chsh -s $(which zsh) # zsh을 기본 셸로 설정\n\n# 로그아웃 후에 다시 로그인하면 zsh이 기본셸로 설정된다. \n&gt; sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" # oh my zsh을 설치하자."
  },
  {
    "objectID": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#powerlevel10kp10k-깔기",
    "href": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#powerlevel10kp10k-깔기",
    "title": "Ubuntu를 깔고 먼저 해야 할 일들",
    "section": "powerlevel10k(p10k) 깔기",
    "text": "powerlevel10k(p10k) 깔기\n셸 꾸미기로 고민 말고 파워레벨10k를 쓰자. 제일 쓸 만 하다.\n&gt; git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k # p10k 끌어오기 \n&gt; nano ~/.zshrc # zsh 설정 열기 \n# ZSH_THEME=\"robbyrussell\" -&gt; ZSH_THEME=\"powerlevel10k/powerlevel10k\" # 테마를 p10k로 바꾸자 \n변경 후 셸을 다시 시작하면 p10k 설정화면이 뜬다. 취향대로 설정하도록 하자. 설정을 바꾸고 싶다면, p10k configure를 실행하거나 ~/.p10k.zsh를 직접 수정해도 좋다.\n\nbrew 설치\n우분투에서 필요한 앱을 까는 방법은 apt, snap 그리고 brew가 있다. OS 단위의 업데이트 혹은 OS와 프로세스과 깊게 연관된 앱들은 apt를 통해서 깔자. snap도 나쁘지는 않지만 번거로운 면이 있다. user 레벨에서 필요한 앱들을 깔고 관리하기에는 brew가 좋다. 어차피 GUI를 쓰지 않는다면 리눅스에서의 활용이 MacOS에서와 크게 다를 것이 없다.\nhttps://brew.sh/\n웹 페이지의 소개된 방식대로 설치하자. 설치 후에는 화면에 뜬 메시지대로 셸의 종류에 따른 사후 작업이 필요하다. .zshrc에 여러가지 경로를 넣어 주는 작업이다. 그래야 brew 명령어를 제대로 실행할 수 있다. 현재 버전대로 메시지를 그대로 옮겨두면 다음과 같다.\n&gt; Next steps:\n- Run these two commands in your terminal to add Homebrew to your PATH:\n    (echo; echo 'eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"') &gt;&gt; /home/anari/.zshrc\n    eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"\n- Install Homebrew's dependencies if you have sudo access:\n    sudo apt-get install build-essential\n  For more information, see:\n    https://docs.brew.sh/Homebrew-on-Linux\n- We recommend that you install GCC:\n    brew install gcc\n- Run brew help to get started\n- Further documentation:\n    https://docs.brew.sh\n\n\ngh, pixi with brew\n이제 brew를 통해서 필요한 앱들을 깔겠다. 필요한 앱을 알아서 깔면 된다. brew를 통해서 설치할 수 있는지 여부는 brew 홈페이지에서 검색으로 확인할 수 있다. 나는 깃헙을 활용하기 위한 gh와 파이썬 의존성 관리도구인 pixi를 가장 먼저 설치했다.\n&gt; brew install gh pixi \ngh를 설치한 후 gh auth login을 통해 깃헙 계정에 로그인을 해두자. 필요한 리포가 있을 경우 gh repo clone {리포-주소}를 통해 편하게 당겨올 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#non-brew",
    "href": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#non-brew",
    "title": "Ubuntu를 깔고 먼저 해야 할 일들",
    "section": "Non-brew",
    "text": "Non-brew\nbrew로 다 설치가 되면 좋겠지만 그렇지 않은 앱들도 있다. 아래 앱들은 직접 설치해야 한다.\n\nMiniforge\nMiniforge는 패키지 관리 도구이자 독립적인 가상 환경을 제공하는 miniconda의 오픈소스 버전이다. Macos에서는 brew를 통해 설치되지만 아쉽게도 리눅스에서는 별도로 설치해야 한다. pixi를 쓴다면 다른 가상 환경은 필요하지 않다. 다만 다른 프로그램이 conda에 의존할 경우 필요할 수 있다.\n&gt; curl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"\n&gt; bash Miniforge3-$(uname)-$(uname -m).sh\n콘다도 설치 후 초기화 작업이 필요하다. 이 역시 메시지에 뜬다.\neval \"$(/home/anari/miniforge3/bin/conda shell.YOUR_SHELL_NAME hook)\"\n\nTo install conda's shell functions for easier access, first activate, then:\n\nconda init\n설명이 약간 혼란스러운데, zsh을 사용한다고 가정하면 다음과 같이 하면 된다.\n&gt; eval \"$(/home/anari/miniforge3/bin/conda shell.zsh hook)\"\n&gt; conda init zsh \n삭제를 비롯한 보다 자세한 사항은 아래 링크를 참고하자.\n🔗 miniforge\n\n\nQuarto\n문서 작성에 필수 도구인 Quarto의 경우 우분투에서는 brew를 통해 설치할 수 없다.\n🔗 Linux에 Quarto 설치하기\n.deb 확장자 파일을 다운받아서 gdebi 앱을 통해서 설치하는 방식이다.\n&gt; sudo curl -LO https://quarto.org/download/latest/quarto-linux-amd64.deb #deb 다운로드 \n&gt; sudo apt-get install gdebi-core\n&gt; sudo gdebi quarto-linux-amd64.deb\n\n\nMojo\nUbuntu 22.04 LTS와 VS Code + Mojo Extension을 활용한다고 가정하자.\n&gt; curl https://get.modular.com | sh - && \\\n  modular auth mut_c4e7186420c84b86b1f7b5219b4028d9\n&gt; modular install mojo\n&gt; code .\n🔗 mojo 설치 및 파이썬 환경 운용"
  },
  {
    "objectID": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#활용",
    "href": "posts/computer-tool/2023-11-03-first-thing-ubuntu.html#활용",
    "title": "Ubuntu를 깔고 먼저 해야 할 일들",
    "section": "활용",
    "text": "활용\n\n윈도 터미널에서 WSL에 접근한 뒤 작업 폴더로 가자.\ncode .을 실행하자. 이 명령어를 실행하면 해당 폴더 아래에서 윈도의 VS Code가 실행된다.\nVS Code는 윈도 앱이다. UI등 윈도의 모든 편리함을 그대로 누리면 된다."
  },
  {
    "objectID": "posts/computer-tool/2022-12-04-matplotlib-korfont-redux.html",
    "href": "posts/computer-tool/2022-12-04-matplotlib-korfont-redux.html",
    "title": "matplotlib + 한글 Redux",
    "section": "",
    "text": "matplotlib에서 한글 사용 마지막으로 정리한다."
  },
  {
    "objectID": "posts/computer-tool/2022-12-04-matplotlib-korfont-redux.html#tl-dr",
    "href": "posts/computer-tool/2022-12-04-matplotlib-korfont-redux.html#tl-dr",
    "title": "matplotlib + 한글 Redux",
    "section": "",
    "text": "matplotlib에서 한글 사용 마지막으로 정리한다."
  },
  {
    "objectID": "posts/computer-tool/2022-12-04-matplotlib-korfont-redux.html#not-in-this-post",
    "href": "posts/computer-tool/2022-12-04-matplotlib-korfont-redux.html#not-in-this-post",
    "title": "matplotlib + 한글 Redux",
    "section": "Not in this Post",
    "text": "Not in this Post\n\n한글 폰트 설치 등의 문제는 다루지 않는다.\n\nOS 별 한글 폰트 설치 및 활용 LINK\n(리눅스) 컨테이너 내에서 한글 폰트 설치 LINK"
  },
  {
    "objectID": "posts/computer-tool/2022-12-04-matplotlib-korfont-redux.html#what-in-this-post",
    "href": "posts/computer-tool/2022-12-04-matplotlib-korfont-redux.html#what-in-this-post",
    "title": "matplotlib + 한글 Redux",
    "section": "What in this Post",
    "text": "What in this Post\n\nmatplotlib 그림 안에서 한글 활용의 최종 버전"
  },
  {
    "objectID": "posts/computer-tool/2022-12-04-matplotlib-korfont-redux.html#matplotlib과-한글의-라벨링",
    "href": "posts/computer-tool/2022-12-04-matplotlib-korfont-redux.html#matplotlib과-한글의-라벨링",
    "title": "matplotlib + 한글 Redux",
    "section": "matplotlib과 한글의 라벨링",
    "text": "matplotlib과 한글의 라벨링\nmatplotlib은 표준적인 파이썬 시각화 패키지다. 아쉽게도 이 녀석이 한글과 별로 안 친하다. 그래픽 렌더링 엔진에 한글 폰트가 빠져 있어서 이를 추가로 인식을 시켜야 결과물 내에서 한글 라벨을 쓸 수 있다. 가장 간단한 해결 방법은 나눔고딕 폰트를 쓸 수 있게 해주는 패키지 koreanize-matplotlib를 쓰는 것이다.\n먼저 문제부터 살펴보자. 테스트를 위해서 아래 코드에 간단한 함수 draw_sample(fontprop)를 작성했다. 인자 fontprop은 그래프 요소에 적용될 폰트 특성이다. 값이 없으면 전역적으로 설정된 내용에 따른다.\n\nCode\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\nimport numpy as np\n\n# 그릴 데이터 생성 \ndef draw_sample(fontprop=None):\n    plt.rcParams['figure.figsize'] = [4, 4]\n    data = np.random.randint(-100, 100, 50).cumsum()\n    plt.plot(range(50), data, 'r')\n    plt.title('가격변동 추이', fontproperties=fontprop)\n    plt.ylabel('가격', fontproperties=fontprop)\n    plt.show()\n\ndraw_sample()\n\n\n/home/anari/github/lostineconomics_quarto/.pixi/env/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/home/anari/github/lostineconomics_quarto/.pixi/env/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 44201 (\\N{HANGUL SYLLABLE GYEOG}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/home/anari/github/lostineconomics_quarto/.pixi/env/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 48320 (\\N{HANGUL SYLLABLE BYEON}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/home/anari/github/lostineconomics_quarto/.pixi/env/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 46041 (\\N{HANGUL SYLLABLE DONG}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/home/anari/github/lostineconomics_quarto/.pixi/env/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 52628 (\\N{HANGUL SYLLABLE CU}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n/home/anari/github/lostineconomics_quarto/.pixi/env/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n위 결과에서 보듯이 한글 폰트가 없으니 출력이 제대로 되지 않는다. 이제 koreanize-matplotlib 패키지를 설치하고 import 후 실행해보자\n$ pip install koreanize-matplotlib \n위에서 보다시피, koreanize-matplotlib는 PyPI에만 있다. conda와 같은 다른 저장소를 통해서는 설치할 수 없다는 것은 유의하시라.\n\nCode\nimport koreanize_matplotlib\ndraw_sample()\n\n\n\n\n \n\n\n\n\n\n \n\n\n\nkoreanize-matplotlib 패키지는 나눔고딕 폰트를 자동으로 설치하고 이를 폰트로 잡아 준다. 위에 보는 것처럼 한글 출력에 문제가 없다."
  },
  {
    "objectID": "posts/computer-tool/2022-12-04-matplotlib-korfont-redux.html#koreanize-matploitlib-이외의-대안",
    "href": "posts/computer-tool/2022-12-04-matplotlib-korfont-redux.html#koreanize-matploitlib-이외의-대안",
    "title": "matplotlib + 한글 Redux",
    "section": "koreanize-matploitlib 이외의 대안",
    "text": "koreanize-matploitlib 이외의 대안\nkoreanize-matplotlib이 간편하고 좋은 해결책이지만 다른 방법도 있다. 만일을 위해 두 가지를 더 알아보자."
  },
  {
    "objectID": "posts/computer-tool/2022-12-04-matplotlib-korfont-redux.html#노트북에서-한글-폰트-가져오기",
    "href": "posts/computer-tool/2022-12-04-matplotlib-korfont-redux.html#노트북에서-한글-폰트-가져오기",
    "title": "matplotlib + 한글 Redux",
    "section": "노트북에서 한글 폰트 가져오기",
    "text": "노트북에서 한글 폰트 가져오기\n앞서 링크에서 소개한 폰트 추가 방법은 시스템에 폰트를 먼저 깔고 해당 폰트를 matplotlib에 등록하는 방법이다. pyodide에서 활용할 수 있는 다른 방법은 없을까? 아래 소개할 방법은 ttf 폰트 파일을 바로 matplotlib이 쓸 수 있게 해주는 방법이다.\n\n\nCode\nfont_path = './font/D2Coding v.1.3.2 ligature Nerd Font Complete.ttf' # 폰트 파일의 위치에 따라서 조정\nfont_callsign = 'D2 Coding Nerd'\nfe = fm.FontEntry(\n    fname=font_path,\n    name=font_callsign) # 원하는 폰트 호출 이름 설정 \nfm.fontManager.ttflist.insert(0, fe) # or simply append\n\n\n\n\n\n\n\n\nCode Tips\n\n\n\n\nfm.FontEntry... 한글 폰트를 matplotlib의 폰트 매니저에 바로 심어주는 명령\n\nfont_path: 폰트의 ttf 파일의 위치와 파일 이름을 지정한다. 각자 알맞게 조정하자.\nfont_callsign: 내가 지정할 폰트의 이름, 폰트를 호출할 때 활용한다. 각자 취향대로 바꾸자.\n\n\n\n\n위 방법의 장점은 폰트의 위치를 가리지 않는다는 것이다. 적당한 위치에 두고 matplotlib이 쓸 수 있도록 폰트를 인식시키는 방식이다. 폰트가 잘 인식되었는지 확인해보자.\n\n\nCode\nprint([(f.name, f.fname) for f in mpl.font_manager.fontManager.ttflist if ('D2' in f.name) | ('Nanum' in f.name) ])\n\n\n[('D2 Coding Nerd', './font/D2Coding v.1.3.2 ligature Nerd Font Complete.ttf'), ('D2Codingligature Nerd Font', '/usr/local/share/fonts/D2Coding Nerd/D2Coding v.1.3.2 ligature Nerd Font Complete.ttf'), ('D2Coding Nerd Font', '/usr/local/share/fonts/D2Coding Nerd/D2Coding v.1.3.2 Nerd Font Complete.ttf'), ('NanumGothic', '/home/anari/github/lostineconomics_quarto/.pixi/env/lib/python3.11/site-packages/koreanize_matplotlib/fonts/NanumGothicLight.ttf'), ('NanumGothic', '/home/anari/github/lostineconomics_quarto/.pixi/env/lib/python3.11/site-packages/koreanize_matplotlib/fonts/NanumGothic.ttf'), ('NanumGothic', '/home/anari/github/lostineconomics_quarto/.pixi/env/lib/python3.11/site-packages/koreanize_matplotlib/fonts/NanumGothicExtraBold.ttf'), ('NanumGothic', '/home/anari/github/lostineconomics_quarto/.pixi/env/lib/python3.11/site-packages/koreanize_matplotlib/fonts/NanumGothicBold.ttf')]"
  },
  {
    "objectID": "posts/computer-tool/2022-12-04-matplotlib-korfont-redux.html#활용",
    "href": "posts/computer-tool/2022-12-04-matplotlib-korfont-redux.html#활용",
    "title": "matplotlib + 한글 Redux",
    "section": "활용",
    "text": "활용\nmatplotlib에서 폰트를 활용하는 방법은 두 가지다. 하나는 폰트의 속성을 지정해놓고 해당 폰트가 활용될 때 이를 호출해서 쓰는 방법이고, 다른 하나는 전역적으로 해당 폰트를 기본 폰트로 지정하는 것이다.\n\n호출해서 활용\n아래 결과에서 보듯이, fontprop을 통해 지정된 폰트 양식을 그래프 요소에 적용해보자.\n\nCode\nfontprop = fm.FontProperties(fname=font_path, size=13)\ndraw_sample(fontprop)\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n전역으로 활용\n폰트 속성을 전역으로 지정하고 그래프를 그려보자.\n\nCode\n# rcParams 설정\nplt.rcParams[\"font.family\"] = 'D2 Coding Nerd'\nplt.rcParams['font.size'] = 15.\nplt.rcParams['xtick.labelsize'] = 12.\nplt.rcParams['ytick.labelsize'] = 12.\nplt.rcParams['axes.labelsize'] = 12.\nplt.rcParams['axes.unicode_minus'] = False\n\n# 그림 그리기 \ndraw_sample()"
  },
  {
    "objectID": "posts/computer-tool/2022-12-22-my-domains.html",
    "href": "posts/computer-tool/2022-12-22-my-domains.html",
    "title": "내 도메인을 GitHub Pages에 연결하자.",
    "section": "",
    "text": "도메인과 깃허브 페이지스를 연결하는 법을 알아보자.\n\n\n\n\n도메인에 관한 상세한 지식\nGithub Pages의 일반적인 설정 방법\n\n\n\n\n\n도메인 구입하고 깃헙 페이지스로 연결하는 방법"
  },
  {
    "objectID": "posts/computer-tool/2022-12-22-my-domains.html#tl-dr",
    "href": "posts/computer-tool/2022-12-22-my-domains.html#tl-dr",
    "title": "내 도메인을 GitHub Pages에 연결하자.",
    "section": "",
    "text": "도메인과 깃허브 페이지스를 연결하는 법을 알아보자.\n\n\n\n\n도메인에 관한 상세한 지식\nGithub Pages의 일반적인 설정 방법\n\n\n\n\n\n도메인 구입하고 깃헙 페이지스로 연결하는 방법"
  },
  {
    "objectID": "posts/computer-tool/2022-12-22-my-domains.html#도메인-구입",
    "href": "posts/computer-tool/2022-12-22-my-domains.html#도메인-구입",
    "title": "내 도메인을 GitHub Pages에 연결하자.",
    "section": "도메인 구입",
    "text": "도메인 구입\n구입은 편한 곳에서 하시면 되겠다. 나는 Google Domains를 이용했다. 도메인을 산다는 것은 무엇일까? 예를 들어 이 홈페이지를 위해 구입한 도메인은 lostineconomics.com이다. 나는 www.lostineconomics.com을 산 것이 아니었다! 웹 서비스 www을 도메인의 하위 도메인으로 설정할 수 있지만, 구입한 것은 도메인 lostineconomics.com이다. 그리고 하위 도메인에는 www만 있는 것이 아니다. blog.lostineconomics.com이나 mail.lostineconomics.com도 설정할 수 있다.\n\n\n자세한 내용은 여기를 참고하자.\n보통 도메인 구입처에서 DNS, 즉 도메인네임서버 관련한 기본적인 서비스를 제공한다. 가장 기초적인 서비스는 포워딩 서비스다. 즉, lostineconomics.com을 호출했을 때 이를 다른 도메인으로 연결시켜주는 서비스다. 개념이 직관적이고 이용이 편리하지만, 포워딩되는 주소로 바뀌는 것이 조금 머쓱하다. 도메인 이름이 좋아서 구입했다면, 녀석이 계속 주소 창에 남아야 하지 않겠는가!\n\n\n여기서는 구글 도메인스의 설정을 소개한다. 대체로 많은 도메인 서비스들이 DNS 관련 설정 서비스를 제공하니 업체별로 검색하면 대체로 비슷한 역할을 수행하는 기능을 발견할 수 있을 것이다."
  },
  {
    "objectID": "posts/computer-tool/2022-12-22-my-domains.html#github에-보유-도메인-소유-증명하기",
    "href": "posts/computer-tool/2022-12-22-my-domains.html#github에-보유-도메인-소유-증명하기",
    "title": "내 도메인을 GitHub Pages에 연결하자.",
    "section": "GitHub에 보유 도메인 소유 증명하기",
    "text": "GitHub에 보유 도메인 소유 증명하기\nGitHub Pages는 훌륭한 스태틱 웹 서비스다. js, css 정도를 쓰는 html 문서를 전달하는 데에는 이보다 싸고 (무료다!), 편한 서비스를 찾기 어려울 듯 싶다. GitHub Pages는 개별 리포의 주소를 외부 도메인과 연결하는 서비스도 제공한다. 다만 연결을 위해 몇 가지 절차를 거쳐야 한다.\n\n도메인 확인하기 1 (GitHub)\n먼저 연결하고자 하는 도메인이 소유자의 것이 맞는지를 확인하는 절차가 필요하다. 깃허브의 계정 Settings &gt; “Code, planning, and autiomation” 섹션에 Pages라는 항목으로 들어가보자.\nwww를 제외하고 구입한 도메인 이름을 넣으면 아래와 같은 창이 뜬다. 1번은 도메인의 앞에 붙여줄 하위 주소 이름이고, 2번은 이를 인증할 수 있는 값이다. 이 창을 띄워 두고 도에인 구입처로 가자. 두 값은 아래 그림처럼 버튼을 통해 복사하면 된다.\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n자세한 내용은 여기를 확인하자. 그런데 이렇게 도메인을 연결해도 actions의 프로세스에 따라서 custom domain이 풀리는 경우가 있다. 이때 필요한 것이 CNAME 파일이다. 페이지가 만들어지는 리포의 디렉토리(보통은 root)에 CNAME 파일을 만들고, 그 안에 연결할 도메인 이름을 적어주면 된다. 이렇게 하면 페이지를 퍼블리싱할 때 해당 도메인이 함께 설정된다. 페이지스 설정에 CNAME 파일이 함께 만들어지는 경우가 있으면 그대로 활용하면 되고 만들어지지 않았다면 추가해서 넣어주면 된다.\n\n\n도메인 확인하기 2 (Google Domains)\n구글 도메인스를 비롯한 도메인 구입처는 대체로 DNS와 관련해서 다양한 서비스를 제공한다.\n\n인증하려는 도메인의 DNS 설정 메뉴로 가자.\n맞춤 레코드 관리 &gt; 새 레코드 만들기\n아래 그림에 각 번호에 위 GitHub 인증 메뉴의 1, 2번을 붙여 넣고 저장한다.\n\n1번은 “호스트 이름”이고 2번은 “데이터”다.\n“유형”은 “TXT”로 설정한다.\n옆의 3600은 그대로 두면 된다. 구글 도메인스에서도 이를 권장한다.\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n도메인 확인하기 3 (GitHub)\n다시 Pages 설정 메뉴로 돌아가서 verify를 눌러준다. 설정되는데 다소 시간이 걸리지만 “verifyig”을 눌러 요구하다보면 인증이 된다. 앞서 도메인 서비스에서 설정한 값이 해당 DNS에 반영되고 이를 깃허브에서 끌어와 확인하면 도메인 소유 확인이 완료된다."
  },
  {
    "objectID": "posts/computer-tool/2022-12-22-my-domains.html#github-pages를-도메인에-연결하기",
    "href": "posts/computer-tool/2022-12-22-my-domains.html#github-pages를-도메인에-연결하기",
    "title": "내 도메인을 GitHub Pages에 연결하자.",
    "section": "GitHub Pages를 도메인에 연결하기",
    "text": "GitHub Pages를 도메인에 연결하기\n특정한 리포지터리의 깃허브 페이지({유저-ID}.github.io/{리포지터리-이름})를 도메인과 연결하기 위해서는 두 가지 과정이 필요하다. Google Domains에서 DNS 설정을 통해 CNAME을 설정해야 한다. CNAME이란 도메인의 이름에서 도메인의 이름으로 연결해주기 위한 설정이라고 생각하면 쉽다. 앞서와 같이 구글 도메인스의 DNS 설정으로 가자.\n\n도메인 연결 1 (Google Domains)\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n위 그림에서 보듯이 유형을 “CNAME”으로 잡는다. 이제 구입한 도메인 앞에 접두어(하위 도메인)이 들어간다. 가장 흔하게 쓸 수 있는 것이 www다. 즉, www.lostineconomics.com을 치면 어디로 포워딩되어야 하는지를 표시하면 된다. 호스트 이름이 www가 되고, 데이터는 anarinsk.github.io가 된다.\n주의할 점; 데이터에 해당 것허브 페이지스의 주소가 /{리포지터리-이름}까지 전부 전달되어야 할 것 같지만, 깃허브 페이지스의 최상위 페이지까지만 DNS에 전달해야 한다. 이후 과정은 연결은 GitHub Pages의 몫이다. /가 들어간 디렉토리는 전달할 수 없다. {이용자-ID}.github.io까지만 전달하면 해당 깃허브 페이지스의 디렉토리 자원과 도메인의 연결이 자동적으로 이루어진다.\n해당 도메인이 깃허브 페이지까지 잘 연결되는지 보려면, 아래의 셸 명령을 활용해보자.\n$ dig www.lostineconomics.com +nostats +nocomments +nocmd\n윈도 파워셸에는 dig 명령어가 없다. 설치가 가능하니 검색을 통해 적절히 방법을 찾으시라. 결과가 {이용자-ID}.github.io까지 잘 타고 들어가는지 확인하면 된다. 뒤에서 다루겠지만 여기서 IP 주소도 확인할 수 있는데, 이 녀석들이 설정에서 다시 활용될 수 있다.\n\n\n도메인 연결 (GitHub Pages)\n커스텀 도메인, 즉 www.lostineconomics.com을 기본 도메인으로 쓰면서 각 리포지터리 이름들이 /아래 서브 디렉토리처럼 들어가는 URL을 생각해보자. 이를 구현하려면 특별한 리포리터리를 만들어야 한다. {이용자-ID}.github.io을 이름으로 갖는 리포를 생성하자. 그리고 이 리포의 GitHub Pages 설정에서 커스텀 도메인을 www.lostineconomics.com로 설정한다. 해당 리포의 Pages의 경우 index.md 혹은 index.html 파일을 고쳐서 적당한 주소로 포워딩되도록 처리하자. 이렇게 해두면 이후 리포의 도메인에서 커스텀 도메인을 지정하지 않아도 www.lostineconomics.com이 내 계정의 기본 도메인이 된다.\n만일 커스텀 도메인이 필요하다면, www을 다른 것으로 바꾸는 방식으로 페이지를 지정할 수 있다. 즉, books.lostineconomics.com 이런 식으로 커스텀 도메인을 지정하고 앞서 살펴본 필요한 조치를 취하면 된다. 다만 이런 주소의 경우 /로 시작하는 서브 도메인은 설정할 수 없다.\n\n\n정리 및 응용\n흐름을 정리해보자. 구입한 도메인의 네임 서버(DNS)가 {이용자-ID}.github.io까지 타고 들어가면 깃허브 페이지스의 설정이 해당 주소를 해당 페이지스의 랜딩 페이지와 연결한다. 따라서 크게 작업 흐름을 정리해보면 다음과 같다.\n\n사용하려는 도메인 이름이 것히브 페이지스 도메인({개별-ID}.github.io)에 연결되도록 설정한다.\n1을 구현하려면 깃허브에서 내가 구입한 도메인을 txt 파일을 통해 인증헤야 한다.\n각 리퍼지토리의 깃허브 페이지스 설정에서 1의 도메인이 해당 리포의 페이지를 호출할 수 있도록 연결한다.\n\n도메인으로 꼭 www만 써야 할까? 아니다. 다른 이름도 가능하다. 이 페이지를 예로 들어보자.\n\nDNS의 레코드 관리에서 호스트의 이름으로 blog 설정하고 blog.lostineconomics.com을 anrinsk.github.io까지 연결한다.\n이 블로그를 담고 있는 리포에서 커스텀 도메인으로 blog.lostineconomics.com을 지정하면 이 주소는 이 블로그의 깃허브 페이지스로 연결된다.\nanarinsk.github.io라는 이름의 리포가 생성하고 이 리포의 커스텀 도메인은 www.lostineconomics.com이다. index.html을 통해 blog.lostineconomics.com으로 연결되도록 했다. 즉, www.lostineconomics.com이 호출되면 기본으로 blog.lostineconomics.com으로 연결된다.\n이제 이 계정의 리포들의 페이지스는 기본으로 www.lostineconomics.com을 기본 주소로 지닌다. 만일 별도의 커스텀 도메인이 필요하다면, blog.lostineconomics.com처럼 호스트 이름을 바꾸어서 설정하면 된다."
  },
  {
    "objectID": "posts/computer-tool/2022-12-22-my-domains.html#곁눈질-www가-없는-호출-포위딩하기",
    "href": "posts/computer-tool/2022-12-22-my-domains.html#곁눈질-www가-없는-호출-포위딩하기",
    "title": "내 도메인을 GitHub Pages에 연결하자.",
    "section": "곁눈질; www가 없는 호출 포위딩하기",
    "text": "곁눈질; www가 없는 호출 포위딩하기\n웹페이지에 들어갈 때 www를 쓰지 않는 경우가 있다. 이런 경우에도 해당 페이지로 잘 안내되는 것은 최상위 도메인이 www 등이 붙은 하위 도메인으로 연결되기 때문이다. 이를 구현하려면 구글 도메인스 DNS 설정에서 “A” 유형을 추가하면 된다. A 유형은 해당 호출을 바로 IP로 연결해준다. 해당 IP는 앞서 설정한 CNAME과 같기 때문에 원 도메인이 CNAME 도메인으로 연결된다.\n앞서 dig 명령을 실행하면 포워딩되는 IP 주소를 확인할 수 있다. 이를 DNS 레코드 관리에서 설정해주자. 도메인 이름은 비워둔다. 유형에는 “A”를 설정하고, 데이터에는 연결되는 IP 주소를 가급적 다 적어주자.\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n구글 도메인의 전체적인 DNS 설정을 한번 정리해보자.\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n유형\n기능\n호스트 이름\n데이터\n예시\n\n\n\n\nA\n원 도메인을 IP로 연결\n\nIP 주소\nyours.com →  185.XXX.1X8.15X\n\n\nTXT\n도메인 소유 여부 입증\n깃허브 계정 설정 제공\n깃허브 계정 설정 제공\n\n\n\nCNAME\n해당 DNS에서 호출되는 이름을 다른 이름으로 연결\nwww, blog, …\n연결될 도메인 이름\nwww.yours.com →  yours.github.io (호출한 리포의 페이지스로 연결)"
  },
  {
    "objectID": "posts/computer-tool/2022-12-22-my-domains.html#참고자료",
    "href": "posts/computer-tool/2022-12-22-my-domains.html#참고자료",
    "title": "내 도메인을 GitHub Pages에 연결하자.",
    "section": "참고자료",
    "text": "참고자료\n\n깃허브; 도메인 인증\n깃허브; 깃허브 페이지스 커스텀 도메인 설정\n구글 도메인스; DNS 레코드 설정"
  },
  {
    "objectID": "posts/computer-tool/2022-12-22-my-domains.html#a-follow-up",
    "href": "posts/computer-tool/2022-12-22-my-domains.html#a-follow-up",
    "title": "내 도메인을 GitHub Pages에 연결하자.",
    "section": "A follow-up",
    "text": "A follow-up\n빌어먹을 구글이 Domains 서비스를 접었다. 하지만 우리에게는 그에 못지 않은 훌륭한 대안이 있다. 도메인 구매와 DNS 관리 그리고 analytics까지 모두 제공하는 Cloudflare를 추천한다. 큰 회사라서 안정성도 큰 염려는 없을 듯 싶다. (하지만 구글은…)\n가입 후 웹 사이트를 등록하면서 DNS을 바꿔주면 그 이후 세부 설정을 할 수 있다. 이 홈페이지의 예시를 간략하게 스샷으로 소개하겠다. 도메인 관리의 모든 기능이 제공되고 인터페이스도 편리하다.\n\n\nlostineconomics.com → www.lostineconomics.com 으로 연결 이동\nwww.lostineconomics → anarinsk.github.io로 연결 이동\nBluesky 핸들 사용을 위한 인증 텍스트 파일\nGithub Pages 연결을 위한 인증 텍스트 파일 이동"
  },
  {
    "objectID": "posts/computer-tool/2023-10-20-github-codespaces.html",
    "href": "posts/computer-tool/2023-10-20-github-codespaces.html",
    "title": "Perfectly Codespaces",
    "section": "",
    "text": "코드 스페이스는 편리하고 저렴하게 활용할 수 있는 거의 완벽한 코딩 환경이다."
  },
  {
    "objectID": "posts/computer-tool/2023-10-20-github-codespaces.html#tl-dr",
    "href": "posts/computer-tool/2023-10-20-github-codespaces.html#tl-dr",
    "title": "Perfectly Codespaces",
    "section": "",
    "text": "코드 스페이스는 편리하고 저렴하게 활용할 수 있는 거의 완벽한 코딩 환경이다."
  },
  {
    "objectID": "posts/computer-tool/2023-10-20-github-codespaces.html#넋두리",
    "href": "posts/computer-tool/2023-10-20-github-codespaces.html#넋두리",
    "title": "Perfectly Codespaces",
    "section": "넋두리",
    "text": "넋두리\n회사에서 퍼블릭 깃헙을 쓸 때 종종 눈치가 보인다. 우선 아예 쓰지 못하게 하는 회사가 있다. 막지는 않는다고 해도 깃헙을 활용하는 개인 작업에 회사 컴퓨터 쓰는 일이 그리 적절해 보이지 않는다. 그렇다고 (솔직히) 회사에서 개인 작업을 아예 안 할 수는 없다. 만일 온라인 도구만으로 필요한 작업을 다 할 수 있다면 어떨까?\n깃헙이 이미 이런 기능을 제공하고 있다. 깃헙 코드스페이시스(깃헙 코스)는 웹을 통해 개발과 컴퓨팅 환경을 상당한 수준에서 제공하는 서비스다. 노트북 환경에 한정된 구글 코랩과 달리 깃헙 코스는 온전한 우분투 환경을 제공한다! 클라우드에 별도의 환경을 세팅하지 않는 이상 깃헙 코스에 버금가는 유연하고 편리한 컴퓨팅 환경을 갖추기 쉽지 않을 것이다. 게다가 깃헙 코스는 리포의 브랜치에 따라서 서로 다른 코스를 붙일 수 있다. 비슷한 개발 환경을 미묘하게 바꿔야 할 필요가 있다면 유용한 기능이 될 것이다. 유료 사용자라면 머신의 유형(하드웨어 스펙) 또한 쉽게 바꿀 수 있다.\n\n\n자세한 것은 링크를 참고하자."
  },
  {
    "objectID": "posts/computer-tool/2023-10-20-github-codespaces.html#깃헙-코스-활성화",
    "href": "posts/computer-tool/2023-10-20-github-codespaces.html#깃헙-코스-활성화",
    "title": "Perfectly Codespaces",
    "section": "깃헙 코스 활성화",
    "text": "깃헙 코스 활성화\n깃헙 코스는 깃헙의 레포지토리를 기반으로 동작한다. 깃헙 레포지토리를 만들고, 레포지토리의 Settings 탭으로 이동한다. Settings 탭에서 Options 메뉴를 선택하고, Features 섹션에서 Codespaces를 활성화한다.\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n그림처럼 깃헙 페이지의 오른쪽 상단에 Code을 누르면 Open with Codespaces 메뉴가 나타난다. 이 메뉴를 선택하면 깃헙 코스가 활성화된다. 활성화된 이후에는 VS Code와 동일한 환경이 제공된다. 별도로 구구절절하게 설명할 것이 없다는 이야기다. 자세한 것은 아래 페이지를 참고하면 된다.\n\n\n\nLINK를 참고하자.\n\n\n\n\n과금은 생각보다 너그러운 편이다. 개인 무료 이용자의 경우 월 15GB 스토리지, 월 120시간의 core hour를 제공한다. 유료 사용자의 경우 스토리지는 월 20GB, core hour는 180시간이다. LINK를 참고하자."
  },
  {
    "objectID": "posts/computer-tool/2023-10-20-github-codespaces.html#나의-활용법",
    "href": "posts/computer-tool/2023-10-20-github-codespaces.html#나의-활용법",
    "title": "Perfectly Codespaces",
    "section": "나의 활용법",
    "text": "나의 활용법\n깃헙 코스를 내가 어떻게 쓰고 있는지 간단히 소개하겠다. 물론 이는 미래에 모든 것을 망각할 나 놈을 위한 동어반복이다. 깃헙 코스를 올리고 처음 구동할 때, 자신의 다른 VS Code의 환경과 연동이 되어 있다면 확장을 설치하는데 시간이 좀 걸린다. 한번만 참고 기다리면 된다.\n\n업데이트와 업그레이드\n최초에 설치한 우분투 디스트는 업데이트와 업그레이드가 필요하다. 아래와 같이 실행하자.\n&gt; sudo apt update \n&gt; sudo apt upgrade -y # sudo full-upgrade -y\n\n\nBrew 설치\n역시 가벼운 앱들은 brew로 깔아서 쓰는 것이 좋다. 리눅스에서 brew를 설치하는 방법은 홈페이지 첫번째 화면에 잘 소개되어 있다.\nhttps://brew.sh\n&gt; /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n위와 같이 brew 설치는 마치면 셸 별로 특화된 추가 설정 명령이 뜬다. 그런데 깃헙 코스의 경우 zsh이 깔여 있음에도 불구하고 brew가 bash 환경에 깔린다. 따라서 셸을 다시 실행했을 때 brew가 인식되지 않는다. 이 문제를 해결하기 위해서 ~/.zshrc에 아래의 명령을 심도록 하자. 실행되면 리눅스용 brew가 셸 환경에 설정된다.\neval $(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\n\n\npixi 설치\nbrew를 이용해서 pixi를 설치하자.\n&gt; pixi init . \n&gt; pixi add python=3.11 pandas scipy matplotlib ipykernel \n이 pixi를 통해 설치된 파이썬 환경은 깃헙 코스에서 실행되는 파이썬 명령의 가상 환경으로 기능한다. VS Code에서 가상 환경을 설정하는 방법은\n\n\n\n\n\n\n파이썬 실행 환경 설정\n\n\n\nF1 &gt; “Python: 인터프리터 선택”\n\n\n그리고 .pixi/env/bin/python을 선택하면 된다. 파이썬 인터프리터가 선택되면 자연스럽게 가상 환경으로 지정된다.\n\n\nQuarto\nbrew를 통해 설치할 수 있으면 좋겠지만 Quarto는 별도로 설치해야 한다. 아래 링크를 참고하자.\nhttps://docs.posit.co/resources/install-quarto/#quarto-deb-file-install\n최신 버전 혹은 특정 버전의 설치 방법은 아래와 같다.\n# Downloading \n# 둘 중 하나를 택해서 deb을 다운받자. \n&gt; sudo curl -LO https://quarto.org/download/latest/quarto-linux-amd64.deb # 최신 버전 다운로드\n&gt; sudo curl -o quarto-linux-amd64.deb -L \\ \n  https://github.com/quarto-dev/quarto-cli/releases/download/v1.4.435/quarto-1.4.435-linux-amd64.deb \n  # 특정 버전의 다운로드 링크를 붙여 넣는다. \n# Installing\n&gt; sudo apt-get install gdebi-core\n&gt; sudo gdebi quarto-linux-amd64.deb\n\n\n\nLINK를 참고하자."
  },
  {
    "objectID": "posts/computer-tool/2022-07-07-pt-with-quarto.html",
    "href": "posts/computer-tool/2022-07-07-pt-with-quarto.html",
    "title": "Presentation with Reveal.js",
    "section": "",
    "text": "Quarto를 쓰면 Markdown으로 편하게 PT 문서를 만들 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2022-07-07-pt-with-quarto.html#tl-dr",
    "href": "posts/computer-tool/2022-07-07-pt-with-quarto.html#tl-dr",
    "title": "Presentation with Reveal.js",
    "section": "",
    "text": "Quarto를 쓰면 Markdown으로 편하게 PT 문서를 만들 수 있다."
  },
  {
    "objectID": "posts/computer-tool/2022-07-07-pt-with-quarto.html#pt-도구-그것이-문제로다.",
    "href": "posts/computer-tool/2022-07-07-pt-with-quarto.html#pt-도구-그것이-문제로다.",
    "title": "Presentation with Reveal.js",
    "section": "PT 도구 그것이 문제로다.",
    "text": "PT 도구 그것이 문제로다.\nReveal.js는 웹 기반으로 프레젠테이션 문서를 구현하는 녀석이다. 우리는 이 녀석을 써서 파워포인트나 키노트가 부럽지 않은 수준의 PT를 비교적 손쉽게 만들 수 있다. 웹 기반이니 브라우저만 있으면 문서를 볼 수 있다.\n아쉬운 점이라면 Markdown처럼 (나같은 문돌이들도) 쉽게 쓸 수 있는 딱 떨어지는 저작 도구가 없다는 것이다. 만일 Reveal.js를 Markdown과 함께 쓸 수 있다면 그야말로 금상첨화일 터! 앞서 Markdown 기반 저작도구인 Quarto를 살펴 보았다. 고맙게도 이 녀석이 VS Code 혹은 Jupyter 위에서 Markdown과 Reveal.js를 함께 부릴 수 있게 해준다. Quarto + Reveal.js의 장점을 다시 따져보자.\n\n\nRStudio가 제공하는 Rmarkdown을 통해 Reveal.js와 마크다운을 함께 부릴 수 있다. 다만 도구로서 VS Code가 좀 더 보편적이라고 생각하기에 이 녀석은 다루지 않겠다.\n\nMarkdown의 문법을 거의 그대로 쓸 수 있다.\n\\(\\rm\\LaTeX\\) 수식을 그대로 쓸 수 있다.\n깔끔하지만 다채로운 슬라이드를 구현할 수 있다.\n코드 및 결과물을 그대로 활용할 수 있다.\nGithub과 같은 웹 도구를 활용하면 결과물을 html로 쉽게 공유할 수 있다.\n\n\n\nQuarto가 pandoc을 백엔드로 쓰기 때문에 qmd 문서를 거의 포맷(docx, pdf, html, tex, pptx 등)으로 변환할 수 있다. html이 특별한 이유는 플랫폼을 불문하고 문서를 원래 의도 그대로 잘 전달할 수 있기 때문이다.\n이제 시작해 보자."
  },
  {
    "objectID": "posts/computer-tool/2022-07-07-pt-with-quarto.html#출발선",
    "href": "posts/computer-tool/2022-07-07-pt-with-quarto.html#출발선",
    "title": "Presentation with Reveal.js",
    "section": "출발선",
    "text": "출발선\n아래의 도구를 설치할 수 있고 기본적인 활용이 가능하다고 가정하겠다.\n\nQuarto (플랫폼에 따라서 설치)\nVS Code\nQuarto Extension for VS Code"
  },
  {
    "objectID": "posts/computer-tool/2022-07-07-pt-with-quarto.html#거의-완벽한-레퍼런스",
    "href": "posts/computer-tool/2022-07-07-pt-with-quarto.html#거의-완벽한-레퍼런스",
    "title": "Presentation with Reveal.js",
    "section": "거의 완벽한 레퍼런스",
    "text": "거의 완벽한 레퍼런스\nQuarto의 문서화는 거의 완벽하다. Quarto + Reveal.js도 예외는 아니다. 링크의 내용을 따라서 쓰면 된다. Markdown 문법과도 크게 다르지 않으니 진입 장벽이 낮다. 몇 가지 주의할 사항만 확인해 보자.\n\nYAML\nMarkdown 문서에 Reveal.js의 기능을 붙이기 위해 문서 앞에 YAML 문을 붙인다. 문서의 앞에 붙는 YAML의 예제는 아래와 같다.\n---\ntitle: \"This Is a Testflight\"\nsubtitle: \"Completely useless presentation\"\nauthor: \"[anarinsk](https://www.lostineconomics.com)\"\ndate: \"2022-09-06\"\nformat: \n    revealjs:\n        embed-resources: true\n        include-in-header: [favicon.html, mathjax.html]\n        incremental: true  \n        #css:\n        theme: [format.scss, black]\n        transition: concave\n        background-transition: fade\n        smaller: false\n        scrollable: true\n        logo: \"logo2.png\"\n        footer: \"TEST FOR FOOTER!\"\n        #preview-links: true\n        #self-contained: true\n---\n대체로 항목이 자명하기 때문에 별도의 설명은 하지 않겠다. reveal.js의 각종 옵션을 지정해 줄 수 있는데, 지원하는 항목은 여기에서 확인할 수 있다. 주의할 내용만 갼락하게 살펴보자.\n\n\n\n\n\n\nCode Tips\n\n\n\n\nembed-resources | 만일 GitHub Pages 등을 통해 퍼블리시 하려면 이 항목을 true로 설정하자.\ntheme | reveal.js의 테마다. 복잡하게 생각하지 말고 간단한 거 쓰자. 주의할 점; css 항목에 format.scss를 넣을 경우 해당 파일에서 지정한 폰트 설정이 작동하지 않는다. 테마와 같은 레벨에 특화된 css를 포함시키도록 하자.\ntransition | 슬라이드 혹은 항목 등장의 시각적인 전환 효과를 지정한다. 🔗를 참고하자.\nbackground-transition | 배경 효과를 지정한다.\npreview-links | true로 설정하면 슬라이드 내에서 링크를 클릭하면 해당 링크가 새 탭에서 열린다. 다만 일부 웹 페이지에서 제대로 작동하지 않는다. 개별 링크에서 별도로 설정할 수 있으므로 false로 두거나 주석 처리하자.\nself-contained | true로 설정하면 html 파일 내에 모든 자원을 포함시킨다. 파일이 지나치게 커질 수도 있고, 제대로 동작하지 않을 수 있으니 되도록 주석처리하자.\n\n\n\n\n\nCustomization\nQuarto + Reveal.js의 기본 설정을 그대로 써도 된다. 다만 영문과 한글 폰트의 괴리 등의 미묘한 대목이 걸린다면, 특화된 css 파일을 통해 볃도로 설정을 바꾸면 된다. Working Example에 소개된 예제의 css 파일을 살펴보자.\n/* @import url('https://fonts.googleapis.com/css2? family=Nanum+Gothic&display=swap'); */\n@import url(\"https://cdn.jsdelivr.net/gh/wan2land/d2coding/d2coding-ligature-subset.css\");\n@import url(\"https://cdn.jsdelivr.net/gh/sunn-us/SUIT/fonts/static/woff2/SUIT.css\");\n@import url(\"https://cdn.jsdelivr.net/gh/sunn-us/SUITE/fonts/static/woff2/SUITE.css\");\n\n/*-- scss:rules --*/\n.reveal h1, \n.reveal h2, \n.reveal h3, \n.reveal h4, \n.reveal h5, \n.reveal h6 {\n  font-family: 'NanumSquare' !important;\n  //text-shadow: -1px -1px 0 rgba(0, 0, 0, .3);\n}\n\n.reveal section p {\n    font-family: 'pretendard' !important;\n    font-size: 90%;\n}\n\n.reveal ul, \n.reveal li, \n.reveal ol{\n    font-family: 'pretendard' !important;\n    font-size: 95%;\n}\n\n.reveal code{\n  font-family: 'D2Coding', monospace ! important;\n  font-size: 95%;\n}\n\n\n\n\n\n\nCode Tips\n\n\n\n\n@import... | 필요한 폰트 3종을 로드한다.\n나머지는 부분은 css의 요소 별로 사용할 폰트와 글자 크기 등을 지정하는 내용이다."
  },
  {
    "objectID": "posts/computer-tool/2022-07-07-pt-with-quarto.html#working-example",
    "href": "posts/computer-tool/2022-07-07-pt-with-quarto.html#working-example",
    "title": "Presentation with Reveal.js",
    "section": "Working Example",
    "text": "Working Example\n시험 삼아서 Reveal.js의 몇 가지 기능을 Quarto로 구현해 보았다. 내용 없이 형식을 구현하는데 집중한 사례이니 참작해 주시라. 아래의 사례는 나 놈이 발견한 새로운 진전이 있을 떄 업데이트된다.\n\n예시: Completely Useless Quarto-Reveal.js\n코드: anarinsk/learn_quarto-revealjs"
  },
  {
    "objectID": "posts/econ-simple/2022-04-30-gdp-import.html",
    "href": "posts/econ-simple/2022-04-30-gdp-import.html",
    "title": "수입은 GDP에 영향을 주는가?",
    "section": "",
    "text": "GDP 항등식에 관한 오해는 경제 저널리즘에서 잘 생기는 오해다. 어제 뉴욕 타임스 사설에 이걸 오해한 내용이 실렸고, 트위터 등에서 여러 경제학자들이 이 사실을 지적했다. GDP 항등식에서 시작해보자. 국내총생산이라는 GDP 항등식은 아래와 같이 제시된다.\n\\[\nY = C + I + G + X - M\n\\]\n\n\n\n항목\n내용\n\n\n\n\n\\(C\\)\n국내 총소비\n\n\n\\(I\\)\n국내 총투자\n\n\n\\(G\\)\n정부 지출\n\n\n\\(X\\)\n수출\n\n\n\\(M\\)\n수입\n\n\n\n저 항등식만 보면 수입이 줄면 \\(Y\\)가 늘 것 같다. 그런데 이건 오해다. 두 가지 측면에서 생각을 해보자.\n\nGDP는 ‘국내’ 총생산이다. 즉, 1년 동안 국내에서 생산된 재화와 서비스의 총량을 측정한다. 그런데 수입품은 국내에서 생산된 것이 아니다. 따라서 빼주는 게 맞다.\n그런데 수입이 줄면 GDP가 주는 게 아닌가? 아니다. 왜냐하면 앞에 \\(C\\), \\(I\\), \\(G\\)는 각각 수입품에 관한 소비, 투자, 정부 지출을 포함하고 있기 때문이다. 즉, \\(C = C_{d} + C_{m}\\), 즉 국내에서 생산된 제품에 관한 소비(\\(C_d\\))와 해외에서 생산된 소비(\\(C_m\\))을 포함하고 있다. GDP란 국내 총생산을 측정하는 것이므로 \\(C_m\\)을 빼주는 게 맞다.\n\n즉, 식을 재구성해보면 이렇다.\n\\[\n(C_d + I_d + G_d) + \\overbrace{(C_m + I_m + G_m)}^{M} + X - M\n\\]\n정의상 \\(C_m + I_m + G_m = M\\)이 되기 때문에 M이 늘고 주는 것은 GDP에 아무런 영향을 주지 않는다. GDP를 측정하기 위한 회계상의 이유로 \\(M\\)이 들어간 것이지 \\(M\\)의 변화가 독자적으로 GDP를 변화시키지는 않는다."
  },
  {
    "objectID": "posts/econ-simple/2022-04-30-gdp-import.html#오해",
    "href": "posts/econ-simple/2022-04-30-gdp-import.html#오해",
    "title": "수입은 GDP에 영향을 주는가?",
    "section": "",
    "text": "GDP 항등식에 관한 오해는 경제 저널리즘에서 잘 생기는 오해다. 어제 뉴욕 타임스 사설에 이걸 오해한 내용이 실렸고, 트위터 등에서 여러 경제학자들이 이 사실을 지적했다. GDP 항등식에서 시작해보자. 국내총생산이라는 GDP 항등식은 아래와 같이 제시된다.\n\\[\nY = C + I + G + X - M\n\\]\n\n\n\n항목\n내용\n\n\n\n\n\\(C\\)\n국내 총소비\n\n\n\\(I\\)\n국내 총투자\n\n\n\\(G\\)\n정부 지출\n\n\n\\(X\\)\n수출\n\n\n\\(M\\)\n수입\n\n\n\n저 항등식만 보면 수입이 줄면 \\(Y\\)가 늘 것 같다. 그런데 이건 오해다. 두 가지 측면에서 생각을 해보자.\n\nGDP는 ‘국내’ 총생산이다. 즉, 1년 동안 국내에서 생산된 재화와 서비스의 총량을 측정한다. 그런데 수입품은 국내에서 생산된 것이 아니다. 따라서 빼주는 게 맞다.\n그런데 수입이 줄면 GDP가 주는 게 아닌가? 아니다. 왜냐하면 앞에 \\(C\\), \\(I\\), \\(G\\)는 각각 수입품에 관한 소비, 투자, 정부 지출을 포함하고 있기 때문이다. 즉, \\(C = C_{d} + C_{m}\\), 즉 국내에서 생산된 제품에 관한 소비(\\(C_d\\))와 해외에서 생산된 소비(\\(C_m\\))을 포함하고 있다. GDP란 국내 총생산을 측정하는 것이므로 \\(C_m\\)을 빼주는 게 맞다.\n\n즉, 식을 재구성해보면 이렇다.\n\\[\n(C_d + I_d + G_d) + \\overbrace{(C_m + I_m + G_m)}^{M} + X - M\n\\]\n정의상 \\(C_m + I_m + G_m = M\\)이 되기 때문에 M이 늘고 주는 것은 GDP에 아무런 영향을 주지 않는다. GDP를 측정하기 위한 회계상의 이유로 \\(M\\)이 들어간 것이지 \\(M\\)의 변화가 독자적으로 GDP를 변화시키지는 않는다."
  },
  {
    "objectID": "posts/econ-simple/2022-04-30-gdp-import.html#다른-주장",
    "href": "posts/econ-simple/2022-04-30-gdp-import.html#다른-주장",
    "title": "수입은 GDP에 영향을 주는가?",
    "section": "다른 주장",
    "text": "다른 주장\nNoahpinion에서 예시했듯이 이렇게 볼 수도 있을 것이다.\n\n만일 수입품을 쓰지 않았더라면 그 만큼 국내에서 생산된 제품을 대신 쓰지 않았겠는가? 따라서 수입을 줄이거나 금지시키면 이에 따라서 국내 총생산이 늘게 될 것이다.\n\n이는 사실 트럼프 진영의 주장이기도 하다. 이러한 주장은 두 가지 차원에서 반박할 수 있다. 먼저 실증의 차원이다. 저 말이 맞다면 수입이 줄 때 GDP는 늘어나는 경향이 있을 것이고 반대로 수입이 늘면 GDP는 줄 것이다. 그런데 자료를 보면 전혀 그렇지 않다. 미국이나 한국이나 오히려 공행하는 듯 싶다.\n미국의 GDP, 수입 증가율 변화 \n한국의 GDP, 수입 증가율 변화 \n다음은 논리의 차원이다. 무역은 비교우위의 원리에 따라서 발생한다. 즉, 해외에서 어떤 제품을 수입했다면 그것이 국내 생산보다 경쟁력이 있기 때문이다. 중국산을 막고 이를 한국산으로 대체했다면 해당 제품을 생산하는 기업의 매출이 증가하고 이는 GDP 증가에 기여할 것이다. 하지만 해당 제품의 수입을 통해서 누리던 효율성이 사라지면서 GDP를 감소시키게 된다. GDP 증가와 감소 중 어느 쪽이 더 클지 미리 정할 수는 없다. 수입이 효율성의 논리에 의해 결정된 것이라면 인위적인 수입대체는 GDP를 감소시키게 될 것이다(자중손실).\n\n\n이는 일국의 ‘총량적인’ 차원에서 하는 이야기라는 점을 지적해두겠다. 예를 들어 무역이 고용이 미치는 영향은 경제적 후생(소비자 잉여 + 생산자 잉여)만으로 판단하기에는 보다 미묘하다. 예를 들어 중국산 철강 때문에 미국 러스트 벨트의 고용이 대체되었다고 하자. 이것이 총량적으로 효율성의 증가라고 해도, 고용과 실업 차원에서는 구성의 큰 변화가 발생한다. 적어도 경제원론 차원에서는 총량적인 효율성을 추구하고 이러한 변화에 따른 자원 배분은 어떤 주체(국가)가 임의로 달성할 수 있다고 가정하는 경향이 있다. 물론 오늘날의 보다 현실적이고 정교한 경제학은 이렇게 생각하지 않는다."
  },
  {
    "objectID": "posts/econ-simple/2022-04-30-gdp-import.html#참고",
    "href": "posts/econ-simple/2022-04-30-gdp-import.html#참고",
    "title": "수입은 GDP에 영향을 주는가?",
    "section": "참고",
    "text": "참고\nNoahpinion, Imports do not subtract from GDP"
  },
  {
    "objectID": "posts/the-books/2024-02-05-조선사-쩐의전쟁.html",
    "href": "posts/the-books/2024-02-05-조선사-쩐의전쟁.html",
    "title": "이한, “조선사 쩐의 전쟁”",
    "section": "",
    "text": "조선은 신분제 사회지만 꽤나 합리적인 절차와 제도를 지니고 있었다.\n송사로 보는 그 시절의 갈등은 오늘날과 별로 다를 것이 없더라."
  },
  {
    "objectID": "posts/the-books/2024-02-05-조선사-쩐의전쟁.html#tl-dr",
    "href": "posts/the-books/2024-02-05-조선사-쩐의전쟁.html#tl-dr",
    "title": "이한, “조선사 쩐의 전쟁”",
    "section": "",
    "text": "조선은 신분제 사회지만 꽤나 합리적인 절차와 제도를 지니고 있었다.\n송사로 보는 그 시절의 갈등은 오늘날과 별로 다를 것이 없더라."
  },
  {
    "objectID": "posts/the-books/2024-02-05-조선사-쩐의전쟁.html#조선은-소송의-나라",
    "href": "posts/the-books/2024-02-05-조선사-쩐의전쟁.html#조선은-소송의-나라",
    "title": "이한, “조선사 쩐의 전쟁”",
    "section": "조선은 소송의 나라?",
    "text": "조선은 소송의 나라?\n조선에는 송사가 난무했다! 이 책이 주는 가장 큰 가르침이다. 봉건 신분제 사회에서 무슨 소송? 양반이면 아무런 거리낌 없이 노비나 상놈을 때려 죽일 수 있었던 시대 아닌가? 아니다. 사극을 봐서 익히 알 수 있듯이 조선은 왕권조차 전능하지 못한 절차의 국가였다. 물론 근대적인 삼권 분립과는 거리가 멀지만, 사법과 행정을 통합한 고을 사또, 절도사 혹은 상급 기관의 장에 의해서 송사가 제기되고 심의될 수 있는 기능을 갖추고 있었다.\n이런 쟁송의 권리는 신분에 구애받지 않았다. 책이 등장하듯 노비는 재산의 일부로 분쟁의 대상이기도 했지만 그가 억울한 일을 당했을 경우 리를 제소해서 바로잡는 것이 아예 불가능한 사회는 아니었다. 신분제 사회에서 구조적이고 체계적인 불이익이 없었을 리 없겠지만 최후의 수단(last resort)로 노비까지 기댈 수 있는 수단이 있었다는 대목이 놀랍다."
  },
  {
    "objectID": "posts/the-books/2024-02-05-조선사-쩐의전쟁.html#과연-우리는-조선에-관해서-제대로-알고-있는가",
    "href": "posts/the-books/2024-02-05-조선사-쩐의전쟁.html#과연-우리는-조선에-관해서-제대로-알고-있는가",
    "title": "이한, “조선사 쩐의 전쟁”",
    "section": "과연 우리는 조선에 관해서 제대로 알고 있는가?",
    "text": "과연 우리는 조선에 관해서 제대로 알고 있는가?\n말로 싸울 수 있게 된 시대 혹자는 근대 민주주의 근간인 의회 정치라는 게 소모적이고 파괴적인 ’내란’을 대체하기 위한 것이라고 말한다. 즉, 서로 목숨을 내놓고 끝장을 보는 대신 말로 싸우고 승복하며 기회가 되면 또 말로 싸워서 이겨보라는 취지라는 것이다. 송사건 정치건 말로 싸우려면 필요한 것이 글자이다. 단순히 소장을 접수하는 문제가 아니다.\n책에서 보듯이 당시 쟁송이란 건 “원님 재판”하듯 마음대로 진행된 것이 아니었다. 피고와 원고 양쪽에서 치열하게 증거를 제출했고 이는 대부분 문서의 형태였다. 조선 사회에서 이렇게 송사가 가능하고 번성할 수 있게 된 데에는 세종 대왕의 한글 창제가 크게 기여했다. 한글 창제의 이유처럼 세종은 신분과 관계없이 백성이 자신의 목소리를 물리적으로 담아 낼 수 있는 큰 그릇을 만든 셈이다."
  },
  {
    "objectID": "posts/the-books/2024-02-05-조선사-쩐의전쟁.html#관료들의-고단함-그리고-전문직",
    "href": "posts/the-books/2024-02-05-조선사-쩐의전쟁.html#관료들의-고단함-그리고-전문직",
    "title": "이한, “조선사 쩐의 전쟁”",
    "section": "관료들의 고단함 그리고 전문직",
    "text": "관료들의 고단함 그리고 전문직\n오늘날의 관점으로 보면 조선의 송사는 민사와 형사가 뒤섞여 있다. 당시 중앙 뿐 아니라 지방 관료의 생활 역시 무척 피곤했을 것이다. 제출된 소장을 다 검토해야 했고, 오늘날의 관점에서 기소해야 할 것과 그렇지 않은 것을 분류하고, 양쪽의 변론을 청취한 뒤 합당한 판결을 내려야 했다. 관청이 수행했던 치안기능까지 고려해보면 DC 코믹스에 등장하는 “저지 드레드”에 가까운 존재가 지방의 사또가 아니었을까 싶다. 이렇듯 막강한 관력을 쥐고 있으니 ’탐관오리’로 변질되기도 쉬웠겠지만, 어느 정도 기능을 하려면 아마 자신의 몸과 마음을 갈아 넣어야 했을 것이다.\n이쯤되면 조선 시대에 ’변호사’가 없었을까 싶은데 실제로 있더라! 소장을 대신 써주고 백성들에게 생소한 법률 자문을 해주는 “외지부”가 그것이다. 요즘 같이 많은 사람들이 우러러보는 직업은 아니었다고 한다. 외지부는 행정 절차를 방해하는 것으로 여겨져서 벌을 받기도 했다고 한다. 하지만 그 기능만은 요즘 변호사 못지 않았던 것 같다. 배심원 제도가 생기면서 배심원에게 호소하는 목적의 소송 변호사가 따로 생겨났듯이, 저 시대의 가장 중요한 외지부의 자질은 자신의 딱한 사정을 호소하는 필력 그리고 격쟁 시 울려 퍼지는 비통한 울음소리 같은 극적 연출이었다."
  },
  {
    "objectID": "posts/the-books/2024-02-05-조선사-쩐의전쟁.html#큰-그림이-함께-있었다면",
    "href": "posts/the-books/2024-02-05-조선사-쩐의전쟁.html#큰-그림이-함께-있었다면",
    "title": "이한, “조선사 쩐의 전쟁”",
    "section": "큰 그림이 함께 있었다면",
    "text": "큰 그림이 함께 있었다면\n저자가 책에 적었듯이 조선에서 벌어진 쟁송 혹은 형식을 갖춘 분쟁의 역사가 이토록 풍부하게 남아 있다면, 좀 더 큰 그림을 체계적으로 봤으면 싶었다. 물론 이는 책의 목적이 아니다. 재미있는 사례를 발굴하기 위해서 예외적인 경우 위주로 소개된 것은 아닐까, 하는 생각이 문득 들었다. 조선 시대의 법적 풍경에 관한 조금 더 큰 그림을 통계와 숫자로 알려주는 짧은 대목이 하나 들어가 있다면 어땠을까 싶다."
  },
  {
    "objectID": "posts/the-books/2024-02-05-조선사-쩐의전쟁.html#인용",
    "href": "posts/the-books/2024-02-05-조선사-쩐의전쟁.html#인용",
    "title": "이한, “조선사 쩐의 전쟁”",
    "section": "인용",
    "text": "인용\n\n조선 시대 역시 일상생황에서 분쟁이 생겼을 때 도저히 해결이 안 된다면 법에 호소할 수 밖에 었었다. 이떄 소송을 거는, 원고 쪽을 원이라고 했고, 피소를 당한 쪽을 척이라고 했다. 한마디로 “척진다”는 말은 조선시대로 치면 “너를 고소하겠다”는 뜻이다. 아무래도 원수가 될 수 밖에 없는 것이다.\n\n\n항소의 방법 중에서는 북을 치고 꽹과리를 치며 높으신 분(임금)에게 하소연하는 격쟁도 있었다. 이것은 그야말로 한풀이의 장이었는데, 이 떄문에 왕의 행차가 사극에서 보는 것처럼 웅장하고 엄숙한 행렬이 아니라 전국 각지에서 몰려들어온 억울한 사람들이 우르르 몰려들어 징을 치며 소리를 지르는 시장판이었다.\n\n\n조선 시대만 하더라도 여성이 결혼하면서 가져간 재산은 시댁 재산에 합쳐지지 않았고, 여성이 재산의 주인으로써 맘대로 팔거나 남에게 물려줄 수 있었다.\n\n\n윤선도는 조선 시대 여러 분쟁에 빠지지 않는 치열한 싸움꾼이었다.\n\n\n이러다보니 왠많나 부자집도 과거에 10년 가까이 도전하다 보면 가진 재산을 다 까먹기 일쑤였기에 자식이 많은 집에서는 장남에게 모든 여력을 올인하곤 했다.\n\n\n한 장군이 뜰에 붉은 깃발을 세워 두고 휘하의 무관들을 모아 놓은 뒤 “아내를 두려워하는 자는 붉은 기 아래로 가고, 두려워하지 않는 자는 푸른기 아래로 가라”로 명했다. 그러자 모든 무관이 붉은 기 아래로 갔는데 단 한사람만이 푸른 기 아래로 갔다. 그 사람을 불러 어째서 푸른기 아래로 갔는지 이유를 물으니, “부인이 남자들이 모이면 여색 이야기나 하나 함께 끼어 있지 말라”라고 당부를 했다고 한다."
  },
  {
    "objectID": "posts/the-books/2023-10-27-drug-mind-yang.html",
    "href": "posts/the-books/2023-10-27-drug-mind-yang.html",
    "title": "양성관, “마약 하는 마음, 마약 파는 사회”",
    "section": "",
    "text": "마약의 이모저모를 잘 알려주긴 한다.\n의사로서의 전문 지식은 책의 장점, 마약의 모든 것을 담으려는 욕심은 과했다."
  },
  {
    "objectID": "posts/the-books/2023-10-27-drug-mind-yang.html#tl-dr",
    "href": "posts/the-books/2023-10-27-drug-mind-yang.html#tl-dr",
    "title": "양성관, “마약 하는 마음, 마약 파는 사회”",
    "section": "",
    "text": "마약의 이모저모를 잘 알려주긴 한다.\n의사로서의 전문 지식은 책의 장점, 마약의 모든 것을 담으려는 욕심은 과했다."
  },
  {
    "objectID": "posts/the-books/2023-10-27-drug-mind-yang.html#넋두리",
    "href": "posts/the-books/2023-10-27-drug-mind-yang.html#넋두리",
    "title": "양성관, “마약 하는 마음, 마약 파는 사회”",
    "section": "넋두리",
    "text": "넋두리\n책은 “1부 마약하는 사람”, “2부 마약 파는 사회”로 구성되어 있다. 1부가 마약 자체의 분류, 효과 그리고 마약하는 개별자에 대해서 다루고, 2부는 마약의 정치경제학(?), 역사 등을 다루고 있다.\n1부는 의학자로서 저자의 전문 지식이 돋보이는 부분이 있다. 마약의 분류, 작용 기제 등에 대한 설명이 다른 대중서들보다 명쾌하다. 2부는 이래저래 다른 자료들을 발췌해서 쓴 느낌이 세게 들더라. ‘마약 왕국’ 챕터에 해당하는 부분은 넷플릭스 시리즈 “나르코스” 그리고 “돕식”(디즈니+), “페인킬러”(디즈니+) 등을 한 번 보는 게 훨씬 나을 듯 싶다. 한국 마약 풍경의 역사에 관해서는 저자가 참고한 서적을 직접 보는 게 나을 것 같다. 전체적인 스케치라는 기준에서 보면, 책의 서술이 나쁘지는 않다.\n내용을 다루다가 저자가 너무 심취하는 순간이 종종 발견된다. 심취하면 말이 많아지고 길을 잃기 십상이다. 이런 게 나는 좀 거슬리더라. 이또한 어쩌면 취향이니 일단 넘어가자."
  },
  {
    "objectID": "posts/the-books/2023-10-27-drug-mind-yang.html#챙길-대목들",
    "href": "posts/the-books/2023-10-27-drug-mind-yang.html#챙길-대목들",
    "title": "양성관, “마약 하는 마음, 마약 파는 사회”",
    "section": "챙길 대목들",
    "text": "챙길 대목들\n\n신경전달물질\n마약은 신경전달물질을 통해서 작용한다. 신경전달물질이 시냅스의 수용체에 달라붙어 효과를 낸다. 저자가 제시한 핵심 신경전달물질을 살펴보자.\n\n아세틸콜린: 가장 기본적인 물질이다. 전화벨과 같다고 한다. 뭘 해야 하는지 알려주는 신호 역할을 한다는 의미로 이해하면 될까? “이 아세틸콜린이 줄어들면 뇌의 모든 기능, 그 중에서도 지식과 정보를 받아들여 저장하고 판단하는 인지 기능에 이상이 생긴다. 바로 알츠하이머 치매다.”\n노르에피네프린: “시계의 알람처럼 긴장과 흥분을 일으켜 혈압을 상승시키기 떄문에 출혈 등으로 혈압이 떨어진 쇼크 환자에게 치료제로 쓴다.”\n도파민: “클럽 DJ가 들려주는 음악같이 운동기능과 함께 즐거움과 쾌락을 준다. 이 도파민을 분비하는 신경세포에 이상에 생기면 운동기능 이상으로 몸을 떨거나 강직이 온다. 바로 파킨슨 병이다.”\n세로토닌: “절의 목탁 소리처럼 평온함과 행복감을 주는데 이것이 부족하면 우울증이 생긴다.”\n엔도르핀: “우리 몸에는 몸이 만든 모르핀(endogenous morphine), 즉 엔도르핀이 극소량이지만 존재한다. 이 엔도르핀은 평소에는 전혀 분비되지 않다가 극한의 상황에서만 분비되기에 어지간히 아프거나 다쳐서는 나오지 않는다.”\n\n\n\n마약 분류\n\n잘 분류해 놓은 그림이다! 코카인/암페타민 계열의 약과 마리화나/모르핀 계열의 약은 각각 업과 다운 계열이다. 그리고 모르핀에서 파생된 헤로인, 마약성 진통제, 펜타닐 등이 모두 다운 계열에 속한다. 알콜이 다운 계열에 속하는 건 약간 의아하기도 하다. 술을 먹으면 자는 사람도 있지만 몹시 흥분하는 부류도 많기 때문이다.\n저자는 다운 계열의 약이 막연히 ’안전’할 것이라는 짐작은 위험하다고 강조한다. 대마에 대해서 이런 종류의 이야기를 듣고는 한다. 대마의 경우 자극이 세지 않아서 중독될 가능성이 낮다고.\n저자에 따르면 오히려 반대가 진실에 가까울 수 있다. 업 계열의 약들이 에너지 소모가 많다. 따라서 효과의 지속시간이 짧다. 업 계열 약에는 복용과 복용 사이의 필연적인 간격이 존재한다. 이에 반해 다운 계열의 약은 그런 식의 주기가 없다. 미끄러지듯이 중독에 빠져들기에는 다운 계열이 오히려 중독되기에 보다 쉬울 수 있다. 마약성 진통제 위기(opioid crisis)에서 옥시콘틴 같은 약에 사람들이 쉽게 빠져들게 된 이유를 여기서 짐작할 수 있다."
  },
  {
    "objectID": "posts/the-books/2023-10-27-drug-mind-yang.html#흥미로운-대목들",
    "href": "posts/the-books/2023-10-27-drug-mind-yang.html#흥미로운-대목들",
    "title": "양성관, “마약 하는 마음, 마약 파는 사회”",
    "section": "흥미로운 대목들",
    "text": "흥미로운 대목들\n\n자연에서 인간을 통해 발견된 것을 제외하면 대부분의 미약을 제약사가 개발했다. 코카인은 원래 ’국소 마취제’로 1885년 머크사가, ’모르핀’은 전쟁 부상병의 고통을 덜기 위한 목적으로 1898년 바이어사가 개발한 제품이다. 독일의 페르비틴, 일본의 필로폰 그리고 영국의 벤제드린은 모두 2차 대전 중 각 나라가 전후방의 전투력을 높일 목적으로 활용했다.\n북한산 필로폰이 높은 순도를 자랑한다는 점을 처음 알았다. 국가에서 정책적(?)으로 제조해서 그렇다고 한다. 북한에서 “빙두”(여기서 두는 독의 한자 발음이다)라고 부르는 이 마약이 탈북자의 네트워크를 통해서 남한으로 전해지지 않았을까 상상해 보았다. 이에 관한 연구가 있는지는 아직 찾아보지 못했다."
  },
  {
    "objectID": "posts/the-books/2024-01-30-백광.html",
    "href": "posts/the-books/2024-01-30-백광.html",
    "title": "렌조 미키히코, “백광”",
    "section": "",
    "text": "명불허전이다. 렌조 미키히코라는 작가를 알게 되서 기쁘다.\n번역이 세심하다. 원작이 지녔으리라 짐작되는 문체와 작풍을 느낄 수 있다."
  },
  {
    "objectID": "posts/the-books/2024-01-30-백광.html#tl-dr",
    "href": "posts/the-books/2024-01-30-백광.html#tl-dr",
    "title": "렌조 미키히코, “백광”",
    "section": "",
    "text": "명불허전이다. 렌조 미키히코라는 작가를 알게 되서 기쁘다.\n번역이 세심하다. 원작이 지녔으리라 짐작되는 문체와 작풍을 느낄 수 있다."
  },
  {
    "objectID": "posts/the-books/2024-01-30-백광.html#완벽한-구조",
    "href": "posts/the-books/2024-01-30-백광.html#완벽한-구조",
    "title": "렌조 미키히코, “백광”",
    "section": "완벽한 구조",
    "text": "완벽한 구조\n렌조 미키히코의 “백광”은 완벽한 추리 소설이다. 이 작품에는 추리 소설이 갖추어야 하는 기본기가 두루 잘 들어 있다. 소설은 인물 간의 뒤틀린 관계 설정, 갈등의 핵심을 이루는 서사의 반복과 변주 그리고 거듭되는 반전에도 무너지지 않는 극의 설득력을 지닌다.\n“백광”은 1명 빼고 가족으로 엮인 7명의 고백으로 구성된다. 나오코라는 네 살짜리 여자 아이가 이모의 집에서 살해 당하고 집 앞마당에 매장되는 사건이 발생한다. 진범을 찾아가는 소설은 7명의 관점에서 같은 사건이 각자의 시선과 경험을 통해 서술되고 해석된다. 7명 각각이 지닌 파편 증거에 기반을 둔 추측과 추리가 번갈아 등장한다. 소설의 이런 구조 때문에 추리 소설의 뼈대인 ’누가 범인인가’의 질문이 계속 수면 위로 떠오른다. 추리 소설의 맛이란 이 질문을 어떻게 바꿔가며 지루하지 않게 던질 수 있는지에 달려 있지 않은가.\n전지적 혹은 관찰자 시점을 지닌 탐정이나 경찰이 거의 등장하지 않기 때문에 각각의 ’추리’는 거의 소설 끝까지 불완전한 채 남는다. 각자의 독백을 읽게 되면 이것은 진실일까 아니면 거짓일까 하는 의문이 계속 맴돈다. 작가는 이런 뒷맛을 의도했다. 책을 읽으면서 영화 “라쇼몽”을 보는 듯한 기분이 종종 드는 것은 소설의 이러한 독특한 서술 구조 덕분이다."
  },
  {
    "objectID": "posts/the-books/2024-01-30-백광.html#독자만-알-수-있다",
    "href": "posts/the-books/2024-01-30-백광.html#독자만-알-수-있다",
    "title": "렌조 미키히코, “백광”",
    "section": "독자만 알 수 있다!",
    "text": "독자만 알 수 있다!\n치매를 앓는 듯한(?) 시아비지의 독백이 소설을 열고 닫는다. 세대와 인물을 넘나들며 반복된 살인, 배신 그리고 각자의 후회와 증오가 소설을 빽빽하게 채우고 있다. 각 장을 채우는 인물의 말투와 분위기가 확연히 다르다. 그 장의 마지막에 의표를 찌르듯 종종 등장하는 ’…하지만 OO은 범인이 아니다’의 구절은 반전을 앞세운 TV 연속극인가 싶기도 하다.\n“백광”에는 전형적인 추리 소설의 클리셰, 즉 뛰어난 지략의 탐정, 초월적인 범죄자 혹은 사건을 끈질기게 추적하는 경찰 등이 없다. 소설의 사건 앞에서 모두가 범인이면서 동시에 모두가 범인이 아닐 수도 있다. 각자 진실의 일부를 알고 있지만 진실의 조각으로는 전체를 파악할 수 없다. 7인의 독백과 대화를 모두 읽은 독자만 전체 그림을 볼 수 있는 셈이다. 어쩌면 이 대목이 소설 “백광”의 가장 근사한 트릭이 아닐까?"
  },
  {
    "objectID": "posts/linear-algebra/2021-01-08-basis.html",
    "href": "posts/linear-algebra/2021-01-08-basis.html",
    "title": "Basis",
    "section": "",
    "text": "벡터 공간 \\(V\\)의 기저\n\\[\nB = \\{ \\vec{e_1}, \\dotsc, \\vec{e_n} \\}  \n\\]\n는 다음의 두 특성을 만족한다.\n\n\n모든 \\(v \\in V\\)는 다음과 같이 기저의 선형 결합으로 표현된다.\n\\[\nv = v_1 \\vec{e_1} + \\dotsc + v_n \\vec{e_n}\n\\]\n\n\n\n즉, 기저를 구성하는 벡터 \\(\\vec{e_i}\\)에 불필요한 것이 없어야 한다. 즉, \\(\\vec{e}\\)를 구성하는 어떤 \\(e_i\\)도 다른 \\(e_j\\)(\\(j \\neq i\\))의 선형 결합으로 표현될 수 없다."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-08-basis.html#two-propoerties-of-basis",
    "href": "posts/linear-algebra/2021-01-08-basis.html#two-propoerties-of-basis",
    "title": "Basis",
    "section": "",
    "text": "벡터 공간 \\(V\\)의 기저\n\\[\nB = \\{ \\vec{e_1}, \\dotsc, \\vec{e_n} \\}  \n\\]\n는 다음의 두 특성을 만족한다.\n\n\n모든 \\(v \\in V\\)는 다음과 같이 기저의 선형 결합으로 표현된다.\n\\[\nv = v_1 \\vec{e_1} + \\dotsc + v_n \\vec{e_n}\n\\]\n\n\n\n즉, 기저를 구성하는 벡터 \\(\\vec{e_i}\\)에 불필요한 것이 없어야 한다. 즉, \\(\\vec{e}\\)를 구성하는 어떤 \\(e_i\\)도 다른 \\(e_j\\)(\\(j \\neq i\\))의 선형 결합으로 표현될 수 없다."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-08-basis.html#two-bases",
    "href": "posts/linear-algebra/2021-01-08-basis.html#two-bases",
    "title": "Basis",
    "section": "Two bases",
    "text": "Two bases\n계속 등장하게 될 두 개의 기저를 살펴보자.\n\nOrthonomal basis\n\\[\nB_{\\hat{e}} = \\{ \\hat{e_1}, \\dotsc, \\hat{e_n} \\} \\text{~with}\n\\]\n\\[\n\\begin{cases}\n\\hat{e_i} \\cdot \\hat{e_j} = 1 & \\text{if $i = j$} \\\\\n\\hat{e_i} \\cdot \\hat{e_j} = 0 & \\text{if $i \\neq j$}\n\\end{cases}\n\\]\n\\[\n(a_1, \\dotsc, a_n)_{B_{\\hat{e}}} = \\underbrace{(\\vec{a} \\cdot \\hat{e_i})}_{a_1} \\hat{e_i} + \\dotsb + (\\vec{a} \\cdot \\hat{e_n}) \\hat{e_n}\n\\]\n\n\nOrthogonal basis\n\\[\nB_{e} = \\{ e_1, \\dotsc, e_n \\} \\text{~with}\n\\]\n\\[\n\\begin{cases}\ne_i \\cdot e_j \\neq 0 & \\text{if $i = j$} \\\\\ne_i \\cdot e_j = 0 & \\text{if $i \\neq j$}\n\\end{cases}\n\\]\n\\[\n(b_1, \\dotsc, b_n)_{B_e} = \\underbrace{(\\vec b \\cdot \\dfrac{e_i}{\\Vert e_i \\Vert})}_{b_1} e_1 + \\dotsb + (\\vec b \\cdot \\dfrac{e_i}{\\Vert e_i \\Vert}) e_n\n\\]\n\\(b_i\\)의 값을 제대로 반영하기 위해서는 정규화된 orthorgonal basis가 필요하고, \\(\\frac{e_i}{\\Vert e_i \\Vert}\\)가 내적 계산에 들어간다."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-08-basis.html#eat-this",
    "href": "posts/linear-algebra/2021-01-08-basis.html#eat-this",
    "title": "Basis",
    "section": "Eat This!",
    "text": "Eat This!\n\nGeneric basis\n서로 직교하지 않는 기저,\n\\[\n\\{ \\vec f_1, \\dotsc, \\vec f_n \\}\n\\]\n가 있다고 하자. \\(\\vec c\\)를 이 기저로 어떻게 표현할 수 있을까?\n\\[\n\\begin{aligned}\nc_1 f_1 + \\dotsb + c_n f_n = \\vec c\n\\end{aligned}\n\\]\n\\(f_i\\)가 직교행렬이 아니기 때문에, \\(c_i\\) 역시 하나씩 결정될 수 없고 동시에 결정되어야 한다. 즉, 이는 연립방정식을 푸는 문제와 같다. 즉 \\(n\\) 개의 미지수와 \\(n\\) 개의 방정식을 푸는 문제다.\n\n\nExample\n\\(T: \\mathbb R^2 \\to \\mathbb R^2\\)의 변환을 생각해보자. 어떤 이유에서인가 \\(T\\)를 기본 기저가 아닌 다른 기저로 표현해야 한다고 하자. 두 개의 기저를 아래와 같이 두자.\n\\[\n\\\\{ \\vec v_1 = (v_{1x}, v_{1y})^T, \\vec v_2 = (v_{2x}, v_{2y})^T \\\\}\n\\]\n이 기저는 \\(T\\)에 의해서 다음과 같이 변형된다.\n\\[\nT(\\vec v_1) =\n\\begin{bmatrix}\nt_{1x} \\\\\nt_{1y}\n\\end{bmatrix},~\nT(\\vec v_2) =\n\\begin{bmatrix}\nt_{2x} \\\\\nt_{2y}\n\\end{bmatrix}\n\\]\n이걸 매트릭스로 표현하면 어떻게 될까? \\(2 \\times 2\\)로 이 변형이 표현될 수 있기 때문에,\n\\[\nM_T =\n\\begin{bmatrix}\nm_{11} & m_{12} \\\\\nm_{21} & m_{22}\n\\end{bmatrix}\n\\]\n앞서 변형을 그대로 적어보자.\n\\[\n\\begin{aligned}\nm_{11} v_{1x} + m_{12} v_{1y} & = t_{1x} \\\\\nm_{21} v_{1x} + m_{22} v_{1y} & = t_{1y} \\\\\nm_{11} v_{2x} + m_{12} v_{2y} & = t_{2x} \\\\\nm_{21} v_{2x} + m_{22} v_{2y} & = t_{2y} \\\\\n\\end{aligned}\n\\]\n여기서 미지수는 \\(m_{\\cdot}\\)이다. 즉 4개의 미지수를 지니는 연립방정식이 된다.\n\\[\nA \\vec m = \\vec t ~\\Leftrightarrow~\n\\begin{bmatrix}\nv_{1x} & v_{1y} & 0 & 0 \\\\\nv_{1x} & v_{1y} & 0 & 0 \\\\\n0 & 0 & v_{2x} & v_{2y} \\\\\n0 & 0 & v_{2x} & v_{2y} \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\nm_{11} \\\\\nm_{12} \\\\\nm_{21} \\\\\nm_{22} \\\\\n\\end{bmatrix} =\n\\begin{bmatrix}\nt_{1x} \\\\\nt_{1y} \\\\\nt_{2x} \\\\\nt_{2y}\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "posts/linear-algebra/2021-01-08-basis.html#change-of-basis",
    "href": "posts/linear-algebra/2021-01-08-basis.html#change-of-basis",
    "title": "Basis",
    "section": "Change of Basis",
    "text": "Change of Basis\n한 벡터의 기저를 다른 기저로 바꾸는 것을 생각해보자. 일반적으로는 \\(T: V \\to W\\) 역시 \\(B_V\\)에서 \\(B_W\\)로 기저를 바꾸는 것이다. 차원이 바뀐다면 기저 역시 바뀌어야 한다.\n기저 변환(change-of-basis)은 매트릭스를 이해하는 매우 중요한 방식이다. 이를 통해 역시 매트릭스 표현에 도달할 수 있다. 선형 번환 \\(T: V \\to W\\)가 있다고 하자.\n\n\n표기법 상 룰을 하나 정하도록 하자. \\(\\phantom{}_{B_W}{M_T}_{B_V}\\)이라고 쓰는 이는 매트릭스 전후로 투입과 산출 벡터를 표기해주는 것이다. 죽, \\(M_T\\)의 투입은 \\({B_V}\\) 이고 산출은 \\(B_W\\)이다.\n\\[\n\\begin{aligned}\nB_V & = \\{ \\hat e_1, \\dotsc, \\hat e_n \\} \\\\\nB_W & =  \\{ \\hat b_1, \\dotsc, \\hat b_m \\}\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\phantom{}_{B_W}{\\lbrack M \\rbrack}_{B_V} \\vec v_{B_V} & =\n\\begin{bmatrix}\n\\vert & \\vert & \\vert \\\\\nT(\\hat e_1) & \\dotsc & T(\\hat e_n) \\\\\n\\vert & \\vert & \\vert \\\\\n\\end{bmatrix}_{B_V}\n\\begin{bmatrix}\nv_1 \\\\\n\\vdots \\\\\nv_n \\\\\n\\end{bmatrix}_{B_V} \\\\\n& = T(\\hat e_1) v_1 + \\dotsb + T(\\hat e_n) v_n \\\\\n& = T(v_1 \\hat e_1 + \\dotsb + v_n \\hat e_n) \\\\\n&  = T(\\vec v) \\\\\n& = \\vec w_{B_W}\n\\end{aligned}\n\\]\n이제 \\(T(\\hat e_1)\\) 하나만 구체적으로 풀어보자. \\(T\\)를 통해서 기저는 \\(B_V\\)에서 \\(B_W\\)로 바뀐다.\n\\[\nT(\\hat e_1) =\n\\begin{bmatrix}\nc_{11} \\\\\n\\vdots \\\\\nc_{m1}\n\\end{bmatrix}_{B_W} = c_{11} \\hat b_1 + \\dotsb + c_{m1} \\hat b_m\n\\]\n이를 모든 행에 대해서 적용하면, 다음과 같다.\n\\[\n\\phantom{}_{B_W}\\lbrack M \\rbrack_{B_V} =\n\\vphantom{\n\\begin{bmatrix}\n\\\\\n\\\\\n\\\\\n\\end{bmatrix}\n}_{B_W}\n\\begin{bmatrix}\nc_{11} & \\cdots & c_{1n} \\\\\n&\\cdots&\\\\\nc_{m1}  & \\cdots & c_{mn} \\\\\n\\end{bmatrix}_{B_V}\n\\]\n정리하면 다음과 같다.\n\\[\n[T(\\vec v)]_{B_W} = \\phantom{}_{B_W} [M_T]_{B_V} [\\vec v]_{B_V}\n\\]\n\nChange-of-basis\n이제 하나의 같은 벡터의 기저를 \\(B_v \\to B_{v^{\\prime}}\\)으로 바꾸는 것을 살펴보자. 즉 \\(T: V \\to V\\)의 경우에 해당한다.\n\\[\n\\vec v = (v_1, v_2, v_3)_B = v_1 \\hat e_1 + v_2 \\hat e_2 + v_3 \\hat e_3\n\\]\n이제 기저를 \\(B \\to B^\\prime\\)으로 바꾸는 어떤 변환이 있다고 하자. 이 변환을 \\(\\phantom{}_{B^{\\prime}}[1]_B\\)라고 표기하자. 이 표기의 뜻은 매트릭스의 인풋(오른쪽)이 원래의 기저 \\(B\\)이고 변환을 통해 산출되는 기저를 \\(B^{\\prime}\\)으로 나타낸 것이다. \\(1\\)의 의미는 벡터의 기저만 바뀌었을 뿐 동일한 벡터의 변환이라는 의미를 지닌다 즉,\n\\[\n(v^{\\prime}_1, v^{\\prime}_2, v^{\\prime}_3) = v^{\\prime}_1 \\hat e^{\\prime}_1 +  + v_2 \\hat e^{\\prime}_2 + v_3 \\hat e^{\\prime}_3 = \\vec v = v_1 \\hat e_1 + v_2 \\hat e_2 + v_3 \\hat e_3\n\\]\n\\(_{B^{\\prime}}1_B\\)을 찾기 위해서 \\(\\hat e_1\\)을 \\(B^{\\prime}\\) 기저로 표현해보자.\n\\[\n\\hat e_1 = (\\hat e^{\\prime}_1 \\cdot \\hat e_1) e^{\\prime}_1 + (\\hat e^{\\prime}_2 \\cdot \\hat e_1) e^{\\prime}_2 + (\\hat e^{\\prime}_3 \\cdot \\hat e_1) e^{\\prime}_3 = ( \\hat e^{\\prime}_1 \\cdot \\hat e_1,  \\hat e^{\\prime}_2 \\cdot \\hat e_1 ,  \\hat e^{\\prime}_3 \\cdot \\hat e_1  )_{B^{\\prime}}\n\\]\n따라서 기저 변환을 위한 매트릭스는 다음과 같다.\n\\[\n\\begin{bmatrix}\ne^{\\prime}_1 & e^{\\prime}_2 & e^{\\prime}_3\n\\end{bmatrix} =\n\\begin{bmatrix}\ne^{\\prime}_1 \\cdot \\hat e_1  & e^{\\prime}_1 \\cdot \\hat e_2 & e^{\\prime}_1 \\cdot \\hat e_3 \\\\\ne^{\\prime}_2 \\cdot \\hat e_1  & e^{\\prime}_2 \\cdot \\hat e_2 & e^{\\prime}_2 \\cdot \\hat e_3 \\\\\ne^{\\prime}_3 \\cdot \\hat e_1  & e^{\\prime}_3 \\cdot \\hat e_2 & e^{\\prime}_3 \\cdot \\hat e_3 \\\\\n\\end{bmatrix} =\n\\phantom{}_{B^{\\prime}}[1]_B\n\\]\n\n\nBack to generic bases\n다시 위에서 살펴보았던 날 기저(generic basis) \\(f\\) 의 문제로 돌아와보자. \\(\\phantom{}_S1_f\\)는 어떻게 구할 수 있을까? 위의 식을 참고하면 된다. \\(B_S = \\{(1,0,0), (0,1,0), (0,0,1)\\}\\)이라고 하자. 표기의 편의상 \\(B_S\\) 각각을 \\(\\hat i\\), \\(\\hat j\\), \\(\\hat k\\) 라고 하자.\n\\[\n\\phantom{}_S[1]_f =\n\\begin{bmatrix}\n\\vec f_1 \\cdot \\hat i  & \\vec f_2 \\cdot \\hat i  & \\vec f_3 \\cdot \\hat i \\\\\n\\vec f_1 \\cdot \\hat j  & \\vec f_2 \\cdot \\hat j  & \\vec f_3 \\cdot \\hat j \\\\\n\\vec f_1 \\cdot \\hat k & \\vec f_2 \\cdot \\hat k & \\vec f_3 \\cdot \\hat k \\\\\n\\end{bmatrix}\n\\]\n\\(\\phantom{}_S[1]_f\\) 매트릭스는 \\(B_f\\) 기저의 벡터를 \\(B_S\\) 기저의 벡터로 바꿔주는 매트릭스다. 이를 적용하면 \\(B_S\\) 기저의 매트리스 벡터가 나온다.\n\\[\n\\underbrace{\\phantom{}_S[1]_f}_{B_S \\leftarrow B_f} \\vec v_{B_f} = \\vec v_{B_S}\n\\]\n\n\nTransformation with change-of-basis\n이제 \\(\\phantom{}_B \\lbrack M_T \\rbrack_B\\) 가 주어져 있다고 하자. 이를 \\(\\phantom{}_{B^{\\prime}}\\lbrack M_T \\rbrack_{B^{\\prime}}\\phantom{}\\)로 어떻게 교체할 수 있을까? 개념적으로는 이럴 것이다.\n\\[\n\\phantom{}_{B^{\\prime}}{[M_T]}_{B^{\\prime}} = \\underbrace{\\phantom{}_{B^{\\prime}}{[1]}_{B}}_{B^\\prime \\leftarrow B}\\phantom{}_{B}{[M_T]}_{B}\\overbrace{\\phantom{}_{B}{[1]}_{B^{\\prime}}}^{B \\leftarrow B^\\prime}\n\\]\n\\(\\phantom{}_{B^{\\prime}}{\\lbrack 1 \\rbrack}_{B}\\)과 \\(\\phantom{}_{B}{\\lbrack 1 \\rbrack}_{B^{\\prime}}\\)이 서로 역변환 관계임을 기억해두자."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-08-basis.html#similar-matrix",
    "href": "posts/linear-algebra/2021-01-08-basis.html#similar-matrix",
    "title": "Basis",
    "section": "Similar Matrix",
    "text": "Similar Matrix\n\\(B \\in \\mathbb R^{n \\times n}\\)과 역행렬이 존재하는 매트릭스 \\(C \\in \\mathbb R^{n \\times n}\\)가 있다고 하자. A은 다음과 같이 정의된다.\n\\[\nA = C B C^{-1}\n\\]\n\\(A\\)과 \\(B\\)은 서로 닮은 꼴의 매트릭스다. 위 식을 만족하는 매트릭스 \\(A\\)과 \\(B\\)을 similar matrix라고 정의한다. 우선 두 매트릭스가 서로 닮은 꼴일 때에는 \\(n \\geq 1\\)에 대해서 \\(A^n = C B^n C^{-1}\\)이 성립한다. 이는 아이겐 분해에서 보듯이 \\(B\\)가 어떤 매트릭스냐에 따라서 계산 상 편리함을 줄 수 있다. 만일 \\(B\\)가 대각 행렬이라면 행렬의 \\(n\\)은 대각 원소의 \\(n\\) 승만 수행하면 된다.\n\\(C\\)가 역행렬을 지니기 때문에 \\(C\\)의 컬럼은 \\(\\mathbb R^n\\)의 기저가 된다. 이렇게 보면 \\(C\\)는 change-of-basis와 같은 맥락에서 이해할 수 있다. 즉, 앞서 살펴 본 기저를 바꾸는 행렬과 동일한 행렬이다. \\(A x\\)라는 변환을 이 맥락에서 다시 이해해보자. 여기서 \\(\\mathcal B\\)는 표준 기저(\\(\\hat e_i\\))로 이해하면 된다.\n\n\\(C^{-1} x\\)는 \\(\\lbrack x \\rbrack_{u}\\)의 기저를 \\([x]_{\\mathcal B}\\)로 바꾸는 것이다. 즉, \\(\\phantom{}_{\\mathcal B}\\lbrack 1 \\rbrack_u\\)\n이 바뀐 기저에서 \\(B\\)이라는 변환을 수행한다. 즉, \\(\\phantom{}_{\\mathcal B} \\lbrack B \\rbrack_{\\mathcal B}\\)\n\\(C\\)는 곱해 다시 통상적인 기저로 돌아오게 된다. 즉, \\(\\phantom{}_{u}{\\lbrack 1 \\rbrack}_{\\mathcal B}\\)\n\n아래 그림에서 보듯이, \\(Ax\\)라는 변환과 \\(B[x]_{\\mathcal B}\\)라는 변환은 좌표계만 다를 뿐 동일한 변환이다. \\(C B C^{-1}\\)의 기저의 변화를 살펴보면,\n\\[\n\\begin{aligned}\n\\underbrace{u \\rightarrow \\mathcal B}_{C^{-1}} & \\cdots B \\cdots \\underbrace{\\mathcal B \\rightarrow u}_{C} \\\\\n& \\cdots A \\cdots\n\\end{aligned}\n\\]\n로 나타낼 수 있다.\n\n\n\n기저 변환의 의미\n\n\n Similar matrix인 \\(A\\)과 \\(B\\) 사이에서 다음과 같은 관계가 성립한다.\n\n\\({\\rm Tr}(A) = {\\rm Tr}(B)\\)\n\\({\\rm det}(A) = {\\rm det}(B)\\)\n\\({\\rm rank}(A) = {\\rm rank}(B)\\)\n\\({\\rm eig}(A) = {\\rm eig}(B)\\)"
  },
  {
    "objectID": "posts/linear-algebra/2021-01-10-Eigenspace-1.html",
    "href": "posts/linear-algebra/2021-01-10-Eigenspace-1.html",
    "title": "Eigenspace, part 1",
    "section": "",
    "text": "아이겐밸류, 아이겐벡터는 중요하다. 어디서나 튀어나온다. 그래서 친숙하지만 나는 이걸 제대로 알고 있는 것일까? 이번 포스팅에서는 아이겐 공간의 관점에서 이 문제를 살펴볼 예정이다.\n사실 아이겐 공간은 \\(n \\times n\\) 매트릭스의 숨은 구조(뼈대)와 같다. 아이겐밸류를 구하는 식을 떠올려보자.\n\\[\nM_T \\vec x = \\lambda \\vec x\n\\]\n\\(M_T\\)라는 \\(n \\times n\\) 변환이 특정한 벡터 아래서는 스칼라 곱의 문제로 환원된다. 이런 의미에서 아이겐벡터는 \\(M_T\\)라는 매트릭스가 지닌 일종의 축이다. 이 축 위에서 변환이 다시 축으로 환원되기 때문이다. \\(M_T\\)의 원래 기저와 상관 없이, 이 아이겐벡터로 다시 기저를 구성한다고 생각해보자. 이때 아이겐밸류는 해당 축의 크기(길이)로 이해할 수 있다."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-10-Eigenspace-1.html#why",
    "href": "posts/linear-algebra/2021-01-10-Eigenspace-1.html#why",
    "title": "Eigenspace, part 1",
    "section": "",
    "text": "아이겐밸류, 아이겐벡터는 중요하다. 어디서나 튀어나온다. 그래서 친숙하지만 나는 이걸 제대로 알고 있는 것일까? 이번 포스팅에서는 아이겐 공간의 관점에서 이 문제를 살펴볼 예정이다.\n사실 아이겐 공간은 \\(n \\times n\\) 매트릭스의 숨은 구조(뼈대)와 같다. 아이겐밸류를 구하는 식을 떠올려보자.\n\\[\nM_T \\vec x = \\lambda \\vec x\n\\]\n\\(M_T\\)라는 \\(n \\times n\\) 변환이 특정한 벡터 아래서는 스칼라 곱의 문제로 환원된다. 이런 의미에서 아이겐벡터는 \\(M_T\\)라는 매트릭스가 지닌 일종의 축이다. 이 축 위에서 변환이 다시 축으로 환원되기 때문이다. \\(M_T\\)의 원래 기저와 상관 없이, 이 아이겐벡터로 다시 기저를 구성한다고 생각해보자. 이때 아이겐밸류는 해당 축의 크기(길이)로 이해할 수 있다."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-10-Eigenspace-1.html#eigenspace",
    "href": "posts/linear-algebra/2021-01-10-Eigenspace-1.html#eigenspace",
    "title": "Eigenspace, part 1",
    "section": "Eigenspace",
    "text": "Eigenspace\n아이겐 공간이란 무엇일까? 특정한 아이겐밸류 \\(\\lambda_i\\)에 의해 파생되는 아이겐 공간은 다음과 같이 정의될 수 있다.\n\\[\nE_{\\lambda_i}  \\overset{\\rm def}{=} \\mathcal N (A - \\lambda_i 1) = \\{ \\vec v | (A - \\lambda_i ) \\vec v = \\vec 0 \\}\n\\]\n즉, \\(A - \\lambda_i 1\\)의 널 스페이스다. 사실 여기서 아이겐밸류를 구하는 공식도 파생된다. 아이겐벡터가 \\(A - \\lambda_i 1\\)의 널 스페이스에 있다는 것은 \\(A - \\lambda_i 1\\)라는 변환이 서로 선형 종속이라는 뜻이다. 즉 \\(\\det (A - \\lambda_i 1) = 0\\)의 의미와 같다. 아이겐밸류를 구하는 특성방정식이 여기서 도출된다.\n\\[\np(\\lambda) = \\vert A - \\lambda 1 \\vert = 0\n\\]\n\nAll distinct eigenvalues\n실용적으로 접근해보자. 모든 아이겐밸류가 다르다면, 아이겐벡터는 선형독립이다. \\(n\\) 개의 서로 다른 아이겐벡터가 있다면 원래 매트릭스(\\(M_T\\))의 컬럼 스페이스를 생성하는 기저가 될 수 있다.\n\n\nAlgebraic vs geometric\n대수적 중복도(algebraic multiplicity: AM)란 특성 방정식에서 특정한 아이겐밸류 \\(\\lambda\\)가 몇 번 나타나는지를 표시한다. 한편 기하적 중복도(geometric multiplicity: GM)란 \\(\\lambda\\)의 아이겐벡터가 생성하는 널 공간의 차원을 의미한다. 예를 들어보자.\n\\[\nA =\n\\begin{bmatrix}\n1 & 2 \\\\\n0 & 1\n\\end{bmatrix}\n\\]\n\\(A\\) 특성방정식을 구하면 \\(p(\\lambda) = (1-\\lambda)^2\\)이다. 따라서 아이겐밸류 1의 AM는 2이다. GM은 어떨까?\n\\[\nA - \\lambda I =\n\\begin{bmatrix}\n0 & 2 \\\\\n0 & 0 \\\\\n\\end{bmatrix} x = 0\n\\]\n이를 만족하는 널 스페이스 \\(x\\)는 아래 벡터 하나다.\n\\[\nx = \\alpha\n\\begin{bmatrix}\n1 \\\\\n0\n\\end{bmatrix}\n\\]\n따라서 \\(\\lambda=1\\)의 GM은 1이 된다.\n일단 직관적으로 알 수 있는 점은 아이겐밸류 \\(\\lambda\\)의 기하적 중복도가 대수적 중복도 보다 클 수는 없다는 점이다. 즉, \\({\\rm GM}(\\lambda) \\leq {\\rm AM}(\\lambda)\\)\n\n\nDefective eigenvalues\n\\({\\rm GM}(\\lambda) &lt; {\\rm AM}(\\lambda)\\)가 되는 \\(\\lambda\\)를 defective eigenvalue라고 부른다. 특성 방정식에서 해당 아이겐벡터가 생성하는 널 스페이스의 차원이 AM보다 작다면, 아이겐벡터를 모아서 특성 방정식 생성한 널 스페이스를 생성할 수 없다. 다시 말하면, 이는 아이겐 분해를 통해서 원래 매트릭스의 컬럼 스페이스를 온전하게 생성할 수 없다는 뜻이다.\n모든 아이겐밸류의 값이 다를 경우, 즉 아이겐밸류의 중복이 없을 경우 각각 아이겐밸류의 AM은 1이 된다. 이 경우 아이겐벡터들이 모두 선형 독립이기 때문에 각 아이겐밸류의 기하적 중복도 역시 1이 된다. 따라서 반복되는 아이겐밸류가 없는 경우에는 defective eigenvalue는 없고, 행렬의 아이겐 분해가 가능해진다."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-10-Eigenspace-1.html#diagonalization-as-change-of-basis",
    "href": "posts/linear-algebra/2021-01-10-Eigenspace-1.html#diagonalization-as-change-of-basis",
    "title": "Eigenspace, part 1",
    "section": "Diagonalization as Change-of-Basis",
    "text": "Diagonalization as Change-of-Basis\n아이겐벡터와 아이겐밸류를 동원해서 매트릭스를 분해하는 것을 대각화라고도 부른다.\n\\[\nA = Q \\Lambda Q^{-1}\n\\]\n이렇게 분해될 때 가운데 매트릭스 \\(\\Lambda\\)가 아이겐밸류의 대각 행렬로 구성되기 때문이다. \\(Q\\)는 다음과 같이 정의된다.\n\\[\nQ =\n\\begin{bmatrix}\n\\vert & \\vert & \\vert \\\\\n\\vec e_{\\lambda_1} & \\dotsc & \\vec e_{\\lambda_n} \\\\\n\\vert & \\vert & \\vert \\\\\n\\end{bmatrix}\n\\]\n앞서 아이겐벡터가 일종의 축의 역할을 한다고 했다. 즉, 이 아이겐벡터는 매트릭스의 인풋으로 아이겐 스페이스 벡터를 받고 이를 현재의 표준 스페이스로 바꿔준다.\\(B_S \\leftarrow B_\\lambda\\) 역할을 한다. 즉,\n\\[\nQ = \\phantom{}_{B_S}[1]_{B_\\lambda}\n\\]\n\\(Q\\)를 기저 변환의 관점에서 보면 아이겐 공간의 좌표를 표준 좌표로 바뀌주는 역할을 한다. \\(Q^{-1}\\)은 반대로 \\(B_{\\lambda} \\leftarrow B_{S}\\)의 역할을 한다. 즉,\n\\[\nQ^{-1} = \\phantom{}_{B_\\lambda}[1]_{B_S}\n\\]\n이 관점에서 보면 행렬의 대각화가 새롭게 보인다.\n\\[\n[\\vec w]_{B_S} = \\phantom{}_{B_S}[A]_{B_S} [\\vec v]_{B_S} = Q \\Lambda Q^{-1}[\\vec v]_{B_S}\n\\]\n\\[\nQ \\Lambda Q^{-1}[\\vec v]_{B_S} = \\underbrace{\\phantom{}_{B_S}[1]_{B_\\lambda}}_{Q}\\phantom{}_{B_\\lambda}[\\Lambda]_{B_\\lambda}\\overbrace{\\phantom{}_{B_\\lambda}[1]_{B_S}}^{Q^{-1}}[\\vec v]_{B_S}\n\\]\n행렬의 대각화란 일정한 변환 혹은 매트릭스를 아이겐 공간을 통해 다시 해석하는 과정이다. 즉, \\(B_S \\to B_\\lambda \\to B_S\\)의 과정을 거친다.\n대각 행렬 \\(\\Lambda\\)는 아이겐벡터들로 구성된 아이겐 공간의 기저(아이겐벡터)의 크기를 나타낸다.\n\nEat this!\n대각화를 통해서 아이겐밸류의 중요한 특성 두 가지를 다시 음미해보자.\n\\[\n{\\rm det}(A) = \\vert A \\vert = \\prod_{i} \\lambda_i\n\\]\n\\[\n{\\rm Tr}(A) = \\sum_{i} a_{ii} = \\sum_{i} \\lambda_i\n\\]\n논리는 아래와 같이 간단하다.\n\\[\n\\vert A \\vert = \\vert Q \\Lambda Q^{-1} \\vert =  \\vert Q \\vert \\vert \\Lambda \\vert \\vert Q^{-1} \\vert = \\vert Q \\vert \\vert Q^{-1} \\vert \\vert \\Lambda \\vert = \\dfrac{\\vert Q \\vert}{\\vert Q^{} \\vert} \\vert \\Lambda \\vert = \\vert \\Lambda \\vert\n\\]\n\\[\n{\\rm Tr}(Q \\Lambda Q^{-1}) = {\\rm Tr}(\\Lambda Q Q^{-1}) = {\\rm Tr}(\\Lambda 1) = {\\rm Tr}(\\Lambda) = \\sum_{i} \\lambda_i\n\\]\n두 가지 속성은 \\({\\rm det}(A) = \\vert A \\vert = \\prod_{i} \\lambda_i\\)는 대각화가 가능한 경우 뿐 아니라 일반적으로 성립한다. 첫번째 속성만 살펴보자. 특성방정식을 생각해보면, \\(\\vert A - \\lambda I \\vert = 0\\)이다. 즉,\n\\[\n\\begin{aligned}\np(\\lambda)  = & {\\rm det} (A - \\lambda I) \\\\\n& (-1)^n (\\lambda - \\lambda_1) \\dotsb  (\\lambda - \\lambda_n) \\\\\n& (\\lambda_1 - \\lambda)\\dotsb(\\lambda_n - \\lambda)\n\\end{aligned}\n\\]\n따라서, \\(\\det (A) = \\lambda_1 \\dotsb \\lambda_n\\).\n\n\nNormal matrix\n매트릭스 \\(A\\)가 노멀이라면, 이는 \\(A^T A = A A^T\\)를 만족하는 경우를 뜻한다. 모든 노멀 매트릭스는 대각화가 가능하고 아울러 \\(Q\\)를 직교 행렬(orthgonal matrix or orthonormal matrix) \\(O\\) 로 택할 수 있다. 이는 \\(Q^{-1}\\)의 계산이 간단해진다는 뜻이다. 즉,\n\\[\nOO^T = I = O^T O\n\\]\n\\[\nO^TO =\n\\begin{bmatrix}\n-- & \\hat e_1 & -- \\\\\n   & \\vdots & \\\\\n-- & \\hat e_n & -- \\\\\n\\end{bmatrix}\n\\begin{bmatrix}\n\\vert &  & \\vert \\\\\n\\hat e_1 & \\dotsc & \\hat e_n \\\\\n\\vert & & \\vert \\\\\n\\end{bmatrix} = I\n\\]"
  },
  {
    "objectID": "posts/linear-algebra/2021-01-10-Eigenspace-1.html#gram-schmidt-orthogonalization",
    "href": "posts/linear-algebra/2021-01-10-Eigenspace-1.html#gram-schmidt-orthogonalization",
    "title": "Eigenspace, part 1",
    "section": "Gram-Schmidt Orthogonalization",
    "text": "Gram-Schmidt Orthogonalization\northnormal, orthogonal, generic 세 가지 기저의 품질을 따져보자. 당연히 orthonormal 기저가 가장 작업하기 쉽다. 위에서 보듯이, \\(Q^T = Q^{-1}\\)라는 좋은 특징도 지니고 있다. 만일 통상적인 벡터를 orthonormal 기저로 변형할 수 있다면, 작업이 훨씬 쉬울 것이다.\n\nDefinition\n\n\\(V\\): \\(n\\) 차원 벡터\n\\(\\{ v_1, \\dotsc, v_n \\}\\): \\(V\\)의 generic 기저\n\\(\\{ e_1, \\dotsc, e_n \\}\\): \\(V\\)의 orthogonal 기저. \\(e_i \\cdot e_j = 0\\) for \\(i \\neq j\\)\n\\(\\{\\hat e_1, \\dotsc, \\hat e_n \\}\\) V의 orthonormal 기저.\nInner production operation: \\(\\langle \\cdot, \\cdot \\rangle: V \\times V \\to \\mathbb R\\)\nLength: \\(\\Vert v \\Vert = \\langle v, v \\rangle\\)\nProjection operation: Projection of \\(u\\) onto \\(e\\):\n\n\\[\n\\Pi_e(u) = \\dfrac{\\langle u, e \\rangle}{\\Vert e \\Vert^2}e\n\\]\n\nThe projection complement of projection \\(\\Pi_e(u)\\) is \\(w\\)\n\n\\[\n\\Pi_e(u) + w = u ~~~\\Rightarrow~~~w = u - \\Pi_e(u)  \n\\]\n\n\nOrthonormal basis is nice\n어떤 벡터 \\(v\\)든 orthonormal 기저를 통해 간편하게 나타낼 수 있다. 즉,\n\\[\nv = \\langle v, \\hat e_1 \\rangle  \\hat e_1 + \\dotsb + \\langle v, \\hat e_n \\rangle \\hat e_n\n\\]\n\n\nOrthogonalization\n일단 기억해야 할 것은 generic 기저 \\(\\{v_i\\}\\)가 생성하는 벡터 공간과 \\(\\{ \\hat e_i \\}\\)가 생성하는 벡터 공간이 동일하다는 것이다. 즉,\n\\[\n\\text{span}(v_1, \\dotsc, v_n) = V = \\text{span}(\\hat e_1, \\dotsc, \\hat e_n)\n\\]\n그람-슈미트 알고리즘은 다음과 같다.\n\n일단 orthogonal 기저를 만든다.\n해당 벡터를 표준화한다.\n\nOrthogonal 기저는 어떻게 만들까? 먼저 과정을 살펴보자. .\n\n\\(e_1 = v_1\\)\n\\(e_2 = v_2 - \\Pi_{e_1}(v_2)\\)\n\n\n\n\nGram-Schmidt 분해\n\n\n 위의 그림에서 보듯이 \\(v_2\\)는 \\(v_1\\) 프로젝션된 벡터와 이와 직교하는 \\(e_2\\)와의 합으로 계산할 수 있다. 따라서 \\(e_2 = v_2 - \\Pi_{e_1}(v_2)\\)가 성립한다. 벡터의 빼기 관점에서 생각해보면 어떨까? \\(v_2\\)와 \\(\\Pi_{e_1}(v_2)\\)의 차이가 \\(e_2\\)다. 벡터는 방향과 크기로 정의된다는 점을 다시 기억하자. 같은 방식으로 아래 그림에서 보듯이 더 많은 축과 직교하는 벡터들을 구성할 수 있다.\n이후 \\(\\hat e_i = \\dfrac{e_i}{\\Vert e_i \\Vert}\\)로 \\(e_i\\)를 표준화하면 된다.\n\n\n\nGram-Schmidt 3차원 분해\n\n\n\\[\nv = {\\rm proj}_{u_1} (v) + {\\rm proj}_{u_2}(v) + w\n\\]\n즉, 원래 벡터(\\(v\\))에서 이미 확립된 직교 벡터에서 \\(v\\)로 쏜 프로젝션 벡터를 빼주면 원하는 새로운 직교 벡터를 얻을 수 있다. 따라서\n\\[\n\\begin{aligned}\ne_3 & = v_3 - \\Pi_{e_1}(v_3) - \\Pi_{e_2}(v_3) \\\\\n&~~~\\vdots \\\\\ne_n & = v_n - \\sum_{i=1}^{n-1} \\Pi_{e_i}(v_n)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/linear-algebra/2021-01-10-Eigenspace-1.html#wrap-it-up",
    "href": "posts/linear-algebra/2021-01-10-Eigenspace-1.html#wrap-it-up",
    "title": "Eigenspace, part 1",
    "section": "Wrap-it-up",
    "text": "Wrap-it-up\n행렬 대각화에 관해서 다시 한번 정리해보자. 때로는 혼동될 사안이라서 정리한다. 증명은 일단 생략한다.\n\nDiagonalization Theorem\n매트릭스 \\(A \\in \\mathbb C^{n \\times n}\\)가 대각화가 가능하다는 것은 \\(n\\)의 선형 독립인 아이겐벡터를 지니고 있다는 뜻이다. 즉, \\(A =Q \\Lambda Q^{-1}\\) 형태로 분해될 수 있음을 뜻한다.\n\n착각하지 말아야 할 것! 대각가능 행렬과 역행렬이 존재하는 행렬은 아무 관계가 없다. 둘은 서로 다른 이야기다.\n아이겐분해(eigendecomposition)이란 닮음 행렬을 통해서 기저를 바꾸는 과정인데, 이때 기저를 바꾸는 매트릭스로 동원되는 것이 아이겐벡터 매트릭스다.\n\n\n\nEat this!\n\n\\(A\\) positive semidefinite \\(\\Rightarrow\\) 아이겐밸류는 비음이다.\n\\(A\\) symmetric \\(\\Rightarrow\\) 아이겐밸류는 실수\n\\(A\\) normal (\\(A^T A = A A^T\\)) \\(\\Rightarrow\\) \\(Q\\)를 직교 행렬 \\(O\\)로 고를 수 있다(\\(O^T O = I\\))."
  },
  {
    "objectID": "posts/linear-algebra/2020-12-16-measuring-distance.html",
    "href": "posts/linear-algebra/2020-12-16-measuring-distance.html",
    "title": "Projection and Distance",
    "section": "",
    "text": "다음과 같은 두 개의 벡터, \\(\\vec a\\), \\(\\vec b\\)를 일단 떠올려보자.\n\n\n\n벡터 \\(\\mathbf a\\)를 벡터 \\(\\mathbf b\\)로 프로젝션 할 때 스칼라 프로젝션은 \\(\\mathbf a_1\\)의 길이를 벡터 프로젝션은 벡터 \\(\\mathbf a_1\\)를 나타난다.\n\n\n스칼라 프로젝션 \\(a_1\\)의 정의는 다음과 같다.\n\\[\na_1 ={\\cos \\theta}{\\lVert \\vec a \\lVert} = \\lVert \\vec a_1 \\lVert\n\\]\n각 \\(\\theta\\)에 관해서 다음과 같이 정의할 수 있다. 혹시 리마인드가 필요하면 포스팅 dot product를 참고하라.\n\\[\n\\cos \\theta = \\dfrac{\\vec a \\cdot \\vec b}{\\lVert \\vec a \\lVert \\lVert \\vec b \\lVert}\n\\]\n그리고\n\\[\n\\hat b = \\dfrac{\\vec b}{\\lVert \\vec b \\lVert}\n\\]\n라고 할 때,\n\\[\na_1 = {\\cos \\theta}{\\lVert \\vec a \\lVert} = \\dfrac{\\vec a \\cdot \\vec b}{\\lVert\\vec b\\lVert} = \\vec a \\cdot \\hat b\n\\]\n쉽게 말해서, \\(\\vec a\\) 벡터와 정규화된 \\(\\vec b\\)의 닷 프로 덕트라고 생각하면 된다.\n\n\n\n스칼라 프로젝션의 크기로 \\(\\vec b\\)의 벡터를 만든 것이 벡터 프로젝션이다. \\(\\vec a\\)를 \\(\\vec b\\) 위로 프로젝션 한 벡터 \\(\\Pi_{\\vec b} (\\vec a)\\)는 다음과 같다. 스칼라 프로젝션의 크기만큼 \\(\\vec b\\) 성분을 지녀야 한다. 따라서 \\(\\vec b\\)는 정규화된 \\(\\hat b\\)를 써야 한다.\n\\[\n\\vec a_1 = \\Pi_{\\vec b} (\\vec a) = a_1 \\hat b = \\dfrac{\\vec a \\cdot \\vec b}{\\lVert\\vec b\\lVert} \\dfrac{\\vec b}{\\lVert\\vec b\\lVert}\n\\]\n말로 풀어보자. \\(\\vec b\\)와 같은 방향성을 지니는 벡터를 \\(\\vec a\\)와 \\(\\vec b\\) 간의 스칼라 프로젝션의 크기로 만들어주는 것이 벡터 프로젝션이다. 영상을 화면 위로 쏘는 행위를 떠올려보자. 이때 스크린에 해당하는 것이 \\(\\hat b\\)이고 여기에 투영되는 상이 \\(\\vec a\\)이다.\n\n\n\n사례를 먼저 살펴보자. \\(x\\)축 위로 프로젝션을 하랴고 한다.\n\\[\n\\Pi_{x}(\n\\begin{bmatrix}\n1 \\\\\n0 \\\\\n\\end{bmatrix}) =\n\\begin{bmatrix}\n1 \\\\\n0 \\\\\n\\end{bmatrix}, ~\n\\Pi_{x}(\n\\begin{bmatrix}\n0 \\\\\n1 \\\\\n\\end{bmatrix}) =\n\\begin{bmatrix}\n0 \\\\\n0 \\\\\n\\end{bmatrix}\n\\]\n\\[\nM_{\\Pi_x} =\n\\begin{bmatrix}\n\\Pi_{x}(\n\\begin{bmatrix}\n1 \\\\\n0 \\\\\n\\end{bmatrix}),~\n\\Pi_{x}(\n\\begin{bmatrix}\n0 \\\\\n1 \\\\\n\\end{bmatrix})\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 & 0 \\\\\n0 & 0\n\\end{bmatrix}\n\\]\n\\(M_{\\Pi_x}\\)를 외적의 관점에서 표현해 보자.\n\\[\n\\begin{aligned}\n\\Pi_{x}(\\vec v) & = (\\hat i \\cdot \\vec v) \\hat i = \\hat i (\\hat i \\cdot \\vec v) = \\hat i (\\hat i^T \\vec v) = (\\hat i \\hat i^T)\\vec v \\\\\n& =\n\\begin{bmatrix}\n1 & 0 \\\\\n0 & 0\n\\end{bmatrix} \\vec v = M_{\\Pi_x} \\vec v\n\\end{aligned}\n\\]\n즉, 프로젝션의 스크린 벡터의 외적이 바로 프로젝션을 구현하는 변형 행렬, 즉 함수에 해당한다. 이 결과는 일반적인 벡터 \\(\\vec b\\)에도 적용할 수 있다. \\(\\vec b\\)로의 프로젝션을 구현하기 위해서는 표준화된 벡터 \\(\\hat b\\)를 먼저 구해야 한다. 그리고 해당 벡터로 아우터 프로덕트(외적)를 구한다.\n\\[\n\\hat b = \\dfrac{\\vec b}{\\Vert b \\Vert},~M_{\\Pi_{\\hat b}} \\vec a = \\hat b \\hat b^T \\vec a  \n\\]\n\\(\\vec a\\)를 인풋 벡터로 이해하면 이를 \\(\\vec b\\)의 프로젝션 위치로 옮기는 선형 변환이 \\(\\Pi_{\\hat b}\\)에 해당한다."
  },
  {
    "objectID": "posts/linear-algebra/2020-12-16-measuring-distance.html#projection-scalar-and-vector",
    "href": "posts/linear-algebra/2020-12-16-measuring-distance.html#projection-scalar-and-vector",
    "title": "Projection and Distance",
    "section": "",
    "text": "다음과 같은 두 개의 벡터, \\(\\vec a\\), \\(\\vec b\\)를 일단 떠올려보자.\n\n\n\n벡터 \\(\\mathbf a\\)를 벡터 \\(\\mathbf b\\)로 프로젝션 할 때 스칼라 프로젝션은 \\(\\mathbf a_1\\)의 길이를 벡터 프로젝션은 벡터 \\(\\mathbf a_1\\)를 나타난다.\n\n\n스칼라 프로젝션 \\(a_1\\)의 정의는 다음과 같다.\n\\[\na_1 ={\\cos \\theta}{\\lVert \\vec a \\lVert} = \\lVert \\vec a_1 \\lVert\n\\]\n각 \\(\\theta\\)에 관해서 다음과 같이 정의할 수 있다. 혹시 리마인드가 필요하면 포스팅 dot product를 참고하라.\n\\[\n\\cos \\theta = \\dfrac{\\vec a \\cdot \\vec b}{\\lVert \\vec a \\lVert \\lVert \\vec b \\lVert}\n\\]\n그리고\n\\[\n\\hat b = \\dfrac{\\vec b}{\\lVert \\vec b \\lVert}\n\\]\n라고 할 때,\n\\[\na_1 = {\\cos \\theta}{\\lVert \\vec a \\lVert} = \\dfrac{\\vec a \\cdot \\vec b}{\\lVert\\vec b\\lVert} = \\vec a \\cdot \\hat b\n\\]\n쉽게 말해서, \\(\\vec a\\) 벡터와 정규화된 \\(\\vec b\\)의 닷 프로 덕트라고 생각하면 된다.\n\n\n\n스칼라 프로젝션의 크기로 \\(\\vec b\\)의 벡터를 만든 것이 벡터 프로젝션이다. \\(\\vec a\\)를 \\(\\vec b\\) 위로 프로젝션 한 벡터 \\(\\Pi_{\\vec b} (\\vec a)\\)는 다음과 같다. 스칼라 프로젝션의 크기만큼 \\(\\vec b\\) 성분을 지녀야 한다. 따라서 \\(\\vec b\\)는 정규화된 \\(\\hat b\\)를 써야 한다.\n\\[\n\\vec a_1 = \\Pi_{\\vec b} (\\vec a) = a_1 \\hat b = \\dfrac{\\vec a \\cdot \\vec b}{\\lVert\\vec b\\lVert} \\dfrac{\\vec b}{\\lVert\\vec b\\lVert}\n\\]\n말로 풀어보자. \\(\\vec b\\)와 같은 방향성을 지니는 벡터를 \\(\\vec a\\)와 \\(\\vec b\\) 간의 스칼라 프로젝션의 크기로 만들어주는 것이 벡터 프로젝션이다. 영상을 화면 위로 쏘는 행위를 떠올려보자. 이때 스크린에 해당하는 것이 \\(\\hat b\\)이고 여기에 투영되는 상이 \\(\\vec a\\)이다.\n\n\n\n사례를 먼저 살펴보자. \\(x\\)축 위로 프로젝션을 하랴고 한다.\n\\[\n\\Pi_{x}(\n\\begin{bmatrix}\n1 \\\\\n0 \\\\\n\\end{bmatrix}) =\n\\begin{bmatrix}\n1 \\\\\n0 \\\\\n\\end{bmatrix}, ~\n\\Pi_{x}(\n\\begin{bmatrix}\n0 \\\\\n1 \\\\\n\\end{bmatrix}) =\n\\begin{bmatrix}\n0 \\\\\n0 \\\\\n\\end{bmatrix}\n\\]\n\\[\nM_{\\Pi_x} =\n\\begin{bmatrix}\n\\Pi_{x}(\n\\begin{bmatrix}\n1 \\\\\n0 \\\\\n\\end{bmatrix}),~\n\\Pi_{x}(\n\\begin{bmatrix}\n0 \\\\\n1 \\\\\n\\end{bmatrix})\n\\end{bmatrix} =\n\\begin{bmatrix}\n1 & 0 \\\\\n0 & 0\n\\end{bmatrix}\n\\]\n\\(M_{\\Pi_x}\\)를 외적의 관점에서 표현해 보자.\n\\[\n\\begin{aligned}\n\\Pi_{x}(\\vec v) & = (\\hat i \\cdot \\vec v) \\hat i = \\hat i (\\hat i \\cdot \\vec v) = \\hat i (\\hat i^T \\vec v) = (\\hat i \\hat i^T)\\vec v \\\\\n& =\n\\begin{bmatrix}\n1 & 0 \\\\\n0 & 0\n\\end{bmatrix} \\vec v = M_{\\Pi_x} \\vec v\n\\end{aligned}\n\\]\n즉, 프로젝션의 스크린 벡터의 외적이 바로 프로젝션을 구현하는 변형 행렬, 즉 함수에 해당한다. 이 결과는 일반적인 벡터 \\(\\vec b\\)에도 적용할 수 있다. \\(\\vec b\\)로의 프로젝션을 구현하기 위해서는 표준화된 벡터 \\(\\hat b\\)를 먼저 구해야 한다. 그리고 해당 벡터로 아우터 프로덕트(외적)를 구한다.\n\\[\n\\hat b = \\dfrac{\\vec b}{\\Vert b \\Vert},~M_{\\Pi_{\\hat b}} \\vec a = \\hat b \\hat b^T \\vec a  \n\\]\n\\(\\vec a\\)를 인풋 벡터로 이해하면 이를 \\(\\vec b\\)의 프로젝션 위치로 옮기는 선형 변환이 \\(\\Pi_{\\hat b}\\)에 해당한다."
  },
  {
    "objectID": "posts/linear-algebra/2020-12-16-measuring-distance.html#more-definition",
    "href": "posts/linear-algebra/2020-12-16-measuring-distance.html#more-definition",
    "title": "Projection and Distance",
    "section": "More Definition",
    "text": "More Definition\n\n\\(S \\subseteq \\mathbb R^n\\): \\(S\\)는 벡터 부분 공간이라고 하자.\n\\(S^\\perp\\): \\(S\\)와 직교 벡터들의 집합이고 이 역시 벡터 부분 공간이다. \\[\nS^\\perp = \\lbrace \\vec w \\in \\mathbb R^n : \\vec w \\cdot s = 0~\\text{for all}~ s \\in S \\rbrace\n\\]\n\\(\\Pi_S\\): 부분 공간 \\(S\\) 위로 프로젝션\n\\(\\Pi_{S^\\perp}\\): 부분 공간 \\(S^\\perp\\) 위로 프로젝션\n\n\\(\\Pi_S\\)는 일종의 함수로서 다음과 같이 정의된다.\n\\[\n\\Pi_S: \\mathbb R^n \\to S\n\\]\n\\(\\vec x \\in \\mathbb R^n\\)의 어떤 벡터가 \\(\\Pi_S\\)를 거치면 \\(S\\)에 속하지 않는 나머지 부분은 사라지게 된다. 즉, \\(S\\)라는 화면 위로 자신의 이미지를 투영한다고 보면 된다. 그래서 프로젝션이다.\n몇 가지 특징은 다음과 같다.\n\nIf \\({\\vec v} \\in S\\), then \\(\\Pi_S(\\vec v) = \\vec v\\)\nIf \\(\\vec w \\in S^\\perp\\), then \\(\\Pi_S(\\vec w) = \\vec 0\\)\nif \\(\\vec u = \\alpha \\vec v + \\beta \\vec w\\) where \\(\\vec v \\in S\\), \\(\\vec w \\in S^{\\perp}\\), then \\(\\Pi_S(\\vec u) = \\alpha \\vec v\\)\n\\(\\Pi_S(\\vec v) (\\Pi_S(\\vec v) ) = \\Pi_S(\\vec v)\\) (idempotent)\n\n\nProjection onto line\n노멀 벡터로 표현된 상태에서 하이퍼플레인과 벡터의 거리를 측정하는 방법을 알아보자.\n\n\n노멀 벡터에 대해서 간략하게 복습하고 가자. 3차원 공간을 예로 들겠다. 각 공간의 축을 \\(x, y, z\\)라고 할 때, 이 공간에 놓인 2차원 평면의 방정식을 \\(2x - y + z = 0\\)이라고 두자. 이를 매트릭스로 쓰면 다음과 같다.\n\\[\n[2, -1, 1]\n\\begin{bmatrix}\nx  \\\\\ny \\\\\nz\n\\end{bmatrix} = 0\n\\]\n열 벡터 \\([2,-1, 1]^\\rm T\\)가 노멀 벡터 \\(\\vec n\\)에 해당한다.\n\n\n\n\\(\\vec u = \\Pi_{l} (\\vec u) + \\Pi_{l^{\\perp}} (\\vec u)\\)\n\n\n그림에서 \\(\\vec u\\)의 \\(\\vec v\\)로의 프로젝션은 앞서 살펴본 벡터 프로젝션이다. \\(\\vec v\\) 대신 \\(l\\)로 표기된 점에 유의하자.\n\\[\nl: \\{ \\vec v' \\in \\mathbb R^n \\lvert \\vec v' = \\vec 0 + t \\vec v, t \\in \\mathbb R \\}\n\\]\n\\[\n\\Pi_l(\\vec u) = \\dfrac{\\vec u \\cdot \\vec v}{\\lVert\\vec v\\lVert^2} \\vec v\n\\]\n이제 여기서 \\(\\Pi_{l^{\\perp}}\\)를 구하는 방법을 알아보자.\n\\[\n\\vec u = \\Pi_{l} (\\vec u) + \\Pi_{l^{\\perp}} (\\vec u)\n\\]\n\\(\\vec u\\)라는 벡터가 두 개의 직교하는 성분의 결합을 통해 표현될 수 있다는 것을 알 수 있다.\n\n\nProjection onto plane\n\n\n\n\\(\\vec u = \\Pi_P(\\vec u) + \\Pi_{P^\\perp}(\\vec u)\\)\n\n\n평면 위로의 프로젝션을 생각해 보자. 기본적인 원리는 동일하다. 이에 앞서 평면을 벡터로 표현하는 방법에 대해 알아보자. 가장 편리한 방법은 노멀 벡터를 활용하는 것이다. 즉, 평면 위의 점 \\(\\vec {p_0}\\)를 지나는 \\(P\\)는 다음과 같이 정의할 수 있다.\n\\[\nP = \\{ \\vec p \\in \\mathbb R^n : \\vec n \\cdot(\\vec p - \\vec p_0) = 0 \\}\n\\]\n여기서 노멀 벡터 \\(\\vec n\\)은 프로젝션 된 지점에서 평면과 직교하는 성분을 나타낸다. 3차원의 경우 노멀 벡터는 3차원 공간에서 해당 평면이 놓인 모습을 결정한다.\n\\[\n\\vec u = \\Pi_P(\\vec u) + \\Pi_{P^\\perp}(\\vec u)\n\\]\n\n\n\n\\(\\vec u\\)에서 노멀 벡터 \\(\\vec n\\)으로 프로젝션했을 때 벡터 프로젝션이 바로 \\(\\Pi_{P^\\perp}(\\vec u)\\)가 된다.\n\n\n우리가 알고 싶은 것은 \\(\\Pi_P(\\vec u)\\)다. 그리고 벡터는 위치가 아니라 방향과 크기에 의해 결정되기 때문에 노멀 벡터 \\(\\vec n\\)은 크기와 뱡향을 유지한다면 어디로든 옮겨도 된다. 이를 \\(\\vec u\\)가 시작하는 위치로 옮겨보자. 이제 \\(\\vec u\\)에서 \\(\\vec n\\)으로 프로젝션을 하자. \\(\\vec n\\) 위의 벡터가 바로 \\(\\Pi_{P^\\perp}(\\vec u)\\)가 된다. 즉,\n\\[\n\\Pi_{P^\\perp}(\\vec u) = \\dfrac{\\vec u \\cdot \\vec n}{\\lVert\\vec n\\lVert}\\dfrac{\\vec n}{\\lVert \\vec n \\lVert}\n\\]\n이제 \\(\\Pi_{P^\\perp}\\) 대입하면 \\(\\Pi_{P}\\)를 구할 수 있다. 즉,\n\\[\n\\Pi_P(\\vec u) + \\Pi_{P^\\perp}(\\vec u) = \\vec u\n\\]\n\\[\n\\Pi_P(\\vec u)  = \\vec u - \\dfrac{\\vec u \\cdot \\vec n}{\\lVert\\vec n\\lVert^2}{\\vec n}\n\\]"
  },
  {
    "objectID": "posts/linear-algebra/2020-12-16-measuring-distance.html#distance-in-vector-space",
    "href": "posts/linear-algebra/2020-12-16-measuring-distance.html#distance-in-vector-space",
    "title": "Projection and Distance",
    "section": "Distance in Vector Space",
    "text": "Distance in Vector Space\n\n노멀 벡터 없이 표현된 hyperplane\n프로젝션은 거리를 측정할 때 유용하다. 먼저 원점(굳이 원점일 필요는 없다)과 해당 벡터 공간에 속하고 \\(\\mathbf {p}_0\\)를 지나는 선 사이의 거리를 구해보자. 이때 선, 즉 하이퍼플레인은 노멀 벡터가 아니라 직접 아래와 같이 제시되어 있다고 하자.\n\\[\nl: \\{ \\vec p \\in \\mathbb R^n | \\vec p = \\mathbf {p}_0 + t \\vec v, t \\in \\mathbb R \\}\n\\]\n\n\n\n아래 그림에서 보듯이 적당한 위치에 \\(\\mathbf p_0\\)가 있다고 하자.\n\n\n위 그림에서 원점과 \\(l\\)의 거리는 어떻게 나타낼 수 있을까? \\(l\\)이 지나가는 \\(\\vec p_0\\)를 그대로 두고, \\(l\\)이 원점을 지나가도록 이동해 보자. 즉,\n\\[\nl_0 = \\{  \\vec p \\in \\mathbb R^n | \\vec p = \\mathbf {0} + t \\vec v, t \\in \\mathbb R \\}\n\\]\n\n\n\n\\(\\mathbf{p_0} = \\Pi_{l_0}(\\mathbf p_0) + \\Pi_{l_0^\\perp}(\\mathbf p_0)\\)\n\n\n이제 이 벡터와 \\(\\vec p_0\\) 사이의 거리를 구하면 된다. 이는 앞서 제시한 벡터 프로젝션의 수직 벡터의 길이와 같다. 즉,\n\\[\n{\\mathbf p_0} = \\Pi_{l_0}({\\mathbf p_0}) + \\Pi_{l_0^\\perp}({\\mathbf p_0} )\n\\]\n이때 \\(\\Pi_{l_0}(\\mathbf p_0)\\)는 \\(\\mathbf p_0\\)를 \\(l_0\\)로 프로젝션한 벡터를 나타낸다. 따라서 거리 \\(d(l, \\vec 0)\\)는 다음과 같다.\n\\[\nd(l, \\vec 0) = d(\\vec p_0, l_0) = \\lVert \\mathbf p_0 - \\dfrac{\\mathbf p_0 \\cdot \\vec v}{\\lVert \\vec v\\lVert^2}\\vec v \\lVert\n\\]\n\n\n노멀 벡터로 표현된 hyperplane\n아래와 같이 노멀 벡터로 표현된 평면과 원점의 거리를 측정해 보자.\n\\[\nP = \\{ \\vec p \\in \\mathbb R^n : \\vec n \\cdot(\\vec p - \\mathbf{p_0}) = 0 \\}\n\\]\n\n\n\n현재 평면을 지나는 점 \\(\\mathbf p_0\\)를 두고 평면을 원점으로 밀어보자. 이때 평면을 정의하는 노멀 벡터 \\(\\vec n\\)을 표현하면 원점과 이 점을 잇는 벡터 \\(\\vec p_0\\)f를 \\(\\vec n\\)으로 프로젝션한 벡터의 길이가 평면과 원점의 거리가 된다.\n\n\n원점을 지나도록 평면을 이동시키고 평면의 노멀 벡터가 정의된 \\(p_0\\)와 원점을 지나는 평면 \\(P_0\\) 사이의 거리를 측정하면 된다.\n\\[\nP_0 = \\{ \\vec p \\in \\mathbb R^n : \\vec n \\cdot(\\vec p - \\vec {0}) = 0 \\}\n\\]\n이 둘 사이의 거리는 \\(\\Pi_{P^\\perp}\\)의 거리와 같다. 즉, \\(\\vec p_0\\)가 원점과 \\(\\mathbf p_0\\)를 잇는 벡터라고 할 때,\n\\[\nd(P, \\vec 0) = d(P_0, \\vec p_0) = \\lVert  \\dfrac{\\vec p_0 \\cdot \\vec n}{\\lVert\\vec n\\lVert}\\dfrac{\\vec n}{\\lVert \\vec n \\lVert}\\lVert = \\dfrac{|\\vec p_0 \\cdot \\vec n |}{\\lVert\\vec n\\lVert}\n\\]"
  },
  {
    "objectID": "posts/linear-algebra/2020-12-16-measuring-distance.html#regression-coefficient",
    "href": "posts/linear-algebra/2020-12-16-measuring-distance.html#regression-coefficient",
    "title": "Projection and Distance",
    "section": "Regression Coefficient",
    "text": "Regression Coefficient\n\n\n\n선형대수로 본 회귀 분석\n\n\n앞서 소개했던 회귀 분석에 관한 포스팅 Understanding Regression을 다시 보자. Origin–Observed Y–Fitted \\(\\hat Y\\)이 만드는 삼각형을 보자. 직각 삼각형이다. 여기서 잔차에 해당하는 \\(e\\)는 \\(X\\)의 칼럼 스페이스와 항상 직교한다. 즉, \\(X' e = 0\\)이 성립한다. 그리고 \\(\\hat Y = X \\hat\\beta\\)이므로\n\\[\nX'(Y - \\hat Y)  = X'(Y - X \\hat\\beta) = 0\n\\]\n이를 노멀 방정식이라고 부른다. 앞서 평면과 직교하는 벡터를 노멀 벡터라고 불렀는데, 둘은 일맥상통한다."
  },
  {
    "objectID": "posts/linear-algebra/2020-12-16-measuring-distance.html#references",
    "href": "posts/linear-algebra/2020-12-16-measuring-distance.html#references",
    "title": "Projection and Distance",
    "section": "References",
    "text": "References\n\nIvan Savov, No bullshit guide to linear algebra 2nd Edition, Minireference, 2017"
  },
  {
    "objectID": "posts/linear-algebra/2021-01-07-linear-transform-matrix.html",
    "href": "posts/linear-algebra/2021-01-07-linear-transform-matrix.html",
    "title": "Matrix as Linear Transformation",
    "section": "",
    "text": "function vs linear transformation\n위의 내용을 이해할 수 있다면, 더 할 것이 없다. 일단 잘 봐두도록 하자. 나중에 돌아와서 음미하면 의미가 와 닿을 것이다.\n선형 변환은 특별한 형태의 함수로 이해할 수 있다. 다만 투입과 산출이 다양한 차원(벡터)을 취할 수 있다. 그리고 이 선형 변환이 매트릭스로 표현될 수 있다. 때문에 매트릭스 표현이 강력하다. 추상적인 선형 변환 함수를 구체적으로 표현하고 쉽게 계산할 수 있게 만드는 것이 매트릭스다."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-07-linear-transform-matrix.html#linear-transformation",
    "href": "posts/linear-algebra/2021-01-07-linear-transform-matrix.html#linear-transformation",
    "title": "Matrix as Linear Transformation",
    "section": "Linear Transformation",
    "text": "Linear Transformation\n\nConcepts\n\n\\(V\\): \\(T\\)의 인풋\n\\(W\\): \\(T\\)의 아웃풋\n\\(T: V \\to W\\): \\(V\\)에서 \\(W\\)로의 선형 변환\n\n\\(T(\\vec v) = \\vec w\\). 즉, \\(\\vec v \\in V\\)를 \\(\\vec w \\in W\\)로 변환하는 것을 나타낸다.\n\n\n\n\n\n함수로서의 행렬\n\n\n 함수와 마찬가지로 위의 선형 변환에서 치역(Im(\\(T\\)))와 커널(스칼라 함수에서는 \\(f(x) = 0\\)의 해)이 정의된다.\n\\[\n{\\rm Im}(T) \\overset{\\rm def}{=} \\{ \\vec w \\in W | \\vec w = T(\\vec v) \\text{ for some } \\vec v \\} \\subseteq W\n\\]\n\\[\n{\\rm Ker}(T) \\overset{\\rm def}{=} \\{ \\vec v \\in V | T(\\vec v) = \\vec 0 \\} \\subseteq V\n\\]"
  },
  {
    "objectID": "posts/linear-algebra/2021-01-07-linear-transform-matrix.html#matrix-representation",
    "href": "posts/linear-algebra/2021-01-07-linear-transform-matrix.html#matrix-representation",
    "title": "Matrix as Linear Transformation",
    "section": "Matrix Representation",
    "text": "Matrix Representation\n인풋, 아웃풋의 기저 벡터를 다음과 같이 두자.\n\\[\nB_V = \\{ \\vec e_1, \\dotsc, \\vec e_n \\}\n\\]\n\\[\nB_W = \\{ \\vec b_1, \\dotsc, \\vec b_m \\}\n\\]\n\n\\(M_T \\in \\mathbb R^{m \\times n}\\)은 선형 변환 \\(T\\)의 매트릭스 표현이다.\n보다 정확하게 표현해보자.\n\n\\[\n\\phantom{}_{B_W}[M]_{B_V}\n\\]\n즉, \\(V\\)의 기저로 표현되는 인풋을 \\(W\\)의 기저로 표현되는 아웃풋으로 바꿔준다."
  },
  {
    "objectID": "posts/linear-algebra/2021-01-07-linear-transform-matrix.html#linearity",
    "href": "posts/linear-algebra/2021-01-07-linear-transform-matrix.html#linearity",
    "title": "Matrix as Linear Transformation",
    "section": "Linearity",
    "text": "Linearity\n선형의 의미는 무엇일까? 기하적으로 선을 다룬다는 뜻이 아니다. 선형의 의미는 함수적인 의미다. 아래 그림을 보자.\n\n\n\n선형 매핑의 의미\n\n\n즉,\n\\[\nT(\\alpha_1 \\vec v_1 + \\alpha_2 \\vec v_2) = \\alpha_1 T(\\vec v_1) + \\alpha_2 T(\\vec v_2) = \\alpha_1 \\vec w_1 + \\alpha_2 \\vec w_2\n\\]"
  },
  {
    "objectID": "posts/linear-algebra/2021-01-07-linear-transform-matrix.html#matrix-as-linear-transformation",
    "href": "posts/linear-algebra/2021-01-07-linear-transform-matrix.html#matrix-as-linear-transformation",
    "title": "Matrix as Linear Transformation",
    "section": "Matrix as Linear Transformation",
    "text": "Matrix as Linear Transformation\n왜 매트릭스가 선형 변환을 나타낼 수 있는지를 좀 더 들여다보자.\n\\[\n\\begin{aligned}\nT(\\vec v)  &=  T(v_1{\\hat e_1} + \\dotsb + v_n{\\hat e_n} ) \\\\\n& =  v_1 T(\\hat e_1) + \\dotsb+ v_n T(\\hat e_n)  \\\\\n& =\n\\begin{bmatrix}\n\\vert & \\vert & \\vert \\\\\nT(\\hat e_1) & \\cdots & T(\\hat e_n) \\\\\n\\vert & \\vert & \\vert\n\\end{bmatrix} \\vec v \\\\\n& = M_T {\\,} \\vec v\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/linear-algebra/2021-01-07-linear-transform-matrix.html#eat-this",
    "href": "posts/linear-algebra/2021-01-07-linear-transform-matrix.html#eat-this",
    "title": "Matrix as Linear Transformation",
    "section": "Eat This!",
    "text": "Eat This!\n\nMapping Spaces\n선형 변환을 다시 적어보자. \\(T: V \\to W\\) where \\({\\rm dim}(W) = m\\), \\({\\rm dim}(V) = n\\). 변환 \\(T\\)는 \\(n\\) 차원의 투입 벡터를 \\(m\\) 차원의 산출 벡터로 바꿔주는 것이다. 우리가 관심이 있는 것은 \\({\\rm dim}(W) \\times {\\rm dim}(V)\\) 의 차원을 지니는 매트릭스 \\(M_T\\)이다.\n\n\n변환임을 강조하기 위해서 \\(M\\)에 하첨자 \\(T\\)를 붙였다.\n먼저 \\(T\\)의 산출부터 따져보자. 산출은 \\(M_T\\)의 열 벡터의 가능한 모든 조합으로 구성된다. 즉, \\(T\\)의 치역 \\({\\rm Im}(T)\\)는 \\(M_T\\)의 컬럼 스페이스다. 즉,\n\\[\n{\\rm Im} (T) = \\lbrace \\vec w \\in W | \\vec w = T(\\vec v), ~ \\text{for some} ~ \\vec v \\in V \\rbrace = \\mathcal C(M_T)\n\\]\n한편 변환 \\(T\\)의 커널(kernel)은 \\(M_T\\)의 널 스페이스를 의미한다. 즉,\n\\[\n{\\rm Ker} (T) = \\lbrace \\vec v \\in V | T(\\vec v) = \\vec 0_{m} \\rbrace = \\lbrace \\vec v \\in V | T(\\vec v) = M_T \\vec v = \\vec 0_m \\rbrace = \\mathcal N(M_T)\n\\]\n이 변환의 투입이 지니는 차원을 생각해보자. \\(n\\) 차원은 로우 공간이 생성하는 \\(\\mathcal R (M_T)\\)와 널 공간으로 가는 \\(\\mathcal N(M_T)\\)으로 나뉘게 된다. 그리고 이 공간은 서로 orthogonal direct sum 관계다. 투입해 해당하는 \\(V\\)의 공간은 다음과 같이 표기할 수 있다.\n\n\ndirect sum의 의미에 대해서 먼저 살펴보자. 만일 \\(V\\) 라는 벡터 스페이스가 서로 선형 독립인 서브 스페이스 \\(V_1, V_2, \\dotsc, V_k\\)를 통해 생성된다고 하자. 이를 표기하면,\n\\[\nW = {\\rm span}(V_1, V_2, \\dotsc, V_k)\n\\]\n로 쓸 수 있다. 이때 \\(V_i\\)가 \\(V\\)의 서브 스페이스인 경우 이를 direct sum으로 표기한다.\n\\[\nW = V_1 \\oplus V_2 \\oplus \\dotsb \\oplus V_k\n\\]\n이때 \\(V_i, V_j\\) for \\(i, j \\in \\lbrace 1, 2, \\dotsc, k \\rbrace\\)가 서로 orthogonal한 것이 orthogonal direct usm이다.\n\\[\nV = \\mathcal R (M_T) \\oplus \\mathcal N (M_T)\n\\]\n앞서의 내용을 두 식으로 압축하면 아래와 같다.\n\\[\nT: \\mathcal R(M_T) \\to \\mathcal C(M_T),~  \nT: \\mathcal N(M) \\to \\{ \\vec 0 \\}\n\\]\n함수처럼 투입 \\(\\vec v \\in \\mathbb R^n\\)을 생성하는 정의역(domain)은 \\(\\mathcal R(M_T)\\)의 선형 결합, 즉 \\(1 \\times n\\)의 벡터 \\(m\\) 개를 선형 결합한 공간으로 이뤄져 있다. 한편 산출 \\(\\vec w \\in \\mathbb R^m\\)을 생성하는 치역(range)은 \\(\\mathcal C(M_T)\\)의 선형 걸합이다. 한편, 투입 \\(\\vec v \\in \\mathcal N(M_T)\\)는 변환을 거쳐서 \\(M_T {\\,}\\vec v = \\vec 0_{m} \\in W\\)로 대응된다.\n\n\n흔히 매트릭스 \\(M_T\\)에서 \\(m \\times n\\)이 크기일 때 앞의 \\(m\\)을 투입 부분의 차원이라고 착각하기 쉽다. 이는 최종 결과물을 떠올리면 쉽니. \\(M_t{\\,}x = y\\)일 떄 산출 벡터 \\(y\\)는 \\({\\rm dim} (y) = m\\)이다. 혼동하지 말자.\n\n\nSurjective and Injective\n\n\n\n전사 함수와 단사 함수\n\n\n함수에서 전사 함수와 단사 함수의 개념을 그대로 적용할 수 있다. 선형 변환 혹은 행렬도 함수다.\n만일, \\(\\vec v_1 \\neq \\vec v_2\\)이고 \\(\\vec v_1, \\vec v_2 \\in \\mathcal R(M_T)\\)라면 이는 선형 변환의 정의에 따라서 서로 다른 \\(\\vec w\\)로 매핑된다. 따라서 만일 단사 변환이 되려면, \\(\\mathcal N(M_T) = \\{ \\vec 0 \\}\\)만 성립하면 된다.\n\\[\nAy - Az = A(y-z)\n\\]\n단사 변환이란 오직 \\(x = y\\)일 때만 \\(Ax = Ay\\)가 성립한다는 뜻이다. 즉 위의 식에서 \\(A(x-y) = 0\\)이 \\(x=y\\)일 때만 성립하면 된다. 즉, \\(A x = 0\\)이 \\(x=0\\)일 때만 성립하면 된다. 전사 변환의 정의는 통상적인 정의, 공역(co-domain)과 치역(range)이 같은 경우에 해당한다. 즉, \\({\\rm Im} (T) = \\mathbb R^m\\).\n매트릭스의 맥락에서 다시 음미해보자. 만일 전사(surjective) 변환이 되려면 \\(n \\geq m\\)이 성립해야 한다. 로우 스페이스의 차원이 컬럼 스페이스보다 커야 컬럼 스페이스 전체를 생성할 수 있다. 반면 단사(injective) 변환이 되려면 \\(n \\leq m\\)이 되어야 한다. 1-1 대응이 가능하려면 컬럼 스페이스의 크기가 로우 스페이스보다 커여 한다.\n따라서 전단사 변환이 되기 위한 조건은 \\(m=n\\)이다. 함수에서 역함수가 존재하려면 전단사 함수여야 한다. 선형 변환도 마찬가지다. 역행렬이 존재하기 위한 필요 조건은 정방 행렬, \\(m=n\\)이다.\n보다 상세한 내용은 여기를 참고하자."
  },
  {
    "objectID": "posts/walk-through/2023-09-21-my-beelink.html",
    "href": "posts/walk-through/2023-09-21-my-beelink.html",
    "title": "소박한 가정용 웹서버",
    "section": "",
    "text": "단순 용도의 개인용 웹 서버를 구축해보자.\n구매부터 기본 세팅까지 개인이 경험한 전 과정을 소개한다. (역시 나중에 잊어버릴 나 놈을 위한 것이다!)\n\n모든 것은 ‘게으른’ 접근이다. 필요한 것을 얻으면 그 이상은 나아가지 않을 것이다."
  },
  {
    "objectID": "posts/walk-through/2023-09-21-my-beelink.html#tl-dr",
    "href": "posts/walk-through/2023-09-21-my-beelink.html#tl-dr",
    "title": "소박한 가정용 웹서버",
    "section": "",
    "text": "단순 용도의 개인용 웹 서버를 구축해보자.\n구매부터 기본 세팅까지 개인이 경험한 전 과정을 소개한다. (역시 나중에 잊어버릴 나 놈을 위한 것이다!)\n\n모든 것은 ‘게으른’ 접근이다. 필요한 것을 얻으면 그 이상은 나아가지 않을 것이다."
  },
  {
    "objectID": "posts/walk-through/2023-09-21-my-beelink.html#넋두리",
    "href": "posts/walk-through/2023-09-21-my-beelink.html#넋두리",
    "title": "소박한 가정용 웹서버",
    "section": "넋두리",
    "text": "넋두리\n“웹 서버”라고 제목에 쓰긴 했지만 사실 단순한 파이썬 앱 호스팅, 토렌트 다운로드, 그리고 DLNA 서버 정도 만드는 것이 전부이다. 본격적인 의미의 NAS를 만드는 것이 아니다. 깃헙과 스트리밍 서비스가 존재하는 시대에 개인용 NAS까지 만들 정도로 보관해야 할 자료가 나에게는 없다."
  },
  {
    "objectID": "posts/walk-through/2023-09-21-my-beelink.html#서버-구매",
    "href": "posts/walk-through/2023-09-21-my-beelink.html#서버-구매",
    "title": "소박한 가정용 웹서버",
    "section": "서버 구매",
    "text": "서버 구매\n목표는 최대한 싸고 간단하게 구축하는 것. 처음에는 라즈베리 파이를 고민했으나 이런 저런 부품을 구비하려면 비용이 꽤 들더라. 이럴 바에야 x86이 낫지 않을까? 알리익스프레스를 검색했다. N95와 같은 준수한 저전력 x86 CPU가 장착된 베이본 물건을 13만원 정도면 살 수 있었다. 윈도 OS도 필요 없고 메모리와 nvme SSD는 이미 굴러다니는 게 있어서 이 녀석을 구매했다. 16GB 메모리는 약 5.5만원 정도, 512GB SSD는 4만원 정도면 구매하니, 대략 베어본 가격에서 10만원 정도 더하면 쓸만한 작은 서버를 갖출 수 있다."
  },
  {
    "objectID": "posts/walk-through/2023-09-21-my-beelink.html#우분투-설치",
    "href": "posts/walk-through/2023-09-21-my-beelink.html#우분투-설치",
    "title": "소박한 가정용 웹서버",
    "section": "우분투 설치",
    "text": "우분투 설치\nUSB 메모리에 다운받아서 설치하면 된다. 부팅 USB를 macos나 윈도에서 편리하게 만들 수 있다. 여기를 참고하자. 설치 과정에서 경험한 몇 가지 사실을 소개한다.\n\n“Ubuntu 22.04.3 LTS” 서버 버전 설치했다. 이 녀석을 통해 GUI를 쓸 일이 없을 듯 하기에 GUI 활용을 위한 데스크탑 앱을 깔지 않았다.\n요즘 버전 우분투 설치시 github을 통해서 ssh 오픈키를 가져올 수 있다. 해당 오픈키의 프라이빗 키가 설정된 노트북에서 바로 서버로 접속이 가능하다.\nOS 설치가 끝난 이후 macos나 윈도가 설치된 기기를 통해 ssh 접속을 통해 작업하기를 권한다. 서버에 디스플레이와 키보드를 붙여서 쓰면 명령어를 모두 타이핑 해야 한다."
  },
  {
    "objectID": "posts/walk-through/2023-09-21-my-beelink.html#설치-후-작업",
    "href": "posts/walk-through/2023-09-21-my-beelink.html#설치-후-작업",
    "title": "소박한 가정용 웹서버",
    "section": "설치 후 작업",
    "text": "설치 후 작업\n우분투 설치 후에는 몇가지 필요한 작업을 해야 한다.\n\n기본 저장소 교체 및 업데이트\napt 패키지 업데이트를 위한 주소는 /etc/apt/sources.list 파일을 편집하면 된다.\n&gt; sudo nano /etc/apt/sources.list\n기본 저장소보다는 카카오의 미러 저장소가 국내에서 빠르다. 해당 파일을 적당한 편집기로 열어 기본 패키지 저장소가 어떻게 되어 있는지 살펴보자. 파일 내의 모든 저장소 URL을 찾아 http://archive.ubuntu.com/ubuntu/ 또는 http://kr.archive.ubuntu.com/ubuntu/ 등의 주소를 http://mirror.kakao.com/ubuntu/로 변경하면 된다. 둘 중 뭘로 되어 있는지 모르니 확인 후 작업하는 것을 권한다. nano 앱에서 crtl-w &gt; crtl-r로 찾아서 바꾸자.\n\n\n패키지 업데이트와 업그레이드\n&gt; sudo apt update \n&gt; sudo apt upgrade # OS 요소까지 모두 업그레이드하려면 upgrade &gt; full-upgrade  \n\n\nzsh 설치\n&gt; sudo apt update # 이미 실행했다면 건너 뛰자 \n&gt; sudo apt install zsh # zsh 설치\n&gt; chsh -s $(which zsh) # zsh을 기본 셸로 설정\n\n# 로그아웃 후에 다시 로그인하면 zsh이 기본셸로 설정된다. \n&gt; sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" # oh my zsh을 설치하자. \n\n\np10k 깔기\n&gt; git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k\n셸 꾸미기로 속 편하게 파워레벨10k를 쓰자.\n&gt; nano ~/.zshrc # zsh 설정 열기 \n# ZSH_THEME=\"robbyrussell\" -&gt; ZSH_THEME=\"powerlevel10k/powerlevel10k\" # 테마를 p10k로 바꾸자 \n변경 후 셸을 다시 시작하면 p10k 설정화면이 뜬다. 취향대로 설정하도록 하자. 설정을 바꾸고 싶다면, p10k configure를 실행하거나 ~/.p10k.zsh를 직접 수정해도 좋다.\n\n\nbrew 설치\n우분투에서 필요한 앱을 까는 방법은 apt, snap 그리고 brew가 있다. OS 단위의 업데이트 혹은 OS와 프로세스과 깊게 연관된 앱들은 apt를 통해서 깔자. snap도 나쁘지는 않지만 거추장스런 면이 있다. user 레벨에서 필요한 앱들을 깔고 관리하기에는 brew가 편하다. macos 만큼 편하지는 않지만 리눅스에서도 쓸만하다.\nhttps://brew.sh/\n웹 페이지의 소개된 방식대로 설치하자. 설치 후에는 화면에 뜬 메시지대로 사후 작업을 꼭 해줘야 한다. 그래야 brew 명령어를 제대로 실행할 수 있다. 사용하는 셸에 따라서 서로 다른 사후 실행 명령이 등장하니 유의하시라.\n\n\ngh, pixi with brew\n이제 brew를 통해서 필요한 앱들을 깔겠다. 필요한 앱을 알아서 깔면 된다. brew를 통해서 설치할 수 있는지 여부는 brew 홈페이지에서 검색으로 확인할 수 있다. 나는 깃헙을 활용하기 위한 gh와 파이썬 의존성 관리도구인 pixi를 가장 먼저 설치했다.\n&gt; brew install gh, pixi \ngh를 설치한 후 gh auth login을 통해 깃헙 계정에 로그인을 해두자. 필요한 리포가 있을 경우 gh repo clone {리포-주소}를 통해 편하게 당겨올 수 있다.\n\n\nstreamlit\n이 소박한 가정용 서버의 목적이 streamlit을 호스팅하기 위한 것이다. 외부 클라우드 컴퓨팅을 사용하면 허름한 것을 쓰더라도 월 만원 정도 나간다. 스트림릿에서 제공하는 무료 티어를 쓸 수도 있지만, 이 녀석은 자주 쓰지 않는 경우 파킹에 들어가기 때문에 사용성이 아주 좋지는 않다. 우분투 깔아서 직접 호스팅하는 편이 소박한 용도라도 제법 편리하다. 앞서 보았듯이 서버 가격이 비싸지 않으며 전기 요금도 얼마 되지 않는다.\n\n설치와 서비스\n\npixi를 통해서 streamlit을 설치한다.\n프로세스를 계속 살려두기 위해서 tmux를 활용하자.\n\ntmux세션을 만든 후에\n해당 세션에서 streamlit 프로세스를 띄우고\n디태치해서 빠져 나온다.\n\n\n&gt; tmux new-session -s {내-세션} # {내-세션}이라는 이름의 새로운 세션 시작 \n&gt; pixi run streamlit {당신의-앱.py} --server.port 8880 # 서버 포트는 필요한 경우 추가 \n&gt; [CTRL-B] + D 로 창을 빠져 나온다. \n#\n&gt; tmux ls # tmux 세션 조회 \n&gt; tmux attach -t {내-세션} # 세션 진입하기 \n\n호스팅 주소가 있다면 해당 서비스의 네임서버에서 A 방식으로 IP 주소를 적어주면 된다. 회사에 따라서는 열어 놓은 포트를 제한하는 곳이 있다. 위에서 스트림릿의 --server.port 옵션은 이를 처리하기 위한 것이다.\n\n\n\nCloudflare를 예로 들어보자. http와 https 별로 특정한 포트가 열려 있다(LINK).해당 포트로만 접근이 가능하다. IP 주소를 감추기 위해 다음과 같은 우회로를 쓸 수 있다. A 호스트네임을 IP 주소와 연동하고 proxy를 켠다. 필요한 서비스에 접속하기 위해서는 A:8880이런 식으로 도메인네임으로 접근하면 된다. 만일 8880을 기억하기 싫다면? CNAME으로 B 호스트네임을 자체 도메인으로 연동한다. 그리고 Rule의 리디렉션 룰을 생성해서 B 호스트네임을 A:8880으로 리디렉션하면 된다."
  },
  {
    "objectID": "posts/walk-through/2023-09-21-my-beelink.html#토렌트-서버",
    "href": "posts/walk-through/2023-09-21-my-beelink.html#토렌트-서버",
    "title": "소박한 가정용 웹서버",
    "section": "토렌트 서버",
    "text": "토렌트 서버\n트랜스미션을 설치할 것이다. 자체적인 웹 인터페이스를 갖고 있어서 서버 버전 용도로 적합하다. 전반적인 설치는 아래 지침을 따르자.\nhttps://hyperhand.tistory.com/entry/우분투에-토렌트-설치\n\n몇 가지 팁\n\n설정을 바꿀 때에는 반드시 서비스를 멈춘 상태에서 진행하도록 하자.\n유저 anari를 가정한 상태에서 이 아래 폴더에 다운로드된 결과를 넣고 싶다고 하자.\\home\\anari\\downloads라고 하자.\n이때 다운로드 파일을 넣고 싶은 폴더는 anari 그룹 안에 속해 있고 이용자는 debian-transmission이다.\n이 경우 anari 그룹 안에 debian-transmission이라는 이용자를 추가하면 권한 문제가 해결된다.\n\n&gt; cat \\etc\\group # 그룹 내역 및 소속 확인하기 \n&gt; sudo usermod -aG anari debian-transmission # anari 그룹 안에 debian-transmission 이용자 추가하기"
  },
  {
    "objectID": "posts/walk-through/2023-09-21-my-beelink.html#dlna-서버",
    "href": "posts/walk-through/2023-09-21-my-beelink.html#dlna-서버",
    "title": "소박한 가정용 웹서버",
    "section": "DLNA 서버",
    "text": "DLNA 서버\n본격적인 활용을 위해서는 Plex 등을 설치하는 게 좋겠지만, 스마트 티비 앱에 영상 정도 전송하는 것이 목적이라면 DLNA 서버만 있으면 된다. 이 용도에 딱 적합한 것이 minidlna다.\nhttps://www.nemonein.xyz/2020/09/4403/\n\n몇 가지 팁\n\n위 설정에 소개된 대로 미디어를 스트리밍할 폴더를 설정해주면 된다.\n만일 내가 전송할 폴더의 위치가 anari 그룹에 속해있다면 마찬가지로 minidlna 유저를 이 그룹에 넣어주면 되겠다.\n\n&gt; sudo usermod -aG anari minidlna # 유저 추가하기\n&gt; sudo systemctl restart minidlna.service # 서비스 재개 \n서비스를 멈추고 설정을 바꾸는 게 좋다. restart 부분을 start, stop 등으로 응용하면 된다."
  },
  {
    "objectID": "posts/container/2020-09-23-docker-humble-practice.html#사전-전제",
    "href": "posts/container/2020-09-23-docker-humble-practice.html#사전-전제",
    "title": "Docker, 소박한 사용법",
    "section": "사전 전제",
    "text": "사전 전제\n\n도커에 관해서 대충 알고 있다.\n도커를 써보기는 했헀다. 하지만… (막상 쓰려면…)"
  },
  {
    "objectID": "posts/container/2020-09-23-docker-humble-practice.html#내가-도커를-쓰는-이유",
    "href": "posts/container/2020-09-23-docker-humble-practice.html#내가-도커를-쓰는-이유",
    "title": "Docker, 소박한 사용법",
    "section": "내가 도커를 쓰는 이유",
    "text": "내가 도커를 쓰는 이유\n\n(사실 있어 보이고 싶어서…)\n개발 환경의 격리고립 및 일관된 환경 공유를 위해서공유를 위한 사전 작업\n가끔 리눅스 환경에서만 구현할 수 있는 파이썬 패키지들이 있다.\n윈도에서 한번은 마주하게 되는 (지긋지긋한) 한글 인코딩 이슈에서 해방"
  },
  {
    "objectID": "posts/container/2020-09-23-docker-humble-practice.html#원칙",
    "href": "posts/container/2020-09-23-docker-humble-practice.html#원칙",
    "title": "Docker, 소박한 사용법",
    "section": "원칙",
    "text": "원칙\n우선 문과생이 도커(docker) 이미지를 쓰는 원칙 하나 보고 가자.\n본인에게 특화된 이미지를 빌드하지 말고 그냥 official build를 당겨와서 쓰자!\n도커의 장점이 개발환경의 격리다. 그렇다면 자신에게 적합한 환경을 세팅해두고 이 녀석을 끌어와 쓰면 좋지 않을까? 약간의 취향과 사용성의 차이를 감안하고 말하자면, 커스텀 이미지는 되도록 피하는게 좋다. 도커 허브에서 공식적으로 관리되고 업데이트되는 도커 이미지들이 많다. 문과생이 쓰는 환경에서 99%의 확률로 여기서 부족함이 없을 것 같다.\n내가 쓰는 특정 환경을 특정 시점에 이미지로 말아두었다고 치자. 당분간은 편리하게 필요할 때 끌어다 쓸 수 있을 것이다. 하지만 이렇게 ‘고정된’ 이미지를 쓸 경우 도커 이미지 안에 속한 패키지나 구성요소들을 개별적으로 업데이트 해줘야 한다. 시간이 지날수록 업데이트해야 할 항목과 갯수가 늘어나게 된다.\n한편 도커 허브의 공식 이미지의 경우 필요한 업데이트를 이미지 관리자가 정기적으로 수행한다. 이 이미지를 주기적으로 새로 끌어다쓰면 업데이트의 번거로움을 피할 수 있다. 물론 팀별로 통일된 환경이 필요하고 이 환경을 조직에서 관리할 수 있다면,Finding Giants in Docker\n도커를 써봤다면 빌드를 해봤을 것이다. 여러가지 바탕이 되는 OS나 패키지들을 끌어와서 자신에게 특화된 이미패키지를 만들어 써도 좋을 것이다.\n파이썬으로 코딩을 하고 주피터 환경을 쓰고 싶다면, 주피터에서 공식적으로 운영하는 도커 이미지를 쓰자. R과 RStudio를 쓰고 싶다면, 역시 rocker라는 공식적인 도커 프로젝트가 있다. 개인이 제조한 사설 이미지 보다는 이런 공식 이미지가 대체로 편안하다.\n\nhttps://hub.docker.com/r/jupyter/datascience-notebook\nhttps://hub.docker.com/r/rocker/rstudio\n\n이하에서는 내가 기본으로 사용하는 두 개의 도커 환경, 주피터 + 파이썬, RStudio + R을 어떻게 쓰는지 살펴 보겠다."
  },
  {
    "objectID": "posts/container/2020-09-23-docker-humble-practice.html#미리-해야-할-것들",
    "href": "posts/container/2020-09-23-docker-humble-practice.html#미리-해야-할-것들",
    "title": "Docker, 소박한 사용법",
    "section": "미리 해야 할 것들",
    "text": "미리 해야 할 것들\n\n원도10 2004 Build 이후 WSL 2 환경\nWSL 2가 깔리는 윈도10 버전으로 업데이트하고 이를 설치하도록 하자. 시중에 가이드가 많으니 구글 검색 후 참고하면 되겠다.\n\nMS 공식 가이드\n\n\n\nDocker Desktop (윈도10)\n네이티브 우분투 환경이라면 sudo apt-get으로 도커를 설치해서 쓰면 된다. 우리는 윈도10과 리눅스를 오가야 하므로, 이에 적합한 맞춤형 도커 버전이 좋다. 다행스럽게 도커 개발사가 WSL 2에 특화된 도커 클라이언트를 제공하고 있다. 보다 안정적인 버전인 Stable과 보다 최신 기능을 담은 버전인 Edge 모두 WSL 2 지원한다.\n\nDocker Desktop for WIndows\n\n\n\nWindows Terminal\n반드시 써야 하는 것은 아니다. 하지만 윈도10에서 리눅스 배포판을 윈도 터미널과 함께 쓰면 더할 나위 없이 좋다. 무엇보다도 별다른 조작 없이 우분투 등 WSL 2에 깔린 리눅스를 터미널이 잘 잡아준다. 다음으로 터미널 환경(폰트, 컬러 등등) 커스터마이즈가 쉽다.\n\nMS 공식 가이드"
  },
  {
    "objectID": "posts/container/2020-09-23-docker-humble-practice.html#내-환경",
    "href": "posts/container/2020-09-23-docker-humble-practice.html#내-환경",
    "title": "Docker, 소박한 사용법",
    "section": "내 환경",
    "text": "내 환경\n이 글을 쓰는 시점에서 내가 도커를 이용하는 환경은 아래와 같다.\n\nWindows 10 Insider Preview 20190.rs\nDocker Desktop Edge 2.3.7.0\nWindows Terminal Preview 1.3\n\n\nComments\n\n윈도우10 20190.rs 버전은 인사이드 프리뷰 버전이다. 프리뷰 버전을 꼭 쓰지 않아도 된다. 202XXX 버전을 쓸 것이라면 20226 이후를 써야 한다.\n도커 버전은 최신 버전을 유지하는 편을 권한다. Edge가 불안하다면 Stable을 쓰면 된다."
  },
  {
    "objectID": "posts/container/2020-09-23-docker-humble-practice.html#docker-compose",
    "href": "posts/container/2020-09-23-docker-humble-practice.html#docker-compose",
    "title": "Docker, 소박한 사용법",
    "section": "Docker Compose",
    "text": "Docker Compose\n도커를 써본 사람이라면 개별 컨테이너를 띄울 때 옵션들–예를 들어 root 권한을 줄 건지, 포트는 어떤 것을 열 것인지 등등–을 써봤을 것이다. 일상적으로 쓸 때에도 이것들을 매번 지정해서 실행해야 할까? 그렇게 해도 되겠지만 조금 불편하다. 한번 정해두고 재사용할 수 있으면 좋겠다. 이러한 용도에 적합한 것이 ’도커 콤포즈’다.\n.yml 확장자의 설정 파일을 만들어 두고 녀석을 실행해서 매번 동일한 환경을 손쉽게 구축할 수 있다. 내가 쓰는 .yml 환경으로 간략하게 살펴보자.\nversion: '3'\nservices:\n    jupyter-ds:\n        image: jupyter/datascience-notebook\n        user: root\n        volumes:\n            - [WSL2 디렉토리]:[컨테이너 디렉토리]\n        ports:\n            - \"8888:8888\"\n            - \"8501-8510:8501-8510\"   \n        environment:\n           - GRANT_SUDO=yes\n           - JUPYTER_ENABLE_LAB=yes\n           - JUPYTER_TOKEN=[내 비번]\n        container_name: jupyter\n#\n    rstudio:\n        image: rocker/verse:latest\n        #image: rocker/verse:4.0.2\n        volumes:\n            - [WSL2 디렉토리]:[컨테이너 디렉토리]\n        ports:\n            - \"8787:8787\"\n        environment:\n            - ROOT=true\n            - PASSWORD=[내 비번]\n        container_name: rstudio\n# End of yml\nyml 파일에서 service 아래 두 개의 항목이 있다. 각각 jupyter/datasicence-notebook과 rocker/verse의 컨테이터 이미지를 의미한다. 첫번째는 데이터를 다룰 때 필요한 파이썬 라이브러리를 주피터와 묶은 이미지이고, 두번째는 R과 RStudio 그리고 tidyverse 및 문서 도구를 묶은 이미지다.\n\nimage: docker-hub 상의 이미지 이름을 뜻한다. : 뒤의 내용은 버전 혹은 여러가지 다른 형태로 묶인 이미지를 나타낸다. latest 최신 버전을 의미한다.\nvolume: WSL 2 환경의 디렉토리와 이미지 내 디렉토리를 매핑한다. 즉, X : Y라고 할 때 X는 윈도우 10의 폴더, Y는 도커 이미지 내의 폴더 이름을 뜻한다. WSL 2는 /mnt 내에 윈도 드라이브를 마운트한다. 따라서 윈도10 환경과 연동된다고 보면 얼추 맞다.\nports: WSL 2에서 인식하는 포트와 이미지 내에서 인식하는 포트를 매핑한다.\nenvironment: 각각 이미지에 맞는 환경을 지정할 수 있다. 이 사례에서 주피터 노트북에는 sudo 권한을 주고, 주피터랩 버전을 쓰며, 최초 진입시 비번은 [내 비번]을 쓰겠다고 지정한 것이다. RStudio의 경우 root 권한을 주고, 패스워드는 내 비번을 쓰겠다는 의미다.\n\n\n통상적으로 쓰려면 docker-compose.yml로 이름을 지은 후 적당한 폴더에 둔다.\n윈도 터미널 등을 통해 Ubuntu와 같은 리눅스 배포판에 접근한다.\n1의 파일이 있는 디렉토리로 이동한 후,\n\nsudo docker-compose -f \"\\mnt\\[YOUR-YML-DIRECTORY]\" -p \"[NAME-OF-PROJECT]\" up -d\n그러면 도커 컴포즈가 알아서 이미지를 끌어온 후 실행까지 할 것이다.\n주의사항 하나 지적하자. docker-compose를 -f 옵션 없이 실행하면 녀석은 HOME 디렉토리에서 해당 파일을 찾는다. WSL 기준에서 볼 때 홈 디렉토리는 윈도의 사용자-계정 디렉토리다. 해당 디렉토리에 docker-compose.yml 파일이 있으면 녀석으로 실행할 것이다. 이렇게 써도 문제는 없지만 yml을 계속 바꿔줘야 할 경우 이는 문제를 일으킬 수 있다. 가급적 yml 파일을 지정해서 활용하는 습관을 들이도록 하자.\n\n도커 컴포즈 공식 가이드"
  },
  {
    "objectID": "posts/container/2020-09-23-docker-humble-practice.html#실제-사용해보자",
    "href": "posts/container/2020-09-23-docker-humble-practice.html#실제-사용해보자",
    "title": "Docker, 소박한 사용법",
    "section": "실제 사용해보자",
    "text": "실제 사용해보자\n앞서 말했듯이 수 있다! 처음에는 이 개념이 환상적일 수 있다. 게다가 개인용 저장소만 만들지 않으면 도커허브에 그냥 올릴 수 있다. 하지만 이런 접근은 본인이 특화된 용도로 사용을 하거나 아니면 패키지 제조에 능숙하지 않다면 크게 권하고 싶지 않다. 당분간 별 문제가 없더라도 언젠가는 이상하게 탈이 난다.\n다행스럽게 도커 허브에서는 여러가지 공식적으로 관리되고 업데이트되는 도커 이미지들이 많이 올라와 있다. 문과생이라면되도록 초반에는 이런 이미지들을 취사선택해서 활용하는 편을 권장한다. 주피터든 RStudio든 모두 웹 브라우저에서 돌아간다. 이미지가 도커 컨테이터로 구동된 이후 범용 웹브라우저에서 다음과 같이 실행하자.\n\nJuypterlab + Python: localhost:8888\nRStudio + R: localhost:8787\n\n주피터야 원래부터 웹 브라우저 기반이었으니 보통 깔아 쓰는 것과 차이를 느낄 수 없다.\n\nRStudio도 그럴까? 그렇다. 원래 RStudio라는 IDE가 웹 기반으로 만들어졌기 때문에 이 역시 차이를 느낄 수 없다. 아래 화면에서 로그인을 하면 친숙한 RStudio의 화면이 뜬다.\n\n\n해당 페이지 아이콘을 바탕화면 혹은 바로가기에 두고 쓰면 조금 편리 하겠다.\n\n특화된 패키지 혹은 설정이 필요하다면?\n그때그때 깔면 된다. 원 도커 이미지에서 웬만해서는 더 깔 것이 없을 것이다. 필요한 경우가 있다면 bash script를 만들어 깔아주도록 하자. 해당 이미지를 내리지 않는 이상 한번 설치한 상태는 유효하다.\n\n\n도커 이미지 관리\n이미지를 업데이트하고 싶다면 어떻게 해야 할까? 정석대로 하자면, WSL 2 콘솔창에서 실행중인 컨테이너를 멈추고, 이 컨테이너의 이미지를 지워야 할 것이다. 그렇게 해도 되지만, 윈도용 도커 프로그램에서는 보다 간편한 방법을 제공한다.\n대시보드 상에서 컨테이너를 실행하고 멈출 수 있고 이미지도 관리할 수 있다.\n\n아예 해당 이미지 및 컨테이너 데이터 전체를 리셋하는 방법도 있다.\n\n예를 들어보자. 파이썬으로 코딩을 한다면 그리고 주피터 환경을 써야 한다면 어떻게 하는 것이 좋을까? 주피터에서 공식적으로 운영하는 도커 이미지가 있다. 도커로 R을 쓰고 싶다면? 역시 rocker라는 공식적인 프로젝트가 있다. 개인이 제조한 사설 이미지보다는 이런 녀석들을 끌어다쓰는 편이 좋다.\n이하에서는 내가 기본으로 사용하는 두 개의 이미지를 바탕에 깔고 설명을 진행하도록 하겠다."
  },
  {
    "objectID": "posts/container/2021-05-09-docker_korfont.html",
    "href": "posts/container/2021-05-09-docker_korfont.html",
    "title": "Docker + Jupyter + 한글 폰트",
    "section": "",
    "text": "koreanize-matplotlib\n\n\n\nmatplotlib에서 한글을 쓸 때 문제가 없도록 하는 패키지가 등장했다. 개발자 분에게 무한 감사를 표하면서 repo를 깔아 쓰도록 하자."
  },
  {
    "objectID": "posts/container/2021-05-09-docker_korfont.html#build도-어렵지-않다",
    "href": "posts/container/2021-05-09-docker_korfont.html#build도-어렵지-않다",
    "title": "Docker + Jupyter + 한글 폰트",
    "section": "Build도 어렵지 않다!",
    "text": "Build도 어렵지 않다!\n이 글은 이 포스팅에서 이어진다. 컨테이너를 올린 뒤 컨테이너 내 터미널에서 sh 스크립트를 실행하지 않고 한글 문제 처음부터 해결할 수 없을까?\n사실 이 포스팅을 쓰게 된 동기는 따로 있다. 글을 쓰는 시점에서 matplotlib.font_manager._rebuild()가 사라졌다! Jupyter에서 폰트 목록을 다시 생성할 다른 방법을 찾아야 했다. docker-compose로 필요한 이미지를 끌어올 때 단순히 이미지를 끌어오는 대신 특화된 형태로 build를 할 수도 있다. 이전 포스팅에서 소개한 방법에서는 build 옵션을 사용하지 않았다. 일단 Build가 꽤 거창하게 느껴졌기 때문이다. 적당한 ubuntu 버전을 끌어오고 여기에 Python, Jupyter를 깔고… 이런 빌드 과정이 꽤 험난하고 불필요해 보였다. Jupyter의 경우 데이터사이언스를 위한 잘 갖춰진 도커 이미지가 이미 있고, 이를 그대로 쓰면 큰 문제는 없다.\n문제가 생겼으니 해결책을 찾아야 한다. 특화된 이미지에 기반해서 빌드를 하면 한글 문제와 같은 특정하게 발생하는 문제를 미리 해결할 수 있지 않을까? 이후 소개하는 방법을 통해 확인한 내용은 다음과 같다. 이용 조건이 비슷하다면 참고해보시라.\n\ndocker-compose를 쓸 때 이미지를 지정하는 image 부분을 제외한 나머지는 거의 그대로 재사용이 가능하다.\nimage를 그대로 끌어오는 것이나 몇 가지 명령어를 넣어서 build를 하는 것이나 시간 상으로는 크게 차이가 없다."
  },
  {
    "objectID": "posts/container/2021-05-09-docker_korfont.html#how-to-implement",
    "href": "posts/container/2021-05-09-docker_korfont.html#how-to-implement",
    "title": "Docker + Jupyter + 한글 폰트",
    "section": "How to Implement",
    "text": "How to Implement\n본론이다.\n\ndocker-compose를 위한 file이 있는 디렉토리 아래 dockerfiles 디렉토리를 하나 더 만든다 (디렉토리 이름은 각자 알아서). 여기에 docker build를 위한 파일을 넣어어둔다.\ndocker-compose용 파일을 약간 수정한다.\n\n\n실행 환경\n\nWindows 10 WSL 2 + Ubuntu 20.04\nDocker for Desktop (Windows)\n\n\n도커를 쓰지 않더라도 dockerfiles과 호환되는 빌드 체계를 갖추고 있다면 응용이 가능하다.\n\n\n\ndockerfiles\n데이터 사이언스를 위한 Jupyter docker 파일을 예시로 들겠다. 다른 이미지라면 응용해서 쓰면 된다.\nFROM jupyter/datascience-notebook:latest\n# Declare root as user \nUSER root\n# Update Ubuntu \nRUN sed -i 's/archive.ubuntu.com/mirror.kakao.com/g' /etc/apt/sources.list && sed -i 's/security.ubuntu.com/mirror.kakao.com/g' /etc/apt/sources.list\n# Install Nanum for Korean Font \nRUN apt-get update && apt-get -y upgrade && apt-get install -y fonts-nanum* && fc-cache -fv && rm -fr ~/.cache/matplotlib\n\nFROM jupyter/datascience-notebook:latest 끌어올 이미지를 지정한다.\nUSER root 이미지 내에서 root 권한을 부여한다. 이후 sudo는 안 써도 된다.\nRUN sed -i... 끌어온 우분투 이미지가 미국 기준이기 때문에 업데이트 서버 주소 역시 미국이다. 이걸 국내에서 가장 안정적이고 빠른 카카오 서버로 바꾼다.\nRUN apt-get update && apt-get -y upgrade...\n\n우분투 배포판의 업데이트 및 업그레이드를 실행한다.\n\n나눔 폰트를 깔아준다.\ndocker 이미지 배포판의 폰트 캐시를 지운다.\nJupyter의 폰트 캐시를 지운다.\n\n\n\n\ndocker-compose.yml\ndocker-compose를 위한 yml을 예시한다. 이 내용 역시 각자 환경에 맞게 변형해서 쓰면 된다. 파일 이름을 “docker-jupyter.yml”이라고 하자.\nversion: '3'\n#\nservices:\n#\n    jupyter-ds:\n      build:\n        context: .\n        dockerfile: ./dockerfiles/dockerfile-jupyter\n      user: root\n      environment:\n        - GRANT_SUDO=yes\n        - JUPYTER_ENABLE_LAB=yes\n        - JUPYTER_TOKEN={YOUR-PASSWORD}\n      volumes:\n        - /mnt/c/Users/{YOUR-DIR}:/home/jovyan/github-anari\n      ports:\n        - \"8888:8888\"\n      container_name: \"jupyter-ds\"\n# End of yml\n\n위의 yml 파일에서 “{}”로 처리된 부분은 각자 채워 넣으면 된다.\nimage 대신 build 명령어를 사용했다. 앞서 지정한 dockerfiles 디렉토리 내의 도커 명령어를 통해 빌드를 수행한다. 이렇게 빌드된 이미지는 처음부터 matplotlib 사용 시 한글 구현에 아무런 문제가 없다.\n\n주피터 환경의 파이썬 그리고 주피터 혹은 R스튜디오 환경의 R에서 한글 설정 방법 및 간단한 테스트는 여기를 참고하자.\n도커 컴포즈를 실행하는 방법은 아래와 같다.\n$ sudo docker-compose -f /mnt/{YOUR DIR}/docker-jupyter.yml -p \"jupyter-ds\" up -d\n실행 옵션은 다음과 같다. 역시 “{}”는 각자의 환경에 맞게 바꾸면 된다.\n\n-f 도커 콤포즈를 특정 파일로 실행하기 위한 옵션이다. 만일 이를 안쓰려면 yml 파일의 이름을 docker-compose.yml로 두고 해당 디렉토리 안에서 실행하면 된다.\n-p 콤포즈 안에 묶인 서비스의 이름을 나타낸다. 같은 네트워크로 묶이며 이 이름을 네트워크 이름으로 갖는다.\nup yml 내에 있는 포함된 콘테이너를 가동한다.\n-d 디태치 모드, 즉 별도의 실행되는 과정으로 실행한다."
  },
  {
    "objectID": "posts/the-lectures/2024-02-16-statquest-attention.html",
    "href": "posts/the-lectures/2024-02-16-statquest-attention.html",
    "title": "Attention Model",
    "section": "",
    "text": "어텐션을 반영하는 하나의 방법을 살펴보자."
  },
  {
    "objectID": "posts/the-lectures/2024-02-16-statquest-attention.html#tl-dr",
    "href": "posts/the-lectures/2024-02-16-statquest-attention.html#tl-dr",
    "title": "Attention Model",
    "section": "",
    "text": "어텐션을 반영하는 하나의 방법을 살펴보자."
  },
  {
    "objectID": "posts/the-lectures/2024-02-16-statquest-attention.html#넋두리",
    "href": "posts/the-lectures/2024-02-16-statquest-attention.html#넋두리",
    "title": "Attention Model",
    "section": "넋두리",
    "text": "넋두리\nLSTM은 단기와 장기의 기억을 나눠서 전달함으로써 RNN이 지는 문제점을 극복하고자 했다. 하지만 여전히 남는 문제가 있었으니, 언어에 따라서 혹은 표현에 따라서 거리가 많이 떨어지는 정보값이 중요해지는 경우가 종종 존재한다.\n아래의 그림을 보자.\n\n\n\n\n\n\n\n\n\n맨 앞의 토큰이 문장 전체의 의미에 가장 중요하다.\n\n\n\n\n \n\n\n\n\n\nLSTM의 실패; 인코딩이 길어지면 앞에 정보가 소실될 수 있다.\n\n\n\n\n \n\n\n\n\n\n인코더의 정보를 디코더로 직접 넘겨주면 어떨까?"
  },
  {
    "objectID": "posts/the-lectures/2024-02-16-statquest-attention.html#어텐션이란-무엇인가",
    "href": "posts/the-lectures/2024-02-16-statquest-attention.html#어텐션이란-무엇인가",
    "title": "Attention Model",
    "section": "어텐션이란 무엇인가?",
    "text": "어텐션이란 무엇인가?\n인코더-디코더 모델을 생각해보자. 결국 인코더의 특정 정보와 디코더의 특정 정보가 얼마나 비슷한지가 문제의 핵셤이다. 만일 둘이 비슷하다면 생성에서 이를 더 강하게 반영하는 것이 맞을 것이다. 인코딩에서 강조된 내용이 디코딩에서도 강조되도록 해야 한다.\n핵심은 인코딩과 디코딩 정보의 유사성을 측정하는 데 있다. 측정에는 여러가지 방법이 있을 것인데, 강의에서는 코사인 유사도를 사용한다. 우리는 벡터를 다루고 있고 두 벡터 사이의 비슷한 정도를 측정하는 데에는 코사인 유사도만한 것이 없다.\n\n코사인 유사도 대신 닷 프로덕트\n코사인 유사도의 원래 정의는 다음과 같다. 크기가 같은 벡터 \\(a_i\\), \\(b_i\\)가 있다고 하자.\n\\[\n\\text{Cosine Similarity} = \\dfrac{\\sum_{i=1}^n a_i b_i}{\\sqrt{\\sum_{i=1}^n a_i^2} \\sqrt{\\sum_{i=1}^n b_i^2}}\n\\]\n식에서 분모는 위의 닷 프로덕트(내적)의 크기를 조절해주는 역할이다. 이 덕분에 코사인 유사도는 그 이름에 걸맞게 \\([-1, 1]\\) 사이의 값을 지니게 된다. 스케일링이 필요한 이유는 개별 벡터의 값이 닷 프로덕트에서 지니게 되는 값의 효과를 통제하기 위해서다. 그런데 앞에서 보듯이 LSTM의 경우에는 산출되는 벡터의 값이 \\([-1,1]\\)사이를 벗어날 수 없다. 따라서 분모는 무시하고 분자만 다루도록 하자."
  },
  {
    "objectID": "posts/the-lectures/2024-02-16-statquest-attention.html#어텐션-구현하기",
    "href": "posts/the-lectures/2024-02-16-statquest-attention.html#어텐션-구현하기",
    "title": "Attention Model",
    "section": "어텐션 구현하기",
    "text": "어텐션 구현하기\n아래 왼쪽 그림을 보자. 인코더의 첫번째 셀의 벡터와 디코더의 첫번째 셀의 결과의 코사인 유사도를 먼저 후간다. 같은 방식으로 두번째 셀의 벡터와 디코더의 첫번째 셀의 결과의 코사인 유사도를 구한다.\n오른쪽 그림처럼 이렇게 구한 코사인 유사도가 일정의 어텐션의 지표가 된다.\n\n\n\n\n\n\n\n\n\n어텐션 구현하기 1\n\n\n\n\n \n\n\n\n\n\n어텐션 구현하기 2\n\n\n\n\n\n이제 이렇게 확보된 어텐션 지표가 디코딩에서 직접 활용된다. 해당 지표를 소프트맥스 처리하고 이를 다시 인코더의 정보와 결합한 뒤 스페인 어로 풀어 놓는다. 여기서 소프트맥스 처리된 코사인 유사도는 인코더의 정보를 어느 정도의 비중으로 반영해야 하는지를 결정한다. 물론 앞서와 마찬가지로 &lt;EOS&gt;가 산출될 때까지 이 과정을 반복한다.\n\n\n\n\n\n\n\n\n\n어텐션을 반영한 디코딩 워드 생성 1\n\n\n\n\n \n\n\n\n\n\n어텐션을 반영한 디코딩 워드 생성 2"
  },
  {
    "objectID": "posts/the-lectures/2024-02-16-statquest-attention.html#seq2seq-모델과-비교하기",
    "href": "posts/the-lectures/2024-02-16-statquest-attention.html#seq2seq-모델과-비교하기",
    "title": "Attention Model",
    "section": "Seq2Seq 모델과 비교하기",
    "text": "Seq2Seq 모델과 비교하기\n아래 그림에서 보듯이 Seq2Seq 모델에 비해서 인코딩의 정보가 디코딩에 직접적으로 영향을 끼치는 것을 알 수 있다.\n\n\n\n\n\n\n\n\n\n어텐션을 반영한 인코더-디코더 과정\n\n\n\n\n \n\n\n\n\n\nseq2seq 인코더-디코더 과정\n\n\n\n\n\n\n\n\n맨 앞의 토큰이 문장 전체의 의미에 가장 중요하다.\nLSTM의 실패; 인코딩이 길어지면 앞에 정보가 소실될 수 있다.\n인코더의 정보를 디코더로 직접 넘겨주면 어떨까?\n어텐션 구현하기 1\n어텐션 구현하기 2\n어텐션을 반영한 디코딩 워드 생성 1\n어텐션을 반영한 디코딩 워드 생성 2\n어텐션을 반영한 인코더-디코더 과정\nseq2seq 인코더-디코더 과정"
  },
  {
    "objectID": "posts/the-lectures/2024-02-08-intro-2-llms.html",
    "href": "posts/the-lectures/2024-02-08-intro-2-llms.html",
    "title": "Busy Person’s Intro to LLMs",
    "section": "",
    "text": "LLMs에 관해 안드레이 카파시의 흥미로운 견해를 정리해보자."
  },
  {
    "objectID": "posts/the-lectures/2024-02-08-intro-2-llms.html#tl-dr",
    "href": "posts/the-lectures/2024-02-08-intro-2-llms.html#tl-dr",
    "title": "Busy Person’s Intro to LLMs",
    "section": "",
    "text": "LLMs에 관해 안드레이 카파시의 흥미로운 견해를 정리해보자."
  },
  {
    "objectID": "posts/the-lectures/2024-02-08-intro-2-llms.html#넋두리",
    "href": "posts/the-lectures/2024-02-08-intro-2-llms.html#넋두리",
    "title": "Busy Person’s Intro to LLMs",
    "section": "넋두리",
    "text": "넋두리\nLLMs를 이해하는 방법은 다양하다. 많이 알수록 더 간결하고 적확한 표현을 구사할 수 있다고들 하는데, 카파시의 경우가 그러했다. 인상적인 대목들 몇 가지 정리해 보자."
  },
  {
    "objectID": "posts/the-lectures/2024-02-08-intro-2-llms.html#ted-chiang-a-blurry-jpeg-of-the-web",
    "href": "posts/the-lectures/2024-02-08-intro-2-llms.html#ted-chiang-a-blurry-jpeg-of-the-web",
    "title": "Busy Person’s Intro to LLMs",
    "section": "Ted Chiang, “A Blurry JPEG of the Web”",
    "text": "Ted Chiang, “A Blurry JPEG of the Web”\n\n\n\n\n\n\n \n\n\n\n\n\n테드 창, The New Yorker 기고문\n\n\n\n\n \n\n\n\n테드 창은 chatGPT란 결국 웹의 부정확한 혹은 흐릿한 압축 버전의 무엇에 지나지 않는다는 뜻으로 이 표현을 사용했다. 이 표현이 부정적인 뉘앙스를 지니고 있지만 LLMs에 관한 논의의 좋은 출발점을 제공한다.\n그래서 LLMs을 의심해야 할까? 그렇다. 그리고 거부해야 할까? LLM을 그냥 적당한 사람으로 대체해보자. LLM 정도로 일을 하는 사람을 우리가 “천재”라고 부르지는 않겠지만 그럭저럭 일 잘하는 사람 정도로는 인정할 수 있을 것이다. 적당한 수준에서 잘하는 것을 blurry라고 표현한다면, 그리 부정적인 것은 아닐 수도 있겠다.\n카파시의 LLMs 이해 역시 비슷하다.\n\n\n\n\n\n\n\n\n\n인터넷을 학습한 LLM\n\n\n\n\n \n\n\n\n\n\nLLMs dream\n\n\n\n\n\n상당 기간 동안 검색을 사용해서 이에 익숙해진 어떤 사람이 있다고 하자. 그가 검색을 통해 알게 된 지식이 모두 맞는 것은 아닐 터다. 하지만 확률적으로 다른 보통의 사람보다 그가 낫다면 그의 쓸모는 충분하다. 컴퓨터가 내놓는 무엇이 언제나 정확하리라는 인간적인 편견을 잠시 치우고 생각하면, 사람이 아닌 이런 존재가 있다면 꽤 활용도가 높지 않을까?\n뉴럴넷은 인터넷 문서를 “꿈꾼다.” LLMs에서 생성이라는 말은 사실 “꿈꾸는” 것에 가깝다. “꿈꾼다”라는 표현이 찰지면서도 정확하다. 엄밀히 말하면 뉴럴넷은 문서를 쓰지 않는다. 꿈꾼다. 여느 인간의 꿈처럼 헛소리가 들어갈수도 있고, 정확하지 않을 수도 있다. 하지만 인간에게도 그러하듯이 꿈꾸는 것, 백지 위에 무엇인가를 그려내는 것이란 쉽지 않은 일이다."
  },
  {
    "objectID": "posts/the-lectures/2024-02-08-intro-2-llms.html#human-feedbacks",
    "href": "posts/the-lectures/2024-02-08-intro-2-llms.html#human-feedbacks",
    "title": "Busy Person’s Intro to LLMs",
    "section": "Human Feedbacks",
    "text": "Human Feedbacks\n\n\n\n\n\n\n\n\n\nHuman Assitant\n\n\n\n\n \n\n\n\n\n\nHuman Guidance\n\n\n\n\n\n뉴럴넷은 인간이 원하는대로 움직이지 않는다. 그 내부의 작동 원리를 온전하게 모른다는 점에서 뉴럴넷은 그 발상을 복제한 인간의 뇌와 꽤 비슷하다. 인간의 아이를 학습시키는 과정을 떠올려보자. 뭔가 가르치고 싶은 것이 있다면 부모가 해당 내용을 밖에서 계속해서 주입한다. 이 작업이 뉴럴넷에 인간의 손길을 더해주는, 즉 양육의 과정이다.\n카파시는 크게 두 가지를 제시한다. 하나는 ’보조 모델(assistant model)’을 인간이 만들고 이 내용을 뉴럴넷 안에 바꿔 끼워넣는 것이다. 두번째는 LLMs가 꿈꾼 여러 답들을 인간이 비교해서 더 나아보이는 것을 알려주는 것이다.\n첫번째 과정이 프리트레인 모델을 얻는 과정이라면 두 번째가 이른바 미세 조정(fine-tuning)이다. 첫번째가 거의 순수한 엔지니어링의 영역이라면 두번째는 ‘소셜’ 엔지니어링의 영역이다. 오늘날 chatGPT의 성공에는 GPU를 활용한 대규모 학습을 가능하게 한 첫번째 영역의 공로 만큼 두 번째 영역의 공로도 크다. 어쩌면 미세 조정의 영역이 각 모델을 내놓는 회사들의 숨은 역량이 발휘되는 곳일지도 모른다.\n\n\n\n\n\n\n \n\n\n\n\n\ntraining of LLM"
  },
  {
    "objectID": "posts/the-lectures/2024-02-08-intro-2-llms.html#system-i-and-ii-for-llms",
    "href": "posts/the-lectures/2024-02-08-intro-2-llms.html#system-i-and-ii-for-llms",
    "title": "Busy Person’s Intro to LLMs",
    "section": "System I and II for LLMs?",
    "text": "System I and II for LLMs?\n카파시는 인공 지능의 미래에 관해서 여러가지 언급을 하고 있다. 다양한 입력 형태(멀티모달)을 받을 수 있게 진화하고 있으며 이는 가속될 것, 그리고 마지막에 꽤 길게 LLMs 보안에 관해 논하고 있다. 보안에 관한 내용이 흥미롭기는 하다. LLM을 해킹하는 방법은 기술적인 것을 뛰어넘는다. 마치 해커들이 서버나 서비스를 해킹할 때 순수한 네트워크 기술 넘머의 소셜 엔지니어링을 활용한 것과 유사하다.\n\n\n\n\n\n\n\n\n\nSystem I\n\n\n\n\n \n\n\n\n\n\nSystem II\n\n\n\n\n\n무튼 미래에 관한 논의에서 내가 제일 놀란 것은 것은 시스템1, 시스템2에 관한 언급이다. 시스템1, 시스템2는 다니엘 카너만의 책에서 나온 개념이다. 시스템1은 빠르고 직관적인 판단을 내리는 것이고 시스템2는 느리고 논리적인 판단을 내리는 것이다. 카파시는 LLM이 시스템1이라고 말했다.\n인공지능이 시스템1이라고? 디지털을 통해 산출된 결과물이 시스템1이라는 발상은 언뜻 와닿지 않지만, 생각해보면 이 말이 맞다! 앞서 LLMs가 꿈꾸는 것이라고 했는데, 꿈은 시스템1의 영역이다. 시스템2는 논리적인 추론을 하는 영역이다. LLMs가 시스템1이라면, LLMs와 어울리는 시스템2는 무엇일까? 아직 미지의 영역이다. 컴퓨팅 자원을 더 소모하고 결과를 얻는데 더 시간이 걸리더라도 이 개념이 만들어지면 LLMs에 또다른 도약이 있지 않을까 한다.\n\n\n\n\n\n\n\n\n\nLLM is System I\n\n\n\n\n \n\n\n\n\n\nLLM as System II?\n\n\n\n\n\n시스템2를 갖춘 LLM이 있다면 맞든 틀리든 녀석의 인과적인 추론의 과정을 뜯어볼 수 있었을 것이다. 이게 가능했다면 보다 정확하고 처방적인 대응을 내놓는 LLM을 만들어 낼 수 있지 않을까?\n이외에 인간 기보에서 배운 초기 알파고 이후에 등장한 스스로 배우는 알파고에 해당하는 LLM 모델에 관한 질문, LLM 중심의 OS 등 흥미로운 슬라이드 샷을 몇 개 덧붙이겠다.\n\n\n\n\n\n\n\n\n\nLLM version of Alpha Go Zero\n\n\n\n\n \n\n\n\n\n\nLLM OS\n\n\n\n\n\n\n\n\n테드 창, The New Yorker 기고문\n인터넷을 학습한 LLM\nLLMs dream\nHuman Assitant\nHuman Guidance\ntraining of LLM\nSystem I\nSystem II\nLLM is System I\nLLM as System II?\nLLM version of Alpha Go Zero\nLLM OS"
  },
  {
    "objectID": "posts/the-lectures/2024-02-15-statquest-seq2seq.html",
    "href": "posts/the-lectures/2024-02-15-statquest-seq2seq.html",
    "title": "Sequence to Sequence Model",
    "section": "",
    "text": "생성형 모델의 원조 같은 seq2seq 모델을 배워보자."
  },
  {
    "objectID": "posts/the-lectures/2024-02-15-statquest-seq2seq.html#tl-dr",
    "href": "posts/the-lectures/2024-02-15-statquest-seq2seq.html#tl-dr",
    "title": "Sequence to Sequence Model",
    "section": "",
    "text": "생성형 모델의 원조 같은 seq2seq 모델을 배워보자."
  },
  {
    "objectID": "posts/the-lectures/2024-02-15-statquest-seq2seq.html#넋두리",
    "href": "posts/the-lectures/2024-02-15-statquest-seq2seq.html#넋두리",
    "title": "Sequence to Sequence Model",
    "section": "넋두리",
    "text": "넋두리\n비로소 (트랜스포머까지 이르는) ’목전’까지 온 느낌이다. Seq2Seq 모델은 이쪽의 정보를 압축해서 저쪽에 보내고 이를 다시 저쪽의 맥락에서 풀어내는 것을 의미한다. 전형적으로 ’번역’을 생각하면 되겠다. 강의 역시 영어 “Let’s go!”를 스페인어 “Vamos!”로 번역하는 과정을 예시로 들고 있다."
  },
  {
    "objectID": "posts/the-lectures/2024-02-15-statquest-seq2seq.html#context-vector",
    "href": "posts/the-lectures/2024-02-15-statquest-seq2seq.html#context-vector",
    "title": "Sequence to Sequence Model",
    "section": "Context Vector",
    "text": "Context Vector\n인코딩 파트의 그림을 잘 보자. 몇 가지 요소들을 확인할 수 있다.\n\n맨 아래 워드 임베딩이 포함되어 있음을 알 수 있다. 이는 언어를 숫자로 바꾸는 과정이다.\nLSTM은 두 개의 레이어로 이루어져 있고, 각 레이어의 셀(노드)은 2개로 구성되어 있다.\n\n이렇게 인코딩을 통해 만들어진 정보를 컨텍스트 벡터라고 부른다. 이 녀석을 활용해서 디코더에 초깃값을 부여한다.\n\n\n\n\n\n\n\n\n\n인코더 만들기\n\n\n\n\n \n\n\n\n\n\n컨텍스트 벡터"
  },
  {
    "objectID": "posts/the-lectures/2024-02-15-statquest-seq2seq.html#decoder",
    "href": "posts/the-lectures/2024-02-15-statquest-seq2seq.html#decoder",
    "title": "Sequence to Sequence Model",
    "section": "Decoder",
    "text": "Decoder\n\n\n\n\n\n\n\n\n\n인코더와 디코더의 웨이트와 바이어스; 둘은 서로 다른 네트워크이고 파라미터도 다르다.\n\n\n\n\n \n\n\n\n\n\n디코더의 인풋; 디코딩의 맥락에서 필요한 단어를 임베딩해서 이 녀석을 투입으로 사용한다.\n\n\n\n\n\n\nWord Embedding for Encoder and Decoder\n인코딩과 디코딩이라고 생각하면 각각 인코딩에서 인풋을 디코딩에서 아웃풋을 처리하는 이미지를 떠올릴 수 있다. 하지만 ’번역’의 맥락에서 인코딩은 인코딩되는 세계의 단어의 정보를 압축하는 것이고 디코딩이란 이 정보에 기반해서 디코딩 세계의 단어의 정보로 풀어내는 것을 의미한다. 따라서 인코딩과 디코딩 각각에 대해서 워드 임베딩이 필요하고, 물론 각각의 웨이트와 바이어스 역시 다르다.\n\n\n\n\n\n\n \n\n\n\n\n\n워드 임베딩\n\n\n\n\n \n\n\n\n\n\nWord Unembedding?\n디코더의 끝단에에서는 디코딩된 정보를 다시 말로 풀어주는 과정이 필요하다. 이는 워드 ㅇㅁ베딩의 역과정이라고 생각하면 된다.\n\n\n\n\n\n\n \n\n\n\n\n\n디코딩의 벡터를 다시 단어로\n\n\n\n\n \n\n\n\n\n\n&lt;EOS&gt; 사용하기\n디코딩에서는 &lt;EOS&gt;를 먼저 넣는다. 그리고 디코딩 프로세스는 &lt;EOS&gt;가 나올 때까지 계속한다.\n\n\n\n\n\n\n\n\n\n&lt;EOS&gt;에서 시작!\n\n\n\n\n \n\n\n\n\n\n&lt;EOS&gt;가 풀려 나올 때까지\n\n\n\n\n \n\n\n\n\n\n전체 과정\n\n\n\n\n\n\n\n\n인코더 만들기\n컨텍스트 벡터\n인코더와 디코더의 웨이트와 바이어스; 둘은 서로 다른 네트워크이고 파라미터도 다르다.\n디코더의 인풋; 디코딩의 맥락에서 필요한 단어를 임베딩해서 이 녀석을 투입으로 사용한다.\n워드 임베딩\n디코딩의 벡터를 다시 단어로\n&lt;EOS&gt;에서 시작!\n&lt;EOS&gt;가 풀려 나올 때까지\n전체 과정"
  },
  {
    "objectID": "posts/the-lectures/2024-02-07-statquest-w2v.html",
    "href": "posts/the-lectures/2024-02-07-statquest-w2v.html",
    "title": "Word2Vec",
    "section": "",
    "text": "w2v의 기본 아이디어 위주로 정리해 보자."
  },
  {
    "objectID": "posts/the-lectures/2024-02-07-statquest-w2v.html#tl-dr",
    "href": "posts/the-lectures/2024-02-07-statquest-w2v.html#tl-dr",
    "title": "Word2Vec",
    "section": "",
    "text": "w2v의 기본 아이디어 위주로 정리해 보자."
  },
  {
    "objectID": "posts/the-lectures/2024-02-07-statquest-w2v.html#넋두리",
    "href": "posts/the-lectures/2024-02-07-statquest-w2v.html#넋두리",
    "title": "Word2Vec",
    "section": "넋두리",
    "text": "넋두리\n이른바 NLP의 주요한 돌파구가 된 것이 w2v의 아이디어다. 요즘 유행하는 트랜스포머 알고리즘 또한 그 시작은 w2v에 있다. 원래의 w2v의 형태로 실전에 활용되는 경우는 거의 없겠지만, 그 기본 아이디어는 여전히 새겨볼 만하다."
  },
  {
    "objectID": "posts/the-lectures/2024-02-07-statquest-w2v.html#word-to-vector",
    "href": "posts/the-lectures/2024-02-07-statquest-w2v.html#word-to-vector",
    "title": "Word2Vec",
    "section": "Word to Vector",
    "text": "Word to Vector\n컴퓨터는 당연히 사람의 언어를 ‘그대로’ 알아들을 수 없다. 컴퓨터가 언어를 이해하기 위해서는 언어를 먼저 숫자로 바꿔야 한다. 이렇게 말(단어, 문장, 문단)을 숫자로 바꾸는 작업이 w2v의 거의 전부이다.\n\n\n\n\n\n\n \n\n\n\n\n\n네 개의 단어를 숫자로 바꾸자.\n\n\n\n\n \n\n\n\n중요한 것은 ‘어떻게’ 바꾸는지에 있다. 우선 강의 슬라이드에 나온 대로 “Troll 2”, “is”, “great”, “Gymkata” 네 개의 단어를 생각해 보자.\n가장 쉬운 방법은 해당 단어들에 임의로 숫자를 부여하는 것이다. 이렇게 숫자를 부여하면 컴퓨터에 넣을 수는 있다. 다만 이렇게 부여된 숫자가 의미 있는 정보일까? 아니다. 인간의 언어가 지닌 ’의미’를 되도록 가깝게 컴퓨터로 옮기려면 말이 지니는 관계 혹은 말 사이의 연결망까지 모두 숫자에 반영되어야 한다.\n\n왜 word to number가 아니라, vector일지 먼저 따져보자. 인간의 언어는 하나의 의미만 지니지 않고 다양한 의미를 지니고 있다. 이를 반영하기 위해서는 스칼라 숫자 하나로는 부족할 것이다. 벡터의 등장은 이런 점에서 타당하다.\n다음으로는 비슷한 의미를 지니는 말들이 서로 비슷한 값을 지니면 좋을 것이다. 언어의 원래 의미가 벡터에도 잘 반영되어야 한다는 뜻이다. 스칼라 값이 아니므로 벡터 사이의 유사도 즉 코사인 유사도 등을 활용하면 되겠다."
  },
  {
    "objectID": "posts/the-lectures/2024-02-07-statquest-w2v.html#neural-net",
    "href": "posts/the-lectures/2024-02-07-statquest-w2v.html#neural-net",
    "title": "Word2Vec",
    "section": "Neural Net",
    "text": "Neural Net\n\n\n\n\n\n\n\n\n\n신경망의 구성\n\n\n\n\n \n\n\n\n\n\n나올 단어 예측\n\n\n\n\n\n\n \n\n\n신경망의 투입이 예측(뒤에 나올 단어)을 잘 맞출 수 있도록 네트워크의 웨이트와 바이어스를 조율해나간다\n\n\n \n\n\n\n이제 신경망을 구성해서 학습을 시킬 차례다. 투입은 당연히 각 단어의 벡터이다. 해당 단어만을 1로 처리하고 나머지를 0으로 둔다. 산출 즉 아웃풋은 뒤에 나올 단어의 예측치가 된다. 이 뉴럴넷을 학습시킬 때 좋은 결과란 뒤에 나올 말을 잘 맞추는 것이다.\n물론 실전 뉴럴넷의 파라미터 차원이 훨씬 복잡하다. 그림에서 보듯이 학습에 단어 3백만 개와 100개의 액티베이션 펑션이 있다고 하자. 아래 그림에 보듯이, 3백만 X 100 X 2 해서 6억 개의 웨이트가 필요하다."
  },
  {
    "objectID": "posts/the-lectures/2024-02-07-statquest-w2v.html#negative-sampling",
    "href": "posts/the-lectures/2024-02-07-statquest-w2v.html#negative-sampling",
    "title": "Word2Vec",
    "section": "Negative Sampling",
    "text": "Negative Sampling\n\n\n\n\n\n\n\n\n\n전체 학습하면 자원의 낭비가 막심\n\n\n\n\n \n\n\n\n\n\nDivide and Conquer!\n\n\n\n\n\n\n \n\n\n“A”를 예측하기 위해서 “aardvark”, “abandon”만을 남긴다. 산출에서 “aardvark”도 고려하지 않아도 된다. 이렇게 하면 학습해야 할 웨이트의 수가 300개로 줄어든다.\n\n\n \n\n\n\n이 녀석들을 한방에 학습시키려면 너무 오랜 시간과 자원이 소모될 것이다. 그래서 조금 꼼수를 고안해볼 수 있을 것이다. 특정 단어를 예측하는데 필요한 단어를 임의로 선택하고 이 녀석의 연결망만 학습시키는 것이다. 이를 negative sampling이라고 한다.\n\n\n\n네 개의 단어를 숫자로 바꾸자.\n신경망의 구성\n나올 단어 예측\n전체 학습하면 자원의 낭비가 막심\nDivide and Conquer!"
  },
  {
    "objectID": "posts/economics/2022-05-16-trilemma.html",
    "href": "posts/economics/2022-05-16-trilemma.html",
    "title": "Trilemma, Lately",
    "section": "",
    "text": "모두가 트릴레마를 넘어서고 싶어 하지만, 그럴 수는 없다. 거시 경제든 코인이든."
  },
  {
    "objectID": "posts/economics/2022-05-16-trilemma.html#tl-dr",
    "href": "posts/economics/2022-05-16-trilemma.html#tl-dr",
    "title": "Trilemma, Lately",
    "section": "",
    "text": "모두가 트릴레마를 넘어서고 싶어 하지만, 그럴 수는 없다. 거시 경제든 코인이든."
  },
  {
    "objectID": "posts/economics/2022-05-16-trilemma.html#거시-경제의-트릴레마",
    "href": "posts/economics/2022-05-16-trilemma.html#거시-경제의-트릴레마",
    "title": "Trilemma, Lately",
    "section": "거시 경제의 트릴레마",
    "text": "거시 경제의 트릴레마\n트릴레마(trilemma)는 두 개의 모순된 선택을 지니는 딜레마의 확장 버전이다. 세 개의 선택지 중에서 두 개는 조합이 가능하지만 그로 인해서 하나의 가치를 포기해야만 하는 상황을 의미한다.\n트릴레마 중에서 가장 많이 알려진 것은 거시 경제의 트릴레마다.\n\n\n\n거시경제의 트릴레마\n\n\n 위 그림에서 보듯이 ‘자본 이동 capital mobility’, ‘고정 환율제 fixed exchange rate’, ’통화 정책의 자율성 monetary autonomy’이 트릴레마를 이룬다. 세 가지 모두 일국의 거시 경제에 도움이 된다. 그림에 예시가 되어 있으니 이해에 도움이 될 것이다.\n\n\nTrilemmas in capital flows, and domestic and international order | VOX, CEPR Policy Portal (voxeu.org) 글에는 거시 경제의 트릴레마 이외에 관련 트렐레마가 몇 가지 더 소개되어 있다.\n시대적 조건에 따라서는 트릴레마의 강도가 미묘하게 변화하기도 한다. 예를 들어 보자. 오늘날 금융 자본주의에서는 자본 이동이 가하는 압박이 상당하다. 이런 환경에서 고정환율제를 택하건 변동환율제를 택하건 간에 자본 이동이 일국의 독자적인 거시경제 정책을 제약하는 경우가 많다.\n브레튼우즈 체제는 자본이동을 제약한 대신 고정환율제와 독자적인 거시경제 정책을 택한 조합이다. 현대 중국의 경우 약간의 독자적인 금융정책을 가장 우선에 두면서 약간의 고정환율제의 요소를 지니고 있다. 대신 자본이동에 관한 통제는 철저하다.\n트릴레마를 구성할 때 중요한 것은 무엇일까? 딜레마를 이루는 요소를 잘 선정해야 한다. 트릴레마를 이룰 수 없는 녀석들을 트릴레마라고 주장한다면 반지성적으로 보일 뿐이다. 트렐레마는 그것이 현실 혹은 역사를 잘 설명할 때 유용성을 지닌다. 위에서 보듯이, 개별 국가의 거시경제 정책 없이 금본위제 기반의 빠른 금융의 세계화가 19세기 중후반은 삼각형의 왼쪽에 해당한다. 2차 대전 이후 브레튼우즈 체제는 고정환율제, 개별 국가의 독자적인 거시경제 운용의 정책의 프레임이었고 대신 국제간 자본이동은 상당 수준으로 제한되었다.\n위 삼각형에는 없지만 트릴레마의 사례를 극적으로 보여주는 것이 1990년 영국의 중앙은행인 영란은행과 조지 소로스 간의 환율 전쟁이다. 파운드-마르크의 밴드 내 고정환율제를 구축했던 영국에서 외환 보유고가 충분하지 않음을 감지한 헤지 펀드는 영국의 외환 선물 시장에서 파운드를 던지고 외화를 퍼내기 시작했다. 이는 파운드가 압력을 이기지 못하고 평가 절하를 할 수밖에 없으며, 이 경우 파운드 선물을 판매한(숏 포지션) 헤지 펀드는 큰 돈을 벌게 될 것이기 때문이다. 실제로 발생한 일은 이와 얼추 비슷하다.\n\n\n일국의 법정 통화를 향한 이런 공격이 항상 성공하는 것은 아니다. 조지 소로스의 퀀텀 펀드를 비롯해 몇 개의 헤지 펀드가 달러에 고정된 홍콩 달러에 대해서 치밀한 분석을 거쳐 비슷한 공격을 가했지만, 중국 정부의 자본시장 통제와 이자율 인상 등의 조치로 인해 성공을 거두지 못했다."
  },
  {
    "objectID": "posts/economics/2022-05-16-trilemma.html#스테이블-코인의-트릴레마",
    "href": "posts/economics/2022-05-16-trilemma.html#스테이블-코인의-트릴레마",
    "title": "Trilemma, Lately",
    "section": "스테이블 코인의 트릴레마",
    "text": "스테이블 코인의 트릴레마\n\n\n\n스테이블 코인의 트릴레마\n\n\n\n\nAlgorithmic stablecoins and devaluation risk | VOX, CEPR Policy Portal (voxeu.org) 글에는 루나와 테라USD의 원리 및 최근의 상황이 잘 요약되어 있다.\n 스테이블 코인의 트렐리마가 흥미로운 이유는 무엇일까? 최근의 여러가지 사태도 있지만, 전체적인 도식이 위 거시경제의 트릴레마와 많이 닮았다. 스테이블 코인이란 일종의 고정환율제다. 위 ’영란 은행 대 소로스’의 일화에서 보았듯이 스테이블 코인의 가치가 유지되기 힘들다는 의구심이 발생하는 순간 해당 코인은 유사한 투기적인 공격에 노출될 수 있다.\n스테이블 코인 테라 USD의 경우 테더(Tether)처럼 현실 법화(legal tender)에 묶인 게 아니라 비트코인에 묶여 있었다. 비트코인 자체의 가격 변화가 심하다면 안정적(stable)이라는 수식어가 무색한 상황이 얼마든지 생길 수 있다.\n\n\n그렇다면 USD에 혹은 다른 법화에 묶는 스테이블 코인은 괜찮을까? 현실의 법화는 국가 혹은 지역 공동체의 법에 의해 지불, 보증, 부채 이행을 보장받는 화폐다. 그리고 이 화폐는 국가 혹은 여타 법적 존재가 최종 대부자로 자리매김하고 있다. 이 화폐에 기반한 상업 활동 및 금융 활동과는 별개로 이에 기반한 화폐 체계는 최종 대부자라는 법화의 공공재에 무임승차 하는 것과 비슷하다. 탈중앙화를 핵심 가치로 중앙은행의 타락을 거부한 암호 화폐가 돌고 돌아서 결국 중앙은행에 의존하게 되는 것 역시 아이러니하다.\n스테이블 코인의 트릴레마를 해결하는 방법은 무엇일까? 트릴레마를 응용한다면 탈중앙화-자본 효율을 추구하는 알고리즘 기반의 이점을 포기하는 방향이 있다. 충분한 수준의 법화 보유고 확보하거나(삼각형의 오른쪽) 혹은 스마트 컨트랙트를 통해서 특정한 조건에서 충분한 수준의 보유고를 확보하거나(삼각형의 왼쪽) 해야 한다.\n다만 스마트 컨트랙트를 통해서 고정 교환비라는 제약 아래 투기적 공격을 막아내기에 충분한 담보 비율을 사전적으로 알 수 있는지는 분명하지 않다. 이 상황이 불비 정보(incomplete information)의 상황이라면 현재 지니고 있는 정보를 통해 미래의 모든 상황을 충분히 파악하기 힘들다. 이때 미래의 사태를 대응하기 위한 장치를 스마트 컨트랙트에 미리 넣을 수 있을까?\n특정한 시점에 레짐 체인지를 통해서 일시적으로 중앙화의 해법을 택한다는 식의 메타 룰을 스마트 컨트랙트에 넣을 수 있는 것인지 잘 모르겠다. 만일 그렇다고 해도 해당 상황에서 누가 통제를 할지 이 통제를 위한 정당성은 어떻게 준비할 수 있는지 등등은 나에게는 여전히 의문이다."
  },
  {
    "objectID": "posts/git/2022-04-27-happy-giting.html",
    "href": "posts/git/2022-04-27-happy-giting.html",
    "title": "Happy Git-ing!",
    "section": "",
    "text": "Note\n\n\n\n이 포스팅은 깃 혹은 깃허브에 관한 일반적인 해설이나 이용법이 아닙니다. 깃 혹은 깃허브를 어느 정도 활용하고 있다고 할 때 가려움을 긁어주는 용도로 작성된 글입니다."
  },
  {
    "objectID": "posts/git/2022-04-27-happy-giting.html#tl-dr",
    "href": "posts/git/2022-04-27-happy-giting.html#tl-dr",
    "title": "Happy Git-ing!",
    "section": "tl; dr",
    "text": "tl; dr\n\n깃과 깃허브를 OS를 아우르면서 써보자.\n깃헙 데스크탑, gh CLI 활용하자.\nWSL에서 쓰기 위해서는 별도의 처방이 필요하다."
  },
  {
    "objectID": "posts/git/2022-04-27-happy-giting.html#common-tools",
    "href": "posts/git/2022-04-27-happy-giting.html#common-tools",
    "title": "Happy Git-ing!",
    "section": "Common Tools",
    "text": "Common Tools\n이상적으로 말하면 git을 쓸 때 터미널(CLI)을 통해 쓰면 좋다. 하지만 우리는 인간이고 터미널 명령어는 잊기 쉽다. 그래서 UI를 갖춘 틀이 있으면 좋다.\n아마도 깃을 쓴다면 저장소로 깃랩이나 깃헙을 같이 쓸 것이다. 나는 깃헙을 쓰고 있으므로 깃헙을 중심으로 설명하겠다.\n깃헙 데스크탑은 플랫폼을 가리지 않고 깃헙을 쓸 수 있게 해주는 앱이다. 플랫폼 별로 다운로드 받아서 쓰면 된다. 리포지터리(리포)를 생성하고 클론하고 하는 작업이 모두 UI 내에서 가능해서 제법 편리하다. 자세한 사용법은 생략한다."
  },
  {
    "objectID": "posts/git/2022-04-27-happy-giting.html#그래도-터미널을-써야-한다면",
    "href": "posts/git/2022-04-27-happy-giting.html#그래도-터미널을-써야-한다면",
    "title": "Happy Git-ing!",
    "section": "그래도 터미널을 써야 한다면?",
    "text": "그래도 터미널을 써야 한다면?\n그래도 터미널에서 직접 깃을 써야 할 때가 있다. 이때부터 문제가 다소 복잡해진다. 깃의 원격 저장소를 세팅해야 하는데, 깃헙을 쓴다면 인증도 해야한다. 이걸 뭔가 편리하게 할 수 없을까?\n\ngh CLI\n이러한 불편을 해소하기 위해서 github에서 만든 툴이 gh CLI다. 이 녀석도 플랫폼별로 제공되고, ,터미널로 깃헙을 제어하고 여러가지 작업을 할 수 있게 만든 툴이다. 다른 명령어들도 유용하지만 제일 유용한 것은 인증에 관련된 것이다.\n$ gh auth login  \n현재 깃헙은 터미널에서 id/password를 통한 로그인을 막고 있다. 저장소 주소를 origin에 넣고 id/password로 로그인 할 수 없다. 위 명령어를 실행하면 조건에 따라서 로그인 절차를 상세하게 안내해준다. 그대로 따라서 깃헙에 로그인 하면 된다."
  },
  {
    "objectID": "posts/git/2022-04-27-happy-giting.html#os-별-설치",
    "href": "posts/git/2022-04-27-happy-giting.html#os-별-설치",
    "title": "Happy Git-ing!",
    "section": "OS 별 설치",
    "text": "OS 별 설치\n앞에 소개했던 github desktop은 그 자체로서 온전하게 운용된다. 다시 말해 이 앱 자체가 외부의 다른 앱에 의존하지 않기 때문에 앱 내에서 git을 쓰는 이상 이 녀석만 깔면 된다. gh CLI의 경우에는 OS에 깃이 깔려 있어야 한다.\n\nLinux, Macos\n두 OS 모두 깃이 기본으로 깔려 있다. 따라서 gh CLI를 깔아서 잘 쓰면 된다.\n\n\nWindows 10\n원도10의 경우는 고려해야 할 사항이 몇 가지 있다. 윈도우용 깃을 다운받아서 깔아도 되지만 그것보다는 Powershell을 통해서 윈도 패키지 매니저인 winget을 이용해 설치하면 좋다.\n$ winget install -e --id Git.Git\n이렇게 깃을 설치한 후 gh auth login을 통해서 로그인을 수행하면 git의 원격 저장소 설정이 잘 이루어진다.\n\nWSL\nWSL은 Windows 10 안에서 돌고 있는 가상 머신이고 엄밀한 관점에서는 별도의 기계다. 다른 Ubuntu와 마찬가지로 깃이 기본으로 깔려 있다. 따라서 외부 저장소에 대한 인증이 필요하다.\n상식적으로는 gh CLI를 통해서 가능할 것 같은데 그렇지 않다. 이에 대한 해결책은 여기 나와 았다. 쉽게 말해서 윈도의 자격 증명을 가져오는 방식이다. 따라서 윈도에 깃과 깃허브에 관한 설정이 이미 완료되어 있어야 한다.\n$ git config --global credential.helper \"/mnt/c/Program\\ Files/Git/mingw64/libexec/git-core/git-credential-manager-core.exe\""
  },
  {
    "objectID": "posts/math-of/2019-12-24-PageRank.html",
    "href": "posts/math-of/2019-12-24-PageRank.html",
    "title": "PageRank as Markov Chain",
    "section": "",
    "text": "페이지와 브린이 창안한 페이지랭크 알고리듬은 수학적으로 보면 마르코프 체인의 극한 분포다."
  },
  {
    "objectID": "posts/math-of/2019-12-24-PageRank.html#tldr",
    "href": "posts/math-of/2019-12-24-PageRank.html#tldr",
    "title": "PageRank as Markov Chain",
    "section": "",
    "text": "페이지와 브린이 창안한 페이지랭크 알고리듬은 수학적으로 보면 마르코프 체인의 극한 분포다."
  },
  {
    "objectID": "posts/math-of/2019-12-24-PageRank.html#pagerank",
    "href": "posts/math-of/2019-12-24-PageRank.html#pagerank",
    "title": "PageRank as Markov Chain",
    "section": "PageRank?",
    "text": "PageRank?\n페이지랭크 알고리듬의 핵심이 사실 마르코프 체인이다. 페이지와 브린의 논문에 보면 “random surfer”라는 표현이 나온다. 이게 딱 확률 과정(stochastic process)을 연상시키지 않나? 문득 이런 생각이 들더라.\n페이지와 브린의 논문 자체가 마르코프 프로세스를 연상시키지는 않는다. 논문을 보면 페이지랭크 스코어링을 위한 몇 가지 원칙들이 언급되어 있을 뿐이다. 더 많은 아웃바운드 링크를 지닌 웹페이지에 내 페이지가 연결되어 있을 때 내 페이지의 스코어를 계산할 때 해당 페이지의 중요성을 낮춘다. 많은 인바운드 링크를 지닌 페이지에 내 페이지가 연결되어 있다면 이 페이지의 중요성을 높인다. 대략 이런 내용들이다. 사실 페이지랭크를 계산하는 과정 자체는 재귀적인 내용을 포함하고 있기 때문에 직관적으로 이해하기는 쉽지 않다. 페이지랭크 스코어링의 함의를 추리고 그 계산 과정은 잘 돌아보지 않는다. 나도 그랬다.\n페이지랭크라는 스코어, 즉 한 웹 페이지가 링크로 구성된 웹 풍경에서 지니는 중요도라는 개념이 마르코프 체인의 극한 분포(limiting distribution)와 개념적으로 연결된다. 내용을 간단히 살펴보도록 하자."
  },
  {
    "objectID": "posts/math-of/2019-12-24-PageRank.html#pagerank-model",
    "href": "posts/math-of/2019-12-24-PageRank.html#pagerank-model",
    "title": "PageRank as Markov Chain",
    "section": "PageRank Model",
    "text": "PageRank Model\n일단 페이지와 브린의 논문에서 다룬 모델링의 세팅을 간단히 살펴보자.\n\n\\(L_{ij}\\): 인디케이터 함수다. \\(j \\to i\\)의 링크가 존재하면 1, 그렇지 않으면 0이다.\n\\(m_j = \\sum_{k=1}^n L_{kj}\\): \\(j\\)가 지닌 아웃바운드 링크의 합을 나타낸다.\n\n이제 웹페이지 \\(i\\)의 Broken Rank \\(p_i\\)은 다음과 같다.\n\\[\np_i = \\sum_{j \\to i} \\dfrac{p_j}{m_j} = \\sum_{k=1}^{n}L_{ik}\\dfrac{p_{k}}{m_k}\n\\]\n\\(i\\) 웹사이트의 ’Broken Rank’는 \\(i\\)로 연결된 페이지들의 Broken Rank에 의해 정해진다. 이를 계산하는 방법은 다음과 같다. 해당 페이지들의 Broken Rank가 높을수록 나의 랭크도 높아진다. 해당 페이지가 더 많은 링크를 가질수록 그 Broken Rank는 낮게 평가된다. \\(m_j\\)로 나눠진 부분이 이를 반영한다.\n여기서 왜 굳이 “broken”이라는 표현을 썼는지는 잠시 후에 나오니 조금만 기다려주시라.\n\nBroken rank as matrix\nBroken rank를 매트릭스로 표현해보자.\n\\[\np = [p_1, \\dotsc, p_n]^T\n\\]\n\\[\nL =\n\\begin{bmatrix}\nL_{11}& \\dotsc& L_{1n} \\\\\n\\vdots& \\ddots& \\vdots \\\\\nL_{n1}& \\dotsc& L_{nn}\n\\end{bmatrix}\n\\]\n\\[\nM =\n\\begin{bmatrix}\nm_{1}& \\dotsc& 0 \\\\\n\\vdots& \\ddots & \\vdots \\\\\n0& \\dotsc& m_{n}\n\\end{bmatrix}\n\\]\n이를 활용하면,\n\\[\np = LM^{-1} p\n\\]\n\\(LM^{-1} = A\\)라고 두면 \\(A\\)가 마르코프 체인의 확률 행렬과 유사하다는 점을 쉽게 파악할 수 있다.\n\\[\nA^T =\n\\begin{bmatrix}\n\\dfrac{L_{11}}{m_1}& \\dotsc& \\dfrac{L_{n1}}{m_1} \\\\\n\\vdots& \\ddots& \\vdots \\\\\n\\dfrac{L_{1n}}{m_n}& \\dotsc& \\dfrac{L_{nn}}{m_n}\n\\end{bmatrix}\n\\]\n\\(A^T\\)를 들어다보자. 일단, 행을 더하면 1이 된다. 즉, \\(i\\)에서 \\(i\\)를 포함해서 어디론가는 가야 한다는 뜻이다. 다음으로 \\(L_\\cdot\\)의 정의를 살펴보면 \\(j \\to i\\)의 이행확률은 \\(j\\)가 \\(i\\)로 향하는 링크를 지닐 경우는 \\(\\frac{1}{m_i}\\)가 되고, 그렇지 않으면 0이다. 페이지와 브린이 정의한 random surfer의 의미가 이것이다. \\(m_i\\)의 링크 중에서 특별히 선호하는 링크 없이 무작위로 하나를 골라서 나간다는 가정이다. 아울러 해당 링크를 선택하는 데에는 현재의 가능성 이외에 그 전의 선택은 고려되지 않는다. 이점에서 이번 기의 선택에 바로 전기만 영향을 끼치는 마르코프 프로세스의 가정과 일치한다.\n한편 행 \\(i\\)는 \\(j \\to i\\)로 들어오는 링크를 의미한다. \\(L_{\\cdot j}\\)가 1이 많을수록 \\(i\\)로 오는 링크가 많다는 뜻이다. 즉, 이 링크는 영향력이 높은 링크를 뜻한다.\n\n\nWhy broken?\n왜 깨진 링크인가? 눈치가 빠른 사람이라면 마르코프 체인에서 해당 체인이 수렴하는 분포를 지니기 위한 조건을 알고 있을 것이다. 극한 분포를 지니려면 마르코프 확률 행렬이 우선 irreducible 행렬이어야 한다.\n이 조건을 말로 풀면 어떻게 될까? 해당 상태에서 언젠가는 다른 모든 상태로 갈 수 있어야 한다. 이를 웹사이트 간의 링크로 다시 풀어보자. A 사이트에서 B 사이트로 갈 수 없으면 안된다. 마르코프 체인에서 확률 행렬이 reducible 행렬이면 수렴하는 유일한 극한 분포를 찾을 수 없다. 다음의 예를 보자.\n\\[\nA =\n\\begin{bmatrix}\n0 & 0 & 1 & 0 & 0  \\\\\n1 & 0 & 1 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 0 & 1 \\\\\n0 & 0 & 0 & 1 & 0\n\\end{bmatrix}\n\\]\n아이겐밸류 1에 해당하는 아이겐벡터는 두 개가 존재한다. 각각\n\\[\np = [\\dfrac{1}{3}, \\dfrac{1}{3} , \\dfrac{1}{3} , 0, 0 ] \\text{~or~} p = [0, 0, 0, \\dfrac{1}{2}, \\dfrac{1}{2} ]\n\\]\n확률 행렬이 기약 행렬(reducible matrix)이면, 웹 페이지에 관해서 유일한 극한 분포를 찾을 수 없다. 시작이 어디인지에 따라서 전혀 다른 극한 분포를 얻게 된다. 위의 예에서 만일 1,2,3 사이트에서 시작했다면 첫번째 극한 분포를, 4,5 사이트에서 출발했다면 두번째 극한 분포를 얻게 될 것이다."
  },
  {
    "objectID": "posts/math-of/2019-12-24-PageRank.html#pagerank-score-as-share",
    "href": "posts/math-of/2019-12-24-PageRank.html#pagerank-score-as-share",
    "title": "PageRank as Markov Chain",
    "section": "PageRank score as share",
    "text": "PageRank score as share\n마르코프 체인을 다루는 분석에서 이런 경우는 종종 생길 수 있다. 이를 해결하는 가장 쉬운 방법은 어떤 상태에 고착되어 벗어날 수 없을 때, 벗어날 수 있는 어떤 기제를 마련해주는 것이다. 예를 들어, 플레이어가 일정한 확률로 실수를 하게 허용한다거나 하는 이론적인 장치가 많이 활용된다.\n페이지랭크 역시 비슷한 해법을 모델에 넣었다. 링크가 없더라도 일정한 확률로 다른 모든 링크로 넘어갈 확률을 임의로 부여하는 것이다. 이를 반영한 페이지랭크의 정의는 아래와 같다.\n\\[\np_i = \\overset{(A)}{(1-d)\\dfrac{1}{n}} + \\overset{(B)}{\\vphantom{\\dfrac{1-d}{n}} d \\cdot \\sum_{j \\to i} \\dfrac{p_j}{m_j}} =  \\dfrac{1-d}{n}  + d \\sum_{k=1}^{n}L_{ij}\\dfrac{p_{j}}{m_j}\n\\]\n\\(d\\)는 어떤 사이트에서 링크가 존재하는 다른 사이트로 옮겨갈 확률을 의미한다. 따라서 \\((1-d)\\)는 링크 유무와 관계 없이 \\(n\\) 개의 사이트 중 임의의 다른 사이트로 옮겨갈 확률이다.\n\n\\((A)\\): 링크 유무와 관계없이 (\\(i\\) 자신을 포함해) 어디선가 \\(i\\)로 올 확률에 기반한 스코어링이다. 이때 스코어 값은 1이다.\n\\((B)\\): \\(i\\)로 오는 링크를 지닌 사이트 중에서 \\(i\\)로 올 확률에 기반한 스코어링이다. 각각의 스코어링 값은 \\(p_j\\)가 된다.\n\n이를 행렬로 나타내면 다음과 같다. \\(p_t\\) 기의 페이지랭크가 주어져 있다면, 링크를 통한 페이지 이동을 거친 이후의 페이지랭크 \\(p_{t+1}\\) 다음과 같다.\n\\[\np_{t+1} = \\overbrace{\\left( \\dfrac{1-d}{n} \\boldsymbol{1}_n + d L M^{-1} \\right)}^{(*)}p_{t}\n\\]\n\\(\\boldsymbol{1}_n\\)은 모든 원소가 1인 \\(n \\times n\\) 행렬이다. \\((*)\\)은 기약 행렬(irreducible matrix)이고, \\(d&gt;0\\)이 만족하면 비주기 행렬(aperiodic matrix)이 된다. 특정한 사이트 \\(i\\)에서 다른 사이트로 갈 확률이 모두 양수가 되기 때문이다.\n이 경우 \\((*)\\)을 확률 행렬로 지니는 마르코프 체인은 극한 분포 \\(p^*\\)를 지니게 된다. 마르코프 체인의 논리에 따라서 \\(p^*\\)는 초기값 혹은 웹사이트의 초기 지분 \\(p_0\\)와 무관하다.\n이 극한 분포 \\(p^*\\)가 바로 페이지랭크다! 마르코프 체인의 관점에서 페이지랭크란 페론-프로베니우스 정리에 따라서 아이겐밸류 \\(1\\)에 해당하는 좌 아이겐벡터를 찾는 과정이다. 물론 구글이 구사하는 실제의 알고리즘은 여기 적은 내용보다 훨씬 복잡하고 정교하다. 다만 그 핵심이 마르코프 체인이라는 사실을 기억해두자.\n\n\n🔗을 참고하라.\n극한 분포가 페이지랭크가 된다는 의미는 무엇일까? 마르코프 체인에서 극한 분포란 무작위로 상태를 옮겨가는 것이 무한이 반복되었을 때 도달하게 되는 분포다. 이는 충분히 긴 장기에 각 상태가 지니게 되는 ‘지분’(share)으로 이해할 수 있다.\n이러한 마르코프 체인에 기반을 둔 해석은 웹 사이트에도 잘 들어 맞는다. 그럴까? 개인의 입장에서는 그렇지 않다. 적어도 나는 그렇다. 구글에서 검색어를 친 뒤 검색 결과를 보면서 필요한 것을 찾아서 클릭, 클릭하기 때문이다.\n하지만 내가 누른 검색어를 친 사람이 많다면 어떨까? 특정 검색어에 관해서 수많은 웹 서퍼가 존재하고 이들이 각자의 취향대로 페이지를 옮겨다닌다면? 전체적으로 이는 특정 사이트에서 다른 사이트로 무작위로 이동한다는 마르코프 체인의 가정과 크게 다르지 않을 수 있겠다. 이러한 상태에서 각 사이트가 차지하는 ‘지분’ 혹은 점유율이 해당 웹사이트가 전체 웹 풍경에서 누리는 ’중요성’이 될 것이다.\n아울러 앞서 페이지랭크의 정의가 동어반복처럼 느껴졌던 이유도 이제 알 수 있다. 이는 장기에 도달하게 되는 일종의 수렴 상태인 셈이다. 이렇게 마르코프 체인과 페이지랭크가 연결된다!"
  },
  {
    "objectID": "posts/math-of/2019-12-24-PageRank.html#reference",
    "href": "posts/math-of/2019-12-24-PageRank.html#reference",
    "title": "PageRank as Markov Chain",
    "section": "Reference",
    "text": "Reference\nPage, Larry, “The PageRank Citation Ranking: Bringing Order to the Web,” http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf. ↩︎\nTibshirani, Ryan, “PageRank,”\nhttps://www.stat.cmu.edu/~ryantibs/datamining/lectures/03-pr.pdf."
  },
  {
    "objectID": "posts/math-of/2019-12-20-Peron-Frobenius-2.html",
    "href": "posts/math-of/2019-12-20-Peron-Frobenius-2.html",
    "title": "Perron-Frobenius Theorem, part 2",
    "section": "",
    "text": "투입-산출 모형을 생각해보자. \\(a_{ij}\\)는 \\(j\\) 재화 1 단위를 생산하는 데 필요한 \\(i\\) 재화의 양, 이라고 하자. 이렇게 되면, 열 벡터 \\(A_j\\)는 아래과 같다. 그 의미는 \\(j\\) 재화 1단위를 생산하는 데 필요한 \\(1, \\dotsc, n\\) 까지 필요한 재화의 양이다.\n\\[\nA_j =\n\\begin{bmatrix}\na_{1j} \\\\\n\\vdots \\\\\na_{nj}\n\\end{bmatrix}\n\\]\n여기서 두 가지를 더 가정하겠다.\n\n투입을 \\(k\\) 배로 하면, 산출도 \\(k\\) 배가 된다. 이를 규모수익불변(constant return to scale)이라고 한다.\n각 재화 생산은 다른 재화 생산에 영향을 주지 않는다.\n\n이제 \\(j\\) 재화를 \\(x_j\\) 만큼 생산하는 데 필요한 투입량은 \\(x_j A_j\\)가 된다. 생산하려는 생산량을 \\(x_1, \\dotsc, x_n\\)이라고 하면 충 투입 벡터는 아래와 같다.\n\\[\nx_1 A_1 + \\dotsc + x_n A_n = A x,~\\text{where $x = [x_1, \\cdots, x_n]^T$}\n\\]\n\n\n\n생산물 벡터 \\(x\\)를 생산하는 데 투입 벡터 \\(Ax\\)가 필요하다면 순 생산물 벡터는 아래와 같다.\n\\[\nx - Ax = (I-A)x\n\\]\n순생산물 벡터 \\(b\\)를 얻게 위해서는 아래의 식이 성립해야 한다.\n\\[\n(I-A) x = b\n\\]\n만일 \\((I-A)\\)가 가역이라면 유일한 해 \\(x\\)가 존재하게 된다. 문제는 \\(x \\geq 0\\)를 보장할 수 있는지, 이다. 즉, 어떤 경제가 생산적이라는 정의는 아래와 같다.\n\\[\nx = (I-A)^{-1} b \\geq 0\n\\]\n\n\n\n원래 바실리 레온티에프 (동지?)가 제시했던 생산적인 행렬 \\(A\\)의 정의는 살짝 더 엄격하다. 원래 \\(A\\)의 정의는 다음과 같다.\n\\((I- A)x &gt; 0\\)을 만족하는 비음의 벡터 \\(x\\)가 존재할 때, \\(A\\)를 생산적 매트릭스 혹은 레온티에프 메트릭스라고 정의한다. 이 정의는 매우 중요하다. 이후의 조건에서 결정적으로 활용되니 잘 기억해두도록 하자.\n잘 생각해보면 경제적인 의미가 있다. 뒤에 다시 나오겠지만, \\(A x\\)는 어떤 의미를 지닐까? 원하는 생산량이 \\(x\\)라면 이에 필요한 투입량이 \\(Ax\\)다. 즉, \\(x - Ax\\)란 다음 기 (목표) 산출에서 이를 위해 필요한 이번 기 투입 산출을 뺀 것이다. 이 값이 양이어야 한다는 것이다. 이 값이 음이라면 생산적이지 못한 것이다. 만일 \\(\\boldsymbol{0}\\) 벡터라면 연속적인 생산이 불가능한 상태가 된다."
  },
  {
    "objectID": "posts/math-of/2019-12-20-Peron-Frobenius-2.html#input-out-model",
    "href": "posts/math-of/2019-12-20-Peron-Frobenius-2.html#input-out-model",
    "title": "Perron-Frobenius Theorem, part 2",
    "section": "",
    "text": "투입-산출 모형을 생각해보자. \\(a_{ij}\\)는 \\(j\\) 재화 1 단위를 생산하는 데 필요한 \\(i\\) 재화의 양, 이라고 하자. 이렇게 되면, 열 벡터 \\(A_j\\)는 아래과 같다. 그 의미는 \\(j\\) 재화 1단위를 생산하는 데 필요한 \\(1, \\dotsc, n\\) 까지 필요한 재화의 양이다.\n\\[\nA_j =\n\\begin{bmatrix}\na_{1j} \\\\\n\\vdots \\\\\na_{nj}\n\\end{bmatrix}\n\\]\n여기서 두 가지를 더 가정하겠다.\n\n투입을 \\(k\\) 배로 하면, 산출도 \\(k\\) 배가 된다. 이를 규모수익불변(constant return to scale)이라고 한다.\n각 재화 생산은 다른 재화 생산에 영향을 주지 않는다.\n\n이제 \\(j\\) 재화를 \\(x_j\\) 만큼 생산하는 데 필요한 투입량은 \\(x_j A_j\\)가 된다. 생산하려는 생산량을 \\(x_1, \\dotsc, x_n\\)이라고 하면 충 투입 벡터는 아래와 같다.\n\\[\nx_1 A_1 + \\dotsc + x_n A_n = A x,~\\text{where $x = [x_1, \\cdots, x_n]^T$}\n\\]\n\n\n\n생산물 벡터 \\(x\\)를 생산하는 데 투입 벡터 \\(Ax\\)가 필요하다면 순 생산물 벡터는 아래와 같다.\n\\[\nx - Ax = (I-A)x\n\\]\n순생산물 벡터 \\(b\\)를 얻게 위해서는 아래의 식이 성립해야 한다.\n\\[\n(I-A) x = b\n\\]\n만일 \\((I-A)\\)가 가역이라면 유일한 해 \\(x\\)가 존재하게 된다. 문제는 \\(x \\geq 0\\)를 보장할 수 있는지, 이다. 즉, 어떤 경제가 생산적이라는 정의는 아래와 같다.\n\\[\nx = (I-A)^{-1} b \\geq 0\n\\]\n\n\n\n원래 바실리 레온티에프 (동지?)가 제시했던 생산적인 행렬 \\(A\\)의 정의는 살짝 더 엄격하다. 원래 \\(A\\)의 정의는 다음과 같다.\n\\((I- A)x &gt; 0\\)을 만족하는 비음의 벡터 \\(x\\)가 존재할 때, \\(A\\)를 생산적 매트릭스 혹은 레온티에프 메트릭스라고 정의한다. 이 정의는 매우 중요하다. 이후의 조건에서 결정적으로 활용되니 잘 기억해두도록 하자.\n잘 생각해보면 경제적인 의미가 있다. 뒤에 다시 나오겠지만, \\(A x\\)는 어떤 의미를 지닐까? 원하는 생산량이 \\(x\\)라면 이에 필요한 투입량이 \\(Ax\\)다. 즉, \\(x - Ax\\)란 다음 기 (목표) 산출에서 이를 위해 필요한 이번 기 투입 산출을 뺀 것이다. 이 값이 양이어야 한다는 것이다. 이 값이 음이라면 생산적이지 못한 것이다. 만일 \\(\\boldsymbol{0}\\) 벡터라면 연속적인 생산이 불가능한 상태가 된다."
  },
  {
    "objectID": "posts/math-of/2019-12-20-Peron-Frobenius-2.html#hawkins-simon-condition",
    "href": "posts/math-of/2019-12-20-Peron-Frobenius-2.html#hawkins-simon-condition",
    "title": "Perron-Frobenius Theorem, part 2",
    "section": "Hawkins-Simon Condition",
    "text": "Hawkins-Simon Condition\n이를 보장해주는 것이 호킨스-사이먼 조건(Hawkins-Simon condition) 이다. H-S 조건을 증명하기에 앞서 몇가지 렘마를 깔아보도록 하자. 앞으로 특별한 언급이 없는 이상 벡터와 매트릭스는 적당한 크기(차원)을 지니고 있다고 가정하겠다.\n\nLemma 1\n\n두 개의 벡터 \\(x^1\\), \\(x^2\\)가 있다고 하자. if \\(x^1 \\geq x^2\\) and \\(A \\geq 0\\), then \\(A x_1 \\geq A x_2\\).\n\n증명은 간단하니 생략하도록 한다. 직접 계산해보면 된다.\n\n\nLemma 2\n\n만일 \\(A\\) 가 생산적 행렬이라면, \\(A^s\\)의 모든 원소는 \\(s \\to \\infty\\)에 따라서 0으로 수렴한다.\n\n증명해보자. 일단 A가 생산적 행렬이라는 조건에서, 아래와 같이 주장할 수 있다.\n\\[\nx &gt; Ax \\geq 0\n\\]\n\\(A\\)와 \\(x\\) 모두 비음이라는 점을 떠올리면 된다. 이것이 성립한다면, \\(0 &lt; \\lambda &lt; 1\\)의 \\(\\lambda\\)가 존재하고 이는 다음을 만족한다.\n\\[\n\\lambda x &gt; A x \\geq 0\n\\]\n여기에 다시 \\(A\\)를 앞 곱하면 다음과 같다.\n\\[\n\\lambda(Ax) &gt; A^2 x \\geq 0\n\\]\n한편, 먼저 식에 이번에는 \\(\\lambda\\)를 곱하면, 다음과 같다.\n\\[\n\\lambda^2 x &gt; \\lambda(Ax) \\geq 0\n\\]\n이제 이렇게 곱한 두 결과를 합치면, 다음과 같다.\n\\[\n\\lambda^2 x &gt; A^2 x \\geq 0\n\\]\n이를 일반화하면,\n\\[\n\\lambda^k x &gt; A^k x \\geq 0\n\\]\n\\(k \\to \\infty\\)에 따라서, \\(\\lambda^k \\to 0\\) 가 되기 때문에\n\\[\n\\lim_{k \\to \\infty} A^k x =0\n\\]\n벡터 \\(A^k x\\)의 \\(i\\) 번째 벡터는 다음과 같다.\n\\[\n\\lim_{k \\to \\infty} \\sum_{j=1}^n a^k_{ij} x_j = 0\n\\]\n이는 임의의 \\(x_j \\geq 0\\)에 대해서 항상 성립해야 한다. 따라서, \\(\\lim_{k \\to \\infty} a^k_{ij} = 0\\)이 성립해야 한다.\n\n\nLemma 3\n\n만일 \\(A\\)가 생산적 행렬이고 어떤 \\(x\\)에 대해서 \\(x \\geq Ax\\)가 성립하면, \\(x \\geq 0\\)\n\n앞서 Lemma 2와 비슷한 논리로 다음과 같이 적을 수 있다.\n\\[\nx \\geq Ax \\geq A^2x \\geq \\dotsb \\geq A^k x.\n\\]\n즉, \\(x \\geq A^k x\\). \\(k \\to \\infty\\)일 때 Lemma 2에 따라서,\n\\[\nx \\geq \\lim_{k \\to \\infty} A^k x = 0.\n\\]\n\n\nLemma 4\n\nIf \\(A\\) 가 생산적 행렬이라면, \\((I-A)\\) is non-singular.\n\n증명은 간단하다. \\((I-A)\\)가 singular 라고 가정하자. 그렇다면, \\(x \\neq 0\\)이면서, \\((I-A) x = 0\\)인 \\(x\\)가 존재하게 된다. \\((I-A)(-x) = 0\\) 역시 마찬가지라고 성립한다. \\(-x \\geq 0\\)가 성립해야 하는데, 이를 만족시키는 \\(x\\)는 \\(x = 0\\)가 유일하다. 이는 \\(x \\neq 0\\) 전제와 모순된다.\n\n\nTheorem 1\n비음의 벡터 \\(d\\)가 있을 때, \\(A\\)가 생산적일 때,\n\\[\n(I-A)x = d\n\\]\n는 유니크한 비음의 해를 지닌다.\n\nProof\nLemma 4에 따르면, \\((I-A)\\)는 비특이(nonsingular) 행렬이다. 따라서 위 시스템의 해 \\(x^*\\)는 유니크하다. 아울러, \\(d \\geq 0\\)이므로,\n\\[\n(I-A) x^*  \\geq 0\n\\] 가 성립한다. \\(A\\)는 생산적이고 위 식이 성립하므로 Lemma 3에 따라서 \\(x^* \\geq 0\\)."
  },
  {
    "objectID": "posts/math-of/2019-12-20-Peron-Frobenius-2.html#hawkins-simon-condition-1",
    "href": "posts/math-of/2019-12-20-Peron-Frobenius-2.html#hawkins-simon-condition-1",
    "title": "Perron-Frobenius Theorem, part 2",
    "section": "Hawkins-Simon Condition",
    "text": "Hawkins-Simon Condition\n\nA는 생산적\n행렬 \\((A-I)^{-1}\\)이 존재하며, 비음\n\\(B = I - A\\) 모든 주 행렬식이 양수\n\n보통 호킨스-사이먼 조건은 3번을 뜻한다. 3과 2번이 동치를 밝히는 것을 호킨스-사이먼 정리로 지칭한다.\n먼저 1과 2가 동치임을 증명해보자.\n\nSufficiency (1 → 2)\nA가 생산적 행렬이며, Lemma 4에 의해서 \\((I-A)^{-1}\\)이 존재함을 알 수 있다.\n\\[\n\\Phi_s = I + A + \\dotsc + A^s\n\\]\n라고 하자. 이때,\n\\[\nA \\Phi_s = A + A^2 + \\dotsc + A^{s+1}.\n\\]\n\\[\n(I - A) \\Phi_s = I - A^{s+1}.\n\\]\n앙변에 극한값을 취하면,\n\\[\n\\lim_{s \\to \\infty} [(I-A) \\Phi_s ] = I\n\\]\n이 성립한다. 이는 Lemma 2에 의해서 \\(\\lim_{s \\to \\infty} A^{s+1} \\to 0\\)가 성립하기 때문이다.\n\\[\n\\lim_{s \\to \\infty} \\Phi_s = (I-A)^{-1}\n\\]\n\\(A \\geq 0\\)이기 때문에, \\(\\Phi_s \\geq 0\\)가 항상 성립한다. 따라서,\n\\[\n(I-A)^{-1} \\geq 0\n\\]\n\n\nNecessity (1 ← 2)\n\\((I-A)^{-1} \\geq 0\\)가 성립한다고 하자. 임의의 \\(d &gt; 0\\)를 잡으면 \\(x = (I-A)^{-1} d \\geq 0\\) 가 성립한다. 이때,\n\\[\nx = A x + d &gt; Ax\n\\]\n가 성립하므로 1이 만족한다.\n나머지 증명은 테크니컬한 문제이므로 생략하자.\n\n\nEigenvalues & Eigenvectors\n이제 생산적 행렬의 아이겐밸류와 아이겐벡터를 고민해보도록 하자. 생산적 행렬의 정의 \\(x - Ax &gt; 0\\)에서 출발해보자. 만일 아이겐밸류 \\(\\lambda\\)가 존재한다면 그 값은 어때야 할까? 즉,\n\\[\n\\lambda x - Ax = \\lambda x - x &lt; 0\n\\]\n따라서 \\(\\lambda &lt; 1\\)이 된다. 아울러, 비음 행렬의 P-F 정리에 따르면 가장 아이겐밸류가 존재할 때 가장 큰 값 \\(\\lambda_{\\rm pf}\\)가 존재하는데, 이 역시 \\(\\lambda_{\\rm pf} &lt; 1\\)이 된다. 따라서 이에 상응하는 아이겐벡터 \\(x_{\\rm pf}\\)는 다음을 만족시켜야 한다. \\((I-A) x_{\\rm pf} \\geq 0\\).\n\\[\n(I-A) x_{\\rm pf} = (\\lambda_{\\rm pf} I - A ) x_{\\rm pf} + (1 - \\lambda_{\\rm pf}) x_{\\rm pf} = (1-\\lambda_{\\rm pf}) x_{\\rm pf} \\geq 0\n\\]\n식의 마지막은 각각 \\(\\lambda_{\\rm pf} &lt; 1\\) 그리고 \\(x_{\\rm pf} \\geq 0\\)로부터 성립한다."
  },
  {
    "objectID": "posts/math-of/2019-12-20-Peron-Frobenius-2.html#some-applications",
    "href": "posts/math-of/2019-12-20-Peron-Frobenius-2.html#some-applications",
    "title": "Perron-Frobenius Theorem, part 2",
    "section": "Some Applications",
    "text": "Some Applications\n\nSteady-state growth rate\n투입계수 행렬 \\(A\\)를 지닌 어떤 경제를 상정하자. \\(A\\)가 생산적 행렬이라고 하자. 그리고 금기 초의 투입물 벡터를 \\(x_0\\)라고 하자. 금기 말에 생산물 벡터를 \\(x_1\\)이라고 하면, 아래의 관계가 성립한다.\n\\[\nx_0 = A x_1\n\\]\n보통 함수를 적을 때 왼쪽에 산출을 오른쪽에 투입을 적어서 약간 의아할 수 있다. 하지만,\n\\[\nA = [A_1, \\dotsc, A_i, \\dotsc, A_n]\n\\]\n\\(A_i\\)는 \\(A\\)의 컬럼 벡터를 나타난다. \\(a_{ij}\\)는 \\(j\\) 한단위를 생산하기 위해 필요한 투입 \\(i\\)를 나타낸다. 따라서,\n\\[\nAx = a_1 x_1 + \\dotsb + a_i x_i + \\dotsb + a_n x_n\n\\]\n는 \\(x_i\\)를 얻기 위해 필요한 투입 벡터들의 선형결합으로 이해하면 쉽다. 따라서 \\(x_0 = A x_1\\)이 성립한다. 이제 \\(x_0\\)가 \\(g\\)의 성장률로 성장한다고 하자. 즉, \\(x_0 = (1+g) x_0\\)이다. 이를 정리해서 쓰면 다음과 같다.\n\\[\nA x_0 = \\dfrac{1}{1+g} x_0\n\\]\n이때 \\(\\dfrac{1}{1+g}\\)는 아이겐밸류, \\(x_0\\)는 아이겐벡터임을 알 수 있다. \\(A\\)가 생산적 행렬이기 때문에 아이겐밸류는 \\([0,1)\\) 사이에 존재하게 된다. 따라서, \\(g = \\dfrac{1}{\\lambda}-1 &gt; 0\\)로 성장하게 된다.\n\n\nEquilibrium price\n투입계수 행렬이 \\(A\\)인 경제를 생각하자. 각 재화를 생산하는 기업의 이윤율이 모두 \\(\\pi\\)로 동일하다고 하자. 이때 가격 백터 \\(p = [p_1, \\dotsc, p_n]^T\\)가 균형 가격이 되기 위한 조건은 무엇일까? 우선 \\(i\\) 기업의 이윤을 따져보자. \\(i\\) 기업이 생산물 1 단위를 생산하기 위해 필요한 원자재는 (\\(i\\) 자신의 물건을 포함해) \\(n\\) 개이고 그 각각 필요량은 \\(a_{1i}, \\dotsc, a_{ni}\\)가 된다. 이들을 시장가격 \\(p_\\cdot\\)으로 조달해와야 하므로 1단위당 원자재의 가격은 \\(a_{1i} p_1 + \\dotsc + a_{ni} p_n\\)이 된다. 이제 원료 가격에 마크업 \\(\\pi\\)를 붙이면 이것이 해당 기업이 설정한 균형 가격이 된다. 즉,\n\\[\np_i = (1+\\pi)(a_{1i} p_1 + \\dotsc + a_{ni} p_n)\n\\]\n이를 행렬로 나타나면 다음과 같다.\n\\[\np = (1 + \\pi) A^T p\n\\]\n위 식에서 \\(p\\)는 \\(A^T\\)의 아이겐벡터이고 균등 이윤과 해당 아이겐밸류는 다음과 같다.\n\\[\n\\dfrac{1}{1+\\pi} = \\lambda_{\\rm pf}\n\\]\n아이겐벡터는 스케일링이 가능하다. 즉, 가격 벡터는 다루기 편한 방식으로 정규화화면 된다.[^1]\n\n\n\n\n통상적인 경우 임의의 재화 하나의 가격을 1로 둔다. 이런 재화를 단위재(numeraire)라고 부른다."
  },
  {
    "objectID": "posts/math-of/2019-05-17-math-pca.html",
    "href": "posts/math-of/2019-05-17-math-pca.html",
    "title": "Math Behind PCA",
    "section": "",
    "text": "PCA를 차원을 축소하는 방법으로 막연하게 이해하지 말자. PCA 역시 다른 방법처럼 어떤 목적 함수를 최적화하는 방법의 하나다.\nPCA는 \\(k\\) 개의 피처를 어떤 스크린 벡터 위에 쏴서 이를 단순화하겠다는 것이다. 이렇게 투영된 이미지와 원래 벡터와의 거리를 최소화하는 과정에서 분산 최대화라는 PCA의 새로운 목적 함수가 도출된다.\nPCA가 스크린으로 활용할 벡터가 하나가 아니라고 할 때, 이 여러 개의 스크린 벡터를 활용해 거리를 최소화하는 과정(즉 분산의 합을 극대화하는 과정)에서 eigenvalue와 eigenvector가 등장한다."
  },
  {
    "objectID": "posts/math-of/2019-05-17-math-pca.html#tl-dr",
    "href": "posts/math-of/2019-05-17-math-pca.html#tl-dr",
    "title": "Math Behind PCA",
    "section": "",
    "text": "PCA를 차원을 축소하는 방법으로 막연하게 이해하지 말자. PCA 역시 다른 방법처럼 어떤 목적 함수를 최적화하는 방법의 하나다.\nPCA는 \\(k\\) 개의 피처를 어떤 스크린 벡터 위에 쏴서 이를 단순화하겠다는 것이다. 이렇게 투영된 이미지와 원래 벡터와의 거리를 최소화하는 과정에서 분산 최대화라는 PCA의 새로운 목적 함수가 도출된다.\nPCA가 스크린으로 활용할 벡터가 하나가 아니라고 할 때, 이 여러 개의 스크린 벡터를 활용해 거리를 최소화하는 과정(즉 분산의 합을 극대화하는 과정)에서 eigenvalue와 eigenvector가 등장한다."
  },
  {
    "objectID": "posts/math-of/2019-05-17-math-pca.html#pca",
    "href": "posts/math-of/2019-05-17-math-pca.html#pca",
    "title": "Math Behind PCA",
    "section": "PCA",
    "text": "PCA\n“차원의 저주”라는 표현이 있다. 언뜻 보면 자명한 이야기 같지만, 곰곰이 생각해보면 모호한 구석이 많다. 관찰 수는 많을수록 좋은데 차원은 관찰과 어떻게 다를까? 쉽게 생각해보자. 관찰 수란 활용할 수 있는 샘플의 수다. 이는 당연히 많을수록 좋다. (물론 미칠 듯이 많으면 새로운 문제가 발생하긴 하나, 대체로 우리는 샘플이 부족해서 문제를 겪는다) 하나의 샘플에서 관찰 가능한 변수가 7개라고 해보자. 샘플 수에 따라서는 적당해 보일 수 있다.\n그런데, 샘플은 100 개인데, 한 샘플에서 관찰할 수 있는 포인트가 1,000 개라고 치자. 이 데이터 셋은 10만 개의 개별 포인트를 지닌 제법 큰 데이터 셋이지만 별 쓸모는 없다. 관찰 수에 비해서 개체의 차원이 지나치게 크기 때문이다. 이럴 경우 어떻게 차원을 줄이면 좋을까? 쉽게 생각할 수 있는 방법은 1,000 개의 특징들을 좀 줄여보는 것이다. 주성분분석(Principal Component Analysis)은 이를 위해 필요한 방법이다."
  },
  {
    "objectID": "posts/math-of/2019-05-17-math-pca.html#objective-function-for-pca",
    "href": "posts/math-of/2019-05-17-math-pca.html#objective-function-for-pca",
    "title": "Math Behind PCA",
    "section": "Objective function for PCA?",
    "text": "Objective function for PCA?\n대체로 많은 PCA에 관한 설명들이 원래 하고 싶은 게 무엇인지에 관해 묻지 않는다. PCA란 데이터의 특성을 압축하는 방법이라는 이야기만 할 뿐. 수학적으로 말하면 목적함수에 관한 질문이고 우리는 먼저 이 질문에 집중하겠다.\n대체로 통계학의 알고리듬은 목적 함수를 최적화하는 형태이다. PCA도 마찬가지다. 관찰 대상 \\(i\\)(for \\(i = 1, \\dotsc, n\\))에 관한 \\(k\\) 차원의 피처 벡터 \\(x_i\\)가 있다고 하자. \\(x_i\\)는 \\(k \\times 1\\)의 칼럼 벡터이다. 앞으로 특별한 언급이 없는 이상 앞으로 \\(x_i\\) 벡터는 \\(n\\)개의 관찰에 대한 평균으로 구성된 벡터 \\(\\mu = [\\mu^1~\\mu^2~\\dotsc~\\mu^k]^T\\)를 뺀 값이라고 간주하자. 즉, \\(X_i\\)가 평균을 빼지 않은 \\(i\\) 라고 할 때,\n\\[\n\\underset{k \\times 1}{x_i} = \\left[\\begin{array}{c}{X^1_i - \\mu^1} \\\\ {X^2_i - \\mu^2} \\\\ {\\vdots} \\\\ {X^k_i - \\mu^k}\\end{array}\\right]\n\\]\n이제 해당 피쳐를 쏠 스크린으로 활용할 유닛 벡터를 \\(w\\)라고 하자. 유닛 벡터란 \\(w \\cdot w = 1\\)를 의미한다. 여기서 스크린이라는 의미는 개별 관찰이 지니는 특징을 이 벡터로 프로젝션해서 그 특징을 요약하겠다는 것이다. 우리에게 익숙한 회귀분석 역시 \\(y_i\\)라는 관찰을 설명변수 \\(\\mathbf X\\)가 형성하는 선형 부분공간으로 프로젝션하는 방법이다. \\(x_i\\)를 \\(w\\)로 스칼라 프로젝션 하면 다음과 같다.\n\\[\n\\operatorname{Proj}_{w}(x_i) = \\dfrac{w}{\\Vert w \\Vert} \\cdot x_i = w \\cdot x_ i\n\\]\n이 스칼라 프로젝션의 벡터 \\(w\\) 위의 이미지, 즉 벡터 프로젝션은 \\((w \\cdot x_i) \\dfrac{w}{\\Vert w \\Vert}\\)이다. \\(\\Vert w \\Vert = 1\\)이므로 결국 벡터 프로젝션은 \\((w \\cdot x_i) w\\)가 된다.\n이 프로젝션 스칼라 값 혹은 프로젝션 벡터의 기댓값은 아래와 같이 0이 된다. \\[\n\\dfrac{1}{n} \\sum^n_{i=1} (w \\cdot x_i) = \\left( \\dfrac{1}{n} \\sum_{i=1}^n x_i \\right)\\cdot w = \\boldsymbol{0} \\cdot w = 0\n\\]\n벡터 \\(x_i\\)와 이 프로젝션 벡터 사이의 유클리드 거리를 구해보자.\n\\[\n\\begin{aligned}\n\\Vert x_i - (w \\cdot x_i) w \\Vert^2 & = \\Vert x_i \\Vert^2 - 2 (w \\cdot x_i)(w \\cdot x_i) +  \\Vert w \\Vert^2 \\\\\n& = \\Vert x_i \\Vert^2 - 2 (w \\cdot x_i)^2 +  1\n\\end{aligned}\n\\]\n모든 관찰 수 \\(n\\)에 대해서 거리를 구해 더하면 이것이 일종의 MSE(Mean Squared Error)가 된다.\n\\[\n\\begin{aligned}\n\\mathrm{MSE}(w) & = \\dfrac{1}{n}\\sum_{i=1}^n \\left( \\Vert x_i \\Vert^2 - 2(w \\cdot x_i)^2 + 1 \\right)  \\\\\n& = \\underbrace{1 +  \\dfrac{1}{n}\\sum_{i=1}^n \\Vert x_i \\Vert^2}_{(\\ast)}  - 2\\dfrac{1}{n}\\sum_{i=1}^n  (w \\cdot x_i)^2\n\\end{aligned}\n\\]\nMSE를 최소화하는 게 목표라고 하자. 목적함수를 최적화 하기 위해서는 \\(w\\)를 조정할 수 있다. \\((*)\\)는 \\(w\\)를 포함하고 있지 않으므로 나머지 부분을 최소화하면 MSE가 극대화된다.\n\\[\n\\dfrac{1}{n} \\sum_{i=1}^n (w \\cdot x_i)^2 = \\left(\\dfrac{1}{n}  \\sum_{i=1}^n w \\cdot x_i \\right)^2 + \\underset{i}{\\mathrm{Var}}[w \\cdot x_i]\n\\]\n이 식이 성립하는 이유는 일반적으로 \\(\\mathrm{Var}(y)= \\mathrm{E}(y^2) - (\\mathrm{E}(y))^2\\)이 성립하기 때문이다. 그리고 앞에서 보았듯이 \\(\\mathrm{E} (w \\cdot x_i) = 0\\) 성립한다. 따라서 MSE를 최소화한다는 것은 \\(\\mathrm{Var}_i [\\cdot]\\)을 최대화하는 것과 같게 된다. PCA에 분산에 관한 이야기가 자꾸 나오는 것은 이 때문이다."
  },
  {
    "objectID": "posts/math-of/2019-05-17-math-pca.html#variance-maximization",
    "href": "posts/math-of/2019-05-17-math-pca.html#variance-maximization",
    "title": "Math Behind PCA",
    "section": "Variance Maximization",
    "text": "Variance Maximization\n\nVariance-covariance matrix\n왜 분산이 등장하는지 그리고 왜 분산이 최대화되어야 하는지 파악했으니, 이제 이를 계산해볼 차례다. 아래 행렬 \\(X\\)를 통해 쉽게 분산-공분산 행렬을 나타낼 수 있다. \\(x_i^j\\) 에서 \\(i (=1,2,\\dotsc, n)\\)는 관찰을, \\(j(=1,2,\\dotsc,k)\\)는 피쳐를 나타낸다.\n\\[\n\\underset{n \\times k}{X} =\n\\begin{bmatrix}\n    {x_1}^T \\\\\n    {x_2}^T  \\\\\n    \\vdots \\\\\n    {x_n}^T\n\\end{bmatrix} =  \n\\begin{bmatrix}\n{x_1^1} & {x_1^2} & {\\cdots} & {x_1^k} \\\\\n{x_2^1} & {x_2^2} & {\\cdots} & {x_2^k}\\\\\n{\\vdots} & {\\vdots} & {\\ddots} & {\\vdots} \\\\\n{x_n^1} & {x_n^2} & {\\cdots} & {x_n^k}\n\\end{bmatrix}\n\\]\n\\[\n\\begin{aligned}\n\\dfrac{1}{n-1} \\underset{(k \\times n) (n \\times k)}{X^{T} X} =\n\\begin{bmatrix}\n\\text{cov}(x^1, x^1) & \\text{cov}(x^1, x^2) & \\cdots & \\text{cov}(x^1, x^k) \\\\\n\\text{cov}(x^2, x^1) & \\text{cov}(x^2, x^2) & \\cdots & \\text{cov}(x^2, x^k) \\\\\n\\text{cov}(x^k, x^1) & \\text{cov}(x^k, x^2) & \\cdots & \\text{cov}(x^k, x^k)\n\\end{bmatrix} = \\Sigma, \\text{~where}\n\\end{aligned}\n\\]\n\\[\n\\text{cov}(x^i, x^j) = \\dfrac{1}{n-1}\\sum_{k=1}^{n} x^i_k x^j_k\n\\]\n\n\neigenvalue는 어떻게 등장하나?\n임의의 단위 벡터 \\(w\\)와 그 프로젝션을 다시 적어보자. 표기를 간단히 하기 위해서 상첨자는 생략한다. 이제 하나의 벡터가 아니라 \\(X\\)라는 매트릭스 전체에 대해서 프로젝션을 하면 아래와 같다.\n\\[\\operatorname{Proj}_{w} (X) = \\dfrac{X w}{\\Vert w \\Vert} \\in {\\mathbb R}^{n \\times 1}\\]\n이제 극대화의 목적은 이렇게 프로젝션된 이미지의 분산을 가장 크게 만드는 것이다. 앞서의 가정에 따라서 \\(\\mathrm{E}(X) = 0\\)가 성립함을 기억해두자.\n\\[\n\\begin{aligned}\n\\mathrm{Var}(X {w}) &= \\frac{1}{n-1}(X {w})^{T}(X {w}) \\\\\n&=\\frac{1}{n-1} {w}^{T} X^{T} X {w} =\\frac{1}{n-1} {w}^{T}\\left(X^{T} X\\right) {w} \\\\\n&={w}^{T}\\left(\\frac{X^{T} X}{n-1}\\right) {w} \\\\\n&={w}^{T} \\Sigma {w}\n\\end{aligned}\n\\]\n그런데, \\(w\\)는 단위벡터임으로 \\(w \\cdot w = 1\\)이다. 이를 제약 조건으로 두고 제약 하의 극대화 문제를 정식화하면 다음과 같다.\n\\[\n{\\mathcal L} =w^{\\operatorname T} \\Sigma w - \\lambda (w \\cdot w -1)\n\\]\n\\[\n\\begin{aligned}\n\\dfrac{\\partial \\mathcal L}{\\partial w} & = 0 = 2 \\Sigma w - 2\\lambda w \\\\\n\\dfrac{\\partial \\mathcal L}{\\partial \\lambda} & = 0 = w \\cdot w - 1\n\\end{aligned}\n\\]\n1계 조건을 다시 보자.\n\n\n사실 여기 적은 1계 조건은 엄밀하지 않다. 이해를 돕기 위해서 여러가지를 퉁쳤는데, 최적화의 결과는 동일하다. 보다 상세한 도출은 여기를 참고하시기 바란다.\n\\(\\Sigma w = \\lambda w\\) 조건이 흥미롭다. 1계 조건이 정확하게 아이겐밸류(eigenvalue, 고유값)와 아이겐벡터(eigenvector, 고유벡터)를 구하는 방법이다. 어떤 매트릭스가 있을 때 해당 매트릭스의 분산-공분산 행렬의 아이겐밸류와 아이겐벡터를 구하면 그 아이겐밸류와 벡터가 바로 MSE를 최적화해주는 값이 된다. 이때 \\(w\\)는 아이겐벡터이며 \\(\\lambda\\)는 아이겐밸류가 된다. 아이겐밸류는 아래 식에서 보듯이 분산이다.\n\n\n흥미로운 일치를 확인하셨는지? 제약 하 극대화에서 라그랑쥬 승수와 아이겐밸류를 나타내는 수학 기호가 모두 \\(\\lambda\\)다. 약간 소름 돋는 대목이다. 일치는 여기서 끝나지 않는다. 라그랑쥬 승수는 제약 하의 극대화에서 잠재 가격(shadow price)로 불리기도 한다. 이는 해당 조건이 제약하는 자원의 잠재적인 가치를 나타낸다. 이는 분산이 클수록 MSE가 작다는 PCA의 목적 함수의 해석과 일치한다.\n\\[\n\\operatorname{Var}(X w) = w^{\\mathrm T} \\Sigma w =  w^{\\mathrm T} (\\lambda w)  = \\lambda w \\cdot w = \\lambda\n\\]\n아마도 최적화 공부를 해본 사람이라면 갸우뚱할지 모르겠다. 1계 조건은 필요 조건이다. 즉, 극대화, 극소화 모두를 그 안에 담고 있을 수 있다. 그렇다면 2계 충분 조건을 따져야 하지 않을까? 그런데, 위 식에 대해서 사실 2계 충분 조건을 따지는 것이 쉽지 않다. 다만 이 문제는 다행스럽게도 지름길이 있다. 위에서 보듯이 1계 조건을 만족하는 \\(w\\)는 \\(\\Sigma\\)의 아이겐벡터다. 따라서 이 아이겐벡터에서만 극대값과 극소값이 존재한다. 1계 조건을 만족하는 아이겐벡터를 \\(\\omega\\)라고 하자.\n\\[\n\\begin{aligned}\n{\\mathcal L}(\\omega) & =\\omega^{T} \\Sigma \\omega - \\lambda (\\omega \\cdot \\omega -1) \\\\\n& = \\omega^T (\\Sigma w - \\lambda w) + \\lambda \\\\\n& = \\lambda\n\\end{aligned}\n\\]\n즉, 1계 조건을 만족하는 값에서 목적 함수의 값은 아이겐밸류 \\(\\lambda\\)가 된다. 그리고 위에서 보았듯이 \\(\\lambda\\)는 \\(Xw\\)의 분산이 되기 때문에 분산이 큰 값의 아이겐벡터가 목적 함수를 극대화하는 \\(w\\)가 된다.\n앞서 \\(\\lambda\\)가 분산이 된다고 말했다. 잠깐, 분산이라면 항상 0보다 커야 하는데, \\(\\lambda\\)가 0보다 크다는 보장이 있는가? 이 문제를 포함하여 앞에서 정리하지 못한 몇 가지 문제를 모아서 살펴보자.\n\n\nProperties of var-cov matrix\n분산-공분산 행렬은 아래와 같은 두 가지 특징을 지닌다.\n\n대칭 행렬\n우선, 분산-공분산 행렬이므로 대칭이다. 행렬이 대칭일 경우 아이겐밸류는 모두 실수이며 아이겐벡터들은 서로 직교(orthogonal)한다.\nFor \\(i, j \\in \\{ 1, 2, \\dotsc, k\\}~\\text{with}~i \\ne j, w^i \\cdot w^j = 0\\), and for \\(i \\in \\{ 1, 2, \\dotsc, k\\}~, w^i \\cdot w^i =1\\)\n여러개의 프로젝션 스크린 벡터들이 존재할 경우 해당 벡터들이 서로 직교하면 분산값의 합을 최대화하는 것과 MSE를 최소화하는 것이 같은 의미를 지닌다. 이 조건이 분산-공분산 행렬의 속성을 통해 성립한다.\n분산-공분산 행렬의 이 특징이 PCA의 흥미로운 점 하나를 드러난다. 2 차원 평면에서 사 분면을 떠올려보자. 사 분면을 구성하는 \\(x\\), \\(y\\) 축은 서로 직교한다. 2 차원 평면 위에 어떤 관찰에 대해서 PCA를 했다고 하자. PCA의 스크린으로 두 개를 사용했고, 해당 스크린이 아이겐벡터라면 이 두 벡터는 서로 직교한다. 즉, 원래 직교했던 두 축에서 직교하는 다른 두 축으로 좌표의 기준을 이동하는 개념이다. 즉 PCA는 분산을 가장 크게 하는 방식으로 좌표축을 이동하는 방법이라고 이해하면 좋겠다. PCA에 관한 소개에서 아래의 그림처럼 축을 돌린 예시가 자주 등장하는 까닭이기도 하겠다.\n\n\n하나 주의할 점이 있다. 이 그림은 차원 회전에 관한 것이지 차원 축소에 관한 것이 아니다. 즉, 변이가 잘 드러나도록 축을 회전할 수 있다는 예시다. 축소는 다른 문제인데, 아래 본문의 내용에서 보듯이 축을 돌려 변이를 상당 부분 설명했다면 변이의 설명력이 낮은 축들을 제거할 수 있다는 것이 차원 축소다.\n\n\n\nPositive-definite\n\\(\\Sigma\\)는 준양정행렬(positive semi-definite) 행렬이다. 즉,\n\\[\nx^T \\Sigma x \\geq 0 ~\\text{for any $x$.}\n\\]\n\n\n증명은 몹시 간단하다. \\(w^T \\Sigma w\\) 라고 하자. \\[\nw^T X^T X w = \\underset{\\text{닷 프로덕트}}{ (Xw)^T (Xw) } \\geq 0\n\\]\n이 경우 모든 아이겐밸류의 값은 음수가 되지 않는다. 앞서 아이겐밸류가 분산이 된다는 사실을 보았다. 아이겐밸류가 음수가 될 수 없고 따라서 분산이 될 수 있다."
  },
  {
    "objectID": "posts/math-of/2019-05-17-math-pca.html#principal-component",
    "href": "posts/math-of/2019-05-17-math-pca.html#principal-component",
    "title": "Math Behind PCA",
    "section": "Principal component?",
    "text": "Principal component?\n프로젝션 스크린 벡터 \\(w\\)에 따른 극대화 문제를 풀면 아이겐밸류와 아이겐벡터를 각각 하나씩 얻게 된다. \\(k\\) 개의 스크린 벡터 혹은 아이겐벡터가 가능하다고 할 때, 분산(아이겐밸류)이 큰 순서대로 아이겐벡터를 정렬한다고 생각해보자. 이렇게 정렬하면 프로젝션 스크린 벡터 중에서 MSE를 더 줄일 수 있는 벡터 순으로 정렬하는 셈이다. 이렇게 분산이 큰 순서대로 나열한 서로 다른 스크린벡터가 바로 주성분(pricipal component)다.\n\\(k\\) 개의 주성분 중에서 임의로 \\(l\\) 개를 취한다면(이게 차원 축소가 아닐까?), MSE를 낮추기 위해서는 분산이 큰 순서대로, 즉 아이겐밸류가 큰 순서대로 주성분을 취하면 된다. 이게 PCA를 직관적으로 이해하는 방법이다.\n그런데 한 가지 찜찜한 점이 남는다. 주성분은 이렇게 순서대로 취할 수 있다는 것은 주성분을 결합해서 더 큰 분산을 얻을 수 없을 때만 가능하다. 예컨대, \\(w_1\\)과 \\(w_2\\)를 적당히 선형결합해 분산을 높일 수 있다면 분산이 큰 순서대로 아이겐벡터를 선택한다는 논의는 깨지게 된다. 이 가능성을 살펴봐야 하겠다.\n프로젝션의 스크린으로 동원되는 벡터가 \\(w^1, w^2, \\dotsc, w^k\\)라고 하자. 이 프로젝션을 통해 생성되는 벡터들이 이루는 부분공간은 다음과 같이 나타낼 수 있다.\n\\[\n\\sum_{j=1}^k \\underset{\\mathrm{가중치}}{( x_i \\cdot w^j) } w^j\n\\]\n\\(x_i\\)와 \\(w^j\\) 모두 \\(k \\times 1\\) 벡터임을 확인하고 가자. 이 녀석과 \\(x_i\\)의 MSE를 최소화하는 문제는 어떻게 될까? 계산이 다소 복잡하니 직관만 짚고 넘어가자.\n\n앞서 스크린이 하나였던 경우와 마친가지로 \\(x_i\\)와 저 값의 내적의 분산을 최대화 해야 한다.\n만일 \\(w_\\cdot\\)들이 서로 직교한다면, \\(w_i \\cdot w_j (i \\neq j)\\)는 0이 되어 사라질 것이고, \\(w_i \\cdot w_i\\)(=1)로 구성된 텀만 만게 된다. 결국\n스크린을 이루는 축들과 \\(x_i\\)의 크로스 프로덕트 값의 분산(\\(\\mathrm{Var} (x_i \\cdot w^j)\\))을 더한 값을 최대화하는 것이 MSE를 극소화 문제가 된다. 즉, 각각 \\(w^j\\)와 \\(x_i\\)의 닷 프로덕트의 분산을 최대화하면 된다. 즉,\n\n\\[\n\\underset{i}{\\text{Var}}[\\sum_{j=1}^k {( x_i \\cdot w^j) } w^j] = \\sum_{j=1}^k {\\lambda^j}  \n\\]"
  },
  {
    "objectID": "posts/math-of/2019-05-17-math-pca.html#마침내-차원-축소",
    "href": "posts/math-of/2019-05-17-math-pca.html#마침내-차원-축소",
    "title": "Math Behind PCA",
    "section": "마침내 차원 축소",
    "text": "마침내 차원 축소\n이제 마침내 차원 축소를 다룰 수 있다! 앞서 MSE 최소화 문제에서 보았듯이 분산이 클수록 좋다. 임의의 갯수로 주성분을 취한다고 할 때 의 기준은 분산이 큰 순서이고 분산은 아이겐밸류와 같다. \\(l(&lt;k)\\) 개의 주성분을 취할 때 취할 때 아이겐밸류가 큰 순서대로 취하면 되겠다.\n\n\n주성분의 갯수를 취하는 방법은 PCA에 관한 튜토리얼에서 항상 등장하는 주제이니 구글링을 해서 확인하시면 되겠다."
  },
  {
    "objectID": "posts/math-of/2019-05-17-math-pca.html#key-questions",
    "href": "posts/math-of/2019-05-17-math-pca.html#key-questions",
    "title": "Math Behind PCA",
    "section": "Key Questions",
    "text": "Key Questions\nQ1. MSE 최소화는 무엇으로 연결되는가?\n\n\\(Xw\\)의 분산을 최대화하는 것이다.\n\nQ2. 아이겐밸류 아이겐벡터는 어떻게 등장하는가?\n\n\\(Xw\\)의 분산을 \\(w^T w =1\\)의 제약하에서 극대화할 때 1계 조건에서 등장한다.\n\nQ3. 아이겐벡터와 아이겐밸류는 어떤 특징을 지니고 있는가?\n\n1계 조건에서 아이겐벡터와 아이겐밸류를 찾아야 하는 매트릭스는 var-cov 행렬 \\(\\Sigma\\)다. 그리고 이 행렬은 대칭행렬이며 Positive definite 행렬이다. 이 조건으로부터, 아이겐벡터들은 서로 orthogonal하고, 아이겐밸류는 모두 양수이다.\n\nQ4. 결국 PCA란 무엇인가?\n\n분산이 큰 순서대로 \\(k\\) 개의 주성분 중에서 임의로 \\(l(&lt;k)\\) 개의 아이겐벡터를 선택하는 것이다. 그리고 이 아이겐벡터는 일종의 피처에 관한 가중치로 이해할 수 있다."
  },
  {
    "objectID": "posts/math-of/2019-05-17-math-pca.html#resource",
    "href": "posts/math-of/2019-05-17-math-pca.html#resource",
    "title": "Math Behind PCA",
    "section": "Resource",
    "text": "Resource\n이 글은 아래 자료를 바탕으로 만들었습니다.\nhttps://www.stat.cmu.edu/~cshalizi/350/lectures/10/lecture-10.pdf"
  },
  {
    "objectID": "posts/stats-simple/2024-02-28-p-value.html",
    "href": "posts/stats-simple/2024-02-28-p-value.html",
    "title": "p값? 너무 믿지 마세요",
    "section": "",
    "text": "p값에 너무 의지하면 분석의 취지가 망가진다."
  },
  {
    "objectID": "posts/stats-simple/2024-02-28-p-value.html#tl-dr",
    "href": "posts/stats-simple/2024-02-28-p-value.html#tl-dr",
    "title": "p값? 너무 믿지 마세요",
    "section": "",
    "text": "p값에 너무 의지하면 분석의 취지가 망가진다."
  },
  {
    "objectID": "posts/stats-simple/2024-02-28-p-value.html#조건부-확률을-생각하라",
    "href": "posts/stats-simple/2024-02-28-p-value.html#조건부-확률을-생각하라",
    "title": "p값? 너무 믿지 마세요",
    "section": "조건부 확률을 생각하라!",
    "text": "조건부 확률을 생각하라!\np값을 이해할 때 가장 먼저 떠올려야 하는 것은 조건부 확률이다. 조건부 확률에서\n\\[\nP(A|B) \\neq P(B|A)\n\\]\n이다. \\(P(\\text{E}|H_0)\\)을 생각해보자. \\(H_0\\)이 영가설(null hypothesis)이다. E는 증거를 뜻한다. 즉, 관측값이다. 우리가 아는 p값이란 영가설이 맞다고 가정할 때 E라는 증거를 관측할 확률이다. 이는 당연히 \\(P(H_0|\\text{E})\\)와는 다르다.\n“P의 비극”은 이 둘을 혼동하는 데에서 시작한다.\n\nAn example\n\n\n\n\n\n\n\n\n\n1~20까지 숫자를 지닌 D&D용 주사위\n\n\n\n\n \n\n\n\n\n\n녹색 모자!\n\n\n\n\n\n\n\n이 사례는 여기에서 가져왔다. 보다 익살스러운 사례로 xkcd 882: Significant도 참고하자.\nD&D라는 게임은 다각 20면을 지닌 주사위를 쓴다. 만일 “녹색 모자를 쓰고 주사위를 던질 때 20이 더 잘나온다”는 대립가설(alternative hypothesis)을 세웠다고 하자. 이때 영가설은 “녹색 모자를 쓰는 것은 주사위의 결과에 영향을 미치지 않는다”가 될 것이다. 그리고 녹색 모자를 쓴 채 주사위를 던져서 20을 얻었다. 이때 p값은 어떻게 될까? 0.05이다.\n\\[\nP(\\text{E}|H_0) = \\dfrac{1}{20} = 0.05\n\\]\n(약간 에누리를 더해서) 10% 유의 수준에서 해당 영가설을 넉넉하게 기각할 수 있다! 좀 더 사악한 경우를 상상해볼까? 녹색 모자를 쓰고 주사위를 1000번 쯤 던졌다고 하자. 주사위가 정상이라면 50번 정도는 20이 나왔을 것이다. 해당 장면들만을 편집해서 마치 20번을 던진 것처럼 보이게 만들었다고 하자. 보라, 놀라운 녹색 모자의 효과를!\n“녹색 모자를 쓰고 주사위를 던질 때 20이 더 잘 나온다!” 당연히 이상하고 잘못된 진술이다. 수많은 D&D 플레이어들은 이 말이 틀리다는 것을 경험적으로 너무나(!) 잘 알고 있다.\n\n\n베이즈 정리\n사실 우리가 알고 싶은 것이 p값이 아닐지 모른다. 우리는 이 값과는 다른 조건부 확률, 즉 \\(P(H_0 | \\text{E})\\)을 알고 싶은 것이다! 영가설을 기각할 때 찾아오는 쾌감을 기억하는가? 이 쾌감이 근거를 지니려면 \\(P(\\cdot)\\)의 값이 충분히 작아야 한다!\n이 문제를 다루는 데에는 베이즈 정리를 활용할 수 있다.\n\\[\nP(H_0|\\text{E}) = \\dfrac{P(\\text{E}|H_0)P(H_0)}{P(\\text{E}|H_0)P(H_0) + P(\\text{E}|\\neg H_0)P(\\neg H_0)}\n\\]\n우리가 알고 싶은 답, 즉 E를 관찰할 때 \\(H_0\\)가 맞을 확률에서 p값(\\(P(\\text{E}|H_0\\))은 한 부분으로 들어갈 뿐이다. 앞서 살펴본 D&D의 사례를 응용해보자. 녹색 모자가 주사위에 어떤 물리적인 조작을 가할 수 있는 것이 아닌 이상 \\(P(H_0)=0.99\\)이라고 기대할 수 있다고 하자. 따라서 \\(P(\\neg H_0) = 1 - P(H_0) = 0.01\\)이다. 앞서 보았듯이 p값은 0.05이다. 만일 녹색 모자가 어떤 이유에서건 영향을 줄 수 있다면 \\(P(\\text{E}|\\neg H_0)=1\\)라고 강하게 기대할 수 있다.\n\\[\nP(H_0|\\text{E}) = \\dfrac{0.05 * 0.999}{0.05 * 0.999 + 1 * 0.001} \\approx 0.98\n\\]\n20이라는 주사위의 관찰이 영가설의 신뢰성을 약간 훼손시키긴 했지만 그 정도가 심하지는 않다. 이게 대체로 상식적인 결과일 것이다.\n\n\n이거 보면 뭔가 떠오르는 게 있는 분들이 있을지도 모르겠다. 유병률이 낮은 질병의 경우 테스트의 정확도(겅정력)이 높더라도 해당 테스트의 양성이 바로 아주 높은 확률의 질병 발생을 의미하지는 않는다. 이게 베이즈 정리의 신비인 것이다.\np값은 중요하다! 하지만 p값을 강한 의미로 해석하려면, 즉 영가설이 어느 정도나 옳은지의 맥락에서 해석하려면 베이즈 정리의 눈, 즉 사전 지식 혹은 믿음의 맥락에 입각해 한번 더 생각해봐야 할 것이다."
  },
  {
    "objectID": "posts/stats-simple/2024-02-28-p-value.html#p값은-검정의-성과-지표가-아니다",
    "href": "posts/stats-simple/2024-02-28-p-value.html#p값은-검정의-성과-지표가-아니다",
    "title": "p값? 너무 믿지 마세요",
    "section": "p값은 검정의 ’성과 지표’가 아니다!",
    "text": "p값은 검정의 ’성과 지표’가 아니다!\np값이 낮으면 낮을수록 좋은 것일까? 이 질문은 미묘하다. p값은 오탐률(false positive)을 통제한다. 여기서 오탐이란 “영가설이 맞는데도 이를 잘못 기각”하는 경우를 의미한다. 오탐률이 낮으면 당연히 좋다. 즉 오탐이 아니라 탐지 못한 것이 맞는 경우, 즉 영가설이 참이면 p값은 아무런 의미가 없다. 다시 베이즈 정리로 돌아가보자.\n\\[\nP(H_0|\\text{E}) = \\dfrac{P(\\text{E}|H_0)P(H_0)}{P(\\text{E}|H_0)P(H_0) + P(\\text{E}|\\neg H_0)P(\\neg H_0)}\n\\]\np값은 \\(P(\\text{E}|H_0)\\)이다. 통계적인 검정력(statistical power)이란 \\(P(\\text{E}|\\neg H_0)\\)를 의미한다. p값과 같은 맥락에서 해석해보자. 해당 증거를 보고 영가설을 올바르게 기각할 확률이 된다. 즉 이는 true positive의 확률을 의미한다. 그리고 prevalence, 즉 유병률은 \\(P(\\neg H_0)\\)이다. 이는 검정하려는 가설에 관한 일종의 사전 정보 혹은 믿음을 나타낸다.\n\n1종 오류와 2종 오류\n위의 내용은 1종 오류, 2종 오류 그리고 이진 분류와 관련되어 있다.\n\n\n\n\n\n\n\n\n\nTable 1: Error types\n\n\n\n\n\n\n\n\n\n\n\n\\(H_0\\) is true\n\\(H_0\\) is false\n\n\n\n\nreject \\(H_0\\)\nfalse positive(\\(\\alpha\\))\ntrue positive(\\(1-\\beta\\))\n\n\naceept \\(H_0\\)\ntrue negative(\\(1-\\alpha\\))\nfalse negative(\\(\\beta\\))\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nTable 2: Binary classification\n\n\n\n\n\n\n\n\n\n\n\nNegative\nPositive\n\n\n\n\npredicted Positve\nfalse positive(\\(\\alpha\\))\ntrue positive(\\(1-\\beta\\))\n\n\npredicted Negative\ntrue negative(\\(1-\\alpha\\))\nfalse negative(\\(\\beta\\))\n\n\n\n\n\n\n\n\n\n몇 가지 용어를 정리해보자.\n\nfalse positive의 허용 확률 \\(\\alpha\\)가 1종 오류(type I error)이다. 유의수준(significance level)이라고도 한다.\nfalse negative의 허용 확률 \\(\\beta\\)가 2종 오류(type II error)이다. \\((1-\\beta)\\)를 통계적 검정력(statistical power)이라고 한다.\n세계의 상태가 결정되어 있다고 하자. 결정된 세계의 상태는 위의 표에서 두 열 중 하나다. 따라서 해당 열에 대한 허용 확률의 합은 1이 된다. 즉, 오탐(false positive) + 정미탐(true negative)의 확률, 그리고 정탐(true positive) + 미탐(false negative)의 확률은 각각 1이어야 한다.\n행의 합은 그렇지 않다. 왜그럴까?\nNegative의 크기를 \\(N\\), Positive의 크기를 \\(P\\)라고 하자. 이때 유병률은 \\(\\frac{P}{P+N}\\)이다. 이 값은 \\(P(\\neg H_0)\\)와 같다.\n\n\n\n\\(\\alpha\\)와 \\(\\beta\\)의 tradeoff\n우리가 알고 싶은 값을 \\(\\alpha\\), \\(\\beta\\)를 넣어서 다시 써보자.\n\\[\nP(H_0|\\text{E}) = \\dfrac{\\alpha P(H_0)}{\\alpha P(H_0) + (1-\\beta)P(\\neg H_0)}\n\\]\n증거 E를 관찰했을 때 영가설을 기각할 확률을 높이려면 위의 확률을 낮춰야 한다. \\(\\alpha\\)와 \\(\\beta\\)가 모두 낮을수록 해당 확률은 낮아진다. 그렇다면 이 둘을 모두 낮추면 좋지 않을까? 불행하게도 이는 불가능하다.\n\n\n\n\n\n\n \n\n\n\n\n\n기준 점을 잡게 되면 1종 오류와 2종 오류의 트레이드오프가 발생한다.\n\n\n\n\n \n\n\n\n위 그림을 보자. 영가설을 잡았고 이론적인 대립가설은 그림과 같다. 만일 영가설과 대립가설이 충분히 떨어져 있어서 겹치는 부분이 없다면 행복할 것이다. 두 에러 모두 0으로 만드는 것이 가능하다. 하지만 이런 경우는 대체로 흥미롭지 않은 경우다. 통계적인 작업이 필요하지 않은 자명한 경우가 거의 대분일 것이다. 만일 사람들이 흥미로워하는데도 이런 통계학적인 상태에 있는 주제가 있다면 어서 논문을 쓰시기 바란다!\n위 그림에서 보듯이 “any mean”을 기준으로 1종 오류와 2종 오류를 구별할 수 있는데, 두 분포가 겹치는 부분이 있는 이상 둘의 트레이드오프는 어쩔 수 없이 발생한다.\n\n\n출판 편향과 p값\n유병률이 낮은 경우 대부분의 관찰은 true negative에 속하게 된다. 이 경우는 흥미를 끌지 못하게 된다. 세간에서 “당연한 걸 뭘 보냐”라는 경우다.” 유병률이 낮을 때 유병(positive)을 관찰한다면 이건 주목을 끌게 된다. 이렇게 주목을 끌게 되는 그리고 주목을 끌고자 하는 저자의 의도가 출판 편향(publication bias)을 낳는다.\n출판된 positive 중에서 true positive의 비율이 얼마나 될까? 이를 결정하는 것이 \\(\\alpha\\), 즉 유의 수준과 통계적 검정력이 된다. 대략 \\(\\alpha=0.1\\) 그리고 통계적 검정력(\\(1-\\beta\\))를 0.6 정도를 가정하자. 이 정도도 관대한 것이다. 그리고 출판 편향이 문제가 되는 상황을 보기 위해서 유병률은 0.1 정도라고 가정하자. \\(N=900, P=100\\)이라고 가정하고 각각의 셀의 숫자를 채워보자.\n\n\n\n\n\\(H_0\\) is true (\\(N=900\\))\n\\(H_0\\) is false (\\(P=100\\))\n\n\n\n\nreject \\(H_0\\)\nfalse positive(0.1), 90\ntrue positive(0.6), 60\n\n\naccept \\(H_0\\)\ntrue negative(0.9), 810\nfalse negative(0.4), 40\n\n\n\nPositive라고 보고한 결과, 즉 \\(H_0\\)을 reject한 연구 중에서 오직 40%(\\(\\frac{60}{90+60}\\))만 타당한 결과다. 나머지 60%는 false positive에 속한다!\n\n\np값은 낮을수록 좋은가?\n만일 \\(P(\\text{E}|\\neg H_0)\\) 혹은 \\((1-\\beta)\\)의 값이 고정되어 있다면, p값, 즉 \\(\\alpha\\) 혹은 \\(P(\\text{E}|H_0)\\)값이 낮을수록 \\(P(H_0|\\text{E})\\) 역시 작아질 것이다. 하지만 위에서 보듯이 영가설과 대립가설의 분포가 겹쳐 있는 상황에서 p값이 작다는 것 즉, 1종 오류를 아주 작게 줄인다는 것은 대개의 경우 2종 오류를 늘이게 된다. 즉, \\((1-\\beta)\\)는 작아지고 우리가 마음 속으로 바라고 있는 값, E라는 증거가 발견되었는데도 영가설 \\(H_0\\)가 맞을 확률은 높아진다. 이 때 \\(\\alpha\\)와 \\(\\beta\\) 중에서 어떤 것이 \\(P(H_0|\\text{E})\\) 변화에 더 큰 영향을 줄것인지는 따져봐야 알 수 있다."
  },
  {
    "objectID": "posts/stats-simple/2024-02-28-p-value.html#그래서-뭐-어쩌라고",
    "href": "posts/stats-simple/2024-02-28-p-value.html#그래서-뭐-어쩌라고",
    "title": "p값? 너무 믿지 마세요",
    "section": "그래서, 뭐 어쩌라고?",
    "text": "그래서, 뭐 어쩌라고?\n통계학은 그 단어와 학문이 품은 ‘모호함’ 만큼 조심스럽게 해석하고 접근해야 한다. 세상의 모든 일이 그렇지만 언제나 ’맥락’이 중요하다. 오늘의 교훈이다. p값 역시 그러한 맥락을 잊지 말자.\n\n\n\n1~20까지 숫자를 지닌 D&D용 주사위\n녹색 모자!\n기준 점을 잡게 되면 1종 오류와 2종 오류의 트레이드오프가 발생한다."
  },
  {
    "objectID": "posts/stats-simple/2022-05-30-markov-chebyshev.html",
    "href": "posts/stats-simple/2022-05-30-markov-chebyshev.html",
    "title": "Markov and Chebyshev Inequalities",
    "section": "",
    "text": "\\[\n\\def\\E{{\\mathbb E}}\n\\def\\V{{\\mathbb V}}\n\\def\\ES#1{\\overline{#1}}\n\\]"
  },
  {
    "objectID": "posts/stats-simple/2022-05-30-markov-chebyshev.html#tl-dr",
    "href": "posts/stats-simple/2022-05-30-markov-chebyshev.html#tl-dr",
    "title": "Markov and Chebyshev Inequalities",
    "section": "TL; DR",
    "text": "TL; DR\n\n마르코프 부등식과 체비쇼프 부등식 정리한다.\n대수의 법칙을 증명할 때 유용하다."
  },
  {
    "objectID": "posts/stats-simple/2022-05-30-markov-chebyshev.html#markov-inequality",
    "href": "posts/stats-simple/2022-05-30-markov-chebyshev.html#markov-inequality",
    "title": "Markov and Chebyshev Inequalities",
    "section": "Markov Inequality",
    "text": "Markov Inequality\nFor \\(X \\in \\mathbb R^+\\), \\[\nP(X \\geq t) \\leq \\dfrac{\\E(X)}{t}\n\\]"
  },
  {
    "objectID": "posts/stats-simple/2022-05-30-markov-chebyshev.html#chebyshev-inequality",
    "href": "posts/stats-simple/2022-05-30-markov-chebyshev.html#chebyshev-inequality",
    "title": "Markov and Chebyshev Inequalities",
    "section": "Chebyshev Inequality",
    "text": "Chebyshev Inequality\n\\[\nP(\\vert X - \\mu \\vert \\geq k) \\leq \\dfrac{\\sigma^2}{k^2}\n\\]"
  },
  {
    "objectID": "posts/stats-simple/2022-05-30-markov-chebyshev.html#어디에-써먹나",
    "href": "posts/stats-simple/2022-05-30-markov-chebyshev.html#어디에-써먹나",
    "title": "Markov and Chebyshev Inequalities",
    "section": "어디에 써먹나?",
    "text": "어디에 써먹나?\n약한 버전의 LLN(대수의 법칙)을 증명할 때 체비쇼프의 부등식을 쓴다. 만일 \\(X_1, X_2, \\dotsc, X_n\\)이 iid를 따르고 \\(\\E (X_i^2) &lt; \\infty\\)라고 가정하자. 이때, 확률 극한의 정의를 따라, 표본 통계량 \\(\\ES{X}_n\\)가 임의의 양수 \\(\\epsilon\\)에 대해서 다음을 증명하면 대수의 법칙이 성립한다.\n\n\niid란 indeendent and indentically distributed를 의미한다. 즉, for \\(i, j \\in \\{1, 2, \\dotsc, n\\}\\), \\(X_i, X_j(i \\neq j)\\) 의 각 확률 변수가 독립적이며, \\(X_i\\)가 모두 동일한 분포에서 추출됨을 의미한다.\n\\[\n\\lim_{n \\to \\infty} P(\\vert \\ES{X}_n - \\mu \\vert \\geq \\epsilon) = 0\n\\]\n\n증명\n체비쇼프 부등식을 그대로 써보자.\n\\[\nP(\\vert \\ES{X}_n - \\mu \\vert \\geq \\epsilon) \\leq \\dfrac{\\E\\lbrack(\\ES{X}_n-\\mu)^2\\rbrack}{\\epsilon^2}\n\\]\n\\[\n\\begin{aligned}\n\\mathbb E \\lbrack(\\ES{X}_n - \\mu)^2\\rbrack = & \\mathbb E \\Big\\lbrace \\Big\\lbrack \\dfrac{1}{n^2}(\\sum_{i=1}^{n}(X_i - \\mu))^2\\Big\\rbrack\\Big\\rbrace \\\\\n= & \\dfrac{1}{n^2} \\sum_{i=1}^n \\sum_{j=1}^n \\mathbb E (X_i - \\mu)(X_j - \\mu) \\\\\n= & \\dfrac{1}{n^2} \\sum_{i=1}^{n}\\mathbb E (X_i - \\mu)^2 \\\\\n= & \\dfrac{\\sigma^2}{n}\n\\end{aligned}\n\\]\n\n\n보다 상세한 유도 과정은 여기를 참고하라.\n위의 결과를 이용하면,\n\\[\nP(\\vert \\ES{X}_n - \\mu \\vert \\geq \\epsilon) \\leq \\dfrac{\\sigma^2}{n \\epsilon^2}\n\\]"
  },
  {
    "objectID": "posts/stats-simple/2022-05-30-markov-chebyshev.html#proof-of-chebshev-inequality",
    "href": "posts/stats-simple/2022-05-30-markov-chebyshev.html#proof-of-chebshev-inequality",
    "title": "Markov and Chebyshev Inequalities",
    "section": "Proof of Chebshev Inequality",
    "text": "Proof of Chebshev Inequality\n\\(P(\\vert X - \\mu \\vert \\geq k) = P\\lbrack (X - \\mu)^2 \\geq k^2 \\rbrack\\)가 성립한다.\n마르코프 부등식에 의하여,\n\\[\nP\\lbrack (X - \\mu)^2 \\geq k^2 \\rbrack \\leq \\dfrac{\\E \\lbrack (X-\\mu)^2 \\rbrack}{k^2} = \\dfrac{\\sigma^2}{k^2}\n\\]\n따라서\n\\[\nP(\\vert X - \\mu \\vert \\geq k) \\leq \\dfrac{\\sigma^2}{k^2}\n\\]"
  },
  {
    "objectID": "posts/stats-simple/2022-05-30-markov-chebyshev.html#proof-of-markov-inequality",
    "href": "posts/stats-simple/2022-05-30-markov-chebyshev.html#proof-of-markov-inequality",
    "title": "Markov and Chebyshev Inequalities",
    "section": "Proof of Markov Inequality",
    "text": "Proof of Markov Inequality\n이산 확률변수와 연속 확률변수 모두에 대해서 증명을 해야 한다. 이산을 잘 이해하면 연속의 경우로 확장 가능하다.\n\\[\n\\E (X) = \\sum_{x=0}^{\\infty} x P(X=x)\n\\]\n임의의 상수 \\(t\\)에 대해서,\n\\[\n\\begin{aligned}\n\\E(X) & = \\sum_{x=0}^{t-1} x P(X=x) + \\sum_{x=t}^{\\infty} x P(X=x) \\\\\n& \\geq \\sum_{x=t}^{\\infty} x P(X=x) \\\\\n& \\geq \\sum_{x=t}^{\\infty} t P(X=x) \\\\\n& = t \\sum_{x=t}^{\\infty} P(X=x) \\\\\n& = t P(X \\geq t)\n\\end{aligned}\n\\]\n따라서,\n\\[\nP(X \\geq t) \\leq \\dfrac{\\E(X)}{t}\n\\]"
  },
  {
    "objectID": "posts/machine-learning/2020-04-19-classification-metrics.html",
    "href": "posts/machine-learning/2020-04-19-classification-metrics.html",
    "title": "Metrics for Binary Classification",
    "section": "",
    "text": "자꾸 까먹어서 기회가 될 때 한번 정리해두고자 한다.\n전공이 아니어서 그런가, 자꾸 까먹는다."
  },
  {
    "objectID": "posts/machine-learning/2020-04-19-classification-metrics.html#footnotes",
    "href": "posts/machine-learning/2020-04-19-classification-metrics.html#footnotes",
    "title": "Metrics for Binary Classification",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n멀티 클래스의 경우에 관해서는 여기를 참고하라.↩︎"
  },
  {
    "objectID": "posts/regression/2019-11-10-understanding-logit-regression.html",
    "href": "posts/regression/2019-11-10-understanding-logit-regression.html",
    "title": "Understanding Logit Regression",
    "section": "",
    "text": "로짓 회귀는 우리가 알던 그 ’회귀’와 다르다!\n로짓 회귀는 아래와 같은 데이터 모형에 기반을 둔 추정법이다.\n\n\\[\n\\ln \\dfrac{p(\\boldsymbol{x_i})}{1-p(\\boldsymbol{x_i})} =\\boldsymbol{x_i}\\boldsymbol{\\beta}\n\\]\n\n회귀식의 계수 \\(\\boldsymbol{\\beta}\\)를 해석할 때 주의하자. 이를 통상적인 회귀 분석의 계수(한계 효과)처럼 해석하려면 별도의 계산이 필요하다."
  },
  {
    "objectID": "posts/regression/2019-11-10-understanding-logit-regression.html#tl-dr",
    "href": "posts/regression/2019-11-10-understanding-logit-regression.html#tl-dr",
    "title": "Understanding Logit Regression",
    "section": "",
    "text": "로짓 회귀는 우리가 알던 그 ’회귀’와 다르다!\n로짓 회귀는 아래와 같은 데이터 모형에 기반을 둔 추정법이다.\n\n\\[\n\\ln \\dfrac{p(\\boldsymbol{x_i})}{1-p(\\boldsymbol{x_i})} =\\boldsymbol{x_i}\\boldsymbol{\\beta}\n\\]\n\n회귀식의 계수 \\(\\boldsymbol{\\beta}\\)를 해석할 때 주의하자. 이를 통상적인 회귀 분석의 계수(한계 효과)처럼 해석하려면 별도의 계산이 필요하다."
  },
  {
    "objectID": "posts/regression/2019-11-10-understanding-logit-regression.html#로짓-회귀-제대로-알고-있나",
    "href": "posts/regression/2019-11-10-understanding-logit-regression.html#로짓-회귀-제대로-알고-있나",
    "title": "Understanding Logit Regression",
    "section": "로짓 회귀, 제대로 알고 있나?",
    "text": "로짓 회귀, 제대로 알고 있나?\n기계 학습을 배우게 되면, 로짓 회귀는 첫 챕터에서 그냥 쓱 지나치기 쉽다. 이어 등장하는 랜덤 포레스트, SVM, 뉴럴넷 등이 더 진보된 방법으로 보이기 때문이다. 로짓 회귀는 단순하면서도 강력한 방법이다. 나는 분류(classification)의 문제에 접근할 때 로짓 회귀를 먼저 해본다. 로짓 회귀에서 ’견적’이 나오면 그 질문 혹은 문제는 더 흥미로운 형태로 진화할 가능성이 높다. 반면 로짓 회귀에서 싹수가 없으면 더 복잡한 고급 방법도 소용이 없는 경우가 많다. 요컨대 로짓 회귀는 시간 낭비를 막는 일종의 ’맛보기’로서도 유용하다."
  },
  {
    "objectID": "posts/regression/2019-11-10-understanding-logit-regression.html#로짓-함수는-어떻게-등장하나",
    "href": "posts/regression/2019-11-10-understanding-logit-regression.html#로짓-함수는-어떻게-등장하나",
    "title": "Understanding Logit Regression",
    "section": "로짓 함수는 어떻게 등장하나?",
    "text": "로짓 함수는 어떻게 등장하나?\n로짓 회귀는 말 그대로 로지스틱 함수(logistic function)를 활용하는 회귀 분석이라는 뜻이다. 로지스틱 함수는 어디서 어떻게 등장할까? 로짓 회귀의 데이터 형태부터 살펴보자. 종속 변수, 반응(response), regressand 등 다양한 형태로 불리는 식의 좌변은 0 또는 1로만 되어 있다. 어떤 상태라면 1, 그렇지 않으면 0이다. 이때 0 또는 1은 값 자체로 의미를 지니지 않는다. 이는 범주형 변수로서 True or False와 같은 이항 변수로 이해하면 좋겠다. 식의 우변에는 통상적인 독립 변수, 예측 변수(predictor)가 등장한다.\n\n\n생각난 김에 짬을 내 회귀식에서 좌변과 우변을 지칭하는 용어를 정리해보자. 취향에 맞춰서 쓰되 일관성만 갖추면 되겠다.\n\n\n\n좌변\n우변\n\n\n\n\n\\(y\\)\n\\(x\\), \\(\\boldsymbol X\\)\n\n\ndependent variable\nindependent variables\n\n\nresponse variable\npredictor variable\n\n\nregressand\nregressor\n\n\ncriterion\ncovariate\n\n\npredicted variable\ncontrolled variable\n\n\nmeasured variable\nmanipulated variable\n\n\nexplained variable\nexplanatory variable\n\n\nexperimental variable\nexposure variable\n\n\nresponding variable\ncovariate\n\n\noutcome variable\ncovariate\n\n\noutput variable\ninput variable\n\n\nendogenous variable\nexogenous variable\n\n\ntarget\nfeature\n\n\nlabel\nfeature\n\n\n\n\n어떤 경우 OLS는 곤란한가?\n\n\n\n\n\n\n \n\n\n\n\n\n로지스틱 리그레션이 필요한 순간\n\n\n\n\n \n\n\n\n독립 변수가 하나인 모형을 가정하고 위의 그림을 보자. 종속 변수가 0, 1인 상태로 그대로 회귀 분석을 하면 그림의 왼쪽 같이 된다. 회귀식의 기울기를 구할 수 있으니 된 것 아니냐? 아니다. 앞서 0과 1은 값 그 자체로 의미를 지니지 않는다고 말했다. 그런데 이를 그대로 값으로 바꿔서 회귀 분석을 해도 좋은 것일까? 그러기에는 어딘가 찜찜하다.\n게다가 \\(x\\) 값에 따라서 회귀식의 예측치가 \\([0,1]\\)을 벗어날 수 있다. 임의로 계단 함수를 다시 얹어서 OLS(통상적인 최소자승법이라는 의미에서 Ordinary Least Squares라고 흔히 부른다)를 구제할 수도 있겠다. 즉,\n\\[\ns(\\beta x) =\n\\begin{cases}\n1 & \\text{if $\\beta x \\geq 1$}  \\\\\n0 & \\text{if $\\beta x &lt; 0$}\n\\end{cases}\n\\]\n회귀식의 예측을 확률에 맞게 임의로 꺾어주는 것이다. 이러한 과정을 조금 더 ‘부드럽게’ 혹은 보다 ‘그럴 듯하게’ 할 수 없을까?\n\n\n범주형에서 확률로\n앞서 0, 1은 값 자체로는 아무 의미를 지니지 않는다고 말했다. 통상적인 회귀 분석의 종속 변수는 실수 형태다. 그렇다면 0, 1을 실수로 바꾸면 어떨까. 범주형 변수가 결국 상태를 나타내는 것이라면 1이라는 상태를 지닐 ’확률’을 추정하는 문제로 바꿔 생각해볼 수 있겠다. 즉,\n\\[\np(y_i = 1 | \\boldsymbol{x_i}) = p(\\boldsymbol{x_i})\n\\]\n그런데 앞서 보았듯이 확률 값을 선형 회귀로 추정하는 데에는 어려움이 있다. 통상적인 회귀 모형의 특성을 유지하면서도 확률 값을 [0,1] 사이에 ‘잘’ 떨구는 일이 무척 귀찮다. 식을 아래와 같이 변형해보도록 하자.\n\\[\n\\dfrac{p(\\boldsymbol{x_i})}{1-p(\\boldsymbol{x_i})}\n\\]\n종속 변수를 이렇게 바꾸면 가능한 값의 범위가 \\([0, \\infty)\\)로 확장된다. 여기에 자연 로그를 적용해보자.\n\\[\n\\ln \\dfrac{p(\\boldsymbol{x_i})}{1-p(\\boldsymbol{x_i})}\n\\]\n이제 가능한 값의 범위가 \\((-\\infty, \\infty)\\)가 된다. 이제 보통의 선형 회귀를 적용해도 좋겠다.\n즉,\n\\[\n\\ln \\dfrac{p(\\boldsymbol{x_i})}{1-p(\\boldsymbol{x_i})} = \\underset{1 \\times k}{\\phantom{\\boldsymbol{\\beta}}\\boldsymbol{\\boldsymbol{x_i}} \\phantom{\\boldsymbol{\\beta}}}\\underset{k \\times 1}{\\boldsymbol{\\beta}}, ~k = 1,  2, \\dotsc, n\n\\]\n\\(n\\) 개의 관찰에 있을 때 이를 매트릭스 형태로 적으면 다음과 같다.\n\\[\n\\ln \\dfrac{p(\\boldsymbol{X})}{1-p(\\boldsymbol{X})} = \\underset{n \\times k}{\\phantom{\\boldsymbol{\\beta}}\\boldsymbol{X}\\phantom{\\boldsymbol{\\beta}}}\\underset{k \\times 1}{\\boldsymbol{\\beta}}\n\\]\n애석하지만 이 식은 우리에게 주어진 자료로는 추정할 수 없다. 좌변의 종속 변수를 얻으려면 확률 함수를 알아야 하는데 이 녀석은 영원히 미지의 사실이다. 따라서 위의 식은 선형 회귀를 적용할 수 있는 방법을 고안한 것일 뿐 실제로 추정 가능한 식이 아니다. 그렇다면, \\(\\boldsymbol{\\beta}\\)는 어떻게 구해야 할까?\n이 문제를 살펴 보기 전에 위의 모형에서 로지스틱 함수를 발견해보자. 위의 식에서 \\(p(x_i)\\)를 구해보자.\n\\[\n\\begin{aligned}\n\\ln \\dfrac{p(\\boldsymbol{x_i})}{1-p(\\boldsymbol{x_i})} & =\\boldsymbol{x_i}\\boldsymbol{\\beta} \\\\\n\\dfrac{p(\\boldsymbol{x_i})}{1-p(\\boldsymbol{x_i})}  & = e^{\\boldsymbol{x_i}\\boldsymbol{\\beta}} \\\\\np(\\boldsymbol{x_i}) & = \\dfrac{e^{\\boldsymbol{x_i}\\boldsymbol{\\beta}}}{1+e^{\\boldsymbol{x_i}\\boldsymbol{\\beta}}} \\\\\np(\\boldsymbol{x_i}) & = \\dfrac{1}{e^{-\\boldsymbol{x_i}\\boldsymbol{\\beta}} + 1}\n\\end{aligned}\n\\]\n앞서 본 그림의 오른쪽과 같은 형태의 로지스틱 함수가 도출된다. 요컨대, 로지스틱 함수는 독립 변수를 해당 사건이 발생할 확률과 연결시키는 장치다. 이렇게 보면 로지스틱 회귀는 이른바 일반 선형 모형(Generalized Linear Model)의 한 사례다. 일반 선형 모형이란 종속 변수, 즉 식의 왼쪽이 어려가지 이유에서 실수 값이 아닌 제한된 값 혹은 범주 값을 지닐 때 이를 여러가지 방법을 통해 실수로 바꾸는 방식으로 추정을 하는 방법이다. 지금까지 살펴본 방법이 그 사례의 하나다."
  },
  {
    "objectID": "posts/regression/2019-11-10-understanding-logit-regression.html#link-function",
    "href": "posts/regression/2019-11-10-understanding-logit-regression.html#link-function",
    "title": "Understanding Logit Regression",
    "section": "Link function",
    "text": "Link function\n말이 나온 김에 “링크 함수”를 한번 보고 가자. 위에서 보듯이, 사실 회귀 분석이란 실수의 범위를 지니는 좌변을 역시 변수의 선형결합을 통해 이루어진 우변으로 설명하려는 것이다. 그런데 만일 좌변의 영역이 실수 전체가 아니라면? 예를 들면 아래와 같다.\n\n절단 자료 (truncated): 지속 시간의 경우 0보다 큰 실수가 된다.\n범주형 자료: 이 경우는 수로 표현하려면 적절한 변형이 필요하다.\n정수형 자료\n\n이럴 때는 어떻게 해야 할까? 회귀 분석의 틀을 벗어나지 않으면서 가장 간단한 해결책은 좌변을 바꾸는 것이다. 좌변은 어떻게 바꿔야 할까? 우선 좌변에 올 것의 조건부 평균을 다음과 같이 두자. 로지스틱 회귀에서 이 조건부 평균이 해당 상태가 될 , 즉 1의 값을 지닐 확률과 같다.\n\\[\n\\mathrm E (y_i | \\boldsymbol x_i) =\\mu_i\n\\]\n그리고 우변의 경우 평범하게 다음과 같이 두자.\n\\[\n\\eta_i = \\beta_0 + \\beta_1 x_{i1}  + \\dotsb + \\beta_p x_{ip}\n\\]\n이 둘은 바로 연결이 안된다. 이 둘을 연결시켜주는 어떤 함수가 있다면? 즉,\n\\[\ng(\\mu_i) = \\eta_i = \\boldsymbol x_i^T \\beta\n\\]\n\\(g(\\cdot)\\)이 링크 함수에 해당한다. 로짓 회귀의 경우에는 \\(\\ln \\frac{p(x_i)}{1-p(x_i)}\\)에 해당한다. 링크 함수의 역함수는 뭐라고 부를까? 로짓 회귀에서 아래의 값에 해당한다.\n\\[\np(\\boldsymbol{x_i}) = \\dfrac{1}{e^{-\\boldsymbol{x_i}\\boldsymbol{\\beta}} + 1}\n\\]\n이는 평균 함수(mean function)이라고 부른다. 로짓 회귀의 경우는 이산 변수를 활용하기 때문에 확률 질량 함수가 곧 확률이 된다는 점을 기억해두자.\n\n삼단계\n위 과정이 세 가지 단계를 거쳤다는 점을 쉽게 알 수 있을 것이다.\n\\[\ny_i \\xrightarrow{\\rm prob.~function} \\mu_i \\xrightarrow{\\rm link~function} \\eta_i = \\boldsymbol x_i \\beta\n\\]\n원래 관찰값 \\(y_i\\)는 확률 (질량/밀도) 함수를 통해 \\(\\mu_i\\) 로 변형된다. 이는 다시 연결 함수를 통해서 선형 회귀가 가능한 형태로 변형된다.\n\n\n\\(y_i\\)가 어떤 특성을 지니는지에 따라서 다양한 형태의 \\(\\mu_i\\)가 가능하고, 여기에 적절한 연결 함수를 적용해야 한다. 이는 논의 범위를 벗어난다. 이 글을 참고하자."
  },
  {
    "objectID": "posts/regression/2019-11-10-understanding-logit-regression.html#계수는-어떻게-구하나",
    "href": "posts/regression/2019-11-10-understanding-logit-regression.html#계수는-어떻게-구하나",
    "title": "Understanding Logit Regression",
    "section": "계수는 어떻게 구하나?",
    "text": "계수는 어떻게 구하나?\n\\(\\hat{\\boldsymbol \\beta}\\)은 어떻게 구할 수 있을까? 현재까지 우리에게 주어진 조건을 보자.\n\n종속 변수의 관찰값은 0 또는 1이다.\n로짓 함수를 통해서 독립 변수를 해당 관찰의 확률과 연결시킬 수 있게 되었다.\n\n어차피 종속 변수를 실수로 바꿀 수 없는 이상 우리가 아는 선형 회귀 분석을 쓸 수는 없다. 그래서 이름과 달리 우리가 아는 ‘회귀 분석’, 즉 OLS를 여기서 쓸 수는 없다. 미안하다. 앞에서 거짓말 했다.\n\\[\n\\ln \\dfrac{p(\\boldsymbol{x_i})}{1-p(\\boldsymbol{x_i})} = \\underset{1 \\times k}{\\phantom{\\boldsymbol{\\beta}}\\boldsymbol{x_i}\\phantom{\\boldsymbol{\\beta}}}\\underset{k \\times 1}{\\boldsymbol{\\beta}}, ~k = 1,  2, \\dotsc, n\n\\]\n애초에 \\(\\boldsymbol \\beta\\)을 알고 있어야, 이 식으로부터 \\(p(\\cdot)\\)을 구해낼 수 있다. 그런데 우리가 아는 회귀 분석이란 \\(y\\)와 \\(\\boldsymbol{\\rm X}\\)가 주어졌을 때 하는 것 아닌가? 회귀 분석의 좌변이 없기에 OLS로는 추정할 수 없다.\n그래서 로짓 회귀는 이름과 달리 \\(\\boldsymbol{\\beta}\\)의 추정치 \\(\\hat{\\boldsymbol\\beta}\\)를 구하는데 OLS의 방법을 쓰지 않는다. 로짓 회귀에서는 어떻게 \\(\\hat{\\boldsymbol\\beta}\\)를 얻는 것일까?\n\n확률 vs 우도\n잠시 로짓 회귀의 추정을 살펴보기 전에 확률과 우도의 차이점에 관해서 알아보자. 분포와 그 분포의 파리미터를 알고 있을 때 해당 샘플이 관찰될 확률을 구할 수 있다. 연속 확률변수 \\(x\\)가 따르는 어떤 분포가 있다고 할 때, 해당 분포를 요약하는 파라미터(정규분포라면 평균과 분산이다) \\(\\theta\\)에 대해서 \\(P(x_1 &lt; x &lt;x_2 | \\theta)\\)를 구한다면, 이것이 확률이다.\n우도(likelihood)는 무엇일까? 우도는 확률 분포의 수학적인 형태에서 관심의 대상을 바꾼 것이다. 위의 연속 확률변수의 예에서 \\(P(\\theta | x_1 &lt; x &lt; x_2)\\)가 우도가 된다. 하나의 관찰 \\(x_i\\)에 대해서는 확률 밀도함수 \\(f(\\theta | x = x_i)\\)를 우도로 정의할 수 있다. 연속 확률변수가 아니라 이산 확률변수라면, 확률 질량함수가 될 것이고 이 경우에는 확률과 같다.\n요컨대 주어진 것(conditioning), 즉 무엇을 파라미터로 볼 것인지의 차이에 따라서 확률과 우도의 정의가 달라진다. 다시 정리해보자.\n\n\n\n명칭\n주어진 것\n변수\n형태\n\n\n\n\n\n확률\n분포의 파라미터(\\(\\theta\\))\n관찰값\n\\(P(x_1 &lt; x &lt; x_2 | \\theta)\\)\n\n\n\n우도\n관찰값\n분포의 파라미터(\\(\\theta\\))\n\\(P(\\theta|x_1 &lt; x &lt; x_2)\\)\n\n\n\n\n\n\n연속확률 변수의 경우 하나의 관찰값에 대해서 확률은 이론적으로 정의되지 않지만, 우도는 정의된다. 이 경우 우도는 확률 밀도함수 \\(f(\\theta|x=x_i)\\)를 따르게 된다.\n\n\n최대 우도 추정(maximum likelihood estimation)\n다시 문제로 돌아오자. 우리는 0, 1 즉 존재/비존재의 특징을 지니는 변수를 갖고 있다. 그리고 이 녀석은 이산 확률 분포를 따르기 때문에 우도 역시 그냥 확률이 되고, 이는 베르누이 분포를 따른다. 즉, 해당 확률이 발생할 확률 \\(p\\)일 때 발생하면 1, 아니면 0이 된다. 베르누이 분포의 확률 질량 함수를 간단하게 표현하는 방법은 없을까?\n\\[\nL(y_i) = p(\\boldsymbol{x_i}; \\boldsymbol{\\beta})^{y_i} (1-p(\\boldsymbol{x_i}; \\boldsymbol{\\beta}))^{1-y_i}\n\\]\n위와 같은 식으로 간단히 해결된다. 위 식에서 \\(y_i\\)가 1이면 \\(p(\\cdot)\\)가, 0이면 \\(1-p(\\cdot)\\)가 할당된다. 이제 우리는 \\(n\\) 개의 관찰에 관해서 식의 좌변에는 0,1을 갖고 있다. 각각의 시행이 독립적이라고 가정하면 주어진 형태의 데이터를 관찰하게 될 우도는 이 확률을 곱한 것과 같다. 즉,\n\\[\nL(y|{\\boldsymbol X}) = \\prod_{i = 1}^{n}  L(y_i) = \\prod p(\\boldsymbol{x_i}; \\boldsymbol{\\beta})^{y_i} (1-p(\\boldsymbol{x_i}; \\boldsymbol{\\beta}))^{1-y_i} = L(\\boldsymbol{\\beta}|y, {\\boldsymbol X})\n\\]\n\\(\\boldsymbol{\\beta}\\)에 따라서 우도가 달라지게 되므로 우도 함수가 일종의 목적 함수가 된다. 우도를 극대화해주는 \\(\\boldsymbol{\\beta}\\)가 최대 우도 추정치, 즉 MLE(MLE, maximum likelihood estimator) \\(\\hat{\\boldsymbol\\beta}\\) 이다. 즉,\n\\[\n\\hat {\\boldsymbol \\beta} = \\text{arg max }{L({\\boldsymbol \\beta}|y, {\\boldsymbol X})}\n\\]\n\n\n간혹 목적 함수, 즉 우도 함수가 비선형이라서 목적 함수의 최대화를 달성하는 해 \\(\\hat{\\boldsymbol\\beta}\\)를 축약형(reduced form)으로 구하기 힘들다는 내용을 접하곤 한다. 이는 반쪽만 맞다. 반례로 선형 회귀 모형에서 에러 항이 정규 분포를 따른다고 가정하면 최대 우도 추정을 적용할 수 있다. 정규 분포의 우도 역시 비선형이지만, 축약형 해를 쉽게 구할 수 있다. 이때 MLE \\(\\hat{\\boldsymbol\\beta}\\)은 통상적인 방법으로 구한 OLS 추정량와 동일하다. 본문에서 말했듯이, 이는 수치적인 방법이 아니라 분석적인 방법을 통해 축약형으로 도출 가능하다. 여기를 참고하라. 왜 로짓 회귀에서는 축약형 해를 구할 수 없을까? 우도 추정에서 우리가 관심이 있는 것은 목적함수를 극대화하는 \\(\\hat{\\boldsymbol\\beta}\\) 값이지 우도 자체가 아니다. 따라서 원래의 우도를 적절한 형태로 변형해도 변형된 목적함수를 극대화해주는 \\(\\hat{\\boldsymbol\\beta}\\)가 바뀌지 않는다면 목적 함수를 변형해도 괜찮다. 때로는 변형이 계산을 쉽게 바꿔준다. 정규분포는 오일러 수(\\(e\\))의 지수 위에 최적화에 필요한 파라미터가 모두 포함되어 있다. 따라서 원래 목적함수에 \\(\\ln(\\log_e)\\)를 취하면 곱셈이 덧셈으로 변하고 \\(e\\) 위에 지수로 올라가 있단 파라미터들이 앞으로 내려온다. 하지만 아래 식에서 보듯이 로짓 함수는 그렇지 않다.\n\\[\np(\\boldsymbol{x_i})  = \\dfrac{1}{e^{-\\boldsymbol{\\boldsymbol{x_i}}\\boldsymbol{\\beta}} + 1}\n\\]\n이 함수에 \\(\\ln\\)을 취한다고 해서 식이 단순해지지 않는다. 로짓 함수의 경우 우도 극대화에서 축약형을 해를 구할 수 있는 변형이 없기 때문에 해당 우도를 극대화하는 파라미터를 찾기 위해서는 수치 최적화(numerical optimization)를 활용한다. 수치 최적화의 자세한 내용과 사례는 이 글을 참고하라.\n\n\n계수의 의미는?\n보통 기계 학습의 맥락에서 로짓 회귀는 가장 원시적인 분류기(classifier)로 소개된다. 즉 \\(y_i\\)의 속성을 예측하는 분류 장치이기 때문에 \\(\\hat{\\boldsymbol\\beta}\\)에 특별한 의미를 부여하지 않는다. 하지만 회귀 분석을 인과관계의 추론의 활용해 온 여타 분야에서는 \\(\\hat{\\boldsymbol\\beta}\\)를 어떻게 해석할 것인지는 중요한 질문이다.\n먼저 OLS의 경우 변수를 어떻게 변형했는지에 따라서 다르지만, 대체적으로 \\(\\beta_i\\)는 해당 독립 변수 \\(x_i\\)의 한계 효과(marginal effect)로 해석할 수 있다. 즉, \\(x_i\\)가 한 단위 변할 때 이에 따른 \\(y_i\\)의 변화량을 의미한다. 그런데, 로짓 회귀에서는 이렇게 해석할 수 없다. 앞서 보았듯이, 로짓 회귀의 추정식은 다음과 같다.\n\\[\n\\ln \\dfrac{p(\\boldsymbol{x_i})}{1-p(\\boldsymbol{x_i})} = \\underset{1 \\times k}{\\phantom{\\boldsymbol{\\beta}}\\boldsymbol{\\boldsymbol{x_i}}\\phantom{\\boldsymbol{\\beta}}}\\underset{k \\times 1}{\\boldsymbol{\\beta}}, ~k = 1,  2, \\dotsc, n\n\\]\n흔히 좌변의 \\(\\dfrac{p(\\boldsymbol{x_i})}{1-p(\\boldsymbol{x_i})}\\)를 오즈(odds) 혹은 승산(勝計)이라고 부른다. 이때 \\(\\boldsymbol{\\beta} = [\\beta_1, \\dotsc, \\beta_j, \\dotsc, \\beta_k]\\)에서 \\(\\beta_j\\)는 독립 변수의 벡터 \\(\\boldsymbol{x_i}\\)에 속한 \\(x_j\\) 한 단위가 변할 때 오즈에 미치는 영향을 뜻한다.\n간혹 \\(\\beta_i\\)를 좌변의 상태를 변화시킬 확률의 변화로 해석하는 경우가 있는데 그렇게 하면 안된다. \\(x_i\\)의 변화가 상태를 0에서 1로 바꾸는 데 미치는 확률에 관심이 있다면, 아래의 두 가지에 유의하자.\n\nOLS의 경우 회귀식 자체가 선형이기 때문에 \\(\\beta_i\\)에 관한 해석이 쉽고 단순하다. 그냥 직선의 기울기다. 그런데 로짓 회귀에서는 그렇게 분명하지 않다. 추정하려는 식 자체가 비선형이므로 한계 효과를 구하기 위한 기울기를 ‘어디서’ 구할지가 문제가 된다. 측정 위치에 따라서 기울기가 달라지기 때문이다.\n도출하는 방법이 크게 어렵지는 않다. 측정에는 대체로 두 가지 방식이 많이 활용된다. 독립 변수 \\(x_i\\) 관찰값 별로 확률값의 변화를 추정한 뒤 이를 평균하는 방식이다. 반대로 독립 변수 값의 평균에서 한번만 \\(p_i\\)에 미치는 영향을 추정하는 방법이다. 통계 패키지가 대체로 두 방법을 모두 지원하니 필요할 경우 찾아서 값을 구하면 되겠다. 해석과 보고 시에는 역시 주의해야 한다. 만일 첫번째 방법으로 수행했다면, \\(x_i\\)의 1단위 변화가 평균적으로 확률에 미치는 영향으로 표현하는 게 비교적 오해를 덜 살 것이다.\n\n\n\n계수의 수학적인 이해\n이 부분이 부담스럽다면 넘어가도 좋다. 앞서 말한 한계 효과는 \\(\\frac{\\partial p}{\\partial x_j}\\)이다. 즉, 독립 변수 벡터의 한 변수\\(x_j\\) 가 한 단위 변할 때 확률 변화를 측정한다. 즉,\n\\[\np(\\boldsymbol{x_i}) = \\dfrac{1}{e^{-\\boldsymbol{x_i}\\boldsymbol{\\beta}} + 1}\n\\]\n이 녀석을 그대로 미분해보자. 먼저 아래와 같이 \\(p(\\cdot)\\)을 변형하자.\n\\[\n\\begin{aligned}\np(\\boldsymbol{x_i}) & = \\dfrac{1}{e^{-\\boldsymbol{x_i}\\boldsymbol{\\beta}} + 1} \\\\\n& = \\dfrac{e^{\\boldsymbol{x_i}\\boldsymbol{\\beta}}}{1 + e^{\\boldsymbol{x_i}\\boldsymbol{\\beta}}}\n\\end{aligned}\n\\]\n\\(\\boldsymbol x_i = [x^1, \\dotsc, x^k]\\)이고, \\(x^j\\)에 대해서 미분하면 아래와 같다.\n\\[\n\\dfrac{\\partial p(\\boldsymbol{x_i})}{\\partial x^j} = \\dfrac{\\beta_j e^{\\boldsymbol{x_i}\\boldsymbol{\\beta}}}{(e^{\\boldsymbol{x_i}\\boldsymbol{\\beta}} + 1)^2}\n\\]\n이처럼 한계 효과는 미분을 통해 간단히 도출할 수 있다. 앞서 말했던 두 가지 측정을 어떻게 구별할 수 있을지 다시 살펴보자.\n\\(\\boldsymbol{\\beta}\\)의 추정치로 MLE를 통해 구한 \\(\\hat{\\boldsymbol\\beta}\\)를 활용한다고 해도, 어떤 \\(\\boldsymbol{x_i}\\)에서 측정하는지에 따라서 값이 달라진다. 평균(marginal effect at mean)에서 한 번만 측정할 것인지 아니면 \\(n\\)개의 모든 데이터 포인트에 대해서 계산한 뒤 이를 평균(average marginal effect)할 것인지 등의 선택이 필요하다. 보통 후자를 많이 활용하는데, 통계 패키지마다 둘 모두를 구할 수 있는 옵션을 제공한다.\n\n\n\n로지스틱 리그레션이 필요한 순간"
  },
  {
    "objectID": "posts/regression/2022-05-26-total-and-parts.html",
    "href": "posts/regression/2022-05-26-total-and-parts.html",
    "title": "전체와 부분",
    "section": "",
    "text": "회귀 분석에서 ’통제’한다는 것의 의미를 전체와 부분이라는 시야에서 다시 음미해 보자.\n교란 요인(confounder)와 충돌 요인(collider)을 심슨의 역설과 벅슨의 역설로 연결해 생각해 보자."
  },
  {
    "objectID": "posts/regression/2022-05-26-total-and-parts.html#tl-dr",
    "href": "posts/regression/2022-05-26-total-and-parts.html#tl-dr",
    "title": "전체와 부분",
    "section": "",
    "text": "회귀 분석에서 ’통제’한다는 것의 의미를 전체와 부분이라는 시야에서 다시 음미해 보자.\n교란 요인(confounder)와 충돌 요인(collider)을 심슨의 역설과 벅슨의 역설로 연결해 생각해 보자."
  },
  {
    "objectID": "posts/regression/2022-05-26-total-and-parts.html#회귀-분석에서-통제한다는-것",
    "href": "posts/regression/2022-05-26-total-and-parts.html#회귀-분석에서-통제한다는-것",
    "title": "전체와 부분",
    "section": "회귀 분석에서 ’통제’한다는 것",
    "text": "회귀 분석에서 ’통제’한다는 것\n회귀 분석에서 독립 변수 혹은 설명 변수와 통제 변수의 차이는 개념적인 것이다. 즉, 내가 갖고 있는 분석의 초점 혹은 모델의 취지에 따라 결정되는 것이지 어떤 기계적인 방법이나 기준은 없다. 일단 ’통제’에 초점을 맞춰서 생각해 보자. 아래와 같은 간략한 회귀 모형을 생각해 보자.\n\\[\ny_i = \\alpha + \\beta x_i + \\gamma D_i + \\epsilon_i\n\\]\n\\(x_i\\)는 설명 변수, \\(D_i\\)는 통제 변수라고 하자. 이해를 돕기 위해서 \\(D_i\\)는 0, 1의 값을 갖는 더미 변수다. \\(D_i\\)를 통제한다는 것의 의미는 무엇일까? \\(x_i\\)가 \\(y_i\\)에 미치는 영향을 그냥 전체로 보지 않고 두 집단 별로 나눠서 보겠다는 것이다. 이때 최소자승법을 통해 계산되는 \\(\\beta\\)는 \\(D_i\\)로 구별되는 집단 각각의 효과를 구한 뒤 이를 적절하게 가중 평균한 값이 된다. ’통제’란 설명 변수의 효과를 보다 정교하게 보기 위해서 관찰을 통제 변수로 구성된 집단으로 나누는 것이라고 생각하면 쉽다. 카테고리로 구별된 집단뿐 아니라 연속 함수에 관해서도 비슷하게 이해하면 된다.\n\n\nAngrist와 Pischke가 이런 맥락에서 회귀 분석이 자동화된 짝짓기(matching) 기계라고 설명한 바 있다."
  },
  {
    "objectID": "posts/regression/2022-05-26-total-and-parts.html#confounder-and-simpsons-paradox",
    "href": "posts/regression/2022-05-26-total-and-parts.html#confounder-and-simpsons-paradox",
    "title": "전체와 부분",
    "section": "Confounder and Simpson’s Paradox",
    "text": "Confounder and Simpson’s Paradox\n먼저 심슨의 역설을 먼저 살펴보자. 아래는 웃자고 만든 그림인데 웃고 넘기기에는 아까운 중요한 통찰이 들어 있다.\n\n\n\n\n\n\n \n\n\n\n\n\n전체를 볼 것인가 부분을 볼 것인가?\n\n\n\n\n \n\n\n\n위 그림에서 심슨가족 전체를 보면 \\(x\\) 축 변인의 증가에 따라서 \\(y\\) 축 변인이 증가하는 형태를 취한다. 반면, 가족 구성원 하나하나에 대해서는 반대의 관계를 취하고 있다. 심슨의 역설은 전체의 경향과 부분의 경향이 어긋나는 현상을 나타낸다. 조금 더 진지한 사례는 아래의 그림과 같다.\n\n\n\n\n\n\n \n\n\n\n\n\n심슨의 역설\n\n\n\n\n \n\n\n\n\n\n심슨의 역설에 흥미로운 사례는 미국 대학 입학의 남녀 학생 비율이다. 전체로 보면 남학생의 입학 비율이 여학생의 입학 비율보다 높았다. 그런데 개별 학과를 보면 여학생의 입학 비율이 대체로 남학생의 입학 비율보다 높았다. 서로 상반되는 듯 보이는 이 결과는 관심의 대상이 비율인데 반해서 학과 단위에서 작용하는 지원자들의 행태를 반영하지 못한 데 따른 것이다. 사례로는 여기와 여기를 참고하자.\n여기서 중요한 것은 역설 자체가 아니다. 역설의 함정에 빠지지 않고 어디에 포커스를 둘 것인지가 문제다. 만일 인구 구성의 각 그룹 별 경향을 평균적으로 살펴보는 것이 관심 사항이라면 위 그림에서 그룹 각각의 기울기를 평균한 값이 우리가 찾는 경향이다. 반대로 개별 그룹은 중요하지 않고 인구 전체가 관심사라면 개별 인구를 동일하게 보고 기울기를 찾는 게 맞다.\n\n\n\n\n\n\n \n\n\n\n\n\nDAG로 본 confounder & collider\n\n\n\n\n \n\n\n\n심슨의 역설은 DAG(Directed Acyclic Graph)를 통한 인과 추론에서 교란 요인(confounder)에 해당한다. A –&gt; Z가 현재 우리가 관찰하는 사실이다. 예를 들어, 교육 수준이 높을수록 졸업 후 취업 시 임금이 높다. 하지만 이는 교육 수준과 임금 모두에게 영향을 미치는 제3의 요인을 고려하지 않는 것일지도 모른다. 교육 수준과 임금 모두에게 영향을 주는 미처 파악하지 못한 변인, 예를 들어 능력치(C)가 있다고 하자. 이 능력치는 교육 수준과 임금 모두에게 영향을 준다.\n이 능력치를 그룹화해서 비교하는 게 가능하다고 가정하자. 이는 위의 심슨 가족 그림에서 가족별로 각 그룹을 나누는 것에 해당한다. 이렇게 능력치를 고려하면 교육은 오히려 졸업 후 임금을 낮출 수도 있다. C(능력치)라는 변수를 명백하게 고려하면 A(교육 수준)가 Z(임금)에 미치는 영향의 크기가 변할 수 있다. 예컨대, C를 고려하지 않았을 때 존재하던 A–&gt;Z의 효과가 사라지거나 기대했던 것과 반대의 효과를 지닐 수도 있다.\n\n그래도 심슨의 역설이 잘 이해가 되지 않는다면…\n벡터를 통해 그래프로 설명하는 사례가 직관적으로 잘 와닿고 이해하기도 좋다.\n\n\n\n\n\n\n \n\n\n\n\n\n붉은 벡터 1,2가 파란 벡터 1,2 보다 각각 더 높은 비율(벡터의 각도)를 지니고 있다. 그럼에도 둘을 결합했을 경우 파란 벡터가 더 높은 비율을 지니게 된다."
  },
  {
    "objectID": "posts/regression/2022-05-26-total-and-parts.html#collider-and-berksons-paradox",
    "href": "posts/regression/2022-05-26-total-and-parts.html#collider-and-berksons-paradox",
    "title": "전체와 부분",
    "section": "Collider and Berkson’s Paradox",
    "text": "Collider and Berkson’s Paradox\n\n\n\n\n\n\n \n\n\n\n\n\n전체를 볼 것인가 부분을 볼 것인가? 해당 밴드를 중심으로 SAT 점수가 높고 GPA도 높은 사람들은 더 좋은 학교에 진학했고, 낮은 사람들은 내가 관찰하는 샘플에서 탈랐했다. 그렇다면 이 관계는 실제로 존재하는 것일까?\n\n\n\n\n \n\n\n\n이번에는 벅슨의 역설을 살펴볼 차례다. 보통 수능 점수와 대학 성적은 별 관련이 없고 심지어 역의 상관성이 있다는 이야기를 접할 때가 있다. 이것은 맞는 주장인가? 이런 종류의 주장은 대체로 전체를 가정한다. ‘수능 점수와 대학 성적이 별로 상관이 없으니, 수능은 인간의 능력을 판단하는 지표로 별로 유용하지 않아.’ 이야기가 이렇게 흐르기 마련이다.\n위의 그림에서 보듯이 이러한 경향은 보편적인 주장이 아니라 특정한 집단 내에서만 타당한 주장이다. 위 그림에서는 내가 관찰하는 집단에 대해서 일종의 자기 선택이 일어난 경우에 해당한다. 내가 속한 밴드의 집단보다 수능 점수와 대학 성적이 모두 낮은 집단은 내가 속한 관찰 집단과는 다른 집단에 속한다. 반면 내가 속한 밴드보다 수능 점수도 높고 대학 성적도 우월한 집단도 마찬가지다.\n벅슨의 역설은 심슨의 역설과 동일하지만 반대의 측면을 지적한다. 전체 대해서 존재하는 경향성이 그룹으로 쪼개서 보면 반대가 되거나 사라지는 경우를 의미한다.\n벅슨의 역설에 해당하는 인과 추론의 DAG 사례가 충돌 요인(collider)이다. 변수를 고려하지 않았다면 전체에 관해서 온전한 주장이 성립했을 것이지만, 해당 변수를 고려해 그룹을 나누게 되면 오히려 잘못된 관계를 추정하게 된다.\n\n\n벅슨의 역설은 통제하지 않아야 할 변수를 통제할 때 발생하기도 하지만 많은 경우 표본 자체를 살피지 않은 데에서 생기기도 한다. 예를 들어 아래 그림을 보자.\n\n보통 배우가 되려면 연기 재능과 외모 둘 중 하나는 갖추어야 한다고들 한다. 이 말 자체는 맞지만 이를 확대 해석해서 외모와 연기 재능이 역의 상관성이 있다고 주장하는 경우가 있다. 이는 모집단 전체(모든 사람)에 대해서 타당한 말일까? 배우라는 집단으로 제한해보면 외모와 재능이 모두 미달되는 사람들은 배우가 아닌 다른 직업을 찾았을 가능성이 높다. 외모와 재능을 사분면으로 나눌 때 3 사분면에 위치한 사람들이 사라진 배우라는 집단에 대해서는 음의 상관성이 관찰되는 것처럼 보인다."
  },
  {
    "objectID": "posts/regression/2022-05-26-total-and-parts.html#중요한-것은-질문과-문제-설정",
    "href": "posts/regression/2022-05-26-total-and-parts.html#중요한-것은-질문과-문제-설정",
    "title": "전체와 부분",
    "section": "중요한 것은 질문과 문제 설정",
    "text": "중요한 것은 질문과 문제 설정\n이렇게 보면 심슨의 역설이든 벅슨의 역설이든 어떤 절대적인 규칙을 알려주는 것이 아니다. 관심을 두는 실증의 효과가 어떻게 작용하는 효과인가라는 질문이 먼저이다. 연구가 전체에 관한 특성을 묻는 질문이라면 충돌 요인(collider)이 변수에 없는지 살펴봐야 한다. 반면 집단을 나누는 것이 효과를 살펴보는 데 중요하다면 교란 요인(confounder)에 주의해야 한다. 충돌 요인이든 교란 요인이든 둘 다 실증 연구를 오도할 수 있지만 방해하는 수준이 다르다.\n이제 회귀 분석에서 통제한다는 것의 의미를 다시 정리해 보자. 회귀 분석의 모델링의 관점에서 보면 통제 변수와 설명 변수 간에 차이가 없다. 연구자의 의도에 비춰 볼 때 통제 변수는 설명 변수에 의도하지 않은 영향이 포함되는 것을 막아 준다. 앞서 말했듯이 회귀 분석은 통제 변수에 따라서 관찰을 여러 그룹으로 나누고 이에 따라서 설명 변수의 효과를 자동으로 계산하는 기계이다. 무엇인가를 통제하지 못했다는 것은 이 설명 변수에 그 효과까지 함께 포함되는 것을 의미한다. 이런 상황에서 발생할 수 있는 사례 중 하나가 심슨의 역설이다. 반면, 넣지 말아야 할 변수를 넣는다는 것은 설명 변수의 효과를 과장하는 결과를 낳는다. 그리고 특정한 인구 집단 혹은 경우에 발생한 일을 일반화해 주장하게 되는 것은 벅슨의 역설이다.\n이렇게 보면 심슨의 역설과 벅슨의 역설은 회귀 분석에서 모델링의 중요성 혹은 적절한 중도를 지키는 것이 얼마나 어려운지를 잘 보여준다. 회귀 분석의 길은 앵그리스트와 피스케 선생이 말했듯이 진정 “도”의 길이었던 것이다!\n\n\n\n전체를 볼 것인가 부분을 볼 것인가?\n심슨의 역설\nDAG로 본 confounder & collider\n붉은 벡터 1,2가 파란 벡터 1,2 보다 각각 더 높은 비율(벡터의 각도)를 지니고 있다. 그럼에도 둘을 결합했을 경우 파란 벡터가 더 높은 비율을 지니게 된다.\n전체를 볼 것인가 부분을 볼 것인가? 해당 밴드를 중심으로 SAT 점수가 높고 GPA도 높은 사람들은 더 좋은 학교에 진학했고, 낮은 사람들은 내가 관찰하는 샘플에서 탈랐했다. 그렇다면 이 관계는 실제로 존재하는 것일까?"
  },
  {
    "objectID": "posts/regression/2022-05-28-normality.html",
    "href": "posts/regression/2022-05-28-normality.html",
    "title": "정규성에 집착하지 말자.",
    "section": "",
    "text": "샘플 크기가 충분하다면 가설 검정 시 정규 분포 가정에 집착할 필요가 없다!\n가설 검정에서 중요한 것은 ’표본 (통계량)’의 분포이지 ’모집단’의 분포가 아니다!"
  },
  {
    "objectID": "posts/regression/2022-05-28-normality.html#tl-dr",
    "href": "posts/regression/2022-05-28-normality.html#tl-dr",
    "title": "정규성에 집착하지 말자.",
    "section": "",
    "text": "샘플 크기가 충분하다면 가설 검정 시 정규 분포 가정에 집착할 필요가 없다!\n가설 검정에서 중요한 것은 ’표본 (통계량)’의 분포이지 ’모집단’의 분포가 아니다!"
  },
  {
    "objectID": "posts/regression/2022-05-28-normality.html#정규-분포는-필요한-가정인가",
    "href": "posts/regression/2022-05-28-normality.html#정규-분포는-필요한-가정인가",
    "title": "정규성에 집착하지 말자.",
    "section": "정규 분포는 필요한 가정인가?",
    "text": "정규 분포는 필요한 가정인가?\n표분의 크기가 크지 않다면 가설 검정을 위해 (정규) 분포 가정이 필요하다. 하지만 표본의 크기가 어느 정도 이상일 때도 가설 검정을 위해 정규 분포 가정이 필요할까? 아래와 같은 다중 회귀 분석 모형을 보자.\n\\[\nY_i = \\alpha + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\dotsb + \\beta_n X_{ni} + \\epsilon_i\n\\]\n원래 정규 분포 가정은 \\(\\epsilon_i \\sim \\rm N (0, \\sigma^2)\\)이다. 그런데 우리는 이 가정을 어떻게 확인할 수 있을까?\n\n\\(Y_i \\sim \\rm N(\\cdot)\\)을 확인하면 될까? 원래의 가정은 오차항에 대한 가정이다. 앞에 여러 가지 변수의 작용으로 \\(Y_i\\)가 결정되므로 \\(Y_i\\)가 정규 분포를 따르는 것이 \\(\\epsilon_i\\)가 정규분포를 따르는 것의 충분 조건이 되지 않는다. 반면 \\(\\epsilon_i\\)가 정규 분포를 따른다고 해서 반드시 \\(Y_i\\)가 정규 분포를 따른다고 볼 수도 없다.\n\\(\\hat\\epsilon_i = Y_i - \\hat{Y}_i\\)가 정규 분포를 따르면 될까? 이 역시 \\(\\hat\\epsilon_i\\)이 정규 분포를 따른다고 해서 \\(\\epsilon_i\\)가 정규 분포를 따르리라고 볼 수 없다. \\(\\hat\\epsilon_i\\)는 회귀 분석의 모델링 아래 도출된 \\(\\epsilon_i\\)에 관한 추정치일 뿐이다. 추정치가 정규 분포를 따르는 것이 모수가 정규 분포를 따르는 것의 충분 조건이 되지는 않는다.\n\n회귀 분석에서 오차항은 모델링을 위한 일종의 ’가정’이다. 모델링의 가정은 받아들이는 것이지 검증하는 것이 아니다.\n\n\n표본이 크지 않을 때 즉 소 표본에 적합한 분석 방법을 찾는 것은 대 표본의 경우에 비해 까다로운 문제이다. 그런데 소 표본에서 회귀 분석은 그리 나쁜 분석 방법이 아니다."
  },
  {
    "objectID": "posts/regression/2022-05-28-normality.html#표본의-크기가-충분히-크다면",
    "href": "posts/regression/2022-05-28-normality.html#표본의-크기가-충분히-크다면",
    "title": "정규성에 집착하지 말자.",
    "section": "표본의 크기가 충분히 크다면…",
    "text": "표본의 크기가 충분히 크다면…\n만일 가정을 받아들일 수 없다면 회귀분석에서 가설 검정을 수행할 수 없을까? 그렇지 않다는 점을 우리는 이미 잘 알고 있다. 만일 표본의 크기가 충분히 크다면 오차 항의 정규 분포 가정 없이도 중심 극한 정리를 활용해 가설 검정을 할 수 있다.\n행렬을 활용해 나타낸 회귀 분석의 계수의 표본 추정량 \\(\\hat \\beta\\)는 다음과 같다. \\[\n\\hat \\beta = (X^T X)^{-1}(X y)\n\\]\n회귀 분석에서 \\(\\beta_i\\)를 검정하기 위한 \\(t\\)-통계량은 다음과 같이 정의된다.\n\\[\nt_i = \\dfrac{\\hat \\beta_i - \\beta}{S \\sqrt{(X^T X)_{ii}^{-1}}}\n\\]\nwith\n\\[\nS(y_i) = \\sqrt{\\dfrac{1}{n-k} \\sum_{i=1}^n (y_i -  \\hat y_i)^2}\n\\]\n여기서 \\(\\hat y_i = \\underset{(1 \\times k)}{x^r_i}\\underset{(k \\times 1)}{\\vphantom{x^r_i}\\hat\\beta}\\)이고, \\(x^r_i\\)은 \\(X\\)의 \\(i\\)’th 행(row) 벡터를 나타낸다.\n\\(n\\)이 커짐에 따라서 \\(t_i\\)의 분포는 \\(\\rm N(0,1)\\)에 점점 다가간다. ’중심극한 정리’가 가설 검정에서 중요한 이유가 여기에 있다.\n\n\n\\(\\sqrt{n}(\\beta_i - \\beta) \\overset{d}{\\longrightarrow} \\rm N (0, \\sigma_i)\\) 직관적으로 설명하면 \\(t_i\\)의 분자와 분모 모두 0으로 수렴한다. 이때 분자와 분모의 수렴이 일정한 분포, 정규 분포로 수렴한다는 것이 중심 극한 정리이다.\n요약하면 표본의 크기가 충분할 때 오차 항의 정규 분포 가정은 잊어도 좋다. 이 가정이 없어도 중심 극한 정리에 따라서 필요한 가설 검정을 수행할 수 있다. \\(t\\)-값과 표준 정규 분포에 근거한 개별 계수의 검정 그리고 F–값과 F 분포에 근거한 전체 계수의 검정이 모두 가능하다. \\(t\\)-값은 항상 \\(t\\) 분포를 따를까? 대 표본이라면, 대략 \\(n \\geq 30\\), t 분포라고 보든 정규 분포라고 보든 문제가 될 것이 없다. 따라서 대표본에서 굳이 \\(t\\) 분포를 고집할 필요는 없다. 사실 표본의 수가 어느 정도 이상이면 \\(t\\) 분포의 값과 정규 분포의 값의 차이는 무시해도 좋을 만큼 작다.\n\n\n표본의 크기가 얼마나 크면 될까? Schmidt and Finan의 연구에 따르면 회귀 모형의 경우 변수 당 대략 10개 이상의 관찰이 필요하다. 옆 그림에서 보듯이 모평균을 추정하는 문제에서 표본 평균의 크기가 30개 이상이면 CLT을 적용할 수 있다.\n\n\n\n\n\n\n \n\n\n\n\n\n표본의 크기가 커질수록 표본 통계량의 분포는 정규 분포에 근접한다.\n\n\n\n\n \n\n\n\n위 그림에서 보듯이 가설 검정에서 모집단의 분포는 우리의 관심사가 아니다. 우리의 관심사는 표본 통계량이고, 이 표본 통계량이 얼마나 믿을만 할지를 가설 검정을 통해 파악한다. 후자를 가능하게 하는 것이 대 표본의 표본 통계량에 대해 성립하는 중심 극한 정리인 셈이다.\n물론 주의해야 할 점이 있다. 중심 극한 정리를 제대로 쓰기 위해서는 표본 분산 \\(S^2\\)의 추정이 중요하다. 만일 어떤 이유에서건 분산의 추정에 방해하는 요인이 개입한다면 이에 따라서 가설 검정도 흔들릴 수 밖에 없다. 때문에 정규성보다는 등분산성 그리고 내생성 등에 더 신경을 쓰는 편이 낫다.\n\n\n\n\n\n\n \n\n\n\n\n\n\\(p=0.75\\)의 베르누이 시행을 \\(n\\)에 따라서 10,000 번 시뮬레이션한 분포"
  },
  {
    "objectID": "posts/regression/2022-05-28-normality.html#references",
    "href": "posts/regression/2022-05-28-normality.html#references",
    "title": "정규성에 집착하지 말자.",
    "section": "References",
    "text": "References\n\nThe Stats Geek\nLarge Sample Inference: 2. Asymptotic Normality\nNormality\nLinear regression and the normality assumption\n\n\n\n\n표본의 크기가 커질수록 표본 통계량의 분포는 정규 분포에 근접한다.\n\\(p=0.75\\)의 베르누이 시행을 \\(n\\)에 따라서 10,000 번 시뮬레이션한 분포"
  },
  {
    "objectID": "posts/math-simple/2022-07-03-ansys-candor-theorem.html",
    "href": "posts/math-simple/2022-07-03-ansys-candor-theorem.html",
    "title": "Cantor’s Theorem",
    "section": "",
    "text": "집합이 ’크다’는 것의 의미를 따져보자. 유한 집합의 경우 원소의 개수에 따라서 크기가 정해지므로 그 뜻이 자명하다. 그러면 무한 집합의 크기는 어떻게 비교할 수 있을까? 무한 집합에 대해서는 원소의 ’개수’라는 개념을 쓸 수 없다. 대신 크기의 비교를 위해서 카디널 수(cardinality)라는 개념을 쓴다. 무한 집합 \\(A\\)에 대해서 \\(|A|\\)라고 쓸 경우 이는 무한 집합의 크기, 즉 카디널 수를 의미한다.\n자세한 내용을 생략하면 두 집합 사이에 일대일 대응 함수가 존재할 경우 같은 카디널 수를 지닌다고 말한다. 그리고 자연수 집합(\\(\\mathbb N\\))은 가장 작은 무한 집합으로 정의한다.\n\n\n\n앞서 보았듯이 집합의 크기를 재려면 집합과 집합 사이에 어떤 짝짓기(mapping)가 가능한지를 살펴야 한다. 용어 및 번역어 먼저 정리하자.\n\n전사 함수(surjective function): onto function\n단사 함수(injective function): 일대일 함수(one-to-one function)\n전단사 함수(bijective function): 일대일 대응(one-to-one correspondence) one-to-one and onto\n\n“일대일 함수”와 “일대일 대응”은 단사 함수와 전단사 함수를 각각 뜻한다. 용어에 주의하자.\n\n\n고등학교에서 함수를 배울 때 “전사 함수”, “단사 함수”와 같은 구별이 필요한 이유는 별로 강조하지 않는다. 이러한 분류가 카디널 수를 따질 필요하다는 것을 미리 알았다면…\n\n\n\n\n\n\n \n\n\n\n\n\n카디널 수에 따른 함수의 구분\n\n\n\n\n \n\n\n\n단사 함수의 경우 정의역 \\(X\\)가 치역 \\(f(X)\\) 보다 ‘크지’ 않아야 존재할 수 있다. 전사함수가 존재하려면 반대로 \\(f(X)\\)가 \\(X\\) 보다 크지 않아야 한다. 해당 함수가 존재할 수 있는 정의역과 치역의 크기에 관한 필요 조건은 다음과 같다.\n\n전사 함수: \\(|X| \\geq |f(X)|\\)\n단사 함수: \\(|X| \\leq |f(X)|\\)\n전단사 함수: \\(|X| = |f(X)|\\)"
  },
  {
    "objectID": "posts/math-simple/2022-07-03-ansys-candor-theorem.html#prelim",
    "href": "posts/math-simple/2022-07-03-ansys-candor-theorem.html#prelim",
    "title": "Cantor’s Theorem",
    "section": "",
    "text": "집합이 ’크다’는 것의 의미를 따져보자. 유한 집합의 경우 원소의 개수에 따라서 크기가 정해지므로 그 뜻이 자명하다. 그러면 무한 집합의 크기는 어떻게 비교할 수 있을까? 무한 집합에 대해서는 원소의 ’개수’라는 개념을 쓸 수 없다. 대신 크기의 비교를 위해서 카디널 수(cardinality)라는 개념을 쓴다. 무한 집합 \\(A\\)에 대해서 \\(|A|\\)라고 쓸 경우 이는 무한 집합의 크기, 즉 카디널 수를 의미한다.\n자세한 내용을 생략하면 두 집합 사이에 일대일 대응 함수가 존재할 경우 같은 카디널 수를 지닌다고 말한다. 그리고 자연수 집합(\\(\\mathbb N\\))은 가장 작은 무한 집합으로 정의한다.\n\n\n\n앞서 보았듯이 집합의 크기를 재려면 집합과 집합 사이에 어떤 짝짓기(mapping)가 가능한지를 살펴야 한다. 용어 및 번역어 먼저 정리하자.\n\n전사 함수(surjective function): onto function\n단사 함수(injective function): 일대일 함수(one-to-one function)\n전단사 함수(bijective function): 일대일 대응(one-to-one correspondence) one-to-one and onto\n\n“일대일 함수”와 “일대일 대응”은 단사 함수와 전단사 함수를 각각 뜻한다. 용어에 주의하자.\n\n\n고등학교에서 함수를 배울 때 “전사 함수”, “단사 함수”와 같은 구별이 필요한 이유는 별로 강조하지 않는다. 이러한 분류가 카디널 수를 따질 필요하다는 것을 미리 알았다면…\n\n\n\n\n\n\n \n\n\n\n\n\n카디널 수에 따른 함수의 구분\n\n\n\n\n \n\n\n\n단사 함수의 경우 정의역 \\(X\\)가 치역 \\(f(X)\\) 보다 ‘크지’ 않아야 존재할 수 있다. 전사함수가 존재하려면 반대로 \\(f(X)\\)가 \\(X\\) 보다 크지 않아야 한다. 해당 함수가 존재할 수 있는 정의역과 치역의 크기에 관한 필요 조건은 다음과 같다.\n\n전사 함수: \\(|X| \\geq |f(X)|\\)\n단사 함수: \\(|X| \\leq |f(X)|\\)\n전단사 함수: \\(|X| = |f(X)|\\)"
  },
  {
    "objectID": "posts/math-simple/2022-07-03-ansys-candor-theorem.html#theorem",
    "href": "posts/math-simple/2022-07-03-ansys-candor-theorem.html#theorem",
    "title": "Cantor’s Theorem",
    "section": "Theorem",
    "text": "Theorem\n이제 칸토어의 정리를 살펴보자. 정리의 대단한 내용을 생각하면, 증명은 매우 간단하다. 임의의 집합 \\(A\\)에 대해서 멱집합 \\(\\mathcal P (A)\\)는 \\(A\\)보다 크다. 즉,\n\\[\n|\\mathcal P(A)| &gt; |A|.\n\\]"
  },
  {
    "objectID": "posts/math-simple/2022-07-03-ansys-candor-theorem.html#proof",
    "href": "posts/math-simple/2022-07-03-ansys-candor-theorem.html#proof",
    "title": "Cantor’s Theorem",
    "section": "Proof",
    "text": "Proof\n\\(A\\)가 유한 집합일 때는 자명하다. 즉, \\(N &lt; 2^N\\) for \\(N \\in \\mathbb N\\)이 성립한다. 이하에서는 \\(A\\)가 무한 집합이라고 전제한다.\n\nPart 1\n\\(|A| \\leq |\\mathcal P (A)|\\)를 증명하자. 이는 \\(f: A \\to \\mathcal P(A)\\)를 만족하는 단사 함수, 즉 일대일 함수가 존재하면 된다. \\(\\mathcal P(A)\\)에는 \\(a \\in A\\)의 \\(\\{ a \\}\\)가 존재한다. \\(f(x) := \\{ x \\}\\)는 \\(X \\to f(X)\\)인 단사 함수이다.\n\n\nPart 2.1\n\\(|A| \\neq |\\mathcal P (A)|\\)\n이는 귀류법(proof by contradiction)을 활용한다. 양변의 카디널 수가 같은 경우, 즉 전단사 함수가 존재한다고 가정하자. 여기 속하는 함수 \\(f: A \\to \\mathcal P(A)\\)는 전사 함수이다. 이제 다음과 같은 집합 \\(B\\)를 빚어보자.\n\\[\nB = \\{ x \\in A| x \\notin f(x) \\}\n\\]\n\\(B\\)는 \\(x \\in A\\)에는 들어 있지만 \\(f\\)에 의해 부분 집합의 집합으로 짝지어진(mapping) 원소(이 원소는 ’집합’이다)에는 속하지 않은 집합 \\(A\\)의 원소로 구성된 집합이다.\n\n\n예를 들어보자. \\(A = \\{1,2,3\\}\\)일 때, \\(1 \\to \\emptyset\\), \\(2 \\to \\{ 1, 3\\}\\), \\(3 \\to \\{ 2\\}\\)와 같은 짝짓기를 의미한다.\n\\(B\\)는 \\(A\\)의 원소들로 구성되어 있으므로 당연히 \\(B \\in \\mathcal P(A)\\)이다. \\(f\\)는 가정에 따라서 전사 함수이다. 따라서 \\(\\mathcal P(A)\\)에 속한 모든 원소에 대응하는 \\(a \\in A\\)가 반드시 존재한다. 이때 집합 \\(B\\)에 대응하는 \\(A\\)의 원소를 \\(a\\)라고 하자. 즉, \\(f(a) = B\\)인 \\(a \\in A\\)가 존재한다.\n\n\nPart 2.2\n\\(a\\)는 \\(B\\)에 속하거나 혹은 그렇지 않거나 둘 중 하나는 참이어야 한다. 각각의 경우를 살펴보자.\n\n\\(a \\in B\\); 이 명제가 맞다면, \\(a \\in f(a)\\)가 성립한다. 그런데 집합 B의 정의(\\(B\\)의 such that)에 따르면 \\(a \\notin f(a) = B\\)이다; \\(a \\notin B.\\) 따라서 모순이다.\n\\(a \\notin B\\); 이 명제가 맞다면, \\(a \\notin f(a)\\)가 성립한다. 그런데 집합 \\(B\\)의 정의에 따르면 \\(a \\notin f(a)\\)는 B의 원소다; \\(a \\in B.\\) 따라서 모순이다.\n\n두 경우 모두 모순이다. 귀류법에 따라 \\(|A| \\neq |\\mathcal P(A)|\\)가 참이다. 앞서 단사함수의 존재 증명과 함께 집합의 카디널 수에 관해 칸토어의 정리가 성립한다;\n\\[\n|A| &lt; |\\mathcal P (A)|.\n\\]"
  },
  {
    "objectID": "posts/math-simple/2022-07-03-ansys-candor-theorem.html#simple-but-beautiful",
    "href": "posts/math-simple/2022-07-03-ansys-candor-theorem.html#simple-but-beautiful",
    "title": "Cantor’s Theorem",
    "section": "Simple but Beautiful",
    "text": "Simple but Beautiful\n이 정리 참 아름답다. ‘전사 함수’ \\(f(X)\\)에 짝지워진 치역에 존재하는 어떤 원소를 폭탄 삼아 잘못된 전제에서 출발한 명제를 폭파시키는 방식의 절묘한 논법이다. 자세히 보면 이 정리는 러셀의 역설과 꽤 닮았다. 러셀이 칸토어의 해당 정리를 먼저 봤다고 하니, 레셀의 아이디어가 칸토어에서 왔다고 볼 수도 있을 듯 싶다. 러셀의 역설이 칸토어의 소박한 집합론에 일격을 날린 것을 생각하면 조금 아이러니한 대목이다.\n소박한 집합론(naive set theory)은 일정한 서술적 특성을 바탕으로 집합을 (쉽게) 정의할 수 있다고 보았다. 러셀의 역설은 이러한 공리에 구멍이 있음을 보여준다. 다소 말장난 같지만 생각해볼 대목이 있다. 직관적으로 생각해보자. 자신을 포함해 모든 것들의 ’집합’이 가능할까? 가능하다고 가정해보자. 이 집합에는 그 자신이 포함될 것이다. \\(x \\in x\\)가 된다. 이제 \\(R = \\{ x: x \\notin x \\}\\)라고 하자. 이 집합 역시 일정한 서술적 특성에 기반하고 있으므로 소박한 집합론에 따르면 집합이 될 수 있어야 한다. 이렇게 함정이 완성된다.\n이제 \\(R \\in R\\)을 만족한다고 하자. 그런데 \\(R\\)의 정의상 \\(R \\notin R\\)이어야 한다. 따라서 모순이다. 만일 \\(R \\notin R\\)이라고 하자. \\(R\\)의 정의상 \\(R \\in R\\)이어야 한다. 따라서 모순이다. 소박한 집합론의 주장과 달리 집합으로 정의될 수 없는 특징 혹은 대상이 존재함을 러셀의 역설이 보여준 셈이다.\n조금 말로 풀어보자. 모든 것을 포함하는 집합이 존재한다면, 그 자신을 포함하지 않는 집합을 정의할 때 문제가 생긴다. 러셀의 역설의 사례로 많이 언급되는 경우들이 거의 이런 재귀적인 특징을 지니고 있다. 마을에 존재하는 유일한 이발사 “갑”은 스스로 이발을 하지 않는 모든 사람을 이발하는 사람이다. 그렇다면 이발사 갑은 자신을 이발할 수 있는가? 할 수 없다. 그는 스스로 이발을 하지 않는 모든 사람을 이발하기 때문이다. 그렇다면 남에게 이발을 부탁할 수 있는가? 그럴 수도 없다. 스스로 이발을 하지 않는 모든 사람을 이발해야 하기 때문이다.\n\n\n\n\n보다 상세한 내용은 여기를 참고하자.\n\n카디널 수에 따른 함수의 구분"
  },
  {
    "objectID": "posts/math-simple/2023-06-26-imply.html",
    "href": "posts/math-simple/2023-06-26-imply.html",
    "title": "조건 명제 그리고 부정",
    "section": "",
    "text": "조건 명제가 의미하는 것을 확인해보고, 조건 명제의 ’부정’도 도출해보자.\n함수 극한의 엡실론-델타 정의를 통해 조건 명제의 의미를 연습해보자."
  },
  {
    "objectID": "posts/math-simple/2023-06-26-imply.html#tl-dr",
    "href": "posts/math-simple/2023-06-26-imply.html#tl-dr",
    "title": "조건 명제 그리고 부정",
    "section": "",
    "text": "조건 명제가 의미하는 것을 확인해보고, 조건 명제의 ’부정’도 도출해보자.\n함수 극한의 엡실론-델타 정의를 통해 조건 명제의 의미를 연습해보자."
  },
  {
    "objectID": "posts/math-simple/2023-06-26-imply.html#조건-명제",
    "href": "posts/math-simple/2023-06-26-imply.html#조건-명제",
    "title": "조건 명제 그리고 부정",
    "section": "조건 명제",
    "text": "조건 명제\n조건 명제는 잘 아는 듯싶지만, 내게는 가끔 혼란의 시간이 찾아오더라. 이 기회에 생각나는 대로 한번 정리해 보겠다. 아울러 극한의 정의까지 응용편으로 살펴보겠다."
  },
  {
    "objectID": "posts/math-simple/2023-06-26-imply.html#용어-정리",
    "href": "posts/math-simple/2023-06-26-imply.html#용어-정리",
    "title": "조건 명제 그리고 부정",
    "section": "용어 정리",
    "text": "용어 정리\n\n명제: 참과 거짓을 가릴 수 있는 언술을 의미한다. 배중률(law of excluded middle)에 따르면 명제는 참 혹은 거짓 중 하나만 될 수 있다. 참과 거짓이 동시에 성립하거나 혹은 동시에 성립하지 않거나 할 수 없다.\n진리 집합(truth set): 진리 집합을 정의하기 위해서는 위에서 설명한 명제 그리고 변수가 필요하다. 변수는 명제에서 변할 수 있는 부분이다. 변수를 주어 그리고 명제의 설명에 해당하는 부분을 술어(predicate)라고 칭하기도 한다. 진리 집합이란 특정 명제를 만족시키는 모든 변수 값들의 집합을 나타낸다.\n\n\n\n\n명제: \\(x &gt; 3\\)\n변수: \\(x\\)\n진리집합: \\(\\{ x \\in \\mathbb R | x &gt; 3 \\}\\)\n\n명제를 진리 집합과 연결해 생각하면 편리할 때가 있다. 명제의 여러 가지 조작을 집합으로 바꿔 생각하면 익숙한 ’벤 다이어그램’을 활용할 수 있다."
  },
  {
    "objectID": "posts/math-simple/2023-06-26-imply.html#조건-명제conditional-proposition",
    "href": "posts/math-simple/2023-06-26-imply.html#조건-명제conditional-proposition",
    "title": "조건 명제 그리고 부정",
    "section": "조건 명제(conditional proposition)",
    "text": "조건 명제(conditional proposition)\n조건 명제는 “만일 \\(p\\;\\)이면, \\(q\\;\\)가 성립한다”와 같이 표현한다. 동일한 의미를 지니는 표현을 몇 가지 더 알아보자.\n\n\\(p \\implies q\\)\nIf \\(p\\), then \\(q\\).\n\\(p\\) implies \\(q\\).\n\\(p\\) is sufficient condition for \\(q\\).\n\n이 관계는 형식 논리의 관계이지 ‘인과’ 관계가 아니다. 즉, 형식 논리상 명제 \\(p\\) 와 명제 \\(q\\) 사이의 관계를 기계적으로 서술한다. 진리 집합으로 보자. \\(p\\)의 진리집합 \\(P\\)와 \\(q\\)의 진리집합 \\(Q\\)가 있다고 하자. 조건 명제가 참이라면, \\(P \\subset Q\\)이다.\n\\(p \\implies q\\)는 진리집합으로 본다면 \\(P\\)에 속하는 모든 원소는 \\(Q\\)에 속해야 한다는 뜻이다. 즉, \\(p\\)라는 명제를 만족하는 모든 경우에 대해서 \\(q\\)가 만족해야 한다.\n\n진리표\n이를 이해하고 나면 \\(p \\implies q\\)와 동일한 진리값을 지니는 \\(\\neg p \\lor q\\)가 달리 보인다.\n\n\n\n\\(p\\)\n\\(q\\)\n\\(\\neg p \\lor q\\)\n\n\n\n\nT\nT\nT\n\n\nT\nF\nF\n\n\nF\nT\nT\n\n\nF\nF\nT\n\n\n\n위 진리표에서 \\(p\\)가 T인 경우에는 \\(q\\)가 T일 때만 T가 된다. 즉, \\(p\\)가 T라면, \\(p \\implies q\\) 혹은 \\(\\neg p \\lor q\\)가 T가 되는 경우는 \\(q\\)가 T일 때 뿐이다.\n\n\n공진리\n‘공진리(vacuous truth)’, ‘항진’ 혹은 ’공허 참’의 문제를 살펴보고 가자. 얼핏 이해가 쉽지 않을 수 있다. 진리집합으로 보면 상대적으로 이해가 쉽다. \\(p\\)가 F라는 것은 \\(P=\\varnothing\\)을 의미한다. 집합의 공리에 따르면 공집합은 모든 집합의 부분 집합이다. 따라서 공진리에 속하는 조건 명제는 아무런 의미를 지니지 않지만 형식 논리상 언제나 참이다.\n\n\n조건 명제의 부정\n조건 명제의 ’부정’은 어떻게 될까? 조건 명제를 \\(p \\implies q\\)의 형태로 놓고 부정 명제를 떠올리기는 쉽지 않다. 대신 \\(\\neg p \\lor q\\)의 부정 명제를 만들어보자. \\(\\neg(\\neg p \\lor q) = p \\land \\neg q\\)가 된다.\n직관적으로 생각해보자. 배중률에 따르면 \\(p \\implies q\\)가 성립하지 않는 경우가 단 하나라도 존재하면 해당 부정형이 참이 된다. 즉, \\(p\\)를 만족하는 경우 중에서 \\(\\neg q\\)를 만족하는 것이 존재하면 된다. 앞서 \\(p \\implies q\\)에서 \\(p\\)가 \\(\\forall\\)의 전칭 한정기호를 달고 있다면, 조건 명제의 부정형에서 \\(p\\)는 \\(\\exists\\)의 존재 한정기호 달고 있다. 진리 집합으로 서술하면 \\(P \\cap Q^C \\neq \\varnothing\\)인 경우에 해당한다."
  },
  {
    "objectID": "posts/math-simple/2023-06-26-imply.html#함수의-극한",
    "href": "posts/math-simple/2023-06-26-imply.html#함수의-극한",
    "title": "조건 명제 그리고 부정",
    "section": "함수의 극한",
    "text": "함수의 극한\n누구나 한번쯤 좌절해봤다는 함수 극한, \\(\\lim_{x \\to a} f(x) = L\\), 에 관한 “엡실론-델타 논법(epsilon-delta argument)”은 다음과 같다.\n\n\n엡실론-델타 논법의 정식화는 대략 코시(Cauchy)로 거슬러 올라간다. 그는 \\(\\epsilon\\)을 error의 의미로 \\(\\delta\\)를 distance의 의미로 썼다고 한다. 즉, 목표가 되는 타겟 \\(f(x)\\)의 ’오차’를 일정한 범위 이하로 줄이기 위해 필요한 \\(a\\) 주변의 ’거리’로 느슨하게 외우면 괜찮을 듯 싶다.\n\n\n\n\n\n\nDefinition\n\n\n\n\\(x \\in \\mathbb R\\)인 모든 \\(x\\)와 모든 \\(\\epsilon &gt; 0\\)에 대해서 다음을 만족하는 어떤 \\(\\delta &gt; 0\\)가 존재한다; \\(0 &lt; |x - a| &lt; \\delta\\) \\(\\implies\\) \\(|f(x)-L| &lt; \\epsilon\\).\n\n\n영어로는 다음과 같다.\n\n\n\n\n\n\nDefinition\n\n\n\nFor every \\(\\epsilon &gt; 0\\), there exists a \\(\\delta &gt; 0\\) s.t. for all \\(x \\in \\mathbb R\\), \\(0 &lt; |x-a| &lt; \\delta\\) implies \\(|f(x)-L| &lt; \\epsilon\\).\n\n\n기호만으로 표현해보자.\n\n\n\n\n\n\nDefinition\n\n\n\n\\((\\forall \\epsilon &gt;0)(\\exists \\delta &gt;0)(\\forall x \\in \\mathbb R)(0 &lt; |x-a| &lt; \\delta \\implies |f(x) - L|&lt;\\epsilon)\\) \\((\\forall \\epsilon &gt;0)(\\forall x \\in \\mathbb R)(\\exists \\delta: 0 &lt; |x-a| &lt; \\delta \\implies |f(x) - L|&lt;\\epsilon)\\)\n\n\n하나씩 끊어서 말로 살펴보자.\n\n\\(x=a\\) 주변으로 양쪽으로 어떤 \\(\\delta\\) 크기의 구간을 잡는다.\n\n해당 구간에 속하는 모든 \\(x\\)를 고려하자.\n\\(x \\to a\\) 일 때 함수 \\(f(x)\\)의 극한값을 \\(L\\)이라고 하자.\n\\(\\delta\\)를 조정해서 \\(f(x)\\)와 \\(L\\) 사이의 거리(\\(|f(x)-L|\\))가 모든 \\(\\epsilon&gt;0\\)보다 작게 만들 수 있다. 즉, 이 조건을 만족하는 \\(\\delta\\)가 존재한다.\n\n양화사(quantifier)에 각별히 주의하자. 명제의 부정을 정의할 때 골치거리가 되는 것이 바로 이 녀석이다.\n\n함수의 극한이 존재하지 않는 경우\n이제 함수의 극한에 관한 정의의 부정(negation)을 만들어 보자. 이 부정이 참이 되는 경우, 즉 극한이 존재하지 않는 경우도 함께 살펴볼 것이다. 정의가 함축(implication, \\(\\implies\\))의 형태를 취하고 있으므로 부정을 만들 때 앞서 살펴본 방식을 따르면 된다.\n여기서 문제가 되는 것이 양화사다. 질문은 다음과 같다.\n\n양화사를 \\(p\\)와 \\(q\\)의 조건이 넣어서 함축 명제의 부정을 만들어야 할까?\n아니면 영화사는 별도로 처리해줘야 할까?\n\n결국 정의의 취지가 무엇인지에 달려 있다. 극한의 정의를 보면 존재하는 세 개의 양화사가 일종의 전제로 제시되어 있다. 따라서 함축과는 별도로 다루는 것이 타당할 것이다. 양화사는 부정을 취하면 반대가 된다. 즉 엡실론-델타 논법에 따른 함수 극한 정의의 부정은 다음과 같다.\n\n\n\n\n\n\nDefinition Negated\n\n\n\n모든 \\(\\delta&gt;0\\)에 대해서 다음을 만족하는 어떤 \\(\\epsilon&gt;0\\)와 어떤 \\(x \\in \\mathbb R\\)이 존재한다; \\(0 &lt; |x-a| &lt; \\delta\\)와 \\(|f(x) - L| \\geq \\epsilon\\)를 동시에 만족한다.\n\n\n역시 구별해서 풀어보자.\n\n\\(a\\)의 모든 주변(\\(\\delta\\)의 크기)에 속한 어떤 \\(x\\)를 고려하자.모든 \\(\\delta&gt;0\\)이므로 \\(a\\) 주변의 지극히 극소한(?) 범위에서까지 만족해야 한다. 이것은 매우 강한 조건이다. 원래 정의에서 \\(\\epsilon\\)에 대해서 강한 조건이었다면 이것이 \\(\\delta\\)로 바뀐 셈이다.\n\\(|f(x)-L|\\) 값을 어떤 \\(\\epsilon\\) 보다 낮게 줄일 수 없는 \\(x\\)가 존재한다.\n\n이 경우는 \\(\\lim_{x \\to a}f(x)\\)는 존재하지 않는다.\n\n\n여기를 같이 참고하자."
  },
  {
    "objectID": "posts/math-simple/2023-06-26-imply.html#진리-집합",
    "href": "posts/math-simple/2023-06-26-imply.html#진리-집합",
    "title": "조건 명제 그리고 부정",
    "section": "진리 집합",
    "text": "진리 집합\n진리 집합으로 다시 따져보도록 하자. 진리 집합은 조건제시법(set builder notation)을 통해 표현한다. 양화사를 함께 표현해보자.\n\\[\n\\begin{aligned}\nP & = \\{\\forall x&gt;0,~\\exists \\delta&gt;0 \\, \\vert ~|x - a| &lt; \\delta \\} \\\\\nQ & = \\{\\forall x&gt;0,~\\forall \\epsilon&gt;0 \\, \\vert ~|f(x) - L| &lt; \\epsilon \\}\n\\end{aligned}\n\\]\n부정형의 양화사를 적용해보자. 앞서 보았듯이 양화사는 이 명제의 전제 조건이다. 따라서 명제를 부정하면 양화사는 반대로 뒤집히게 된다. 따라서 같은 \\(P\\)의 진리집합이라고 해도 원래의 명제와 부정형의 명제에는 서로 다른 영화사가 적용된다. \\(P\\)의 진리 집합에 적용되는 한정사는 \\(\\forall \\delta &gt; 0\\)이고, \\(Q^C\\)에 적용되는 한정 명제는 \\(\\exists \\epsilon &gt; 0\\)이다. 원 명제의 진리집합과 구별하기 위해서 아래와 같이 표기해보자. \\[\n\\begin{aligned}\n\\hat P & = \\{ \\exists x&gt;0, ~\\forall \\delta&gt;0 \\, |~|x - a| &lt; \\delta \\} \\\\\n\\hat Q^C & = \\{ \\exists x&gt;0, ~\\exists \\epsilon&gt;0 \\, | ~ |f(x) - L| \\geq \\epsilon \\}\n\\end{aligned}\n\\]\n\n\n조건제시법을 쓸 때 \\(|\\)과 \\(:\\)는 차이가 있을까? 별 차이가 없다는 게 중론인 듯 싶다. 영어로 옮기면 “such that(s.t.)”에 해당한다. 사례처럼 “s.t.”이 중복되면 번갈아서 써주면 어떨까 싶다.\n만일 \\(\\hat P \\cap \\hat Q^C \\neq \\varnothing\\)이면, 정의상 함수의 극한은 존재하지 않는다.\n머리 속으로 그림을 그려보자. 모든 \\(\\delta&gt;0\\)에 관해서 \\(\\hat P \\cap \\hat Q^C \\neq \\varnothing\\)이 만족하면 극한은 존재하지 않는다. 아래 그림에서 보듯이 \\(x\\)를 \\(a\\)에 아무리 가깝게 근접시키더라도 \\(|f(x)-L|\\)의 크기를 더 줄이기 힘든 어떤 한계가 존재한다면, \\(\\lim_{x \\to a} f(x)\\)는 존재하지 않는다."
  },
  {
    "objectID": "posts/math-simple/2023-06-26-imply.html#그림으로-살펴보면",
    "href": "posts/math-simple/2023-06-26-imply.html#그림으로-살펴보면",
    "title": "조건 명제 그리고 부정",
    "section": "그림으로 살펴보면",
    "text": "그림으로 살펴보면\n여러가지 상세한 조건을 과감히 생략하고 \\(x \\in \\mathbb R\\)에서 정의되는 \\(f(x)\\)의 그림을 통해 함수 극한을 살펴보기로 하자.\n\n\n\n\n\n\n\n\n\n\\(\\lim_{x \\to a} f(x)\\)가 존재하는 경우\n\n\n\n\n \n\n\n\n\n\n\\(\\lim_{x \\to a} f(x)\\)가 존재하지 않는 경우\n\n\n\n\n\n\n\n그림이 정확하지는 않지만 이해하는 데 도움이 되지 않을까 싶어 소개한다. 아래 “[ ]”에 있는 그림은 \\(y\\)축을 옆으로 눕혀 확대해서 그린 것이다. \\(f(x)\\)가 존재하는 왼쪽의 경우 \\(L\\) 주변에서 임의의 \\(\\epsilon\\)을 잡더라도 \\(\\delta\\)를 더 작게 설정함으로써 \\(|f(x)-L| &lt; \\epsilon\\) for \\(x \\in (f(a-\\delta), f(a+\\delta))\\)를 만족한다. 오른쪽의 경우를 보자. \\(x=a\\)에서 \\(f(x)\\)의 점프가 있다. 따라서 해당 구간에 적당한 크기의 \\(\\epsilon\\)을 설정하면 \\(|f(x)-L| \\geq \\epsilon\\) for \\(x=a\\)가 모든 \\(\\delta\\)에 대해서 성립한다.\n\n함수의 극한이 존재하는 경우\n\\(\\lim_{x \\to a} f(x)\\)가 존재하는 경우를 살펴보자. 문장으로는 이상하지만 이렇게 풀어 놓고 써보자.\n\n\\(p\\): 다음의 조건을 만족하는 어떤 \\(\\delta&gt;0\\)가 존재한다; \\(|x - a| &lt; \\delta\\)\n\\(q\\): 모든 \\(\\epsilon&gt;0\\), 모든 \\(x \\in \\mathbb R\\)에 대해서 다음 조건을 만족한다; \\(|f(x) - L| &lt; \\epsilon\\)\n\n그림에서 보듯이 어떤 크기의 \\(\\epsilon\\)가 주어진다고 해도 \\(\\delta\\)를 필요한 만큼 작게 택하여 \\(f(x)\\)와 \\(L\\)의 거리를 충분히 좁힐 수 있을 때, 함수의 극한값이 존재한다.\n\n\n다소 동어반복이 될지는 모르겠지만 극한이 존재하지 않는 경우에 넣어서 따져보면 이해에 도움이 된다. 진리집합 \\(Q^C\\) 즉 \\(|f(x) - L| \\geq \\epsilon\\)를 만족하는 \\(\\epsilon\\)와 \\(x\\)가 존재한다고 하자. \\(x\\)를 \\(a\\)에 충분히 붙이게 되면, 즉 \\(\\delta\\)를 충분히 작게 잡으면, 이 조건을 만족하는 \\(\\epsilon\\)은 존재하지 않는다. 즉, \\(P \\cap Q^C = \\emptyset\\)이다.\n\n\n함수의 극한이 존재하지 않는 경우\n\n\n\n\n\n\n\n\n\n\\(\\lim_{x \\to a} f(x)\\)가 존재하는 않는 경우\n\n\n\n\n \n\n\n\n\n\n\\(\\lim_{x \\to a} f(x)\\)가 존재하는 경우\n\n\n\n\n\n\\(L\\)이 \\((f(a-\\delta), f(a+\\delta))\\) 사이 어딘가에 존재한다고 하자. 이때 \\(|L-f(a-\\delta)|\\)(그림의 *)과 \\(|L-f(a+\\delta)|\\)(그림의 **) 중 작은 값보다 같거나 작은 어떤 값을 \\(\\epsilon\\)이라고 두자. 이때 \\(|x-a|&lt;\\delta\\)를 만족하는 모든 \\(\\delta\\)에 대해서 \\(|f(x)-L| \\geq \\epsilon\\)을 만족하는 \\(x\\)를 찾을 수 있다. 즉, \\(P \\cap Q^C \\neq \\emptyset\\). 이 상황을 명제로 표현하면 아래와 같다.\n\\((\\exists \\epsilon)(\\exists x)(\\forall\\delta&gt;0)\\) s.t. \\(|f(x)-L| \\geq \\epsilon\\) for \\(x \\in (a-\\delta, a+\\delta)\\).\n\n\n\\(f(x)\\)는 \\(x=a\\) 주변에서 끊어져 있고, 이 간격과 \\(L\\)의 위치를 고려해서 모든 \\(\\delta\\)와 \\(|f(x)-L| \\geq \\epsilon\\)를 만족하는 \\(\\epsilon&gt;0\\)와 \\(x\\)를 찾을 수 있다. 위 그림에서 보듯이 \\(\\delta\\)를 아무리 작게 설정해도 \\(x=a\\)에서 존재하는 \\(f(x)\\)의 간격을 줄일 수는 없다. 즉, \\(\\lim_{x \\to a} f(x)\\)는 존재하지 않는다.\n연습 삼아서 \\(a\\)에서 \\(f(x)\\)의 극한값이 존재하는 경우도 살펴보자. 위의 그림에서 보듯이 모든 \\(\\delta\\)에 대해서 성립해야 하므로 어떤 \\(\\epsilon\\)이나 \\(x\\)를 잡더라도 \\(\\delta\\) 를 좁히면 \\(|f(x)-L| \\geq \\epsilon\\)의 조건을 깰 수 있다."
  },
  {
    "objectID": "posts/math-simple/2023-06-26-imply.html#my-bullshit",
    "href": "posts/math-simple/2023-06-26-imply.html#my-bullshit",
    "title": "조건 명제 그리고 부정",
    "section": "My bullshit",
    "text": "My bullshit\n엡실론-델타 논법을 어렵게 여기는 이유가 무엇일까? 아마도 극한을 우리가 머리 속에서 떠올리고 말하는 방식 때문이 아닐까 싶다. \\(x \\to a\\)를 표현할 때 흔히 “\\(x\\)가 \\(a\\)에 한없이 다가갈 때”라고 말한다. 이 말은 \\(x\\)가 \\(a\\)를 향해 끊임없이 (조금씩) 접근하는 동적인 이미지를 떠올리게 한다. 하지만 \\(x\\)가 \\(a\\)에 수렴하는 동적인 경로는 셀 수 없이 많다. 이 모든 경로에 대해서 \\(f(x)\\)가 \\(L\\)에 수렴하는지를 확인하기는 불가능하다.\n극한을 찾고 싶은 점(\\(x=a\\))의 함수 값에서 아주 미세한 교란이 발생했다고 하자. 이때 다시 원래의 값으로 돌아갈 수 있는 \\(x=a\\) 주변의 범위를 잡을 수 있는지가 극한 정의의 관심사이다. 어떻게 다시 \\(L\\)로 돌아갈지는 정할 수도 없고 관심사도 아니다. 함수 주변에서 임의의 교란이 발생했을 때 원래 값을 복원할 수 있는 \\(x\\)의 범위를 \\(a\\) 주변에서 정할 수 있다면, \\(L\\)을 극한으로 보겠다는 것이다.\n‘무한히’ 존재할 동적인 수렴을 다룰 수 없으니 이를 정적인 형태로 바꿔 수학적으로 다룰 수 있도록 만든 장치가 엡실론-델타 정의가 아닐까?\n\n\n\n\\(\\lim_{x \\to a} f(x)\\)가 존재하는 경우\n\\(\\lim_{x \\to a} f(x)\\)가 존재하지 않는 경우\n\\(\\lim_{x \\to a} f(x)\\)가 존재하는 않는 경우\n\\(\\lim_{x \\to a} f(x)\\)가 존재하는 경우"
  },
  {
    "objectID": "posts/math-simple/2019-07-13-Poisson.html",
    "href": "posts/math-simple/2019-07-13-Poisson.html",
    "title": "Poisson as Binormial Distribution",
    "section": "",
    "text": "푸아송 분포는 이항 분포를 주어진 시간(기간) 안에 발생하는 평균 발생 횟수로 다시 모델링한 분포다.\n이항 분포의 평균은 \\(\\lambda = n p\\)이고, 이항 분포에 \\(p = \\frac{\\lambda}{n}\\)을 다시 넣은 후 \\(n \\to \\infty\\) 극한값을 얻은 결과가 푸아송 분포다."
  },
  {
    "objectID": "posts/math-simple/2019-07-13-Poisson.html#tldr",
    "href": "posts/math-simple/2019-07-13-Poisson.html#tldr",
    "title": "Poisson as Binormial Distribution",
    "section": "",
    "text": "푸아송 분포는 이항 분포를 주어진 시간(기간) 안에 발생하는 평균 발생 횟수로 다시 모델링한 분포다.\n이항 분포의 평균은 \\(\\lambda = n p\\)이고, 이항 분포에 \\(p = \\frac{\\lambda}{n}\\)을 다시 넣은 후 \\(n \\to \\infty\\) 극한값을 얻은 결과가 푸아송 분포다."
  },
  {
    "objectID": "posts/math-simple/2019-07-13-Poisson.html#defining-poisson-distribution",
    "href": "posts/math-simple/2019-07-13-Poisson.html#defining-poisson-distribution",
    "title": "Poisson as Binormial Distribution",
    "section": "Defining Poisson Distribution",
    "text": "Defining Poisson Distribution\n사실, 푸아송 분포 직관적으로 잘 안 와 닿는다. 정의부터 먼저 살펴보자. 한글 위키피디어에서 가져왔다.\n푸아송 분포(Poisson distribution)는 확률론에서 단위 시간 안에 어떤 사건이 몇 번 발생할 것인지를 표현하는 이산 확률 분포이다. 일단 정의에서 알 수 있는 것:\n\n푸아송이라는 사람이 만들었다.\n단위 시간 안에 발생하는 사건이 중요하다.\n이산 확률 분포다.\n\n수학적인 정의는 일단 생략하자. 뒤에서 다시 만나게 될 테니까. 정의만 봐서는 이해가 쉽지 않은 분포다. 직관적인 방식으로 푸아송 분포의 정의를 끌어낼 수는 없을까?\n\n\n정확하게 언급하자면 분포의 정의라기보다는 분포의 확률 질량 함수 혹은 확률 밀도 함수라고 적는 게 맞을 것이다. 하지만 편의상 특별한 언급이 없는 경우 분포의 정의를 이런 의미로 사용하도록 하자."
  },
  {
    "objectID": "posts/math-simple/2019-07-13-Poisson.html#poisson-as-binary",
    "href": "posts/math-simple/2019-07-13-Poisson.html#poisson-as-binary",
    "title": "Poisson as Binormial Distribution",
    "section": "Poisson as Binary",
    "text": "Poisson as Binary\n잠시 이항 분포를 떠올려보자. 아마도 모든 확률 관련 수업에서 제일 처음 배우는 분포가 아닐까 한다. 이항 분포란, 1회 시행 시 발생할 확률이 \\(p\\;\\)인 어떤 사건을 \\(n\\) 번 시행할 때 해당 사건이 \\(k\\) 번 발생할 확률의 분포를 나타낸다. 개별적으로 존재하는 사건이니까 당연히 이산 확률 분포에 속한다. 수학적으로는 아래와 같다.\n\\[\nB(k;  n,p)  =  {n \\choose k}  p^k(1-p)^{n-k}\n\\]\n위 정의를 말로 풀어보자. n번 시행 중에 사건이 발생한 경우 \\(k\\) 개를 뽑는다. 즉, 이런 경우가 \\(n\\) 번 중에서 얼마나 발생할 수 있는지 따진다. 그리고 해당 경우의 수가 발생할 확률을 곱해준 것이다.\n이항 분포를 ’시간’의 맥락으로 한번 바꿔보자. 하루 동안 내 사이트에 방문객이 한 명 찾아올 확률을 0.1이라고 하자. 28일 동안 10 명의 방문자가 찾아올 확률은? 이항 분포의 맥락에서 생각한다면, \\(B(10; 28, 0.1)\\)로 나타낼 수 있다. 그런데 이 모델링 어딘가 찜찜하다.\n이항 분포의 모델링은 하루 동안 사이트 방문객이 한 명일 확률에 기대고 있다. 그런데 하루에 방문객이 두 명 이상이라면? 하루에 방문객이 한 명 씩만 온다는 가정이 비현실적이지 않나?\n두 명 이상의 방문자를 수용하려면 이항 분포의 모형을 어떻게 수정해야 할까? 가장 손쉬운 방법은 단위 시간을 바꾸는 것이다. 단위 시간을 하루가 아니라 시간으로 바꿔보자. 하루는 24시간이고 매 시간 동일한 정도로 이용자가 방문한다면, 시간당 1명이 방문할 확률은 0.1/24이 된다. 낮은 확률이지만 이러한 가정에서 하루에 두 명 이상도 방문할 수 있게 된다."
  },
  {
    "objectID": "posts/math-simple/2019-07-13-Poisson.html#deriving-poisson",
    "href": "posts/math-simple/2019-07-13-Poisson.html#deriving-poisson",
    "title": "Poisson as Binormial Distribution",
    "section": "Deriving Poisson",
    "text": "Deriving Poisson\n이항 분포와 달리 푸아송 분포에서 파라미터는 한 개다. 푸아송 분포의 파라미터 \\(\\lambda\\)는 단위 시간 당 평균 발생 횟수를 뜻한다. 비율(rate)이라고도 부른다.\n\\(\\lambda\\)가 ’파라미터’라는 의미는 무엇일까? 과거의 데이터로부터 혹은 어떤 방법으로든 푸아송 분포를 정의하는 시점에서 알려진 혹은 정의된 사실이라는 의미다. 즉, 우리가 관심을 두고 있는 기간 내에 평균적인 방문자 수가 주어진다는 뜻이다.\n기간 내에 특정 순간 동안 어느 정도의 방문자가 올지 미리 알 수 없다. 방문자가 없다가 어느 순간 10명이 몰려올 수도 있다. 일정한 간격으로 한 명씩 10 명이 올 수도 있다. 매번 시행 때마다 해당 사건이 발생할 확률을 모형화하는 이항분포를 시간의 맥락으로 바꾸면 이렇게 뭔가 어색해 보인다.\n이항 분포를 통해 푸아송 분포를 표현하는 방법은 없을까? 어떤 패턴으로 방문자가 올지 알 수 없다면, 이항 분포의 기준이 되는 시행(시점)을 최대한 잘게 쪼개면 어떨까? 이항 분포에서 평균은 \\(np\\;\\) 다. 즉, 이항 분포의 맥락에서 보면 푸아송 분포의 파라미터 \\(\\lambda = n p\\;\\)다. \\(\\lambda\\)가 고정되어 있다면 \\(n\\)을 무한대로 갈 때 \\(p\\)는 적절한 방식으로 0으로 접근한다고 가정해도 무방하다. 정리하면 푸아송 분포를 이항 분포에서 도출하기 위한 전략은 다음과 같다.\n\n\\(n\\)과 \\(p\\)를 \\(\\lambda\\) 파라미터 하나로 바꾼다.\n\\(n\\)이 무한대로 갈 때 이항 분포의 확률 밀도 함수의 극한값을 도출한다.\n\n\\[\n\\begin{aligned}\n\\lim_{n \\to \\infty} B(k; n, p) = & \\lim_{n \\to \\infty}  {n \\choose k }  p^k(1-p)^{n-k} \\\\\n= & \\lim_{n \\to \\infty}  \\dfrac{n!}{k!(n-k)!}(\\dfrac{\\lambda}{n})^k  (1-\\dfrac{\\lambda}{n})^{n-k}  \\\\\n= & \\lim_{n \\to \\infty}  \\underbrace{\\left[  \\dfrac{n!}{(n-k)!  n^k} \\right]}_{(가)}  \\left[  \\dfrac{\\lambda^k}{k!}  (1-\\dfrac{\\lambda}{n})^{n}  \\right]  \\underbrace{\\left[  (1-\\dfrac{\\lambda}{n})^{-k}\\right]}_{(나)}  \\\\\n= &  1\\left[  \\dfrac{\\lambda^k}{k!}  e^{-\\lambda}\\right] 1 \\\\\n= & f(k; \\lambda)\n\\end{aligned}\n\\]\n푸아송 분포 확률 질량 함수 \\(f(k; \\lambda)\\) 앞 뒤로 붙은 극한값 (가)와 (나)에 관해 사족을 덧붙여보자. 먼저 (가)는 아래와 같다.\n\\[\n  \\lim_{n \\to \\infty} \\dfrac{n!}{(n-k)!  n^k} =  \\lim_{n \\to \\infty}  \\dfrac{n(n-1)\\dotsb(n-(k-1))}{n^k}  = 1\n\\]\n분자와 분모 모두 가장 높은 \\(n\\)의 차수는 \\(k\\)이고, 그 계수가 모두 1이므로 극한값은 1이다. (나)의 극한값은 쉽게 알 수 있으니 생략하자.\n이항 분포의 확률 혹은 확률 질량 함수의 극한값이 바로 푸아송 분포의 그것이다! 이거 참 재미있는 연결 고리가 아닌가! 사실 푸아송 분포의 정의를 그냥 들여다봐서는 그다지 직관적인 이해를 얻기는 쉽지 않다. 이렇게 이항 분포에서 출발하는 것이 직관적으로 이해하는 데 도움이 된다."
  },
  {
    "objectID": "posts/computer-tool/2024-06-06-google-sheet-api.html",
    "href": "posts/computer-tool/2024-06-06-google-sheet-api.html",
    "title": "Google Sheet와 파이썬 연동하기",
    "section": "",
    "text": "Google Sheet를 파이썬과 연동하는 방법을 알아보자.\n🔗LINK와 함께 참고하시라."
  },
  {
    "objectID": "posts/computer-tool/2024-06-06-google-sheet-api.html#tl-dr",
    "href": "posts/computer-tool/2024-06-06-google-sheet-api.html#tl-dr",
    "title": "Google Sheet와 파이썬 연동하기",
    "section": "",
    "text": "Google Sheet를 파이썬과 연동하는 방법을 알아보자.\n🔗LINK와 함께 참고하시라."
  },
  {
    "objectID": "posts/computer-tool/2024-06-06-google-sheet-api.html#데이터-앱-만들기의-0단계",
    "href": "posts/computer-tool/2024-06-06-google-sheet-api.html#데이터-앱-만들기의-0단계",
    "title": "Google Sheet와 파이썬 연동하기",
    "section": "데이터 앱 만들기의 0단계",
    "text": "데이터 앱 만들기의 0단계\n따로 DB를 만들지 않을 것이라면 데이터 소스는 엑셀형태가 가장 흔할 것 같다. 그리고 데이터가 다른 원천에 의해서 변한다면 구글 스프레드 시트가 쉬운 선택지가 아닐까 싶다. 그렇다면 파이썬과 구글 스프레드 시트는 어떻게 연동하면 될까? 이 포스트 역시 내용을 까먹을 미래의 나놈을 위한 것이다.\n\n\n기본적인 내용은 LINK를 참고했다."
  },
  {
    "objectID": "posts/computer-tool/2024-06-06-google-sheet-api.html#google-sheet-api-설정",
    "href": "posts/computer-tool/2024-06-06-google-sheet-api.html#google-sheet-api-설정",
    "title": "Google Sheet와 파이썬 연동하기",
    "section": "Google Sheet API 설정",
    "text": "Google Sheet API 설정\n\nGoogle Cloud Console에서 프로젝트 생성\n먼저 새 프로젝트를 적절하게 생성하자.\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nFigure 1: 프로젝트를 생성하자.\n\n\n\n\n\n \n\n\n\n\n\nAPI 활성화\nAPI를 활성화해야 한다. API를 활성화하는 메뉴에서 Figure 2와 같이 두 개의 API를 활성화하자.\n활성화해야 하는 API는 Google Drive API, Google Sheets API 두 가지이다.\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nFigure 2: Google Drive와 Google Sheet API 활성화\n\n\n\n\n\n \n\n\n\n\n\n사용자 인증 정보 만들기\n\n구글 시트에 접근하기 위해서는 “서비스 계정”(Figure 3)으로 만들도록 하자.\n사용자 인증 정보 유형은 “어플리케이션 데이터”이다(Figure 4).\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: 서비스 계정 활성화\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nFigure 4: API 설정\n\n\n\n\n\n\n\n\n키 생성하기\n\nFigure 5에서 생성된 서비스 계정을 클릭한다.\nFigure 6에서 보듯이 “키” 탭에서 JSON으로 생성하면 해당 JSON 파일이 다운로드 된다. 이 파일을 파이썬에서 구글 시트에 접근하는데 활용한다. 이 파일은 패스워드가 같은 것이므로 노출되지 않도록 주의하자.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: 로봇 계정 선택\n\n\n\n\n\n \n\n\n\n\n\n\n\n\nFigure 6: 키 생성\n\n\n\n\n\n\n\n\n가장 흔히 저지르를 실수가 public 계정의 github에 해당 파일을 넣어두는 것이다. 이 점 각별히 주의하도록 하자. public 계정이라도 마스킹 처리가 부분적으로 가능하고, private 계정이라고 해도, GitHub Pages 서비스는 가능하다.\n\n\nGoogle Spread Sheet 공유하기\n구글 스프레드 시트의 상단의 공유 버튼에서 앞서 크리덴셜을 생성한 로봇 유저를 공유자로 지정한다."
  },
  {
    "objectID": "posts/computer-tool/2024-06-06-google-sheet-api.html#파이썬에서-작업하기",
    "href": "posts/computer-tool/2024-06-06-google-sheet-api.html#파이썬에서-작업하기",
    "title": "Google Sheet와 파이썬 연동하기",
    "section": "파이썬에서 작업하기",
    "text": "파이썬에서 작업하기\n설치 등의 과정은 생략하고 테스트할 수 있는 코드만 간략하게 소개한다.\n#!pip3 install gspread\n#!pip3 install --upgrade google-api-python-client oauth2client\n\n#importing the required libraries\nimport gspread\nimport pandas as pd\nfrom oauth2client.service_account import ServiceAccountCredentials\n이제 크리덴셜을 활용해서 해당 구글 스프레드 시트에 접근할 수 있다. add_json_file_here.json에 앞서 다운로드한 JSON 파일을 넣으면 된다.\n# define the scope\nscope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n\n# add credentials to the account\ncreds = ServiceAccountCredentials.from_json_keyfile_name('add_json_file_here.json', scope)\n\n# authorize the clientsheet \nclient = gspread.authorize(creds)\n’구글 스프레드 시트 이름’에는 접근할 구글 스프레드 시트의 타이틀을 넣는다. 시트의 선택은 아래 get_worksheet(0)로 한다. 0번이 첫번째 위치한 시트이다.\n# get the instance of the Spreadsheet\nsheet = client.open('구글 스프레드 시트 이름')\n\n# get the first sheet of the Spreadsheet\nsheet_instance = sheet.get_worksheet(0)\nget_all_records()를 통해 모든 데이터를 가져올 수 있고, dictionary 형태로 저장된다. 이를 pandas의 DataFrame으로 변환하면 된다.\n# get all the records of the data\nrecords_data = sheet_instance.get_all_records()\n\n# convert the json to dataframe\nrecords_df = pd.DataFrame.from_dict(records_data)\n\n\n\nFigure 1: 프로젝트를 생성하자.\nFigure 2: Google Drive와 Google Sheet API 활성화\nFigure 3: 서비스 계정 활성화\nFigure 4: API 설정\nFigure 5: 로봇 계정 선택\nFigure 6: 키 생성"
  }
]