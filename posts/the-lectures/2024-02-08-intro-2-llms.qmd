---
title: "Busy Person's Intro to LLMs" 
description: LLM에 관해 알아야 할 두세 가지 것들 
author: "JS HUHH"
date: "02/08/2024"
image: "./images/cat-learning.webp"
categories: [the-lectures, machine-learning]
#fig-align: center
filters:
   - lightbox
   #- line-highlight
lightbox: auto
#jupyter: python3
draft: false
format:
  html:
    code-fold: false
    code-block-bg: true
    highlight-style: github
---

## TL; DR
LLMs에 관해 안드레이 카파시의 견해를 정리해보자. 

{{< video https://www.youtube.com/watch?v=zjkBMFhNj_g&t=1s >}}

## 넋두리 

LLMs를 이해하는 방법은 다양하다. 많이 알수록 보다 간결하고 적확한 표현을 구사할 수 있다고들 하는데, 카파시의 경우가 그러했다. 인상적인 대목들 몇 가지 정리해보자. 

## Ted Chiang, "A Blurry JPEG of the Web"

::: {layout="[-2, 5, -2]"}
![](https://media.newyorker.com/photos/63e43df04138f62754b70bc1/1:1/w_571,h_571,c_limit/Chiang_final.gif)
:::

테드 창은 chatGPT란 결국 웹의 부정확한(흐릿한) 압축버전의 무엇에 지나지 않는다는 뜻으로 말했지만 이 표현은 LLMs에 관한 정확한 묘사이자 좋은 논의의 출발점을 제공한다. 

그래서 LLMs을 의심해야 할까? 이것도 맞다. 하지만 인간과 웹의 상호 작용을 곰곰히 따져보면 이 말이 그리 틀리지도 않고 만일 사람이 아닌 누군가가 이걸 적당한 수준에서 '잘' 할 수 있다면 blurry라는 표현이 그리 김빠지는 것이 아닐 수도 있겠다. 

카파시 역시 LLMs을 비슷하게 이해한다. 

::: {layout="[-1, 5, -1]"}
![](./images/karpathy/karpathy-1.jpeg)
:::

상당 기간동안 검색에 익숙해진 사람이 있다고 하자. 그가 검색을 통해 알게 된 지식이 모두 맞지 않는다. 하지만 확률적으로 다른 보통의 사람보다 낫다면 그는 쓸모가 있을 것이다. 컴퓨터가 내놓는 무엇은 정확하리라는 인간적인 편견을 누리고 보면, 사람이 아닌 이런 존재가 있다면 무척 활용도가 높지 않을까? 

## LLMs Dream Internet

::: {layout="[-1, 5, -1]"}
![](./images/karpathy/karpathy-2.jpeg)
:::

뉴럴넷은 인터넷 문서를 "꿈꾼다." LLMs 편에서 보면 생성이라는 말은 "꿈꾸는" 것에 가깝다. "꿈꾼다"라는 표현이 찰지고도 정확하다. 엄밀히 말하면 뉴럴넷은 문서를 생성한다기다는 꿈꾸는 것에 가깝다. 그래서 헛소리가 들어갈수도 있고 정확하지 않을 수도 있다. 하지만 인간에게도 그러하듯이 꿈꾸는 것, 백지 위에 무엇인가를 그려내는 것이 얼마나 어려운 일인가? 

## Human Feedback 

::: {layout="[[5,-1,5]]"}
![](./images/karpathy/karpathy-3.jpeg)

![](./images/karpathy/karpathy-4.jpeg)
:::

하지만 뉴럴넷은 인간이 원하는대로 움직이지 않는다. 그 내부의 작동 원리를 온전하게 모른다는 점에서 뉴럴넷은 그 발상을 복제한 인간의 뇌와 비슷하다. 인간의 아이를 학습시키는 과정을 떠올려보자. 뭔가 가르치고 싶은 것이 있다면 부모가 해당 내용을 밖에서 주입한다. 이 과정이 뉴럴넷에 인간의 손길을 더해주는 과정이다. 

카파시는 크게 두 가지를 제시한다. 하나는 '보조 모델'을 인간이 만들고 이 내용을 뉴럴넷 안에 끼워넣는 것이다. 두번째는 LLMs가 꿈꾼 답을 비교해서 인간에게 더 좋아보이는 답을 제시해주는 것이다.

첫번째 과정이 프리트레인 모델을 얻는 과정이라면 두 번째가 이른바 미세 조정(fine-tuning)이다. 첫번째가 엔지니어링의 영역이라면 두번째는 소셜 엔지니어링의 영역이다. 오늘날 chatGPT의 성공에는 GPU를 활용한 대규모 학습을 가능하게 한 첫번째 영역의 공로 만큼 두 번째 영역의 공로도 크다. 어쩌면 미세 조정의 영역이 각 모델을 내놓는 회사들의 숨은 역량이 발휘되는 곳일지도 모른다. 

::: {layout="[[-1,5,-1]]"}
![](./images/karpathy/karpathy-6.jpeg)
:::

## System I and II for LLMs?

인공 지능의 미래에 관해서 여러가지 언급을 하고 있다. 다양한 입력 형태(멀티모달)을 지니게 되고 있으며 앞으로 가속될 것, 그리고 뒤에 길게 LLMs 보안에 관해 논하고 있다. 보안에 관한 내용이 흥미롭기는 하다. LLM을 해킹하는 방법은 기술적인 것 이상을 포괄한다. 마치 해커들이 현실 세계를 해킹할 대 소셜 엔지니어링을 활용한 것과 유사하다. 

::: {layout="[[5,-1,5]]"}
![](./images/karpathy/karpathy-7.jpeg)

![](./images/karpathy/karpathy-8.jpeg)
:::

미래에 관한 논의에서 제일 놀라웠던 것은 시스템1,2에 관한 언급이다. 시스템 1,2는 다니엘 카너만의 책에서 나온 개념이다. 시스템1은 빠르고 직관적인 판단을 내리는 것이고 시스템2는 느리고 논리적인 판단을 내리는 것이다. 카파시는 LLM이 시스템1이라고 말했다.

시스템1이라고? 디지털을 통해 산출된 결과물이 시스템1이라는 언뜻 와닿지 않지만 생각해보면 이 말이 맞다. 앞서 LLMs가 꿈꾸는 것이라고 했는데, 꿈은 시스템1의 영역이다. 시스템2는 논리적인 추론을 하는 영역이다. LLMs가 시스템1이라면, 시스템2는 무엇일까?

::: {layout="[[5,-1,5]]"}
![](./images/karpathy/karpathy-9.jpeg)

![](./images/karpathy/karpathy-10.jpeg)
:::

만일 LLM이 시스템2였다면 맞든 틀리든 인과적인 추론의 과정을 뜯어볼 수 있었을 것이다. 이게 가능했다면 보다 정확한 LLM을 만들어내는 것도 가능하게 되지 않을까 싶다. 앞으로 LLM이 발전한다면 이 방면으로 발전하지 않을까? 

::: {layout="[[5,-1,5]]"}
![](./images/karpathy/karpathy-11.jpeg)

![](./images/karpathy/karpathy-12.jpeg)
:::

이외에 인간 기보에서 배운 초기 알파고 이후에 등장한 스스로 배우는 알파고에 해당하는 LLM 모델에 관한 질문, LLM 중심의 OS 등 흥미로운 슬라이드 샷을 몇 개 덧붙이겠다. 